{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM,Flatten\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from tensorflow import keras\n",
    "import kerastuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,LSTM,Flatten\n",
    "from tensorflow.keras.optimizers import SGD,Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from kerastuner.tuners.randomsearch import RandomSearch\n",
    "from tensorflow.python.keras.metrics import Metric\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "import pickle\n",
    "#import gin.tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firstly we deal with the dataset \"1 years before\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset is comprised of 145 rows and 25 columns. We have 49 bankrupted companies and 96 companies that still operate.\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"1 years before.csv\")\n",
    "df['final'][df['final']=='Bankrupted']=0\n",
    "df['final'][df['final']=='Non-Bankrupted']=1\n",
    "df.head()\n",
    "\n",
    "bankruptcies=df['final'][df['final']==0].count()\n",
    "rows=df.shape[0]\n",
    "columns=df.shape[1]\n",
    "print(f'Our dataset is comprised of {rows} rows and {columns} columns. We have {bankruptcies} bankrupted companies and {rows-bankruptcies} companies that still operate.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(333)\n",
    "\n",
    "X=df.iloc[:,0:-1].values\n",
    "Y=df.iloc[:,-1]\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=43) \n",
    "X_train=preprocessing.normalize(X_train)\n",
    "X_test=preprocessing.normalize(X_test)\n",
    "y_train=y_train.astype(int)\n",
    "y_test=y_test.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Int(\"input_units\",min_value=24,max_value=120,step=12),input_shape=(24,),activation='relu'))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\",1,4)):\n",
    "    \n",
    "        model.add(Dense(hp.Int(f\"dense_{i}_units\",min_value=24,max_value=120,step=12),activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    model.compile(Adam(lr=0.01),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do NOT run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6986 - accuracy: 0.40 - 1s 5ms/sample - loss: 0.6505 - accuracy: 0.5776 - val_loss: 0.6372 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5145 - accuracy: 0.75 - 0s 275us/sample - loss: 0.6448 - accuracy: 0.6638 - val_loss: 0.6099 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6789 - accuracy: 0.53 - 0s 155us/sample - loss: 0.5968 - accuracy: 0.6983 - val_loss: 0.6057 - val_accuracy: 0.6207\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6078 - accuracy: 0.65 - 0s 163us/sample - loss: 0.5795 - accuracy: 0.7069 - val_loss: 0.5914 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.81 - 0s 180us/sample - loss: 0.5675 - accuracy: 0.7155 - val_loss: 0.5769 - val_accuracy: 0.6207\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6080 - accuracy: 0.68 - 0s 1ms/sample - loss: 0.5436 - accuracy: 0.7328 - val_loss: 0.5693 - val_accuracy: 0.6897\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6030 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5320 - accuracy: 0.7414 - val_loss: 0.5672 - val_accuracy: 0.6897\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6528 - accuracy: 0.62 - 0s 172us/sample - loss: 0.5139 - accuracy: 0.7414 - val_loss: 0.5692 - val_accuracy: 0.6897\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5158 - accuracy: 0.71 - 0s 163us/sample - loss: 0.5198 - accuracy: 0.6983 - val_loss: 0.5898 - val_accuracy: 0.6552\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4597 - accuracy: 0.81 - 0s 1ms/sample - loss: 0.5005 - accuracy: 0.7414 - val_loss: 0.5832 - val_accuracy: 0.7241\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4065 - accuracy: 0.75 - 0s 146us/sample - loss: 0.5055 - accuracy: 0.7241 - val_loss: 0.5893 - val_accuracy: 0.6897\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4610 - accuracy: 0.78 - 0s 155us/sample - loss: 0.4793 - accuracy: 0.7586 - val_loss: 0.6246 - val_accuracy: 0.6897\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4553 - accuracy: 0.78 - 0s 180us/sample - loss: 0.4693 - accuracy: 0.7586 - val_loss: 0.6050 - val_accuracy: 0.6897\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2453 - accuracy: 0.93 - 0s 163us/sample - loss: 0.4850 - accuracy: 0.7759 - val_loss: 0.6321 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4482 - accuracy: 0.78 - 0s 155us/sample - loss: 0.4612 - accuracy: 0.7500 - val_loss: 0.6579 - val_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4184 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4280 - accuracy: 0.8017 - val_loss: 0.6389 - val_accuracy: 0.6552\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4940 - accuracy: 0.71 - 0s 163us/sample - loss: 0.4256 - accuracy: 0.8017 - val_loss: 0.6917 - val_accuracy: 0.6552\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4057 - accuracy: 0.81 - 0s 163us/sample - loss: 0.4003 - accuracy: 0.8017 - val_loss: 0.7494 - val_accuracy: 0.6897\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.81 - 0s 172us/sample - loss: 0.3991 - accuracy: 0.8017 - val_loss: 0.7535 - val_accuracy: 0.6897\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4011 - accuracy: 0.84 - 0s 163us/sample - loss: 0.3822 - accuracy: 0.8362 - val_loss: 0.8030 - val_accuracy: 0.6897\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.90 - 0s 163us/sample - loss: 0.3675 - accuracy: 0.8362 - val_loss: 0.8764 - val_accuracy: 0.6552\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3827 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3448 - accuracy: 0.8362 - val_loss: 0.9370 - val_accuracy: 0.6552\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2624 - accuracy: 0.93 - 0s 172us/sample - loss: 0.3408 - accuracy: 0.8621 - val_loss: 0.9774 - val_accuracy: 0.6897\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.93 - 0s 172us/sample - loss: 0.3273 - accuracy: 0.8362 - val_loss: 1.0257 - val_accuracy: 0.7241\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.90 - 0s 163us/sample - loss: 0.3440 - accuracy: 0.8362 - val_loss: 1.0897 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3257 - accuracy: 0.8534 - val_loss: 1.0699 - val_accuracy: 0.6552\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2927 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3227 - accuracy: 0.8707 - val_loss: 1.0994 - val_accuracy: 0.6552\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2357 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2837 - accuracy: 0.8793 - val_loss: 1.2111 - val_accuracy: 0.6897\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2541 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2860 - accuracy: 0.8621 - val_loss: 1.2464 - val_accuracy: 0.6897\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2943 - accuracy: 0.84 - 0s 163us/sample - loss: 0.2731 - accuracy: 0.8879 - val_loss: 1.3285 - val_accuracy: 0.6897\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2358 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2593 - accuracy: 0.8966 - val_loss: 1.3782 - val_accuracy: 0.6897\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1997 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2294 - accuracy: 0.9310 - val_loss: 1.4430 - val_accuracy: 0.6552\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1551 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2321 - accuracy: 0.8793 - val_loss: 1.5637 - val_accuracy: 0.6897\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 1.00 - 0s 155us/sample - loss: 0.2139 - accuracy: 0.9310 - val_loss: 1.7049 - val_accuracy: 0.6552\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2833 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2079 - accuracy: 0.9310 - val_loss: 1.8086 - val_accuracy: 0.6207\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1948 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1832 - accuracy: 0.9397 - val_loss: 1.9314 - val_accuracy: 0.6552\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1685 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1916 - accuracy: 0.9138 - val_loss: 1.9858 - val_accuracy: 0.6897\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1981 - accuracy: 0.93 - 0s 172us/sample - loss: 0.1830 - accuracy: 0.9397 - val_loss: 2.0343 - val_accuracy: 0.6207\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1888 - accuracy: 0.9310 - val_loss: 2.1369 - val_accuracy: 0.6552\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1558 - accuracy: 0.9569 - val_loss: 2.2629 - val_accuracy: 0.6552\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1410 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1473 - accuracy: 0.9569 - val_loss: 2.3550 - val_accuracy: 0.6207\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0965 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1438 - accuracy: 0.9397 - val_loss: 2.4368 - val_accuracy: 0.5862\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1397 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1489 - accuracy: 0.9655 - val_loss: 2.5669 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1837 - accuracy: 0.9138 - val_loss: 2.5764 - val_accuracy: 0.6552\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1280 - accuracy: 0.9655 - val_loss: 2.5468 - val_accuracy: 0.6552\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1672 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1345 - accuracy: 0.9483 - val_loss: 2.6093 - val_accuracy: 0.5862\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1451 - accuracy: 0.9397 - val_loss: 2.6809 - val_accuracy: 0.6552\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0950 - accuracy: 0.9828 - val_loss: 2.7632 - val_accuracy: 0.6207\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1191 - accuracy: 0.9655 - val_loss: 2.8253 - val_accuracy: 0.6207\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1087 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1165 - accuracy: 0.9483 - val_loss: 2.9018 - val_accuracy: 0.6207\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1045 - accuracy: 0.9483 - val_loss: 2.9836 - val_accuracy: 0.6552\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0612 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1002 - accuracy: 0.9655 - val_loss: 3.1196 - val_accuracy: 0.6207\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0673 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1143 - accuracy: 0.9397 - val_loss: 3.0813 - val_accuracy: 0.6207\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1429 - accuracy: 0.9310 - val_loss: 3.1452 - val_accuracy: 0.6552\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1564 - accuracy: 0.9138 - val_loss: 3.0695 - val_accuracy: 0.6552\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1508 - accuracy: 0.9397 - val_loss: 3.1325 - val_accuracy: 0.6552\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1711 - accuracy: 0.9310 - val_loss: 3.3634 - val_accuracy: 0.5517\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1468 - accuracy: 0.9397 - val_loss: 3.2315 - val_accuracy: 0.6897\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0920 - accuracy: 0.9483 - val_loss: 3.2651 - val_accuracy: 0.6897\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0823 - accuracy: 0.9741 - val_loss: 3.2424 - val_accuracy: 0.6552\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0546 - accuracy: 0.9914 - val_loss: 3.2514 - val_accuracy: 0.6207\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0730 - accuracy: 0.9741 - val_loss: 3.3491 - val_accuracy: 0.6207\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0819 - accuracy: 0.9741 - val_loss: 3.5070 - val_accuracy: 0.6207\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0968 - accuracy: 0.9655 - val_loss: 3.6860 - val_accuracy: 0.6207\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0735 - accuracy: 0.9914 - val_loss: 3.6208 - val_accuracy: 0.5517\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0646 - accuracy: 0.9741 - val_loss: 3.6238 - val_accuracy: 0.6552\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0597 - accuracy: 0.9914 - val_loss: 3.7379 - val_accuracy: 0.5862\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0544 - accuracy: 0.9828 - val_loss: 3.9044 - val_accuracy: 0.6207\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0414 - accuracy: 0.9914 - val_loss: 3.8954 - val_accuracy: 0.6552\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0441 - accuracy: 0.9914 - val_loss: 3.8573 - val_accuracy: 0.6207\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0348 - accuracy: 1.0000 - val_loss: 3.9125 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0338 - accuracy: 1.0000 - val_loss: 3.9653 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0294 - accuracy: 1.0000 - val_loss: 3.9949 - val_accuracy: 0.6207\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0262 - accuracy: 1.0000 - val_loss: 4.0626 - val_accuracy: 0.6207\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0250 - accuracy: 1.0000 - val_loss: 4.1519 - val_accuracy: 0.6207\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0249 - accuracy: 1.0000 - val_loss: 4.2519 - val_accuracy: 0.6207\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0234 - accuracy: 1.0000 - val_loss: 4.3991 - val_accuracy: 0.6207\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0279 - accuracy: 1.0000 - val_loss: 4.3451 - val_accuracy: 0.6207\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0257 - accuracy: 1.0000 - val_loss: 4.4006 - val_accuracy: 0.6207\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0194 - accuracy: 1.0000 - val_loss: 4.4432 - val_accuracy: 0.5862\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0214 - accuracy: 1.0000 - val_loss: 4.5114 - val_accuracy: 0.5862\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0168 - accuracy: 1.0000 - val_loss: 4.5323 - val_accuracy: 0.6207\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0271 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0198 - accuracy: 1.0000 - val_loss: 4.6324 - val_accuracy: 0.6207\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0175 - accuracy: 1.0000 - val_loss: 4.6887 - val_accuracy: 0.6207\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0175 - accuracy: 1.0000 - val_loss: 4.6893 - val_accuracy: 0.6207\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 4.8057 - val_accuracy: 0.6207\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0143 - accuracy: 1.0000 - val_loss: 4.8498 - val_accuracy: 0.5862\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0130 - accuracy: 1.0000 - val_loss: 4.8788 - val_accuracy: 0.6207\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 4.9383 - val_accuracy: 0.6207\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 4.9733 - val_accuracy: 0.6207\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0121 - accuracy: 1.0000 - val_loss: 5.0261 - val_accuracy: 0.6207\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 5.0514 - val_accuracy: 0.6207\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 5.0389 - val_accuracy: 0.6207\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 5.1242 - val_accuracy: 0.5862\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 5.2002 - val_accuracy: 0.6207\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 5.1466 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 5.2789 - val_accuracy: 0.6207\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 5.3369 - val_accuracy: 0.6207\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 5.3242 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 5.3527 - val_accuracy: 0.6207\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 5.3847 - val_accuracy: 0.6207\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 5.3776 - val_accuracy: 0.5862\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 5.4247 - val_accuracy: 0.6207\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 5.4652 - val_accuracy: 0.6207\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 5.4707 - val_accuracy: 0.5862\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 5.5243 - val_accuracy: 0.6207\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.00 - 0s 198us/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 5.5120 - val_accuracy: 0.6207\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 198us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 5.4729 - val_accuracy: 0.5862\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 5.5676 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.00 - 0s 189us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 5.6023 - val_accuracy: 0.6207\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 5.6049 - val_accuracy: 0.5862\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 5.5907 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 5.6414 - val_accuracy: 0.6207\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 5.6661 - val_accuracy: 0.5862\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 5.7029 - val_accuracy: 0.5862\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 5.7121 - val_accuracy: 0.6207\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 5.7068 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 5.7299 - val_accuracy: 0.5862\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 5.7905 - val_accuracy: 0.6207\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 5.8226 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 5.8494 - val_accuracy: 0.6207\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.8200 - val_accuracy: 0.5862\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 5.8463 - val_accuracy: 0.6207\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.9111 - val_accuracy: 0.6207\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 5.9589 - val_accuracy: 0.6207\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 5.9264 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 5.9507 - val_accuracy: 0.6207\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 5.9797 - val_accuracy: 0.6207\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 6.0066 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 5.9995 - val_accuracy: 0.5862\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 6.0077 - val_accuracy: 0.5862\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 6.0545 - val_accuracy: 0.6207\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 6.0785 - val_accuracy: 0.6207\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 6.0868 - val_accuracy: 0.5862\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 6.1360 - val_accuracy: 0.5862\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 6.1678 - val_accuracy: 0.6207\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 6.1666 - val_accuracy: 0.6207\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 6.1649 - val_accuracy: 0.6207\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 6.1867 - val_accuracy: 0.6207\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.1956 - val_accuracy: 0.6207\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.1998 - val_accuracy: 0.5862\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.2286 - val_accuracy: 0.5862\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 6.2530 - val_accuracy: 0.6207\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.2740 - val_accuracy: 0.5862\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 6.2587 - val_accuracy: 0.5862\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 6.2996 - val_accuracy: 0.6207\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 6.3174 - val_accuracy: 0.6207\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.3167 - val_accuracy: 0.5862\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 6.3452 - val_accuracy: 0.5862\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.3697 - val_accuracy: 0.6207\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.3675 - val_accuracy: 0.6207\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 6.3390 - val_accuracy: 0.5862\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 6.3708 - val_accuracy: 0.5862\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 6.4032 - val_accuracy: 0.6207\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7985e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 6.4096 - val_accuracy: 0.6207\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7018e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 6.4048 - val_accuracy: 0.5862\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 6.4207 - val_accuracy: 0.6207\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.4359 - val_accuracy: 0.6207\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.4586 - val_accuracy: 0.6207\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 6.4827 - val_accuracy: 0.6207\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.4826 - val_accuracy: 0.5862\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.4957 - val_accuracy: 0.6207\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.5010 - val_accuracy: 0.6207\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.5030 - val_accuracy: 0.5862\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.5108 - val_accuracy: 0.5862\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7927e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.5318 - val_accuracy: 0.5862\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.5435 - val_accuracy: 0.6207\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.5542 - val_accuracy: 0.6207\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.5568 - val_accuracy: 0.5862\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.5727 - val_accuracy: 0.5862\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.6176 - val_accuracy: 0.6207\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3942e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.6358 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6785e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.5956 - val_accuracy: 0.5862\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.6056 - val_accuracy: 0.5862\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.6436 - val_accuracy: 0.6207\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.6652 - val_accuracy: 0.6207\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.6673 - val_accuracy: 0.5862\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.6680 - val_accuracy: 0.5862\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.6706 - val_accuracy: 0.5862\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7489e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.6828 - val_accuracy: 0.6207\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.7074 - val_accuracy: 0.6207\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.6204e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.7091 - val_accuracy: 0.5862\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.6950 - val_accuracy: 0.5862\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.7042 - val_accuracy: 0.5862\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1584e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.7320 - val_accuracy: 0.6207\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.7560 - val_accuracy: 0.6207\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.7615 - val_accuracy: 0.5862\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.7846 - val_accuracy: 0.6207\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8522e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.7937 - val_accuracy: 0.6207\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.7918 - val_accuracy: 0.5862\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.8141 - val_accuracy: 0.6207\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.8236 - val_accuracy: 0.5862\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.8238 - val_accuracy: 0.5862\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.1164e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.8465 - val_accuracy: 0.6207\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3071e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.8482 - val_accuracy: 0.6207\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2377e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.8645e-04 - accuracy: 1.0000 - val_loss: 6.8457 - val_accuracy: 0.5862\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.6254e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 9.7018e-04 - accuracy: 1.0000 - val_loss: 6.8529 - val_accuracy: 0.5862\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 9.3693e-04 - accuracy: 1.0000 - val_loss: 6.8729 - val_accuracy: 0.6207\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 146us/sample - loss: 9.7024e-04 - accuracy: 1.0000 - val_loss: 6.8857 - val_accuracy: 0.6207\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 129us/sample - loss: 9.1710e-04 - accuracy: 1.0000 - val_loss: 6.8782 - val_accuracy: 0.5862\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6973 - accuracy: 0.37 - 0s 3ms/sample - loss: 0.6577 - accuracy: 0.5776 - val_loss: 0.6316 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6066 - accuracy: 0.68 - 0s 172us/sample - loss: 0.6143 - accuracy: 0.6552 - val_loss: 0.6075 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5877 - accuracy: 0.71 - 0s 163us/sample - loss: 0.5906 - accuracy: 0.6810 - val_loss: 0.5939 - val_accuracy: 0.6897\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6668 - accuracy: 0.65 - 0s 181us/sample - loss: 0.5770 - accuracy: 0.6897 - val_loss: 0.5832 - val_accuracy: 0.6207\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.78 - 0s 164us/sample - loss: 0.5762 - accuracy: 0.6983 - val_loss: 0.5838 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4621 - accuracy: 0.81 - 0s 155us/sample - loss: 0.5435 - accuracy: 0.7328 - val_loss: 0.5869 - val_accuracy: 0.6897\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5728 - accuracy: 0.65 - 0s 181us/sample - loss: 0.5549 - accuracy: 0.7328 - val_loss: 0.5763 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.71 - 0s 172us/sample - loss: 0.5259 - accuracy: 0.7586 - val_loss: 0.6073 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6156 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5345 - accuracy: 0.7500 - val_loss: 0.5893 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4912 - accuracy: 0.81 - 0s 164us/sample - loss: 0.5185 - accuracy: 0.7500 - val_loss: 0.5953 - val_accuracy: 0.6552\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5252 - accuracy: 0.68 - 0s 138us/sample - loss: 0.5051 - accuracy: 0.7414 - val_loss: 0.6160 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4109 - accuracy: 0.78 - 0s 164us/sample - loss: 0.5039 - accuracy: 0.7414 - val_loss: 0.6169 - val_accuracy: 0.6207\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4230 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4881 - accuracy: 0.7586 - val_loss: 0.6300 - val_accuracy: 0.6897\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5113 - accuracy: 0.78 - 0s 172us/sample - loss: 0.4567 - accuracy: 0.7759 - val_loss: 0.6342 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4465 - accuracy: 0.75 - 0s 155us/sample - loss: 0.4518 - accuracy: 0.7500 - val_loss: 0.6599 - val_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5530 - accuracy: 0.65 - 0s 138us/sample - loss: 0.4385 - accuracy: 0.7759 - val_loss: 0.6585 - val_accuracy: 0.6897\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3632 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4173 - accuracy: 0.7672 - val_loss: 0.6675 - val_accuracy: 0.6897\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2963 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4090 - accuracy: 0.7759 - val_loss: 0.6873 - val_accuracy: 0.6897\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4056 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3900 - accuracy: 0.8190 - val_loss: 0.7123 - val_accuracy: 0.6897\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3630 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3998 - accuracy: 0.8190 - val_loss: 0.7468 - val_accuracy: 0.6897\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3514 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4288 - accuracy: 0.7931 - val_loss: 0.7324 - val_accuracy: 0.6897\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.71 - 0s 129us/sample - loss: 0.3776 - accuracy: 0.8190 - val_loss: 0.7502 - val_accuracy: 0.6897\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3542 - accuracy: 0.8534 - val_loss: 0.7715 - val_accuracy: 0.7241\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.71 - 0s 138us/sample - loss: 0.3572 - accuracy: 0.8362 - val_loss: 0.8367 - val_accuracy: 0.6552\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.78 - 0s 129us/sample - loss: 0.3269 - accuracy: 0.8276 - val_loss: 0.8575 - val_accuracy: 0.6897\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3182 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3167 - accuracy: 0.8534 - val_loss: 0.9131 - val_accuracy: 0.6552\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4310 - accuracy: 0.75 - 0s 129us/sample - loss: 0.3228 - accuracy: 0.8534 - val_loss: 0.9423 - val_accuracy: 0.6897\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2432 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3175 - accuracy: 0.8448 - val_loss: 1.0459 - val_accuracy: 0.6207\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2215 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2872 - accuracy: 0.8707 - val_loss: 1.0786 - val_accuracy: 0.6897\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2728 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2776 - accuracy: 0.8793 - val_loss: 1.1441 - val_accuracy: 0.6897\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.93 - 0s 137us/sample - loss: 0.2585 - accuracy: 0.8793 - val_loss: 1.2547 - val_accuracy: 0.6897\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2963 - accuracy: 0.8534 - val_loss: 1.3709 - val_accuracy: 0.6207\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2530 - accuracy: 0.8879 - val_loss: 1.3581 - val_accuracy: 0.6897\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2634 - accuracy: 0.8621 - val_loss: 1.4920 - val_accuracy: 0.6552\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2429 - accuracy: 0.9052 - val_loss: 1.5159 - val_accuracy: 0.6897\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2051 - accuracy: 0.9138 - val_loss: 1.4893 - val_accuracy: 0.6897\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1201 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2003 - accuracy: 0.9138 - val_loss: 1.6409 - val_accuracy: 0.6552\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1467 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1979 - accuracy: 0.9397 - val_loss: 1.7392 - val_accuracy: 0.6897\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1866 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1800 - accuracy: 0.9310 - val_loss: 1.8686 - val_accuracy: 0.6897\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1663 - accuracy: 0.9310 - val_loss: 1.9803 - val_accuracy: 0.6552\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1476 - accuracy: 0.9569 - val_loss: 1.9993 - val_accuracy: 0.6897\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1435 - accuracy: 0.9569 - val_loss: 2.0674 - val_accuracy: 0.6897\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1118 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1435 - accuracy: 0.9569 - val_loss: 2.1756 - val_accuracy: 0.6552\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0922 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1490 - accuracy: 0.9224 - val_loss: 2.2933 - val_accuracy: 0.5517\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1986 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1717 - accuracy: 0.9138 - val_loss: 2.2995 - val_accuracy: 0.6552\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1676 - accuracy: 0.9224 - val_loss: 2.4002 - val_accuracy: 0.6207\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0781 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1120 - accuracy: 0.9828 - val_loss: 2.5442 - val_accuracy: 0.6897\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1062 - accuracy: 0.9741 - val_loss: 2.6000 - val_accuracy: 0.6552\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1019 - accuracy: 0.9655 - val_loss: 2.6445 - val_accuracy: 0.6207\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0955 - accuracy: 0.9914 - val_loss: 2.8435 - val_accuracy: 0.6552\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1160 - accuracy: 0.9569 - val_loss: 2.8439 - val_accuracy: 0.5517\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0986 - accuracy: 0.9655 - val_loss: 2.9405 - val_accuracy: 0.6552\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0709 - accuracy: 0.9741 - val_loss: 2.9478 - val_accuracy: 0.5862\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1152 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0929 - accuracy: 0.9741 - val_loss: 3.1007 - val_accuracy: 0.6207\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0375 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0674 - accuracy: 0.9655 - val_loss: 3.1272 - val_accuracy: 0.5517\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0926 - accuracy: 0.9741 - val_loss: 3.3540 - val_accuracy: 0.6552\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0757 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0630 - accuracy: 0.9914 - val_loss: 3.3451 - val_accuracy: 0.5862\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 1.00 - 0s 181us/sample - loss: 0.0598 - accuracy: 0.9914 - val_loss: 3.5739 - val_accuracy: 0.6552\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0906 - accuracy: 0.9741 - val_loss: 3.4982 - val_accuracy: 0.5172\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1531 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0972 - accuracy: 0.9569 - val_loss: 3.6780 - val_accuracy: 0.6552\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1035 - accuracy: 0.9655 - val_loss: 3.7752 - val_accuracy: 0.5517\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0758 - accuracy: 0.9741 - val_loss: 3.9789 - val_accuracy: 0.6552\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0857 - accuracy: 0.9655 - val_loss: 3.7663 - val_accuracy: 0.6552\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0900 - accuracy: 0.9741 - val_loss: 3.6087 - val_accuracy: 0.6207\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0442 - accuracy: 1.0000 - val_loss: 3.5778 - val_accuracy: 0.6207\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0446 - accuracy: 0.9914 - val_loss: 3.8184 - val_accuracy: 0.5862\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0335 - accuracy: 0.9914 - val_loss: 4.0329 - val_accuracy: 0.5862\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0312 - accuracy: 1.0000 - val_loss: 4.0519 - val_accuracy: 0.5862\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0227 - accuracy: 1.0000 - val_loss: 4.0942 - val_accuracy: 0.6207\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0228 - accuracy: 1.0000 - val_loss: 4.1072 - val_accuracy: 0.6207\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0197 - accuracy: 1.0000 - val_loss: 4.1602 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0197 - accuracy: 1.0000 - val_loss: 4.1997 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0189 - accuracy: 1.0000 - val_loss: 4.2890 - val_accuracy: 0.6207\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0174 - accuracy: 1.0000 - val_loss: 4.3758 - val_accuracy: 0.6207\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0146 - accuracy: 1.0000 - val_loss: 4.4386 - val_accuracy: 0.6207\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0153 - accuracy: 1.0000 - val_loss: 4.4921 - val_accuracy: 0.5862\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0144 - accuracy: 1.0000 - val_loss: 4.5359 - val_accuracy: 0.5862\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0145 - accuracy: 1.0000 - val_loss: 4.5298 - val_accuracy: 0.5862\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0125 - accuracy: 1.0000 - val_loss: 4.6252 - val_accuracy: 0.6207\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0147 - accuracy: 1.0000 - val_loss: 4.6173 - val_accuracy: 0.6207\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0158 - accuracy: 1.0000 - val_loss: 4.6588 - val_accuracy: 0.6207\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 4.7477 - val_accuracy: 0.6207\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 4.7316 - val_accuracy: 0.5862\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0146 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 4.7700 - val_accuracy: 0.6207\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 4.8430 - val_accuracy: 0.6207\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 4.8499 - val_accuracy: 0.6207\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 4.8675 - val_accuracy: 0.6207\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 4.8851 - val_accuracy: 0.6207\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0106 - accuracy: 1.0000 - val_loss: 5.0559 - val_accuracy: 0.6207\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0214 - accuracy: 0.9828 - val_loss: 4.9110 - val_accuracy: 0.5862\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0428 - accuracy: 0.9828 - val_loss: 5.0524 - val_accuracy: 0.6207\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0190 - accuracy: 1.0000 - val_loss: 5.0036 - val_accuracy: 0.6207\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0141 - accuracy: 1.0000 - val_loss: 4.8895 - val_accuracy: 0.6207\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 4.9224 - val_accuracy: 0.6207\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0143 - accuracy: 1.0000 - val_loss: 4.9525 - val_accuracy: 0.6207\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 5.0506 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0107 - accuracy: 1.0000 - val_loss: 5.2148 - val_accuracy: 0.6207\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 5.1257 - val_accuracy: 0.5862\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 5.1289 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 5.3118 - val_accuracy: 0.6207\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 5.2368 - val_accuracy: 0.5862\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 5.1707 - val_accuracy: 0.5862\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 5.3071 - val_accuracy: 0.6207\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 5.2619 - val_accuracy: 0.5862\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 5.2054 - val_accuracy: 0.5862\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 5.3502 - val_accuracy: 0.5862\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 5.4381 - val_accuracy: 0.6207\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 5.3169 - val_accuracy: 0.5862\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 5.3656 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 5.4765 - val_accuracy: 0.6207\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 5.4837 - val_accuracy: 0.6207\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.4962 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 5.5356 - val_accuracy: 0.5862\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.5968 - val_accuracy: 0.6207\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 5.5771 - val_accuracy: 0.6207\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 5.5770 - val_accuracy: 0.6207\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 5.6086 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 5.6732 - val_accuracy: 0.6207\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.7035 - val_accuracy: 0.6207\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 5.7029 - val_accuracy: 0.6207\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 5.7240 - val_accuracy: 0.6207\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 5.7361 - val_accuracy: 0.5862\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.7429 - val_accuracy: 0.5862\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.7796 - val_accuracy: 0.5862\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.7973 - val_accuracy: 0.5862\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.8148 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.8467 - val_accuracy: 0.5862\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.8716 - val_accuracy: 0.6207\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.8872 - val_accuracy: 0.5862\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.8927 - val_accuracy: 0.5862\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.9048 - val_accuracy: 0.5862\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.9483 - val_accuracy: 0.6207\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 5.9513 - val_accuracy: 0.6207\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.9351 - val_accuracy: 0.5862\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 5.9549 - val_accuracy: 0.6207\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.9890 - val_accuracy: 0.6207\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.0013 - val_accuracy: 0.6207\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 5.9933 - val_accuracy: 0.5862\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.0066 - val_accuracy: 0.5862\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.0354 - val_accuracy: 0.6207\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.0425 - val_accuracy: 0.6207\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0686e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.0408 - val_accuracy: 0.6207\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.0527 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.0693 - val_accuracy: 0.6207\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.0929 - val_accuracy: 0.6207\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7143e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.1007 - val_accuracy: 0.6207\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.1177 - val_accuracy: 0.6207\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.1357 - val_accuracy: 0.6207\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.6431e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.1408 - val_accuracy: 0.6207\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.1539 - val_accuracy: 0.6207\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.1533 - val_accuracy: 0.6207\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.1746 - val_accuracy: 0.6207\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3120e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.1817 - val_accuracy: 0.6207\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.1911 - val_accuracy: 0.6207\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.1975 - val_accuracy: 0.6207\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.2241 - val_accuracy: 0.6207\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8976e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.2466 - val_accuracy: 0.6207\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7479e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.2443 - val_accuracy: 0.6207\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.2359 - val_accuracy: 0.6207\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.2381 - val_accuracy: 0.6207\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.2535 - val_accuracy: 0.6207\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.2780 - val_accuracy: 0.6207\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.2848 - val_accuracy: 0.6207\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.2943 - val_accuracy: 0.6207\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5438e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.3005 - val_accuracy: 0.5862\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.9215e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.3247 - val_accuracy: 0.6207\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0994e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.3553 - val_accuracy: 0.6207\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4314e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.3345 - val_accuracy: 0.6207\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.3278 - val_accuracy: 0.5862\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9862e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.3419 - val_accuracy: 0.6207\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 120us/sample - loss: 9.9296e-04 - accuracy: 1.0000 - val_loss: 6.3659 - val_accuracy: 0.6207\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 129us/sample - loss: 9.9125e-04 - accuracy: 1.0000 - val_loss: 6.3794 - val_accuracy: 0.6207\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 129us/sample - loss: 9.7193e-04 - accuracy: 1.0000 - val_loss: 6.3901 - val_accuracy: 0.6207\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 129us/sample - loss: 9.6756e-04 - accuracy: 1.0000 - val_loss: 6.4013 - val_accuracy: 0.5862\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6391e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 9.4136e-04 - accuracy: 1.0000 - val_loss: 6.4063 - val_accuracy: 0.6207\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9353e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 9.2108e-04 - accuracy: 1.0000 - val_loss: 6.4201 - val_accuracy: 0.6207\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.2575e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.3963e-04 - accuracy: 1.0000 - val_loss: 6.4227 - val_accuracy: 0.6207\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6802e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.9788e-04 - accuracy: 1.0000 - val_loss: 6.4305 - val_accuracy: 0.6207\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6496e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 8.9440e-04 - accuracy: 1.0000 - val_loss: 6.4449 - val_accuracy: 0.6207\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6135e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 8.8971e-04 - accuracy: 1.0000 - val_loss: 6.4531 - val_accuracy: 0.6207\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 155us/sample - loss: 8.9078e-04 - accuracy: 1.0000 - val_loss: 6.4601 - val_accuracy: 0.6207\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4209e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 8.5887e-04 - accuracy: 1.0000 - val_loss: 6.4761 - val_accuracy: 0.6207\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5908e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.4997e-04 - accuracy: 1.0000 - val_loss: 6.4855 - val_accuracy: 0.6207\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6536e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.3923e-04 - accuracy: 1.0000 - val_loss: 6.4869 - val_accuracy: 0.6207\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9958e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.2329e-04 - accuracy: 1.0000 - val_loss: 6.4855 - val_accuracy: 0.6207\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5859e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.2122e-04 - accuracy: 1.0000 - val_loss: 6.4933 - val_accuracy: 0.6207\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3264e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.3047e-04 - accuracy: 1.0000 - val_loss: 6.5199 - val_accuracy: 0.6207\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 129us/sample - loss: 8.0646e-04 - accuracy: 1.0000 - val_loss: 6.5294 - val_accuracy: 0.6207\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7810e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.8912e-04 - accuracy: 1.0000 - val_loss: 6.5375 - val_accuracy: 0.6207\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7264e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.8311e-04 - accuracy: 1.0000 - val_loss: 6.5388 - val_accuracy: 0.6207\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2698e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 7.7645e-04 - accuracy: 1.0000 - val_loss: 6.5482 - val_accuracy: 0.6207\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8334e-04 - accuracy: 1.00 - 0s 112us/sample - loss: 7.8161e-04 - accuracy: 1.0000 - val_loss: 6.5542 - val_accuracy: 0.6207\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5451e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.5636e-04 - accuracy: 1.0000 - val_loss: 6.5816 - val_accuracy: 0.6207\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4521e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.8200e-04 - accuracy: 1.0000 - val_loss: 6.5944 - val_accuracy: 0.6207\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.6965e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.7062e-04 - accuracy: 1.0000 - val_loss: 6.5772 - val_accuracy: 0.6207\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1577e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.8943e-04 - accuracy: 1.0000 - val_loss: 6.5722 - val_accuracy: 0.6207\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.1559e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.5358e-04 - accuracy: 1.0000 - val_loss: 6.6106 - val_accuracy: 0.6207\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6313e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.1717e-04 - accuracy: 1.0000 - val_loss: 6.6250 - val_accuracy: 0.6207\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7153e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.2901e-04 - accuracy: 1.0000 - val_loss: 6.6339 - val_accuracy: 0.6207\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3710e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.0607e-04 - accuracy: 1.0000 - val_loss: 6.6287 - val_accuracy: 0.6207\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6856 - accuracy: 0.68 - 0s 3ms/sample - loss: 0.6479 - accuracy: 0.6724 - val_loss: 0.6292 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5850 - accuracy: 0.68 - 0s 155us/sample - loss: 0.6196 - accuracy: 0.6638 - val_loss: 0.6114 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6416 - accuracy: 0.59 - 0s 146us/sample - loss: 0.6050 - accuracy: 0.6810 - val_loss: 0.6030 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5947 - accuracy: 0.6810 - val_loss: 0.6066 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5591 - accuracy: 0.68 - 0s 172us/sample - loss: 0.5803 - accuracy: 0.6897 - val_loss: 0.5891 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5928 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5687 - accuracy: 0.7155 - val_loss: 0.5911 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5557 - accuracy: 0.75 - 0s 146us/sample - loss: 0.5572 - accuracy: 0.7414 - val_loss: 0.5859 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4686 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5666 - accuracy: 0.7414 - val_loss: 0.5922 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5426 - accuracy: 0.7414 - val_loss: 0.5953 - val_accuracy: 0.6552\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5845 - accuracy: 0.56 - 0s 163us/sample - loss: 0.5363 - accuracy: 0.7069 - val_loss: 0.5820 - val_accuracy: 0.6552\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4675 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5150 - accuracy: 0.7759 - val_loss: 0.5885 - val_accuracy: 0.6897\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5097 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4998 - accuracy: 0.7500 - val_loss: 0.5919 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4995 - accuracy: 0.68 - 0s 155us/sample - loss: 0.5023 - accuracy: 0.7414 - val_loss: 0.6001 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4697 - accuracy: 0.75 - 0s 155us/sample - loss: 0.4905 - accuracy: 0.7586 - val_loss: 0.6211 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4278 - accuracy: 0.78 - 0s 155us/sample - loss: 0.4710 - accuracy: 0.7500 - val_loss: 0.6341 - val_accuracy: 0.6207\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4361 - accuracy: 0.78 - 0s 155us/sample - loss: 0.4531 - accuracy: 0.7672 - val_loss: 0.6274 - val_accuracy: 0.6552\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4446 - accuracy: 0.7672 - val_loss: 0.6436 - val_accuracy: 0.6552\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4009 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4217 - accuracy: 0.7672 - val_loss: 0.6504 - val_accuracy: 0.6552\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3651 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4150 - accuracy: 0.7845 - val_loss: 0.6796 - val_accuracy: 0.6207\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4024 - accuracy: 0.8017 - val_loss: 0.7196 - val_accuracy: 0.6207\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3969 - accuracy: 0.8017 - val_loss: 0.7256 - val_accuracy: 0.6207\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.68 - 0s 146us/sample - loss: 0.4166 - accuracy: 0.7672 - val_loss: 0.7173 - val_accuracy: 0.6897\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2590 - accuracy: 0.90 - 0s 138us/sample - loss: 0.4091 - accuracy: 0.8190 - val_loss: 0.7372 - val_accuracy: 0.6897\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4342 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4357 - accuracy: 0.7672 - val_loss: 0.7952 - val_accuracy: 0.6552\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4241 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3586 - accuracy: 0.8276 - val_loss: 0.7880 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2981 - accuracy: 0.87 - 0s 138us/sample - loss: 0.4097 - accuracy: 0.8190 - val_loss: 0.7442 - val_accuracy: 0.6897\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3644 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3625 - accuracy: 0.8448 - val_loss: 0.8007 - val_accuracy: 0.6897\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.3105 - accuracy: 0.93 - 0s 155us/sample - loss: 0.3386 - accuracy: 0.8707 - val_loss: 0.8187 - val_accuracy: 0.6897\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3754 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3342 - accuracy: 0.8362 - val_loss: 0.8451 - val_accuracy: 0.6207\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.81 - 0s 120us/sample - loss: 0.2964 - accuracy: 0.8793 - val_loss: 0.9071 - val_accuracy: 0.6552\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3069 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3047 - accuracy: 0.8793 - val_loss: 0.9092 - val_accuracy: 0.6897\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3018 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2770 - accuracy: 0.8879 - val_loss: 0.9551 - val_accuracy: 0.6552\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2673 - accuracy: 0.93 - 0s 120us/sample - loss: 0.2613 - accuracy: 0.9138 - val_loss: 1.0018 - val_accuracy: 0.6552\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2804 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2458 - accuracy: 0.9052 - val_loss: 1.0491 - val_accuracy: 0.6552\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2463 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2345 - accuracy: 0.9052 - val_loss: 1.1140 - val_accuracy: 0.6552\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1909 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2351 - accuracy: 0.9224 - val_loss: 1.1412 - val_accuracy: 0.6897\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1415 - accuracy: 0.96 - 0s 172us/sample - loss: 0.2505 - accuracy: 0.8879 - val_loss: 1.2080 - val_accuracy: 0.6207\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1665 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2545 - accuracy: 0.8621 - val_loss: 1.1489 - val_accuracy: 0.6207\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.96 - 0s 137us/sample - loss: 0.2288 - accuracy: 0.9138 - val_loss: 1.1331 - val_accuracy: 0.6207\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2159 - accuracy: 0.9052 - val_loss: 1.1879 - val_accuracy: 0.6207\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1287 - accuracy: 1.00 - 0s 120us/sample - loss: 0.1934 - accuracy: 0.9397 - val_loss: 1.3085 - val_accuracy: 0.6207\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1575 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2016 - accuracy: 0.9310 - val_loss: 1.3690 - val_accuracy: 0.5862\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1667 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1997 - accuracy: 0.9052 - val_loss: 1.4420 - val_accuracy: 0.5862\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1951 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1815 - accuracy: 0.9483 - val_loss: 1.4294 - val_accuracy: 0.5862\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.93 - 0s 172us/sample - loss: 0.1649 - accuracy: 0.9655 - val_loss: 1.5971 - val_accuracy: 0.5862\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1718 - accuracy: 0.9310 - val_loss: 1.6570 - val_accuracy: 0.6207\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1553 - accuracy: 0.9397 - val_loss: 1.6116 - val_accuracy: 0.5862\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0997 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1365 - accuracy: 0.9655 - val_loss: 1.7737 - val_accuracy: 0.5862\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.96 - 0s 137us/sample - loss: 0.1548 - accuracy: 0.9310 - val_loss: 1.8209 - val_accuracy: 0.5862\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0849 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1947 - accuracy: 0.9310 - val_loss: 1.7569 - val_accuracy: 0.5862\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1681 - accuracy: 0.9224 - val_loss: 1.9121 - val_accuracy: 0.6207\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1227 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1319 - accuracy: 0.9569 - val_loss: 1.9393 - val_accuracy: 0.6207\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1662 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1147 - accuracy: 0.9655 - val_loss: 2.0109 - val_accuracy: 0.5862\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1006 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1116 - accuracy: 0.9569 - val_loss: 2.1923 - val_accuracy: 0.6207\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0951 - accuracy: 0.9741 - val_loss: 2.1632 - val_accuracy: 0.6207\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1253 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1056 - accuracy: 0.9741 - val_loss: 2.2629 - val_accuracy: 0.6207\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1269 - accuracy: 0.93 - 0s 120us/sample - loss: 0.0897 - accuracy: 0.9741 - val_loss: 2.4871 - val_accuracy: 0.6207\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1586 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0896 - accuracy: 0.9741 - val_loss: 2.5085 - val_accuracy: 0.6207\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0811 - accuracy: 0.9741 - val_loss: 2.5810 - val_accuracy: 0.6207\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0949 - accuracy: 0.9569 - val_loss: 2.7213 - val_accuracy: 0.6207\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0911 - accuracy: 0.9655 - val_loss: 2.6266 - val_accuracy: 0.6207\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0817 - accuracy: 0.9741 - val_loss: 2.7168 - val_accuracy: 0.6207\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0691 - accuracy: 0.9655 - val_loss: 2.7961 - val_accuracy: 0.6207\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0682 - accuracy: 0.9741 - val_loss: 2.7290 - val_accuracy: 0.6207\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0546 - accuracy: 1.0000 - val_loss: 2.9168 - val_accuracy: 0.6207\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0633 - accuracy: 0.9655 - val_loss: 2.9570 - val_accuracy: 0.6207\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0571 - accuracy: 1.0000 - val_loss: 2.9362 - val_accuracy: 0.6207\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0662 - accuracy: 0.9741 - val_loss: 3.1828 - val_accuracy: 0.6207\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0759 - accuracy: 0.9655 - val_loss: 3.1102 - val_accuracy: 0.6207\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0509 - accuracy: 0.9828 - val_loss: 3.1520 - val_accuracy: 0.6207\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0603 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0504 - accuracy: 0.9914 - val_loss: 3.2745 - val_accuracy: 0.5862\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0449 - accuracy: 0.9828 - val_loss: 3.4543 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0377 - accuracy: 0.9914 - val_loss: 3.2990 - val_accuracy: 0.6207\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0418 - accuracy: 0.9914 - val_loss: 3.5953 - val_accuracy: 0.6207\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0336 - accuracy: 0.9914 - val_loss: 3.4879 - val_accuracy: 0.6207\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0319 - accuracy: 1.0000 - val_loss: 3.6750 - val_accuracy: 0.6207\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0357 - accuracy: 0.9914 - val_loss: 3.6146 - val_accuracy: 0.6207\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0286 - accuracy: 1.0000 - val_loss: 3.6939 - val_accuracy: 0.5862\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0246 - accuracy: 1.0000 - val_loss: 3.7411 - val_accuracy: 0.6207\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0245 - accuracy: 1.0000 - val_loss: 3.7503 - val_accuracy: 0.6207\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0273 - accuracy: 1.0000 - val_loss: 3.9060 - val_accuracy: 0.6207\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0380 - accuracy: 0.9914 - val_loss: 3.7765 - val_accuracy: 0.6207\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0300 - accuracy: 1.0000 - val_loss: 3.8346 - val_accuracy: 0.6207\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0320 - accuracy: 0.9914 - val_loss: 4.0500 - val_accuracy: 0.6207\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0196 - accuracy: 1.0000 - val_loss: 3.8997 - val_accuracy: 0.5517\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0339 - accuracy: 1.0000 - val_loss: 4.1779 - val_accuracy: 0.6207\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0208 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0178 - accuracy: 1.0000 - val_loss: 4.2444 - val_accuracy: 0.5517\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0170 - accuracy: 1.0000 - val_loss: 4.2967 - val_accuracy: 0.6207\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0167 - accuracy: 1.0000 - val_loss: 4.3643 - val_accuracy: 0.6207\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 4.3729 - val_accuracy: 0.5862\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0178 - accuracy: 1.0000 - val_loss: 4.5286 - val_accuracy: 0.6207\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0171 - accuracy: 1.0000 - val_loss: 4.4754 - val_accuracy: 0.5862\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 4.6746 - val_accuracy: 0.5862\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0172 - accuracy: 1.0000 - val_loss: 4.5970 - val_accuracy: 0.6207\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 4.5944 - val_accuracy: 0.6207\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 4.7326 - val_accuracy: 0.6207\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0133 - accuracy: 1.0000 - val_loss: 4.7719 - val_accuracy: 0.5862\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0272 - accuracy: 0.9914 - val_loss: 4.8860 - val_accuracy: 0.6207\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0518 - accuracy: 0.9741 - val_loss: 4.7577 - val_accuracy: 0.5517\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1648 - accuracy: 0.9483 - val_loss: 4.7537 - val_accuracy: 0.6207\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1487 - accuracy: 0.9483 - val_loss: 5.0144 - val_accuracy: 0.5172\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3941 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2397 - accuracy: 0.9052 - val_loss: 4.6431 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2171 - accuracy: 0.8879 - val_loss: 4.5110 - val_accuracy: 0.4483\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3987 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2812 - accuracy: 0.8879 - val_loss: 4.4815 - val_accuracy: 0.6207\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4191 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2700 - accuracy: 0.9052 - val_loss: 3.7318 - val_accuracy: 0.5172\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1661 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2477 - accuracy: 0.8793 - val_loss: 4.1024 - val_accuracy: 0.5517\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 1.00 - 0s 120us/sample - loss: 0.1353 - accuracy: 0.9310 - val_loss: 3.7955 - val_accuracy: 0.5862\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1461 - accuracy: 0.9224 - val_loss: 3.6947 - val_accuracy: 0.6207\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0936 - accuracy: 0.9655 - val_loss: 3.8686 - val_accuracy: 0.5862\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1017 - accuracy: 0.9569 - val_loss: 3.9394 - val_accuracy: 0.5517\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0704 - accuracy: 0.9914 - val_loss: 3.9962 - val_accuracy: 0.5517\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 1.00 - 0s 198us/sample - loss: 0.0714 - accuracy: 0.9741 - val_loss: 4.2473 - val_accuracy: 0.5517\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.96 - 0s 180us/sample - loss: 0.0574 - accuracy: 0.9914 - val_loss: 4.5031 - val_accuracy: 0.5172\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0501 - accuracy: 0.9914 - val_loss: 4.4587 - val_accuracy: 0.5517\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0417 - accuracy: 0.9914 - val_loss: 4.4221 - val_accuracy: 0.5517\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0320 - accuracy: 1.0000 - val_loss: 4.6173 - val_accuracy: 0.5862\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0269 - accuracy: 0.9914 - val_loss: 4.7347 - val_accuracy: 0.5517\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0387 - accuracy: 0.9914 - val_loss: 4.7426 - val_accuracy: 0.5517\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0495 - accuracy: 0.9914 - val_loss: 4.6683 - val_accuracy: 0.5862\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0481 - accuracy: 0.9741 - val_loss: 5.0397 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0285 - accuracy: 1.0000 - val_loss: 4.8114 - val_accuracy: 0.5172\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0453 - accuracy: 0.9914 - val_loss: 5.0562 - val_accuracy: 0.5517\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0219 - accuracy: 1.0000 - val_loss: 5.3891 - val_accuracy: 0.6207\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0416 - accuracy: 0.9741 - val_loss: 5.2104 - val_accuracy: 0.5517\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0401 - accuracy: 0.9914 - val_loss: 5.1422 - val_accuracy: 0.5172\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0193 - accuracy: 1.0000 - val_loss: 5.4437 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0363 - accuracy: 0.9914 - val_loss: 5.5485 - val_accuracy: 0.5517\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0199 - accuracy: 1.0000 - val_loss: 5.2766 - val_accuracy: 0.5172\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0278 - accuracy: 0.9914 - val_loss: 5.4501 - val_accuracy: 0.5517\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0188 - accuracy: 1.0000 - val_loss: 5.5863 - val_accuracy: 0.5517\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0226 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0177 - accuracy: 1.0000 - val_loss: 5.6877 - val_accuracy: 0.5172\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0150 - accuracy: 1.0000 - val_loss: 5.6301 - val_accuracy: 0.5172\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0127 - accuracy: 1.0000 - val_loss: 5.6617 - val_accuracy: 0.5517\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 5.6981 - val_accuracy: 0.5862\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 5.7613 - val_accuracy: 0.5862\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 5.7936 - val_accuracy: 0.5862\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 5.8165 - val_accuracy: 0.5862\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 5.8682 - val_accuracy: 0.5862\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0106 - accuracy: 1.0000 - val_loss: 5.8364 - val_accuracy: 0.5517\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 5.9746 - val_accuracy: 0.5862\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 6.0207 - val_accuracy: 0.5862\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 6.0264 - val_accuracy: 0.5862\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 206us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 6.0164 - val_accuracy: 0.5862\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 6.0954 - val_accuracy: 0.5862\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 6.1588 - val_accuracy: 0.5862\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 6.1412 - val_accuracy: 0.5517\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 6.1418 - val_accuracy: 0.5517\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 6.2195 - val_accuracy: 0.5517\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 6.2473 - val_accuracy: 0.5517\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 6.2980 - val_accuracy: 0.5862\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 6.2890 - val_accuracy: 0.5862\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 6.3128 - val_accuracy: 0.5862\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 6.3961 - val_accuracy: 0.5862\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 6.4101 - val_accuracy: 0.5862\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 6.4095 - val_accuracy: 0.5862\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 6.4710 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 6.4479 - val_accuracy: 0.5517\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 6.4787 - val_accuracy: 0.5862\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 6.5337 - val_accuracy: 0.5862\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 6.5324 - val_accuracy: 0.5862\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 6.5707 - val_accuracy: 0.5862\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 6.5875 - val_accuracy: 0.5862\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 6.6385 - val_accuracy: 0.5862\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 6.6825 - val_accuracy: 0.5862\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 6.7060 - val_accuracy: 0.5862\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 6.7224 - val_accuracy: 0.5862\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 6.7055 - val_accuracy: 0.5862\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 6.7282 - val_accuracy: 0.5862\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 6.8040 - val_accuracy: 0.5862\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 6.8382 - val_accuracy: 0.5862\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 6.8244 - val_accuracy: 0.5862\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 6.8447 - val_accuracy: 0.5862\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 6.8988 - val_accuracy: 0.5862\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 6.8879 - val_accuracy: 0.5862\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 6.8948 - val_accuracy: 0.5862\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 6.9910 - val_accuracy: 0.5862\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 6.9720 - val_accuracy: 0.5862\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 6.9512 - val_accuracy: 0.5862\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 6.9900 - val_accuracy: 0.5862\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 7.0479 - val_accuracy: 0.5862\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 7.1024 - val_accuracy: 0.5862\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 7.0933 - val_accuracy: 0.5862\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 7.0776 - val_accuracy: 0.5862\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 7.0849 - val_accuracy: 0.5862\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 7.1297 - val_accuracy: 0.5862\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 7.1989 - val_accuracy: 0.5862\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 7.1372 - val_accuracy: 0.5862\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 7.1500 - val_accuracy: 0.5862\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 7.2155 - val_accuracy: 0.5862\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 7.2623 - val_accuracy: 0.5862\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 7.2293 - val_accuracy: 0.5862\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 7.2718 - val_accuracy: 0.5862\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 7.2871 - val_accuracy: 0.5862\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 7.2979 - val_accuracy: 0.5862\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 7.3234 - val_accuracy: 0.5862\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 7.3483 - val_accuracy: 0.5862\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 7.3603 - val_accuracy: 0.5862\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 7.3630 - val_accuracy: 0.5862\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 7.3861 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 7.4045 - val_accuracy: 0.5862\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6872 - accuracy: 0.68 - 0s 3ms/sample - loss: 0.6655 - accuracy: 0.6724 - val_loss: 0.6359 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7988 - accuracy: 0.46 - 0s 155us/sample - loss: 0.6498 - accuracy: 0.6724 - val_loss: 0.6258 - val_accuracy: 0.6897\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6148 - accuracy: 0.68 - 0s 155us/sample - loss: 0.5991 - accuracy: 0.6897 - val_loss: 0.6024 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6243 - accuracy: 0.68 - 0s 163us/sample - loss: 0.5868 - accuracy: 0.6724 - val_loss: 0.5995 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5455 - accuracy: 0.78 - 0s 163us/sample - loss: 0.5664 - accuracy: 0.6983 - val_loss: 0.5888 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4455 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5622 - accuracy: 0.7241 - val_loss: 0.5889 - val_accuracy: 0.5862\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6146 - accuracy: 0.68 - 0s 155us/sample - loss: 0.5661 - accuracy: 0.7069 - val_loss: 0.5872 - val_accuracy: 0.5862\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.65 - 0s 146us/sample - loss: 0.5524 - accuracy: 0.7155 - val_loss: 0.6252 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5453 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5455 - accuracy: 0.7586 - val_loss: 0.6116 - val_accuracy: 0.6207\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5065 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5241 - accuracy: 0.7500 - val_loss: 0.6100 - val_accuracy: 0.6552\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4863 - accuracy: 0.75 - 0s 172us/sample - loss: 0.5054 - accuracy: 0.7586 - val_loss: 0.6180 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5649 - accuracy: 0.75 - 0s 155us/sample - loss: 0.4977 - accuracy: 0.7500 - val_loss: 0.6327 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4227 - accuracy: 0.75 - 0s 181us/sample - loss: 0.4863 - accuracy: 0.7414 - val_loss: 0.6513 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4019 - accuracy: 0.81 - 0s 172us/sample - loss: 0.4757 - accuracy: 0.7414 - val_loss: 0.6643 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.84 - 0s 215us/sample - loss: 0.4867 - accuracy: 0.7672 - val_loss: 0.6717 - val_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4629 - accuracy: 0.71 - 0s 172us/sample - loss: 0.4830 - accuracy: 0.7241 - val_loss: 0.7101 - val_accuracy: 0.5517\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4618 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4659 - accuracy: 0.7586 - val_loss: 0.6924 - val_accuracy: 0.6552\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2806 - accuracy: 0.93 - 0s 155us/sample - loss: 0.4484 - accuracy: 0.7759 - val_loss: 0.7088 - val_accuracy: 0.6207\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4626 - accuracy: 0.71 - 0s 163us/sample - loss: 0.4349 - accuracy: 0.7672 - val_loss: 0.7103 - val_accuracy: 0.6552\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4217 - accuracy: 0.7845 - val_loss: 0.7358 - val_accuracy: 0.6552\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.81 - 0s 129us/sample - loss: 0.4179 - accuracy: 0.7672 - val_loss: 0.7635 - val_accuracy: 0.6207\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3919 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4031 - accuracy: 0.8017 - val_loss: 0.7479 - val_accuracy: 0.6552\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.81 - 0s 129us/sample - loss: 0.4048 - accuracy: 0.8103 - val_loss: 0.7650 - val_accuracy: 0.6552\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3820 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3925 - accuracy: 0.7931 - val_loss: 0.8063 - val_accuracy: 0.6207\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4477 - accuracy: 0.75 - 0s 120us/sample - loss: 0.3910 - accuracy: 0.8017 - val_loss: 0.8278 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3690 - accuracy: 0.8362 - val_loss: 0.8384 - val_accuracy: 0.6207\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3578 - accuracy: 0.8190 - val_loss: 0.8780 - val_accuracy: 0.6207\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.75 - 0s 129us/sample - loss: 0.3587 - accuracy: 0.8103 - val_loss: 0.9387 - val_accuracy: 0.6207\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.96 - 0s 129us/sample - loss: 0.3438 - accuracy: 0.8448 - val_loss: 0.9258 - val_accuracy: 0.5862\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3546 - accuracy: 0.8190 - val_loss: 0.8749 - val_accuracy: 0.6207\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2960 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3825 - accuracy: 0.8362 - val_loss: 0.8725 - val_accuracy: 0.6552\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3219 - accuracy: 0.84 - 0s 120us/sample - loss: 0.3471 - accuracy: 0.8276 - val_loss: 0.9192 - val_accuracy: 0.7241\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2509 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3109 - accuracy: 0.8534 - val_loss: 0.9107 - val_accuracy: 0.6552\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4029 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3294 - accuracy: 0.8534 - val_loss: 0.9651 - val_accuracy: 0.5862\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3977 - accuracy: 0.71 - 0s 129us/sample - loss: 0.3128 - accuracy: 0.8362 - val_loss: 1.0075 - val_accuracy: 0.6207\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3619 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3213 - accuracy: 0.8448 - val_loss: 0.9944 - val_accuracy: 0.6552\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3179 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2883 - accuracy: 0.8707 - val_loss: 0.9659 - val_accuracy: 0.6207\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3017 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2843 - accuracy: 0.8966 - val_loss: 1.0046 - val_accuracy: 0.6207\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3335 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2703 - accuracy: 0.8793 - val_loss: 1.1111 - val_accuracy: 0.5862\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2563 - accuracy: 0.8879 - val_loss: 1.0906 - val_accuracy: 0.6897\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2283 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2468 - accuracy: 0.8966 - val_loss: 1.1247 - val_accuracy: 0.6897\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1945 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2284 - accuracy: 0.9052 - val_loss: 1.1828 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2236 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2227 - accuracy: 0.9138 - val_loss: 1.2794 - val_accuracy: 0.6552\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2177 - accuracy: 0.9138 - val_loss: 1.3204 - val_accuracy: 0.6552\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2058 - accuracy: 0.9397 - val_loss: 1.3435 - val_accuracy: 0.6552\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1970 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2299 - accuracy: 0.8966 - val_loss: 1.4133 - val_accuracy: 0.6207\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2655 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2294 - accuracy: 0.9052 - val_loss: 1.4794 - val_accuracy: 0.6897\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3028 - accuracy: 0.81 - 0s 138us/sample - loss: 0.1996 - accuracy: 0.9052 - val_loss: 1.3123 - val_accuracy: 0.6552\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1912 - accuracy: 0.9397 - val_loss: 1.4401 - val_accuracy: 0.6207\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1922 - accuracy: 0.9052 - val_loss: 1.5514 - val_accuracy: 0.6207\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2475 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1828 - accuracy: 0.9224 - val_loss: 1.5885 - val_accuracy: 0.6207\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1761 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1512 - accuracy: 0.9569 - val_loss: 1.5383 - val_accuracy: 0.6207\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1592 - accuracy: 0.9397 - val_loss: 1.6207 - val_accuracy: 0.6897\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1610 - accuracy: 0.9397 - val_loss: 1.6459 - val_accuracy: 0.6207\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1883 - accuracy: 0.9310 - val_loss: 1.6840 - val_accuracy: 0.6897\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1496 - accuracy: 0.9483 - val_loss: 1.7802 - val_accuracy: 0.5862\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1454 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1844 - accuracy: 0.9310 - val_loss: 1.8897 - val_accuracy: 0.6897\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1514 - accuracy: 0.90 - 0s 137us/sample - loss: 0.1792 - accuracy: 0.9224 - val_loss: 1.7059 - val_accuracy: 0.6897\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1655 - accuracy: 0.9397 - val_loss: 1.8379 - val_accuracy: 0.6207\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1585 - accuracy: 0.9138 - val_loss: 1.8892 - val_accuracy: 0.6552\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1372 - accuracy: 0.9569 - val_loss: 1.8912 - val_accuracy: 0.6207\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1378 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1451 - accuracy: 0.9397 - val_loss: 2.0365 - val_accuracy: 0.6552\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1940 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1582 - accuracy: 0.9224 - val_loss: 1.9577 - val_accuracy: 0.6552\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1097 - accuracy: 0.9655 - val_loss: 1.9639 - val_accuracy: 0.6552\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1682 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1242 - accuracy: 0.9483 - val_loss: 1.8975 - val_accuracy: 0.6552\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1070 - accuracy: 0.9569 - val_loss: 2.0122 - val_accuracy: 0.6552\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0943 - accuracy: 0.9828 - val_loss: 2.0479 - val_accuracy: 0.6552\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1005 - accuracy: 0.9741 - val_loss: 2.2325 - val_accuracy: 0.6552\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0827 - accuracy: 0.9828 - val_loss: 2.3804 - val_accuracy: 0.6552\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0752 - accuracy: 0.9914 - val_loss: 2.4717 - val_accuracy: 0.6552\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0702 - accuracy: 0.9914 - val_loss: 2.4540 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0661 - accuracy: 0.9914 - val_loss: 2.4737 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0669 - accuracy: 0.9828 - val_loss: 2.4917 - val_accuracy: 0.6207\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0611 - accuracy: 0.9828 - val_loss: 2.5818 - val_accuracy: 0.6207\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0667 - accuracy: 0.9914 - val_loss: 2.6917 - val_accuracy: 0.6207\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0662 - accuracy: 0.9741 - val_loss: 2.6554 - val_accuracy: 0.6552\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0746 - accuracy: 0.9828 - val_loss: 2.7700 - val_accuracy: 0.6552\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0534 - accuracy: 0.9828 - val_loss: 2.8150 - val_accuracy: 0.6207\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0649 - accuracy: 0.9741 - val_loss: 2.8198 - val_accuracy: 0.6207\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0661 - accuracy: 0.9741 - val_loss: 2.8882 - val_accuracy: 0.5862\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0610 - accuracy: 0.9914 - val_loss: 2.9292 - val_accuracy: 0.6207\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0478 - accuracy: 0.9914 - val_loss: 2.8758 - val_accuracy: 0.6207\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0514 - accuracy: 0.9828 - val_loss: 2.9930 - val_accuracy: 0.6207\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0478 - accuracy: 0.9914 - val_loss: 3.0792 - val_accuracy: 0.6207\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0469 - accuracy: 0.9914 - val_loss: 3.1308 - val_accuracy: 0.6207\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0454 - accuracy: 1.0000 - val_loss: 3.2557 - val_accuracy: 0.6207\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0537 - accuracy: 0.9828 - val_loss: 3.2701 - val_accuracy: 0.6207\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0948 - accuracy: 0.9655 - val_loss: 3.2895 - val_accuracy: 0.6207\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1280 - accuracy: 0.9310 - val_loss: 3.7777 - val_accuracy: 0.5862\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0887 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1495 - accuracy: 0.9483 - val_loss: 3.3132 - val_accuracy: 0.6552\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3081 - accuracy: 0.84 - 0s 129us/sample - loss: 0.1603 - accuracy: 0.9138 - val_loss: 2.6763 - val_accuracy: 0.5862\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1438 - accuracy: 0.9310 - val_loss: 3.0200 - val_accuracy: 0.6552\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.87 - 0s 129us/sample - loss: 0.1918 - accuracy: 0.9224 - val_loss: 3.0830 - val_accuracy: 0.5862\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0954 - accuracy: 0.9741 - val_loss: 2.6530 - val_accuracy: 0.5862\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1148 - accuracy: 0.9655 - val_loss: 2.8337 - val_accuracy: 0.6207\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0666 - accuracy: 0.9741 - val_loss: 3.4874 - val_accuracy: 0.6207\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0729 - accuracy: 0.9741 - val_loss: 3.6300 - val_accuracy: 0.5862\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0762 - accuracy: 0.9741 - val_loss: 3.3031 - val_accuracy: 0.5862\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0757 - accuracy: 0.9828 - val_loss: 3.0935 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0846 - accuracy: 0.9741 - val_loss: 3.2158 - val_accuracy: 0.5862\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1016 - accuracy: 0.9828 - val_loss: 3.7629 - val_accuracy: 0.5862\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0633 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0548 - accuracy: 0.9828 - val_loss: 3.5773 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0495 - accuracy: 0.9741 - val_loss: 3.5329 - val_accuracy: 0.6207\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0535 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0599 - accuracy: 0.9828 - val_loss: 3.5043 - val_accuracy: 0.6207\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0356 - accuracy: 0.9914 - val_loss: 3.5196 - val_accuracy: 0.6207\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0270 - accuracy: 1.0000 - val_loss: 3.5914 - val_accuracy: 0.6207\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0251 - accuracy: 1.0000 - val_loss: 3.6819 - val_accuracy: 0.6207\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0240 - accuracy: 1.0000 - val_loss: 3.7508 - val_accuracy: 0.6207\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0201 - accuracy: 1.0000 - val_loss: 3.7771 - val_accuracy: 0.5862\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0184 - accuracy: 1.0000 - val_loss: 3.8421 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0154 - accuracy: 1.0000 - val_loss: 3.9401 - val_accuracy: 0.6207\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0145 - accuracy: 1.0000 - val_loss: 4.0059 - val_accuracy: 0.6207\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0141 - accuracy: 1.0000 - val_loss: 4.0109 - val_accuracy: 0.6207\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 4.0256 - val_accuracy: 0.5862\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 4.0513 - val_accuracy: 0.6207\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0123 - accuracy: 1.0000 - val_loss: 4.0903 - val_accuracy: 0.6207\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0130 - accuracy: 1.0000 - val_loss: 4.1039 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 4.1316 - val_accuracy: 0.6207\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 4.1529 - val_accuracy: 0.6207\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 4.1700 - val_accuracy: 0.6207\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 4.1928 - val_accuracy: 0.5862\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 4.2184 - val_accuracy: 0.6207\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 4.2234 - val_accuracy: 0.6207\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0092 - accuracy: 1.0000 - val_loss: 4.2574 - val_accuracy: 0.6207\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0086 - accuracy: 1.0000 - val_loss: 4.2598 - val_accuracy: 0.6207\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 4.2659 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 4.2942 - val_accuracy: 0.5862\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 4.3239 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 4.3370 - val_accuracy: 0.5862\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 4.3668 - val_accuracy: 0.5862\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 4.4062 - val_accuracy: 0.6207\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 4.4110 - val_accuracy: 0.5862\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 4.4087 - val_accuracy: 0.5862\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 4.4418 - val_accuracy: 0.5862\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0063 - accuracy: 1.0000 - val_loss: 4.4761 - val_accuracy: 0.5862\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 4.5101 - val_accuracy: 0.5862\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 4.5225 - val_accuracy: 0.5862\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.5172 - val_accuracy: 0.5862\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 4.5423 - val_accuracy: 0.5862\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 4.5811 - val_accuracy: 0.5862\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.6059 - val_accuracy: 0.6207\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 4.5798 - val_accuracy: 0.5862\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.00 - 0s 189us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 4.5737 - val_accuracy: 0.5862\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.6303 - val_accuracy: 0.5862\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.6801 - val_accuracy: 0.5862\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.6960 - val_accuracy: 0.5862\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 4.6877 - val_accuracy: 0.5862\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 4.6951 - val_accuracy: 0.5862\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.7368 - val_accuracy: 0.5862\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.7536 - val_accuracy: 0.5862\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.7828 - val_accuracy: 0.5862\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.8062 - val_accuracy: 0.5862\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.7916 - val_accuracy: 0.5862\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.7879 - val_accuracy: 0.5862\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.8122 - val_accuracy: 0.5862\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 4.8457 - val_accuracy: 0.5862\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.8649 - val_accuracy: 0.5862\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.8798 - val_accuracy: 0.5862\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.8960 - val_accuracy: 0.5862\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.9000 - val_accuracy: 0.5517\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.8911 - val_accuracy: 0.5862\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.9146 - val_accuracy: 0.5862\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.9524 - val_accuracy: 0.5517\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.9600 - val_accuracy: 0.5517\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 4.9700 - val_accuracy: 0.5517\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.9853 - val_accuracy: 0.5517\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 5.0016 - val_accuracy: 0.5517\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.0195 - val_accuracy: 0.5517\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.0262 - val_accuracy: 0.5517\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 5.0484 - val_accuracy: 0.5517\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 5.0512 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 5.0683 - val_accuracy: 0.5517\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 5.0849 - val_accuracy: 0.5517\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 5.0980 - val_accuracy: 0.5517\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 5.0996 - val_accuracy: 0.5517\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 5.1260 - val_accuracy: 0.5517\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 5.1616 - val_accuracy: 0.5517\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 5.1685 - val_accuracy: 0.5517\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.1575 - val_accuracy: 0.5517\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.1659 - val_accuracy: 0.5517\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 5.2045 - val_accuracy: 0.5517\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 5.2151 - val_accuracy: 0.5517\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.1922 - val_accuracy: 0.5517\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 5.2066 - val_accuracy: 0.5517\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 5.2306 - val_accuracy: 0.5517\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.2485 - val_accuracy: 0.5517\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 198us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 5.2678 - val_accuracy: 0.5517\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.2605 - val_accuracy: 0.5517\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.2680 - val_accuracy: 0.5517\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9526e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.2958 - val_accuracy: 0.5517\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.3273 - val_accuracy: 0.5517\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.3332 - val_accuracy: 0.5517\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.3164 - val_accuracy: 0.5517\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.3251 - val_accuracy: 0.5517\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.3777 - val_accuracy: 0.5517\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.3899 - val_accuracy: 0.5517\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.3916 - val_accuracy: 0.5517\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.3948 - val_accuracy: 0.5517\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.4031 - val_accuracy: 0.5517\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 5.4283 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 3f6eb9de5a37b0589415e39d1d143fc1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7155171632766724</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 84</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7064 - accuracy: 0.18 - 1s 6ms/sample - loss: 0.7056 - accuracy: 0.4914 - val_loss: 0.6423 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6603 - accuracy: 0.62 - 0s 370us/sample - loss: 0.6352 - accuracy: 0.6638 - val_loss: 0.6370 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6125 - accuracy: 0.65 - 0s 198us/sample - loss: 0.6196 - accuracy: 0.6638 - val_loss: 0.6357 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6182 - accuracy: 0.62 - 0s 155us/sample - loss: 0.6118 - accuracy: 0.6638 - val_loss: 0.6156 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6211 - accuracy: 0.62 - 0s 181us/sample - loss: 0.5914 - accuracy: 0.6983 - val_loss: 0.6180 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6633 - accuracy: 0.59 - 0s 163us/sample - loss: 0.5810 - accuracy: 0.7155 - val_loss: 0.6009 - val_accuracy: 0.6207\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4846 - accuracy: 0.75 - 0s 164us/sample - loss: 0.5626 - accuracy: 0.7328 - val_loss: 0.5853 - val_accuracy: 0.5862\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6493 - accuracy: 0.59 - 0s 172us/sample - loss: 0.5823 - accuracy: 0.6810 - val_loss: 0.6029 - val_accuracy: 0.6207\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4760 - accuracy: 0.78 - 0s 172us/sample - loss: 0.5958 - accuracy: 0.7328 - val_loss: 0.6209 - val_accuracy: 0.5862\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5291 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5441 - accuracy: 0.7414 - val_loss: 0.6126 - val_accuracy: 0.6207\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4870 - accuracy: 0.87 - 0s 155us/sample - loss: 0.5415 - accuracy: 0.7328 - val_loss: 0.6373 - val_accuracy: 0.6207\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6732 - accuracy: 0.59 - 0s 155us/sample - loss: 0.5235 - accuracy: 0.7414 - val_loss: 0.6591 - val_accuracy: 0.6207\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5679 - accuracy: 0.71 - 0s 163us/sample - loss: 0.5076 - accuracy: 0.7500 - val_loss: 0.6224 - val_accuracy: 0.6207\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5566 - accuracy: 0.71 - 0s 138us/sample - loss: 0.4901 - accuracy: 0.7586 - val_loss: 0.6592 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5023 - accuracy: 0.68 - 0s 146us/sample - loss: 0.4845 - accuracy: 0.7759 - val_loss: 0.7108 - val_accuracy: 0.6207\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5740 - accuracy: 0.71 - 0s 138us/sample - loss: 0.4914 - accuracy: 0.7759 - val_loss: 0.6640 - val_accuracy: 0.6552\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4472 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4679 - accuracy: 0.7586 - val_loss: 0.7253 - val_accuracy: 0.6207\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3955 - accuracy: 0.81 - 0s 2ms/sample - loss: 0.4914 - accuracy: 0.7586 - val_loss: 0.6846 - val_accuracy: 0.6897\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.75 - 0s 284us/sample - loss: 0.4690 - accuracy: 0.7759 - val_loss: 0.6969 - val_accuracy: 0.6552\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.81 - 0s 1ms/sample - loss: 0.4720 - accuracy: 0.7845 - val_loss: 0.7133 - val_accuracy: 0.7241\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.81 - 0s 249us/sample - loss: 0.4164 - accuracy: 0.8103 - val_loss: 0.7222 - val_accuracy: 0.6207\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5027 - accuracy: 0.75 - 0s 155us/sample - loss: 0.4245 - accuracy: 0.8448 - val_loss: 0.7175 - val_accuracy: 0.6552\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4913 - accuracy: 0.71 - 0s 163us/sample - loss: 0.3991 - accuracy: 0.8190 - val_loss: 0.7886 - val_accuracy: 0.6897\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3766 - accuracy: 0.8190 - val_loss: 0.8464 - val_accuracy: 0.6552\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3411 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3618 - accuracy: 0.8448 - val_loss: 0.8992 - val_accuracy: 0.6207\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3290 - accuracy: 0.78 - 0s 155us/sample - loss: 0.3640 - accuracy: 0.8276 - val_loss: 0.9589 - val_accuracy: 0.6207\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3345 - accuracy: 0.8534 - val_loss: 0.9553 - val_accuracy: 0.6897\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3134 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3335 - accuracy: 0.8707 - val_loss: 1.1520 - val_accuracy: 0.6552\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3436 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3655 - accuracy: 0.8534 - val_loss: 1.0718 - val_accuracy: 0.6897\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4663 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3336 - accuracy: 0.8534 - val_loss: 1.4333 - val_accuracy: 0.5172\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3548 - accuracy: 0.8190 - val_loss: 1.0332 - val_accuracy: 0.7241\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2959 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3341 - accuracy: 0.8362 - val_loss: 1.3067 - val_accuracy: 0.6552\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6709 - accuracy: 0.65 - 0s 146us/sample - loss: 0.4015 - accuracy: 0.8190 - val_loss: 1.2679 - val_accuracy: 0.6897\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3921 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4059 - accuracy: 0.8448 - val_loss: 1.2783 - val_accuracy: 0.6552\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3289 - accuracy: 0.8793 - val_loss: 1.2651 - val_accuracy: 0.5862\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3214 - accuracy: 0.8793 - val_loss: 1.3452 - val_accuracy: 0.6207\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2515 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2977 - accuracy: 0.8707 - val_loss: 1.5006 - val_accuracy: 0.6207\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2824 - accuracy: 0.8793 - val_loss: 1.6987 - val_accuracy: 0.5517\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3135 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2541 - accuracy: 0.9052 - val_loss: 1.7326 - val_accuracy: 0.6552\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2460 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2790 - accuracy: 0.9052 - val_loss: 1.9587 - val_accuracy: 0.4483\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2327 - accuracy: 0.8879 - val_loss: 1.8174 - val_accuracy: 0.6552\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2190 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3477 - accuracy: 0.8621 - val_loss: 1.7870 - val_accuracy: 0.6207\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2497 - accuracy: 0.9310 - val_loss: 1.8471 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2732 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2482 - accuracy: 0.9310 - val_loss: 1.7551 - val_accuracy: 0.6207\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1728 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2278 - accuracy: 0.9224 - val_loss: 2.0778 - val_accuracy: 0.5517\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1848 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2170 - accuracy: 0.9310 - val_loss: 2.0923 - val_accuracy: 0.6207\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2709 - accuracy: 0.8966 - val_loss: 2.2709 - val_accuracy: 0.6207\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2558 - accuracy: 0.8707 - val_loss: 2.3182 - val_accuracy: 0.6207\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4067 - accuracy: 0.81 - 0s 129us/sample - loss: 0.2397 - accuracy: 0.8966 - val_loss: 2.4177 - val_accuracy: 0.5862\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2222 - accuracy: 0.9138 - val_loss: 2.2976 - val_accuracy: 0.6207\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1260 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1862 - accuracy: 0.9138 - val_loss: 2.5743 - val_accuracy: 0.5517\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1646 - accuracy: 0.9397 - val_loss: 2.9226 - val_accuracy: 0.5517\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 1.00 - 0s 172us/sample - loss: 0.1360 - accuracy: 0.9569 - val_loss: 3.2255 - val_accuracy: 0.5517\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1836 - accuracy: 0.90 - 0s 120us/sample - loss: 0.1206 - accuracy: 0.9483 - val_loss: 3.2735 - val_accuracy: 0.6207\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1170 - accuracy: 0.9483 - val_loss: 3.4125 - val_accuracy: 0.6207\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 1.00 - 0s 138us/sample - loss: 0.2189 - accuracy: 0.9138 - val_loss: 4.1359 - val_accuracy: 0.4483\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3049 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2574 - accuracy: 0.8966 - val_loss: 3.1239 - val_accuracy: 0.6207\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5685 - accuracy: 0.71 - 0s 138us/sample - loss: 0.4184 - accuracy: 0.8276 - val_loss: 2.6977 - val_accuracy: 0.6207\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3147 - accuracy: 0.8793 - val_loss: 2.5163 - val_accuracy: 0.5862\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1664 - accuracy: 0.90 - 0s 137us/sample - loss: 0.2391 - accuracy: 0.8793 - val_loss: 2.1619 - val_accuracy: 0.5862\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2932 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2144 - accuracy: 0.8966 - val_loss: 2.2042 - val_accuracy: 0.5517\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1940 - accuracy: 0.9224 - val_loss: 2.1102 - val_accuracy: 0.5862\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1914 - accuracy: 0.9138 - val_loss: 2.1845 - val_accuracy: 0.6207\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1230 - accuracy: 0.9569 - val_loss: 2.3825 - val_accuracy: 0.5862\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1785 - accuracy: 0.9052 - val_loss: 2.3087 - val_accuracy: 0.5862\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1532 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1195 - accuracy: 0.9397 - val_loss: 2.8258 - val_accuracy: 0.5862\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1265 - accuracy: 0.9483 - val_loss: 2.9920 - val_accuracy: 0.5862\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0953 - accuracy: 0.9483 - val_loss: 2.7148 - val_accuracy: 0.6552\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1179 - accuracy: 0.9397 - val_loss: 2.8807 - val_accuracy: 0.6207\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0854 - accuracy: 0.9569 - val_loss: 3.1879 - val_accuracy: 0.5862\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0850 - accuracy: 0.9741 - val_loss: 3.3157 - val_accuracy: 0.5862\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0489 - accuracy: 0.9828 - val_loss: 3.5860 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1801 - accuracy: 0.90 - 0s 155us/sample - loss: 0.0803 - accuracy: 0.9655 - val_loss: 3.8199 - val_accuracy: 0.5517\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0728 - accuracy: 0.9741 - val_loss: 4.3600 - val_accuracy: 0.6207\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0591 - accuracy: 0.9569 - val_loss: 4.5065 - val_accuracy: 0.5862\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0358 - accuracy: 0.9914 - val_loss: 4.5742 - val_accuracy: 0.5517\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0317 - accuracy: 1.0000 - val_loss: 4.8732 - val_accuracy: 0.5862\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0187 - accuracy: 1.0000 - val_loss: 5.1396 - val_accuracy: 0.5862\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0235 - accuracy: 0.9914 - val_loss: 5.3904 - val_accuracy: 0.5862\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0164 - accuracy: 0.9914 - val_loss: 5.9394 - val_accuracy: 0.5517\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0744 - accuracy: 0.9828 - val_loss: 5.8615 - val_accuracy: 0.5517\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 137us/sample - loss: 0.1869 - accuracy: 0.9397 - val_loss: 5.0226 - val_accuracy: 0.5862\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1208 - accuracy: 0.9569 - val_loss: 4.2950 - val_accuracy: 0.5862\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1080 - accuracy: 0.9655 - val_loss: 3.5735 - val_accuracy: 0.6207\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0896 - accuracy: 0.9655 - val_loss: 3.4257 - val_accuracy: 0.6207\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0722 - accuracy: 0.9741 - val_loss: 3.6098 - val_accuracy: 0.5862\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1492 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0699 - accuracy: 0.9741 - val_loss: 3.8021 - val_accuracy: 0.5862\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0617 - accuracy: 0.9741 - val_loss: 3.9814 - val_accuracy: 0.5862\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0523 - accuracy: 0.9828 - val_loss: 4.1326 - val_accuracy: 0.5862\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0451 - accuracy: 0.9914 - val_loss: 4.3851 - val_accuracy: 0.5862\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0358 - accuracy: 0.9914 - val_loss: 4.7172 - val_accuracy: 0.5862\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0305 - accuracy: 0.9914 - val_loss: 4.9350 - val_accuracy: 0.5862\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0275 - accuracy: 0.9914 - val_loss: 5.1800 - val_accuracy: 0.5862\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0236 - accuracy: 0.9914 - val_loss: 5.4625 - val_accuracy: 0.5862\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0213 - accuracy: 0.9914 - val_loss: 5.7596 - val_accuracy: 0.5862\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0213 - accuracy: 0.9914 - val_loss: 5.9158 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0157 - accuracy: 1.0000 - val_loss: 5.9267 - val_accuracy: 0.5862\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0107 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0267 - accuracy: 0.9914 - val_loss: 6.0814 - val_accuracy: 0.5862\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0148 - accuracy: 0.9914 - val_loss: 6.2711 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0356 - accuracy: 0.9741 - val_loss: 6.3165 - val_accuracy: 0.5862\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0298 - accuracy: 0.9914 - val_loss: 6.2417 - val_accuracy: 0.5862\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0125 - accuracy: 1.0000 - val_loss: 6.4448 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0333 - accuracy: 0.9828 - val_loss: 6.4476 - val_accuracy: 0.5862\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0392 - accuracy: 0.9828 - val_loss: 6.0887 - val_accuracy: 0.6207\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0869 - accuracy: 0.9828 - val_loss: 6.2688 - val_accuracy: 0.5517\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0505 - accuracy: 0.9828 - val_loss: 6.1789 - val_accuracy: 0.5862\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1758 - accuracy: 0.9310 - val_loss: 6.0825 - val_accuracy: 0.5862\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 1.00 - 0s 138us/sample - loss: 0.3022 - accuracy: 0.9138 - val_loss: 5.1414 - val_accuracy: 0.5172\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.96 - 0s 163us/sample - loss: 0.3427 - accuracy: 0.8879 - val_loss: 4.3536 - val_accuracy: 0.5862\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1357 - accuracy: 0.93 - 0s 155us/sample - loss: 0.4425 - accuracy: 0.8966 - val_loss: 3.2288 - val_accuracy: 0.6552\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.96 - 0s 155us/sample - loss: 0.3552 - accuracy: 0.8793 - val_loss: 2.9196 - val_accuracy: 0.5862\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3566 - accuracy: 0.87 - 0s 120us/sample - loss: 0.2613 - accuracy: 0.9224 - val_loss: 2.4220 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2274 - accuracy: 0.9052 - val_loss: 2.0595 - val_accuracy: 0.5862\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2518 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2168 - accuracy: 0.9138 - val_loss: 1.8630 - val_accuracy: 0.5862\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1904 - accuracy: 0.9397 - val_loss: 1.9014 - val_accuracy: 0.5517\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1859 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1721 - accuracy: 0.9483 - val_loss: 2.0958 - val_accuracy: 0.5517\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1246 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1362 - accuracy: 0.9483 - val_loss: 2.4364 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.96 - 0s 172us/sample - loss: 0.0960 - accuracy: 0.9655 - val_loss: 2.7968 - val_accuracy: 0.5862\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.96 - 0s 172us/sample - loss: 0.0756 - accuracy: 0.9741 - val_loss: 3.1658 - val_accuracy: 0.5862\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0590 - accuracy: 0.9828 - val_loss: 3.4861 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0464 - accuracy: 0.9828 - val_loss: 3.8440 - val_accuracy: 0.5862\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0436 - accuracy: 0.9914 - val_loss: 4.1147 - val_accuracy: 0.5862\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0329 - accuracy: 0.9914 - val_loss: 4.4439 - val_accuracy: 0.5862\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0306 - accuracy: 0.9914 - val_loss: 4.7728 - val_accuracy: 0.5862\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0299 - accuracy: 0.9914 - val_loss: 5.0351 - val_accuracy: 0.5862\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0170 - accuracy: 1.0000 - val_loss: 5.1304 - val_accuracy: 0.5517\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0469 - accuracy: 0.9828 - val_loss: 5.4762 - val_accuracy: 0.5862\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0644 - accuracy: 0.9741 - val_loss: 5.1502 - val_accuracy: 0.5862\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0385 - accuracy: 0.9828 - val_loss: 4.9260 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0391 - accuracy: 0.9914 - val_loss: 5.1228 - val_accuracy: 0.5862\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0677 - accuracy: 0.9655 - val_loss: 5.2567 - val_accuracy: 0.5862\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0538 - accuracy: 0.9741 - val_loss: 5.0698 - val_accuracy: 0.5517\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0740 - accuracy: 0.9569 - val_loss: 5.1807 - val_accuracy: 0.5862\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0345 - accuracy: 0.9828 - val_loss: 5.2392 - val_accuracy: 0.5517\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0337 - accuracy: 0.9914 - val_loss: 5.4094 - val_accuracy: 0.5862\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0299 - accuracy: 0.9828 - val_loss: 5.7168 - val_accuracy: 0.5862\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0253 - accuracy: 0.9828 - val_loss: 5.6425 - val_accuracy: 0.5517\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0361 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0144 - accuracy: 0.9914 - val_loss: 5.7138 - val_accuracy: 0.5517\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0172 - accuracy: 0.9914 - val_loss: 5.9850 - val_accuracy: 0.5517\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 6.1745 - val_accuracy: 0.5862\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 6.3035 - val_accuracy: 0.5862\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 6.5132 - val_accuracy: 0.5517\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 6.6512 - val_accuracy: 0.5517\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 6.7919 - val_accuracy: 0.5517\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 7.0012 - val_accuracy: 0.5862\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0199 - accuracy: 0.9914 - val_loss: 6.9110 - val_accuracy: 0.5517\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0196 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 7.0318 - val_accuracy: 0.5517\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 7.1060 - val_accuracy: 0.5517\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 7.1295 - val_accuracy: 0.5517\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 7.2069 - val_accuracy: 0.5862\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1037e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 7.2825 - val_accuracy: 0.5862\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 7.3376 - val_accuracy: 0.5517\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6606e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 7.3824 - val_accuracy: 0.5517\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 7.4458 - val_accuracy: 0.5517\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.9906e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 7.5051 - val_accuracy: 0.5517\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 7.5487 - val_accuracy: 0.5862\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3425e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 7.6022 - val_accuracy: 0.5862\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 7.6583 - val_accuracy: 0.5862\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9989e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 7.7143 - val_accuracy: 0.5517\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2773e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.7733 - val_accuracy: 0.5517\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.9462e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.8140 - val_accuracy: 0.5517\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.8573 - val_accuracy: 0.5517\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 7.8955 - val_accuracy: 0.5517\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.9362 - val_accuracy: 0.5517\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.9669 - val_accuracy: 0.5517\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.0124 - val_accuracy: 0.5517\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 8.1016 - val_accuracy: 0.5862\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3701e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 8.1083 - val_accuracy: 0.5517\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7494e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 9.9911e-04 - accuracy: 1.0000 - val_loss: 8.1201 - val_accuracy: 0.5517\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4487e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.0427e-04 - accuracy: 1.0000 - val_loss: 8.1731 - val_accuracy: 0.5517\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.4196e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 8.2281 - val_accuracy: 0.5517\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7910e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.0598e-04 - accuracy: 1.0000 - val_loss: 8.2390 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1853e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.6499e-04 - accuracy: 1.0000 - val_loss: 8.2647 - val_accuracy: 0.5517\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1061e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.5624e-04 - accuracy: 1.0000 - val_loss: 8.3214 - val_accuracy: 0.5517\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.2335e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 7.5357e-04 - accuracy: 1.0000 - val_loss: 8.3586 - val_accuracy: 0.5517\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7212e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.0020e-04 - accuracy: 1.0000 - val_loss: 8.4018 - val_accuracy: 0.5517\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3662e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.2793e-04 - accuracy: 1.0000 - val_loss: 8.4298 - val_accuracy: 0.5517\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5890e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 6.5761e-04 - accuracy: 1.0000 - val_loss: 8.4477 - val_accuracy: 0.5517\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0540e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.4197e-04 - accuracy: 1.0000 - val_loss: 8.4723 - val_accuracy: 0.5517\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4066e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.6060e-04 - accuracy: 1.0000 - val_loss: 8.5098 - val_accuracy: 0.5517\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0161e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 6.1510e-04 - accuracy: 1.0000 - val_loss: 8.5291 - val_accuracy: 0.5517\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8617e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.9906e-04 - accuracy: 1.0000 - val_loss: 8.5651 - val_accuracy: 0.5517\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3709e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.9891e-04 - accuracy: 1.0000 - val_loss: 8.5998 - val_accuracy: 0.5517\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 146us/sample - loss: 5.5467e-04 - accuracy: 1.0000 - val_loss: 8.6215 - val_accuracy: 0.5517\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 146us/sample - loss: 5.3851e-04 - accuracy: 1.0000 - val_loss: 8.6480 - val_accuracy: 0.5517\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4408e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.3213e-04 - accuracy: 1.0000 - val_loss: 8.6748 - val_accuracy: 0.5517\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1421e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.3010e-04 - accuracy: 1.0000 - val_loss: 8.6952 - val_accuracy: 0.5517\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0771e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.9770e-04 - accuracy: 1.0000 - val_loss: 8.7277 - val_accuracy: 0.5517\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5723e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.8935e-04 - accuracy: 1.0000 - val_loss: 8.7601 - val_accuracy: 0.5517\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0742e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.8857e-04 - accuracy: 1.0000 - val_loss: 8.7812 - val_accuracy: 0.5517\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2024e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.7068e-04 - accuracy: 1.0000 - val_loss: 8.7984 - val_accuracy: 0.5517\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7065e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.6827e-04 - accuracy: 1.0000 - val_loss: 8.8248 - val_accuracy: 0.5517\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4504e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.3641e-04 - accuracy: 1.0000 - val_loss: 8.8406 - val_accuracy: 0.5517\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6773e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.2331e-04 - accuracy: 1.0000 - val_loss: 8.8580 - val_accuracy: 0.5517\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3470e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.3824e-04 - accuracy: 1.0000 - val_loss: 8.8838 - val_accuracy: 0.5517\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8771e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.4525e-04 - accuracy: 1.0000 - val_loss: 8.9039 - val_accuracy: 0.5517\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2079e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.0827e-04 - accuracy: 1.0000 - val_loss: 8.9361 - val_accuracy: 0.5517\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5515e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.8823e-04 - accuracy: 1.0000 - val_loss: 8.9652 - val_accuracy: 0.5517\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3624e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.8191e-04 - accuracy: 1.0000 - val_loss: 8.9939 - val_accuracy: 0.5517\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3935e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.8558e-04 - accuracy: 1.0000 - val_loss: 9.0161 - val_accuracy: 0.5517\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6999 - accuracy: 0.34 - 0s 4ms/sample - loss: 0.6712 - accuracy: 0.5776 - val_loss: 0.6401 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5711 - accuracy: 0.78 - 0s 155us/sample - loss: 0.6544 - accuracy: 0.6638 - val_loss: 0.6405 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.71 - 0s 155us/sample - loss: 0.6225 - accuracy: 0.6638 - val_loss: 0.6328 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6306 - accuracy: 0.65 - 0s 155us/sample - loss: 0.6236 - accuracy: 0.6638 - val_loss: 0.6281 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6600 - accuracy: 0.59 - 0s 155us/sample - loss: 0.6040 - accuracy: 0.6638 - val_loss: 0.6232 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6694 - accuracy: 0.56 - 0s 155us/sample - loss: 0.5963 - accuracy: 0.6638 - val_loss: 0.6179 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4942 - accuracy: 0.75 - 0s 163us/sample - loss: 0.5845 - accuracy: 0.6724 - val_loss: 0.5944 - val_accuracy: 0.6207\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6631 - accuracy: 0.56 - 0s 172us/sample - loss: 0.5954 - accuracy: 0.6983 - val_loss: 0.5971 - val_accuracy: 0.6207\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5174 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5832 - accuracy: 0.6897 - val_loss: 0.6040 - val_accuracy: 0.6207\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5404 - accuracy: 0.78 - 0s 163us/sample - loss: 0.5528 - accuracy: 0.7328 - val_loss: 0.6015 - val_accuracy: 0.6552\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6081 - accuracy: 0.62 - 0s 155us/sample - loss: 0.5568 - accuracy: 0.7155 - val_loss: 0.5987 - val_accuracy: 0.6897\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.75 - 0s 172us/sample - loss: 0.5365 - accuracy: 0.7500 - val_loss: 0.6227 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4975 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5249 - accuracy: 0.7241 - val_loss: 0.6565 - val_accuracy: 0.6207\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.78 - 0s 172us/sample - loss: 0.5060 - accuracy: 0.7500 - val_loss: 0.6672 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3350 - accuracy: 0.87 - 0s 163us/sample - loss: 0.5100 - accuracy: 0.7500 - val_loss: 0.6733 - val_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3559 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4927 - accuracy: 0.7586 - val_loss: 0.6638 - val_accuracy: 0.6552\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.84 - 0s 129us/sample - loss: 0.4972 - accuracy: 0.7328 - val_loss: 0.6753 - val_accuracy: 0.6897\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4559 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4482 - accuracy: 0.8103 - val_loss: 0.7098 - val_accuracy: 0.6897\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4468 - accuracy: 0.7845 - val_loss: 0.8279 - val_accuracy: 0.6207\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3751 - accuracy: 0.78 - 0s 129us/sample - loss: 0.4264 - accuracy: 0.7931 - val_loss: 0.8150 - val_accuracy: 0.6897\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.75 - 0s 129us/sample - loss: 0.4151 - accuracy: 0.8017 - val_loss: 0.9235 - val_accuracy: 0.5517\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.78 - 0s 146us/sample - loss: 0.3890 - accuracy: 0.7931 - val_loss: 0.8849 - val_accuracy: 0.6897\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3972 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4205 - accuracy: 0.7845 - val_loss: 1.0609 - val_accuracy: 0.6552\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3769 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3650 - accuracy: 0.8621 - val_loss: 1.0637 - val_accuracy: 0.6897\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3098 - accuracy: 0.84 - 0s 206us/sample - loss: 0.3996 - accuracy: 0.8017 - val_loss: 1.1658 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3648 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3934 - accuracy: 0.8534 - val_loss: 1.1700 - val_accuracy: 0.6207\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2365 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3465 - accuracy: 0.8362 - val_loss: 1.0254 - val_accuracy: 0.6207\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3013 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3128 - accuracy: 0.8621 - val_loss: 1.1383 - val_accuracy: 0.5862\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3327 - accuracy: 0.8621 - val_loss: 1.3300 - val_accuracy: 0.5862\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2848 - accuracy: 0.8707 - val_loss: 1.5155 - val_accuracy: 0.5517\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3167 - accuracy: 0.90 - 0s 172us/sample - loss: 0.2888 - accuracy: 0.8793 - val_loss: 1.5964 - val_accuracy: 0.6207\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2837 - accuracy: 0.8879 - val_loss: 1.4495 - val_accuracy: 0.6552\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3077 - accuracy: 0.8534 - val_loss: 1.4028 - val_accuracy: 0.6552\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3378 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3011 - accuracy: 0.8621 - val_loss: 1.7201 - val_accuracy: 0.5862\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2449 - accuracy: 0.8793 - val_loss: 2.0024 - val_accuracy: 0.5862\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2161 - accuracy: 0.9224 - val_loss: 2.1708 - val_accuracy: 0.6207\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1953 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2167 - accuracy: 0.9138 - val_loss: 2.4092 - val_accuracy: 0.6207\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1747 - accuracy: 0.9138 - val_loss: 2.3604 - val_accuracy: 0.6552\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2401 - accuracy: 0.8879 - val_loss: 2.5069 - val_accuracy: 0.5517\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.93 - 0s 120us/sample - loss: 0.2438 - accuracy: 0.8879 - val_loss: 3.0163 - val_accuracy: 0.5862\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2329 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3018 - accuracy: 0.8621 - val_loss: 2.1750 - val_accuracy: 0.6552\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3096 - accuracy: 0.8621 - val_loss: 2.5472 - val_accuracy: 0.5517\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2640 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2545 - accuracy: 0.9052 - val_loss: 2.0433 - val_accuracy: 0.6207\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2524 - accuracy: 0.8793 - val_loss: 2.3615 - val_accuracy: 0.6207\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2616 - accuracy: 0.8793 - val_loss: 2.6014 - val_accuracy: 0.6207\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1977 - accuracy: 0.87 - 0s 129us/sample - loss: 0.1804 - accuracy: 0.9138 - val_loss: 2.6667 - val_accuracy: 0.6897\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1998 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2091 - accuracy: 0.9138 - val_loss: 3.1466 - val_accuracy: 0.6207\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1687 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1597 - accuracy: 0.9483 - val_loss: 3.0939 - val_accuracy: 0.6207\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1317 - accuracy: 0.9483 - val_loss: 3.4196 - val_accuracy: 0.5862\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1270 - accuracy: 0.9483 - val_loss: 3.6718 - val_accuracy: 0.6207\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1501 - accuracy: 0.9310 - val_loss: 3.8789 - val_accuracy: 0.5517\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.96 - 0s 181us/sample - loss: 0.1272 - accuracy: 0.9483 - val_loss: 3.9689 - val_accuracy: 0.6207\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.93 - 0s 181us/sample - loss: 0.1416 - accuracy: 0.9310 - val_loss: 4.0337 - val_accuracy: 0.5862\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.96 - 0s 215us/sample - loss: 0.0990 - accuracy: 0.9569 - val_loss: 4.5519 - val_accuracy: 0.5172\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.93 - 0s 172us/sample - loss: 0.1025 - accuracy: 0.9483 - val_loss: 4.4052 - val_accuracy: 0.6207\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1016 - accuracy: 0.9569 - val_loss: 5.1143 - val_accuracy: 0.5517\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1046 - accuracy: 0.9483 - val_loss: 4.7763 - val_accuracy: 0.6552\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2125 - accuracy: 0.9224 - val_loss: 4.8793 - val_accuracy: 0.6552\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0590 - accuracy: 0.9655 - val_loss: 4.7304 - val_accuracy: 0.6207\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.96 - 0s 172us/sample - loss: 0.0757 - accuracy: 0.9655 - val_loss: 4.8775 - val_accuracy: 0.4828\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1140 - accuracy: 0.9397 - val_loss: 4.5724 - val_accuracy: 0.6207\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2056 - accuracy: 0.8966 - val_loss: 5.0284 - val_accuracy: 0.5517\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3436 - accuracy: 0.81 - 0s 138us/sample - loss: 0.2876 - accuracy: 0.8707 - val_loss: 4.1005 - val_accuracy: 0.6552\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2617 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2312 - accuracy: 0.8879 - val_loss: 3.9256 - val_accuracy: 0.6552\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1282 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1775 - accuracy: 0.9138 - val_loss: 3.9106 - val_accuracy: 0.6207\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1047 - accuracy: 0.9569 - val_loss: 3.6092 - val_accuracy: 0.6207\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1487 - accuracy: 0.8966 - val_loss: 3.7904 - val_accuracy: 0.6552\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1089 - accuracy: 0.9569 - val_loss: 4.0959 - val_accuracy: 0.5862\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0932 - accuracy: 0.9828 - val_loss: 4.1584 - val_accuracy: 0.6552\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1012 - accuracy: 0.9569 - val_loss: 4.2620 - val_accuracy: 0.6552\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0721 - accuracy: 0.9741 - val_loss: 4.3480 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0720 - accuracy: 0.9914 - val_loss: 4.5250 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0685 - accuracy: 0.9655 - val_loss: 4.6957 - val_accuracy: 0.6207\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0609 - accuracy: 0.9741 - val_loss: 4.8620 - val_accuracy: 0.5862\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0523 - accuracy: 0.9828 - val_loss: 5.0638 - val_accuracy: 0.5862\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0424 - accuracy: 0.9914 - val_loss: 5.2571 - val_accuracy: 0.5862\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0388 - accuracy: 0.9914 - val_loss: 5.4726 - val_accuracy: 0.5862\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 1.00 - 0s 189us/sample - loss: 0.0390 - accuracy: 0.9914 - val_loss: 5.7606 - val_accuracy: 0.5862\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0293 - accuracy: 0.9914 - val_loss: 6.1500 - val_accuracy: 0.5517\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0503 - accuracy: 0.9741 - val_loss: 6.1756 - val_accuracy: 0.5517\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0408 - accuracy: 0.9828 - val_loss: 6.2261 - val_accuracy: 0.5862\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0684 - accuracy: 0.9741 - val_loss: 6.3987 - val_accuracy: 0.5517\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0560 - accuracy: 0.9828 - val_loss: 6.5812 - val_accuracy: 0.6207\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0268 - accuracy: 0.9914 - val_loss: 6.4721 - val_accuracy: 0.5862\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0318 - accuracy: 0.9828 - val_loss: 6.5390 - val_accuracy: 0.5862\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0311 - accuracy: 0.9914 - val_loss: 6.6951 - val_accuracy: 0.5862\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0322 - accuracy: 0.9828 - val_loss: 6.5738 - val_accuracy: 0.6207\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0580 - accuracy: 0.9828 - val_loss: 6.7733 - val_accuracy: 0.6207\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0779 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0634 - accuracy: 0.9828 - val_loss: 7.0919 - val_accuracy: 0.6207\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2529 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1154 - accuracy: 0.9483 - val_loss: 6.6704 - val_accuracy: 0.6207\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0554 - accuracy: 0.9741 - val_loss: 6.4825 - val_accuracy: 0.6207\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0398 - accuracy: 0.9914 - val_loss: 6.5790 - val_accuracy: 0.6207\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0625 - accuracy: 0.9828 - val_loss: 6.4966 - val_accuracy: 0.6207\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0821 - accuracy: 0.9569 - val_loss: 6.3562 - val_accuracy: 0.6207\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0426 - accuracy: 0.9914 - val_loss: 6.3131 - val_accuracy: 0.5862\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0375 - accuracy: 0.9914 - val_loss: 6.3523 - val_accuracy: 0.6207\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0475 - accuracy: 0.9741 - val_loss: 6.5082 - val_accuracy: 0.5862\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0419 - accuracy: 0.9828 - val_loss: 6.5937 - val_accuracy: 0.6207\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0588 - accuracy: 0.9741 - val_loss: 6.5122 - val_accuracy: 0.6207\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0821 - accuracy: 0.9741 - val_loss: 6.7988 - val_accuracy: 0.6207\n",
      "Epoch 101/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0678 - accuracy: 0.9741 - val_loss: 6.9234 - val_accuracy: 0.6207\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0809 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0584 - accuracy: 0.9655 - val_loss: 6.6151 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1147 - accuracy: 0.9741 - val_loss: 6.7535 - val_accuracy: 0.5862\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0211 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1016 - accuracy: 0.9655 - val_loss: 6.4840 - val_accuracy: 0.5862\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0838 - accuracy: 0.9655 - val_loss: 6.1924 - val_accuracy: 0.6207\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0537 - accuracy: 0.9741 - val_loss: 6.4257 - val_accuracy: 0.5862\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0493 - accuracy: 0.9828 - val_loss: 5.8018 - val_accuracy: 0.5862\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0501 - accuracy: 0.9914 - val_loss: 5.9427 - val_accuracy: 0.5862\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0386 - accuracy: 1.00 - 0s 206us/sample - loss: 0.0426 - accuracy: 0.9914 - val_loss: 6.0980 - val_accuracy: 0.5862\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0262 - accuracy: 1.0000 - val_loss: 6.2718 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0269 - accuracy: 1.0000 - val_loss: 6.5757 - val_accuracy: 0.5862\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0238 - accuracy: 0.9914 - val_loss: 6.7586 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 6.8730 - val_accuracy: 0.5862\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0173 - accuracy: 1.0000 - val_loss: 7.1754 - val_accuracy: 0.5862\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 7.3890 - val_accuracy: 0.5862\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0122 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0140 - accuracy: 1.0000 - val_loss: 7.4587 - val_accuracy: 0.5862\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0176 - accuracy: 0.9914 - val_loss: 7.7049 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0297 - accuracy: 0.9914 - val_loss: 7.9302 - val_accuracy: 0.5862\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 7.5987 - val_accuracy: 0.5862\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0286 - accuracy: 0.9914 - val_loss: 7.5529 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0294 - accuracy: 0.9914 - val_loss: 7.6689 - val_accuracy: 0.5517\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0239 - accuracy: 0.9914 - val_loss: 7.7911 - val_accuracy: 0.5517\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0236 - accuracy: 0.9914 - val_loss: 7.9850 - val_accuracy: 0.5862\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 8.1103 - val_accuracy: 0.5862\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 8.1510 - val_accuracy: 0.5862\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3676e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0069 - accuracy: 1.0000 - val_loss: 8.2029 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 1.00 - 0s 181us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 8.3190 - val_accuracy: 0.5862\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4081e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 8.4634 - val_accuracy: 0.5862\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 8.4778 - val_accuracy: 0.5862\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0057 - accuracy: 1.0000 - val_loss: 8.7416 - val_accuracy: 0.5862\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 8.9756 - val_accuracy: 0.5862\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 9.1093 - val_accuracy: 0.5862\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8691e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 9.2395 - val_accuracy: 0.5862\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 9.3868 - val_accuracy: 0.5862\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 9.5781 - val_accuracy: 0.5517\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 9.7013 - val_accuracy: 0.5517\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.7793 - val_accuracy: 0.5517\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.8588 - val_accuracy: 0.5517\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3166e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 9.9637 - val_accuracy: 0.5517\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4828e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 9.0942e-04 - accuracy: 1.0000 - val_loss: 10.0345 - val_accuracy: 0.5517\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1768e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.6844e-04 - accuracy: 1.0000 - val_loss: 10.0998 - val_accuracy: 0.5517\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4023e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.4408e-04 - accuracy: 1.0000 - val_loss: 10.1613 - val_accuracy: 0.5517\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7933e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.7497e-04 - accuracy: 1.0000 - val_loss: 10.2906 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7667e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.5067e-04 - accuracy: 1.0000 - val_loss: 10.2996 - val_accuracy: 0.5517\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 146us/sample - loss: 6.1433e-04 - accuracy: 1.0000 - val_loss: 10.3903 - val_accuracy: 0.5517\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 138us/sample - loss: 5.3778e-04 - accuracy: 1.0000 - val_loss: 10.4922 - val_accuracy: 0.5517\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7650e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.3562e-04 - accuracy: 1.0000 - val_loss: 10.5303 - val_accuracy: 0.5517\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4114e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.9496e-04 - accuracy: 1.0000 - val_loss: 10.5657 - val_accuracy: 0.5517\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9879e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.6992e-04 - accuracy: 1.0000 - val_loss: 10.5981 - val_accuracy: 0.5517\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6268e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.6438e-04 - accuracy: 1.0000 - val_loss: 10.6270 - val_accuracy: 0.5517\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2462e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.3280e-04 - accuracy: 1.0000 - val_loss: 10.6755 - val_accuracy: 0.5517\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9785e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.1840e-04 - accuracy: 1.0000 - val_loss: 10.7168 - val_accuracy: 0.5517\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6228e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.1219e-04 - accuracy: 1.0000 - val_loss: 10.7509 - val_accuracy: 0.5517\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8641e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.8658e-04 - accuracy: 1.0000 - val_loss: 10.7521 - val_accuracy: 0.5517\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1292e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.5891e-04 - accuracy: 1.0000 - val_loss: 10.7673 - val_accuracy: 0.5517\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0254e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.8113e-04 - accuracy: 1.0000 - val_loss: 10.8838 - val_accuracy: 0.5517\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5113e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.2406e-04 - accuracy: 1.0000 - val_loss: 10.9179 - val_accuracy: 0.5517\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0023e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.6407e-04 - accuracy: 1.0000 - val_loss: 10.9006 - val_accuracy: 0.5517\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2284e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.2300e-04 - accuracy: 1.0000 - val_loss: 10.8906 - val_accuracy: 0.5517\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4410e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.0505e-04 - accuracy: 1.0000 - val_loss: 10.9028 - val_accuracy: 0.5517\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4806e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.1381e-04 - accuracy: 1.0000 - val_loss: 11.0362 - val_accuracy: 0.5517\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7775e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.3927e-04 - accuracy: 1.0000 - val_loss: 11.0506 - val_accuracy: 0.5517\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2097e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.1006e-04 - accuracy: 1.0000 - val_loss: 11.0398 - val_accuracy: 0.5517\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6171e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.0656e-04 - accuracy: 1.0000 - val_loss: 11.0431 - val_accuracy: 0.5517\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2569e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.9849e-04 - accuracy: 1.0000 - val_loss: 11.0962 - val_accuracy: 0.5517\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2309e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.7230e-04 - accuracy: 1.0000 - val_loss: 11.1331 - val_accuracy: 0.5517\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6750e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.7490e-04 - accuracy: 1.0000 - val_loss: 11.1839 - val_accuracy: 0.5517\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5808e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 2.7084e-04 - accuracy: 1.0000 - val_loss: 11.1916 - val_accuracy: 0.5517\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2019e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.5900e-04 - accuracy: 1.0000 - val_loss: 11.2188 - val_accuracy: 0.5517\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0928e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.5309e-04 - accuracy: 1.0000 - val_loss: 11.2170 - val_accuracy: 0.5517\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6263e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.4307e-04 - accuracy: 1.0000 - val_loss: 11.2460 - val_accuracy: 0.5517\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4935e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.3608e-04 - accuracy: 1.0000 - val_loss: 11.2924 - val_accuracy: 0.5517\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3613e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.2927e-04 - accuracy: 1.0000 - val_loss: 11.3220 - val_accuracy: 0.5517\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1389e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 2.2750e-04 - accuracy: 1.0000 - val_loss: 11.3593 - val_accuracy: 0.5517\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8509e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.2755e-04 - accuracy: 1.0000 - val_loss: 11.3764 - val_accuracy: 0.5517\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4435e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.1671e-04 - accuracy: 1.0000 - val_loss: 11.3842 - val_accuracy: 0.5517\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1191e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.2428e-04 - accuracy: 1.0000 - val_loss: 11.3820 - val_accuracy: 0.5517\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4742e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.1984e-04 - accuracy: 1.0000 - val_loss: 11.4354 - val_accuracy: 0.5517\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7002e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.0299e-04 - accuracy: 1.0000 - val_loss: 11.4599 - val_accuracy: 0.5517\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1286e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.0313e-04 - accuracy: 1.0000 - val_loss: 11.4796 - val_accuracy: 0.5517\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3122e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.0076e-04 - accuracy: 1.0000 - val_loss: 11.4781 - val_accuracy: 0.5517\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0100e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.9746e-04 - accuracy: 1.0000 - val_loss: 11.4932 - val_accuracy: 0.5517\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0995e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.9006e-04 - accuracy: 1.0000 - val_loss: 11.5230 - val_accuracy: 0.5517\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8430e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.8534e-04 - accuracy: 1.0000 - val_loss: 11.5518 - val_accuracy: 0.5517\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.2686e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.8070e-04 - accuracy: 1.0000 - val_loss: 11.5799 - val_accuracy: 0.5517\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4006e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7821e-04 - accuracy: 1.0000 - val_loss: 11.5957 - val_accuracy: 0.5517\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1468e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7407e-04 - accuracy: 1.0000 - val_loss: 11.6116 - val_accuracy: 0.5517\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.8969e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.6919e-04 - accuracy: 1.0000 - val_loss: 11.6410 - val_accuracy: 0.5517\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2503e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.6814e-04 - accuracy: 1.0000 - val_loss: 11.6650 - val_accuracy: 0.5517\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5644e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.6634e-04 - accuracy: 1.0000 - val_loss: 11.6786 - val_accuracy: 0.5517\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8122e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.6393e-04 - accuracy: 1.0000 - val_loss: 11.7057 - val_accuracy: 0.5517\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0458e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.6436e-04 - accuracy: 1.0000 - val_loss: 11.7142 - val_accuracy: 0.5517\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0561e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.5707e-04 - accuracy: 1.0000 - val_loss: 11.7466 - val_accuracy: 0.5517\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8980e-05 - accuracy: 1.00 - 0s 137us/sample - loss: 1.5285e-04 - accuracy: 1.0000 - val_loss: 11.7695 - val_accuracy: 0.5517\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1963e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4933e-04 - accuracy: 1.0000 - val_loss: 11.7907 - val_accuracy: 0.5517\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3949e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.4667e-04 - accuracy: 1.0000 - val_loss: 11.8059 - val_accuracy: 0.5517\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2674e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4416e-04 - accuracy: 1.0000 - val_loss: 11.8265 - val_accuracy: 0.5517\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2143e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4682e-04 - accuracy: 1.0000 - val_loss: 11.8388 - val_accuracy: 0.5517\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3924e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4150e-04 - accuracy: 1.0000 - val_loss: 11.8693 - val_accuracy: 0.5517\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1262e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.3841e-04 - accuracy: 1.0000 - val_loss: 11.8960 - val_accuracy: 0.5517\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7075 - accuracy: 0.31 - 0s 3ms/sample - loss: 0.6681 - accuracy: 0.5603 - val_loss: 0.6535 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5221 - accuracy: 0.78 - 0s 163us/sample - loss: 0.6615 - accuracy: 0.6638 - val_loss: 0.6295 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6480 - accuracy: 0.59 - 0s 155us/sample - loss: 0.6257 - accuracy: 0.6638 - val_loss: 0.6372 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6305 - accuracy: 0.65 - 0s 164us/sample - loss: 0.6177 - accuracy: 0.6638 - val_loss: 0.6172 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6830 - accuracy: 0.53 - 0s 155us/sample - loss: 0.5931 - accuracy: 0.6638 - val_loss: 0.6096 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7485 - accuracy: 0.50 - 0s 155us/sample - loss: 0.5900 - accuracy: 0.6897 - val_loss: 0.5889 - val_accuracy: 0.5517\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6248 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5959 - accuracy: 0.6810 - val_loss: 0.5976 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5953 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5541 - accuracy: 0.7328 - val_loss: 0.6380 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5959 - accuracy: 0.68 - 0s 138us/sample - loss: 0.5621 - accuracy: 0.7241 - val_loss: 0.6099 - val_accuracy: 0.6207\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6190 - accuracy: 0.68 - 0s 146us/sample - loss: 0.5434 - accuracy: 0.7759 - val_loss: 0.6065 - val_accuracy: 0.6207\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5128 - accuracy: 0.71 - 0s 146us/sample - loss: 0.5210 - accuracy: 0.7414 - val_loss: 0.6578 - val_accuracy: 0.6207\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.84 - 0s 155us/sample - loss: 0.5214 - accuracy: 0.7759 - val_loss: 0.6405 - val_accuracy: 0.6207\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5433 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4965 - accuracy: 0.7845 - val_loss: 0.6507 - val_accuracy: 0.6207\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4310 - accuracy: 0.75 - 0s 155us/sample - loss: 0.4983 - accuracy: 0.7500 - val_loss: 0.6376 - val_accuracy: 0.6207\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3564 - accuracy: 0.81 - 0s 2ms/sample - loss: 0.4763 - accuracy: 0.7672 - val_loss: 0.6280 - val_accuracy: 0.7586\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3507 - accuracy: 0.87 - 0s 155us/sample - loss: 0.4556 - accuracy: 0.7845 - val_loss: 0.6181 - val_accuracy: 0.6552\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3258 - accuracy: 0.90 - 0s 181us/sample - loss: 0.4616 - accuracy: 0.7759 - val_loss: 0.6340 - val_accuracy: 0.6552\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4523 - accuracy: 0.7759 - val_loss: 0.6446 - val_accuracy: 0.6552\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4557 - accuracy: 0.81 - 0s 172us/sample - loss: 0.4384 - accuracy: 0.7931 - val_loss: 0.6612 - val_accuracy: 0.6897\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.78 - 0s 155us/sample - loss: 0.4214 - accuracy: 0.7759 - val_loss: 0.6648 - val_accuracy: 0.6552\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4125 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3963 - accuracy: 0.8362 - val_loss: 0.7008 - val_accuracy: 0.6897\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2887 - accuracy: 0.93 - 0s 155us/sample - loss: 0.4117 - accuracy: 0.8190 - val_loss: 0.7147 - val_accuracy: 0.6897\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3650 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3961 - accuracy: 0.8190 - val_loss: 0.8039 - val_accuracy: 0.5862\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3983 - accuracy: 0.71 - 0s 138us/sample - loss: 0.3921 - accuracy: 0.8276 - val_loss: 0.6725 - val_accuracy: 0.7241\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.81 - 0s 172us/sample - loss: 0.3715 - accuracy: 0.8362 - val_loss: 0.6816 - val_accuracy: 0.7586\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3404 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3351 - accuracy: 0.8448 - val_loss: 0.6961 - val_accuracy: 0.6897\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.3673 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3243 - accuracy: 0.8534 - val_loss: 0.8518 - val_accuracy: 0.6552\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.78 - 0s 155us/sample - loss: 0.3192 - accuracy: 0.8362 - val_loss: 0.9878 - val_accuracy: 0.5862\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4566 - accuracy: 0.75 - 0s 129us/sample - loss: 0.3547 - accuracy: 0.8276 - val_loss: 0.8965 - val_accuracy: 0.6897\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.93 - 0s 146us/sample - loss: 0.3161 - accuracy: 0.8707 - val_loss: 0.9098 - val_accuracy: 0.6897\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.93 - 0s 155us/sample - loss: 0.4155 - accuracy: 0.8276 - val_loss: 0.8604 - val_accuracy: 0.5862\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2840 - accuracy: 0.87 - 0s 181us/sample - loss: 0.3489 - accuracy: 0.8276 - val_loss: 0.8011 - val_accuracy: 0.6897\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3024 - accuracy: 0.93 - 0s 146us/sample - loss: 0.3087 - accuracy: 0.8707 - val_loss: 0.8453 - val_accuracy: 0.6552\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2907 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2992 - accuracy: 0.8362 - val_loss: 1.0677 - val_accuracy: 0.6897\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.81 - 0s 129us/sample - loss: 0.2514 - accuracy: 0.9052 - val_loss: 1.1435 - val_accuracy: 0.6897\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.87 - 0s 120us/sample - loss: 0.2285 - accuracy: 0.8966 - val_loss: 1.3223 - val_accuracy: 0.6552\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2360 - accuracy: 0.8879 - val_loss: 1.7292 - val_accuracy: 0.5862\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3125 - accuracy: 0.87 - 0s 163us/sample - loss: 0.2199 - accuracy: 0.9052 - val_loss: 1.5511 - val_accuracy: 0.6897\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2382 - accuracy: 0.8879 - val_loss: 1.3674 - val_accuracy: 0.6897\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.87 - 0s 129us/sample - loss: 0.4704 - accuracy: 0.8017 - val_loss: 1.5267 - val_accuracy: 0.6552\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3053 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3674 - accuracy: 0.8707 - val_loss: 1.0627 - val_accuracy: 0.6552\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1965 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3457 - accuracy: 0.8534 - val_loss: 0.8493 - val_accuracy: 0.6897\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3000 - accuracy: 0.8534 - val_loss: 0.9503 - val_accuracy: 0.6552\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2931 - accuracy: 0.8707 - val_loss: 1.0434 - val_accuracy: 0.6552\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2527 - accuracy: 0.96 - 0s 120us/sample - loss: 0.2519 - accuracy: 0.9310 - val_loss: 1.1217 - val_accuracy: 0.6897\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2813 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2306 - accuracy: 0.9138 - val_loss: 1.5378 - val_accuracy: 0.6552\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2081 - accuracy: 0.9224 - val_loss: 1.6998 - val_accuracy: 0.6897\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2306 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1835 - accuracy: 0.9310 - val_loss: 1.8971 - val_accuracy: 0.6552\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1937 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1572 - accuracy: 0.9397 - val_loss: 2.0164 - val_accuracy: 0.6897\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1684 - accuracy: 0.9224 - val_loss: 2.2294 - val_accuracy: 0.6552\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1514 - accuracy: 0.9483 - val_loss: 2.1658 - val_accuracy: 0.6897\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2186 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2145 - accuracy: 0.8966 - val_loss: 2.4025 - val_accuracy: 0.6207\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.87 - 0s 146us/sample - loss: 0.1658 - accuracy: 0.9310 - val_loss: 2.0774 - val_accuracy: 0.6552\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.84 - 0s 146us/sample - loss: 0.1637 - accuracy: 0.9310 - val_loss: 2.2117 - val_accuracy: 0.6897\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1444 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1590 - accuracy: 0.9310 - val_loss: 2.0552 - val_accuracy: 0.6897\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1824 - accuracy: 0.9310 - val_loss: 2.2422 - val_accuracy: 0.6552\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1377 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1574 - accuracy: 0.9397 - val_loss: 2.2195 - val_accuracy: 0.6552\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0813 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1542 - accuracy: 0.9397 - val_loss: 2.1716 - val_accuracy: 0.6552\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1436 - accuracy: 0.9397 - val_loss: 2.2017 - val_accuracy: 0.6552\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1727 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1748 - accuracy: 0.9310 - val_loss: 2.2678 - val_accuracy: 0.6207\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1252 - accuracy: 0.9310 - val_loss: 2.6370 - val_accuracy: 0.6552\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1436 - accuracy: 0.9310 - val_loss: 2.2581 - val_accuracy: 0.6207\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3043 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1258 - accuracy: 0.9483 - val_loss: 2.1334 - val_accuracy: 0.6207\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1118 - accuracy: 0.9569 - val_loss: 2.3656 - val_accuracy: 0.5517\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0869 - accuracy: 0.9655 - val_loss: 2.5811 - val_accuracy: 0.5862\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0717 - accuracy: 0.9741 - val_loss: 2.9222 - val_accuracy: 0.5862\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0373 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0615 - accuracy: 0.9828 - val_loss: 3.2171 - val_accuracy: 0.5862\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0596 - accuracy: 0.9741 - val_loss: 3.4232 - val_accuracy: 0.5862\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0451 - accuracy: 0.9741 - val_loss: 3.6023 - val_accuracy: 0.5517\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0428 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0510 - accuracy: 0.9741 - val_loss: 3.8389 - val_accuracy: 0.5517\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0534 - accuracy: 0.9655 - val_loss: 3.9255 - val_accuracy: 0.5862\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0622 - accuracy: 0.9655 - val_loss: 4.0300 - val_accuracy: 0.5862\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0565 - accuracy: 0.9655 - val_loss: 4.1999 - val_accuracy: 0.5862\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0665 - accuracy: 0.9655 - val_loss: 4.0994 - val_accuracy: 0.5862\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0460 - accuracy: 0.9914 - val_loss: 4.3319 - val_accuracy: 0.5862\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0471 - accuracy: 0.9828 - val_loss: 4.3613 - val_accuracy: 0.5517\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0310 - accuracy: 0.9914 - val_loss: 4.5299 - val_accuracy: 0.6207\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1973 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1390 - accuracy: 0.9310 - val_loss: 4.4048 - val_accuracy: 0.5517\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.00 - 0s 146us/sample - loss: 0.2917 - accuracy: 0.9224 - val_loss: 4.0310 - val_accuracy: 0.5517\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0296 - accuracy: 1.00 - 0s 146us/sample - loss: 0.3494 - accuracy: 0.8621 - val_loss: 3.1108 - val_accuracy: 0.5862\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2394 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2754 - accuracy: 0.8707 - val_loss: 2.1765 - val_accuracy: 0.6207\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1832 - accuracy: 0.9569 - val_loss: 1.7850 - val_accuracy: 0.5862\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2133 - accuracy: 0.8879 - val_loss: 1.5119 - val_accuracy: 0.6552\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1408 - accuracy: 0.9397 - val_loss: 1.5491 - val_accuracy: 0.6897\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1358 - accuracy: 0.9483 - val_loss: 1.9731 - val_accuracy: 0.6207\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1979 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1338 - accuracy: 0.9655 - val_loss: 2.2009 - val_accuracy: 0.6552\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0996 - accuracy: 0.9569 - val_loss: 2.3340 - val_accuracy: 0.6207\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1006 - accuracy: 0.9655 - val_loss: 3.1378 - val_accuracy: 0.6207\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0665 - accuracy: 0.9828 - val_loss: 3.4476 - val_accuracy: 0.6552\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0559 - accuracy: 0.9741 - val_loss: 3.6614 - val_accuracy: 0.6552\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0685 - accuracy: 0.9741 - val_loss: 3.8613 - val_accuracy: 0.6207\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0207 - accuracy: 1.0000 - val_loss: 3.9527 - val_accuracy: 0.5862\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0453 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0294 - accuracy: 0.9914 - val_loss: 3.9767 - val_accuracy: 0.6207\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0161 - accuracy: 1.0000 - val_loss: 4.1440 - val_accuracy: 0.5862\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0161 - accuracy: 1.0000 - val_loss: 4.3381 - val_accuracy: 0.6207\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 4.4709 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0151 - accuracy: 0.9914 - val_loss: 4.6670 - val_accuracy: 0.5517\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 4.8012 - val_accuracy: 0.5862\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 4.9539 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 5.0930 - val_accuracy: 0.5862\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 5.2084 - val_accuracy: 0.5862\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.3342 - val_accuracy: 0.5862\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 5.4429 - val_accuracy: 0.5862\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.5349 - val_accuracy: 0.6207\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 5.6091 - val_accuracy: 0.6207\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.6874 - val_accuracy: 0.5862\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.7539 - val_accuracy: 0.5517\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3739e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.8245 - val_accuracy: 0.5862\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 5.8982 - val_accuracy: 0.5862\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 5.9681 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.0260 - val_accuracy: 0.5517\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.0761 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.1153 - val_accuracy: 0.5517\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2882e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.1540 - val_accuracy: 0.5862\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0231e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 9.1625e-04 - accuracy: 1.0000 - val_loss: 6.1946 - val_accuracy: 0.5862\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8642e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 8.6748e-04 - accuracy: 1.0000 - val_loss: 6.2352 - val_accuracy: 0.5862\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.2599e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.4664e-04 - accuracy: 1.0000 - val_loss: 6.2739 - val_accuracy: 0.6207\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3445e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.9303e-04 - accuracy: 1.0000 - val_loss: 6.3116 - val_accuracy: 0.6207\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7480e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.3590e-04 - accuracy: 1.0000 - val_loss: 6.3479 - val_accuracy: 0.5862\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7591e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.9692e-04 - accuracy: 1.0000 - val_loss: 6.3816 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5841e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 6.8857e-04 - accuracy: 1.0000 - val_loss: 6.4238 - val_accuracy: 0.5517\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 6.5426e-04 - accuracy: 1.0000 - val_loss: 6.4637 - val_accuracy: 0.5517\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4654e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.3851e-04 - accuracy: 1.0000 - val_loss: 6.4977 - val_accuracy: 0.5862\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.5511e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.1866e-04 - accuracy: 1.0000 - val_loss: 6.5221 - val_accuracy: 0.5862\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.8256e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.9608e-04 - accuracy: 1.0000 - val_loss: 6.5455 - val_accuracy: 0.5862\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5986e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 5.6099e-04 - accuracy: 1.0000 - val_loss: 6.5651 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0499e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.4466e-04 - accuracy: 1.0000 - val_loss: 6.5976 - val_accuracy: 0.5862\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 138us/sample - loss: 5.1549e-04 - accuracy: 1.0000 - val_loss: 6.6307 - val_accuracy: 0.5862\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1191e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.9185e-04 - accuracy: 1.0000 - val_loss: 6.6572 - val_accuracy: 0.5862\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4094e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.7832e-04 - accuracy: 1.0000 - val_loss: 6.6891 - val_accuracy: 0.5862\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3885e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.6094e-04 - accuracy: 1.0000 - val_loss: 6.7180 - val_accuracy: 0.5862\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8761e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.4647e-04 - accuracy: 1.0000 - val_loss: 6.7406 - val_accuracy: 0.5862\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6739e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.3022e-04 - accuracy: 1.0000 - val_loss: 6.7654 - val_accuracy: 0.5862\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3080e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.1870e-04 - accuracy: 1.0000 - val_loss: 6.7874 - val_accuracy: 0.5862\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1805e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.0722e-04 - accuracy: 1.0000 - val_loss: 6.8095 - val_accuracy: 0.5862\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7669e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.9076e-04 - accuracy: 1.0000 - val_loss: 6.8319 - val_accuracy: 0.5862\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3045e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.8030e-04 - accuracy: 1.0000 - val_loss: 6.8572 - val_accuracy: 0.5862\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6405e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.6231e-04 - accuracy: 1.0000 - val_loss: 6.8866 - val_accuracy: 0.5862\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7132e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.5831e-04 - accuracy: 1.0000 - val_loss: 6.9139 - val_accuracy: 0.5862\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6828e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.5083e-04 - accuracy: 1.0000 - val_loss: 6.9387 - val_accuracy: 0.5862\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2339e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.3272e-04 - accuracy: 1.0000 - val_loss: 6.9613 - val_accuracy: 0.5862\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2326e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.2107e-04 - accuracy: 1.0000 - val_loss: 6.9841 - val_accuracy: 0.5862\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4330e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.1300e-04 - accuracy: 1.0000 - val_loss: 7.0047 - val_accuracy: 0.5862\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7772e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.0374e-04 - accuracy: 1.0000 - val_loss: 7.0230 - val_accuracy: 0.5862\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4494e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 2.9854e-04 - accuracy: 1.0000 - val_loss: 7.0447 - val_accuracy: 0.5862\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9619e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 2.8562e-04 - accuracy: 1.0000 - val_loss: 7.0675 - val_accuracy: 0.5862\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9918e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 2.8150e-04 - accuracy: 1.0000 - val_loss: 7.0917 - val_accuracy: 0.5862\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3790e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 2.7457e-04 - accuracy: 1.0000 - val_loss: 7.1116 - val_accuracy: 0.5862\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0560e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.6523e-04 - accuracy: 1.0000 - val_loss: 7.1285 - val_accuracy: 0.5862\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6020e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.5867e-04 - accuracy: 1.0000 - val_loss: 7.1463 - val_accuracy: 0.5862\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7406e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 2.5334e-04 - accuracy: 1.0000 - val_loss: 7.1667 - val_accuracy: 0.5862\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5172e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.4711e-04 - accuracy: 1.0000 - val_loss: 7.1839 - val_accuracy: 0.5862\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7021e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 2.4614e-04 - accuracy: 1.0000 - val_loss: 7.2070 - val_accuracy: 0.5862\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4357e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 2.4301e-04 - accuracy: 1.0000 - val_loss: 7.2258 - val_accuracy: 0.5862\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3237e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.3089e-04 - accuracy: 1.0000 - val_loss: 7.2468 - val_accuracy: 0.5862\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0067e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.2330e-04 - accuracy: 1.0000 - val_loss: 7.2637 - val_accuracy: 0.5862\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0684e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.1903e-04 - accuracy: 1.0000 - val_loss: 7.2802 - val_accuracy: 0.5862\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0986e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.1304e-04 - accuracy: 1.0000 - val_loss: 7.3013 - val_accuracy: 0.5862\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6568e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.0861e-04 - accuracy: 1.0000 - val_loss: 7.3223 - val_accuracy: 0.5862\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.9109e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.0436e-04 - accuracy: 1.0000 - val_loss: 7.3412 - val_accuracy: 0.5862\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4311e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.9998e-04 - accuracy: 1.0000 - val_loss: 7.3595 - val_accuracy: 0.5862\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2163e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.9702e-04 - accuracy: 1.0000 - val_loss: 7.3770 - val_accuracy: 0.5862\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8595e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.8883e-04 - accuracy: 1.0000 - val_loss: 7.3957 - val_accuracy: 0.5862\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2317e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.8901e-04 - accuracy: 1.0000 - val_loss: 7.4126 - val_accuracy: 0.5862\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1851e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.8463e-04 - accuracy: 1.0000 - val_loss: 7.4269 - val_accuracy: 0.5862\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0085e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.7909e-04 - accuracy: 1.0000 - val_loss: 7.4407 - val_accuracy: 0.5862\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0745e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.7589e-04 - accuracy: 1.0000 - val_loss: 7.4570 - val_accuracy: 0.5862\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4074e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7035e-04 - accuracy: 1.0000 - val_loss: 7.4738 - val_accuracy: 0.5862\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7375e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.6720e-04 - accuracy: 1.0000 - val_loss: 7.4894 - val_accuracy: 0.5862\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8518e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.6502e-04 - accuracy: 1.0000 - val_loss: 7.5041 - val_accuracy: 0.5862\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1950e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.6051e-04 - accuracy: 1.0000 - val_loss: 7.5231 - val_accuracy: 0.5862\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4994e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.5795e-04 - accuracy: 1.0000 - val_loss: 7.5382 - val_accuracy: 0.5862\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1803e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.6050e-04 - accuracy: 1.0000 - val_loss: 7.5520 - val_accuracy: 0.5862\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0054e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.5142e-04 - accuracy: 1.0000 - val_loss: 7.5687 - val_accuracy: 0.5862\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2847e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.4740e-04 - accuracy: 1.0000 - val_loss: 7.5850 - val_accuracy: 0.5862\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2773e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4518e-04 - accuracy: 1.0000 - val_loss: 7.5993 - val_accuracy: 0.5862\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9542e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4279e-04 - accuracy: 1.0000 - val_loss: 7.6138 - val_accuracy: 0.5862\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4098e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4100e-04 - accuracy: 1.0000 - val_loss: 7.6289 - val_accuracy: 0.5862\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5773e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3717e-04 - accuracy: 1.0000 - val_loss: 7.6430 - val_accuracy: 0.5862\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3766e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.3509e-04 - accuracy: 1.0000 - val_loss: 7.6592 - val_accuracy: 0.5862\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6072e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.3188e-04 - accuracy: 1.0000 - val_loss: 7.6750 - val_accuracy: 0.5862\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6978e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.2926e-04 - accuracy: 1.0000 - val_loss: 7.6903 - val_accuracy: 0.5862\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4041e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2640e-04 - accuracy: 1.0000 - val_loss: 7.7043 - val_accuracy: 0.5862\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6787e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2463e-04 - accuracy: 1.0000 - val_loss: 7.7187 - val_accuracy: 0.5862\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3607e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.2248e-04 - accuracy: 1.0000 - val_loss: 7.7316 - val_accuracy: 0.5862\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2999e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2023e-04 - accuracy: 1.0000 - val_loss: 7.7439 - val_accuracy: 0.5862\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3817e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.1893e-04 - accuracy: 1.0000 - val_loss: 7.7554 - val_accuracy: 0.5862\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1850e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1569e-04 - accuracy: 1.0000 - val_loss: 7.7704 - val_accuracy: 0.5862\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.9433e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.1575e-04 - accuracy: 1.0000 - val_loss: 7.7849 - val_accuracy: 0.5862\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.9845e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.1259e-04 - accuracy: 1.0000 - val_loss: 7.8008 - val_accuracy: 0.5862\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2525e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0902e-04 - accuracy: 1.0000 - val_loss: 7.8152 - val_accuracy: 0.5862\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.6772e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0909e-04 - accuracy: 1.0000 - val_loss: 7.8290 - val_accuracy: 0.5862\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3206e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.0745e-04 - accuracy: 1.0000 - val_loss: 7.8415 - val_accuracy: 0.5862\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6515e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0602e-04 - accuracy: 1.0000 - val_loss: 7.8551 - val_accuracy: 0.5517\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 8.0603e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0334e-04 - accuracy: 1.0000 - val_loss: 7.8676 - val_accuracy: 0.5862\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0725e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.0115e-04 - accuracy: 1.0000 - val_loss: 7.8822 - val_accuracy: 0.5517\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3569e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 9.9749e-05 - accuracy: 1.0000 - val_loss: 7.8962 - val_accuracy: 0.5517\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5652e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 9.8105e-05 - accuracy: 1.0000 - val_loss: 7.9093 - val_accuracy: 0.5862\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3504e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.6234e-05 - accuracy: 1.0000 - val_loss: 7.9243 - val_accuracy: 0.5517\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7453e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 9.4729e-05 - accuracy: 1.0000 - val_loss: 7.9379 - val_accuracy: 0.5517\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6886 - accuracy: 0.65 - 0s 3ms/sample - loss: 0.6655 - accuracy: 0.6552 - val_loss: 0.6240 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7036 - accuracy: 0.59 - 0s 172us/sample - loss: 0.6228 - accuracy: 0.6638 - val_loss: 0.6113 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6261 - accuracy: 0.59 - 0s 163us/sample - loss: 0.5964 - accuracy: 0.6638 - val_loss: 0.6333 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.62 - 0s 163us/sample - loss: 0.6024 - accuracy: 0.6724 - val_loss: 0.5896 - val_accuracy: 0.6207\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5167 - accuracy: 0.75 - 0s 146us/sample - loss: 0.5801 - accuracy: 0.7069 - val_loss: 0.5873 - val_accuracy: 0.5862\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5602 - accuracy: 0.7241 - val_loss: 0.5892 - val_accuracy: 0.5862\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5617 - accuracy: 0.75 - 0s 164us/sample - loss: 0.5517 - accuracy: 0.7414 - val_loss: 0.6343 - val_accuracy: 0.5862\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.71 - 0s 146us/sample - loss: 0.5438 - accuracy: 0.7241 - val_loss: 0.6292 - val_accuracy: 0.5862\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5709 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5171 - accuracy: 0.7672 - val_loss: 0.6490 - val_accuracy: 0.6207\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3669 - accuracy: 0.84 - 0s 215us/sample - loss: 0.4955 - accuracy: 0.7672 - val_loss: 0.6287 - val_accuracy: 0.6207\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4141 - accuracy: 0.84 - 0s 189us/sample - loss: 0.4918 - accuracy: 0.7759 - val_loss: 0.6935 - val_accuracy: 0.6207\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3924 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4836 - accuracy: 0.7672 - val_loss: 0.7114 - val_accuracy: 0.5862\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5116 - accuracy: 0.78 - 0s 163us/sample - loss: 0.4553 - accuracy: 0.7845 - val_loss: 0.7295 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5252 - accuracy: 0.71 - 0s 146us/sample - loss: 0.4553 - accuracy: 0.7845 - val_loss: 0.7109 - val_accuracy: 0.7241\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4304 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4378 - accuracy: 0.7759 - val_loss: 0.7760 - val_accuracy: 0.6897\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3662 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4072 - accuracy: 0.7845 - val_loss: 0.7853 - val_accuracy: 0.6897\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3857 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3973 - accuracy: 0.8362 - val_loss: 0.8472 - val_accuracy: 0.6552\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3374 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3795 - accuracy: 0.8534 - val_loss: 0.9183 - val_accuracy: 0.6552\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3097 - accuracy: 0.84 - 0s 129us/sample - loss: 0.4062 - accuracy: 0.8017 - val_loss: 0.9799 - val_accuracy: 0.6897\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.93 - 0s 146us/sample - loss: 0.3591 - accuracy: 0.8534 - val_loss: 0.9465 - val_accuracy: 0.6552\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.87 - 0s 146us/sample - loss: 0.4038 - accuracy: 0.8017 - val_loss: 1.0226 - val_accuracy: 0.7241\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3214 - accuracy: 0.87 - 0s 146us/sample - loss: 0.4289 - accuracy: 0.8190 - val_loss: 0.9328 - val_accuracy: 0.6552\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4852 - accuracy: 0.78 - 0s 155us/sample - loss: 0.3975 - accuracy: 0.8362 - val_loss: 0.8934 - val_accuracy: 0.6207\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4187 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3607 - accuracy: 0.8448 - val_loss: 0.9607 - val_accuracy: 0.6552\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 1.00 - 0s 129us/sample - loss: 0.3323 - accuracy: 0.8879 - val_loss: 1.0421 - val_accuracy: 0.6207\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3729 - accuracy: 0.81 - 0s 163us/sample - loss: 0.3136 - accuracy: 0.8534 - val_loss: 1.2260 - val_accuracy: 0.6207\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2614 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2869 - accuracy: 0.8793 - val_loss: 1.4961 - val_accuracy: 0.6207\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2889 - accuracy: 0.8621 - val_loss: 1.5711 - val_accuracy: 0.6552\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2374 - accuracy: 0.9138 - val_loss: 1.7700 - val_accuracy: 0.6207\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3618 - accuracy: 0.78 - 0s 138us/sample - loss: 0.2425 - accuracy: 0.8966 - val_loss: 1.9435 - val_accuracy: 0.6207\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1671 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2304 - accuracy: 0.8966 - val_loss: 2.3496 - val_accuracy: 0.6207\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2773 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3007 - accuracy: 0.8707 - val_loss: 2.4415 - val_accuracy: 0.5517\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2994 - accuracy: 0.87 - 0s 155us/sample - loss: 0.4283 - accuracy: 0.7931 - val_loss: 2.3672 - val_accuracy: 0.5862\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4861 - accuracy: 0.78 - 0s 129us/sample - loss: 0.3699 - accuracy: 0.8190 - val_loss: 1.7142 - val_accuracy: 0.6207\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2815 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2873 - accuracy: 0.8793 - val_loss: 1.6089 - val_accuracy: 0.6552\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2464 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2820 - accuracy: 0.8534 - val_loss: 1.5596 - val_accuracy: 0.6552\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2689 - accuracy: 0.8879 - val_loss: 1.5253 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3206 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2501 - accuracy: 0.9138 - val_loss: 1.6151 - val_accuracy: 0.6552\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2245 - accuracy: 0.90 - 0s 163us/sample - loss: 0.1877 - accuracy: 0.9483 - val_loss: 1.8965 - val_accuracy: 0.6552\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1799 - accuracy: 0.9310 - val_loss: 2.2200 - val_accuracy: 0.5862\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.90 - 0s 172us/sample - loss: 0.1786 - accuracy: 0.9310 - val_loss: 2.5171 - val_accuracy: 0.5862\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1844 - accuracy: 0.9224 - val_loss: 2.6634 - val_accuracy: 0.6552\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1559 - accuracy: 0.9397 - val_loss: 2.8068 - val_accuracy: 0.5862\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2150 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1241 - accuracy: 0.9483 - val_loss: 3.0021 - val_accuracy: 0.6552\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1283 - accuracy: 0.9310 - val_loss: 3.2560 - val_accuracy: 0.5862\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1097 - accuracy: 0.9483 - val_loss: 3.4104 - val_accuracy: 0.6207\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1023 - accuracy: 0.9569 - val_loss: 3.6305 - val_accuracy: 0.6207\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0872 - accuracy: 0.9741 - val_loss: 3.8983 - val_accuracy: 0.6552\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0870 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1056 - accuracy: 0.9310 - val_loss: 4.1378 - val_accuracy: 0.5862\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1381 - accuracy: 0.9483 - val_loss: 4.2645 - val_accuracy: 0.6552\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1599 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1079 - accuracy: 0.9397 - val_loss: 4.3580 - val_accuracy: 0.5862\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1489 - accuracy: 0.9569 - val_loss: 4.7464 - val_accuracy: 0.5862\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1753 - accuracy: 0.9052 - val_loss: 4.8779 - val_accuracy: 0.6207\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.87 - 0s 155us/sample - loss: 0.4989 - accuracy: 0.8103 - val_loss: 4.1317 - val_accuracy: 0.5862\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1801 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3082 - accuracy: 0.8534 - val_loss: 2.9895 - val_accuracy: 0.5517\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3937 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3364 - accuracy: 0.8621 - val_loss: 2.0997 - val_accuracy: 0.6552\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1976 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2637 - accuracy: 0.8793 - val_loss: 2.1213 - val_accuracy: 0.6552\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.96 - 0s 163us/sample - loss: 0.2069 - accuracy: 0.9138 - val_loss: 2.2634 - val_accuracy: 0.6207\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2122 - accuracy: 0.9052 - val_loss: 2.6404 - val_accuracy: 0.5862\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.93 - 0s 181us/sample - loss: 0.1729 - accuracy: 0.9397 - val_loss: 2.5942 - val_accuracy: 0.6207\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1341 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1487 - accuracy: 0.9310 - val_loss: 2.8189 - val_accuracy: 0.5172\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1278 - accuracy: 0.9483 - val_loss: 2.9983 - val_accuracy: 0.6207\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1399 - accuracy: 0.9483 - val_loss: 3.4196 - val_accuracy: 0.6207\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1459 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1349 - accuracy: 0.9224 - val_loss: 3.5019 - val_accuracy: 0.5862\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0882 - accuracy: 0.9741 - val_loss: 3.6088 - val_accuracy: 0.6207\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0786 - accuracy: 0.9569 - val_loss: 3.9906 - val_accuracy: 0.5517\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0865 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1262 - accuracy: 0.9224 - val_loss: 3.8316 - val_accuracy: 0.6207\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2086 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1395 - accuracy: 0.9224 - val_loss: 3.9707 - val_accuracy: 0.5172\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1311 - accuracy: 0.9397 - val_loss: 3.9537 - val_accuracy: 0.6207\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 1.00 - 0s 163us/sample - loss: 0.2220 - accuracy: 0.9224 - val_loss: 4.1677 - val_accuracy: 0.6207\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3379 - accuracy: 0.9052 - val_loss: 3.7486 - val_accuracy: 0.5862\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.96 - 0s 163us/sample - loss: 0.2798 - accuracy: 0.9224 - val_loss: 3.0818 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3765 - accuracy: 0.8879 - val_loss: 2.7908 - val_accuracy: 0.4483\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2616 - accuracy: 0.87 - 0s 137us/sample - loss: 0.3722 - accuracy: 0.8276 - val_loss: 2.3531 - val_accuracy: 0.5862\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3644 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2389 - accuracy: 0.9310 - val_loss: 2.2479 - val_accuracy: 0.6207\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2203 - accuracy: 0.9138 - val_loss: 2.2494 - val_accuracy: 0.6552\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1950 - accuracy: 0.9224 - val_loss: 2.3268 - val_accuracy: 0.6552\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1903 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1834 - accuracy: 0.9310 - val_loss: 2.4222 - val_accuracy: 0.5862\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.87 - 0s 163us/sample - loss: 0.1410 - accuracy: 0.9483 - val_loss: 2.6149 - val_accuracy: 0.5862\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1455 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1225 - accuracy: 0.9569 - val_loss: 2.9063 - val_accuracy: 0.6207\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1027 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1102 - accuracy: 0.9483 - val_loss: 3.2728 - val_accuracy: 0.6207\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0883 - accuracy: 0.9655 - val_loss: 3.6861 - val_accuracy: 0.6207\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0776 - accuracy: 0.9741 - val_loss: 4.0488 - val_accuracy: 0.5862\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0755 - accuracy: 0.9655 - val_loss: 4.3973 - val_accuracy: 0.5862\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0543 - accuracy: 0.9914 - val_loss: 4.7594 - val_accuracy: 0.5862\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0492 - accuracy: 0.9828 - val_loss: 5.0948 - val_accuracy: 0.5862\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0436 - accuracy: 0.9828 - val_loss: 5.4727 - val_accuracy: 0.5517\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0638 - accuracy: 0.9655 - val_loss: 5.5608 - val_accuracy: 0.5862\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0865 - accuracy: 0.9569 - val_loss: 5.6283 - val_accuracy: 0.5862\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1440 - accuracy: 0.9224 - val_loss: 5.5157 - val_accuracy: 0.5862\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.00 - 0s 129us/sample - loss: 0.3565 - accuracy: 0.9138 - val_loss: 4.7793 - val_accuracy: 0.5862\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5647 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3177 - accuracy: 0.9138 - val_loss: 4.2057 - val_accuracy: 0.5862\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2448 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1633 - accuracy: 0.9310 - val_loss: 3.9087 - val_accuracy: 0.6207\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3375 - accuracy: 0.87 - 0s 129us/sample - loss: 0.1943 - accuracy: 0.9224 - val_loss: 3.8411 - val_accuracy: 0.4483\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1208 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1067 - accuracy: 0.9483 - val_loss: 3.5841 - val_accuracy: 0.6207\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1149 - accuracy: 0.9483 - val_loss: 3.5006 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0762 - accuracy: 0.9828 - val_loss: 3.6141 - val_accuracy: 0.5517\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0732 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0647 - accuracy: 0.9828 - val_loss: 3.6736 - val_accuracy: 0.5862\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0616 - accuracy: 0.9741 - val_loss: 3.8760 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0503 - accuracy: 0.9914 - val_loss: 4.1542 - val_accuracy: 0.5862\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0437 - accuracy: 0.9914 - val_loss: 4.4163 - val_accuracy: 0.6207\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0344 - accuracy: 1.0000 - val_loss: 4.7095 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0349 - accuracy: 0.9741 - val_loss: 4.9260 - val_accuracy: 0.5862\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0294 - accuracy: 0.9914 - val_loss: 5.0678 - val_accuracy: 0.5862\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0339 - accuracy: 0.9828 - val_loss: 5.2429 - val_accuracy: 0.5862\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0248 - accuracy: 1.0000 - val_loss: 5.5195 - val_accuracy: 0.6207\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0270 - accuracy: 0.9914 - val_loss: 5.6951 - val_accuracy: 0.5862\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0241 - accuracy: 1.0000 - val_loss: 5.7377 - val_accuracy: 0.5862\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0213 - accuracy: 0.9914 - val_loss: 5.8288 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0322 - accuracy: 0.9828 - val_loss: 6.0268 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0218 - accuracy: 1.0000 - val_loss: 6.1516 - val_accuracy: 0.5862\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0230 - accuracy: 0.9914 - val_loss: 6.2331 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0246 - accuracy: 0.9914 - val_loss: 6.3189 - val_accuracy: 0.5862\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0223 - accuracy: 0.9914 - val_loss: 6.5174 - val_accuracy: 0.5862\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0265 - accuracy: 0.9828 - val_loss: 6.7094 - val_accuracy: 0.5862\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0151 - accuracy: 0.9914 - val_loss: 6.7239 - val_accuracy: 0.5862\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0137 - accuracy: 0.9914 - val_loss: 6.7506 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0143 - accuracy: 0.9914 - val_loss: 6.8621 - val_accuracy: 0.5862\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0171 - accuracy: 1.0000 - val_loss: 6.9995 - val_accuracy: 0.5862\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 7.0476 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0191 - accuracy: 0.9914 - val_loss: 7.1874 - val_accuracy: 0.5862\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0165 - accuracy: 0.9914 - val_loss: 7.2858 - val_accuracy: 0.5862\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0213 - accuracy: 0.9914 - val_loss: 7.2228 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0232 - accuracy: 1.0000 - val_loss: 7.2576 - val_accuracy: 0.5862\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.2337e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 7.2987 - val_accuracy: 0.5862\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0042 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0199 - accuracy: 0.9914 - val_loss: 7.3593 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 7.5344 - val_accuracy: 0.5862\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0167 - accuracy: 0.9914 - val_loss: 7.5128 - val_accuracy: 0.5862\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0163 - accuracy: 0.9828 - val_loss: 7.5475 - val_accuracy: 0.5862\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0135 - accuracy: 0.9914 - val_loss: 7.6973 - val_accuracy: 0.6207\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0383 - accuracy: 0.9828 - val_loss: 7.4924 - val_accuracy: 0.5862\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1188 - accuracy: 0.9655 - val_loss: 5.3562 - val_accuracy: 0.6552\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1281 - accuracy: 0.93 - 0s 138us/sample - loss: 0.6261 - accuracy: 0.9224 - val_loss: 4.2784 - val_accuracy: 0.5862\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.96 - 0s 146us/sample - loss: 0.3369 - accuracy: 0.9138 - val_loss: 4.2730 - val_accuracy: 0.6207\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1082 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2987 - accuracy: 0.9138 - val_loss: 3.3727 - val_accuracy: 0.6552\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1452 - accuracy: 0.9483 - val_loss: 2.3934 - val_accuracy: 0.6207\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1567 - accuracy: 0.9224 - val_loss: 2.0939 - val_accuracy: 0.6897\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2395 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1558 - accuracy: 0.9569 - val_loss: 1.9749 - val_accuracy: 0.6897\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1538 - accuracy: 0.9224 - val_loss: 2.1413 - val_accuracy: 0.5862\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1211 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0971 - accuracy: 0.9655 - val_loss: 2.4238 - val_accuracy: 0.6207\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0868 - accuracy: 0.9741 - val_loss: 2.4543 - val_accuracy: 0.6897\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0761 - accuracy: 0.9655 - val_loss: 2.7719 - val_accuracy: 0.5862\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0578 - accuracy: 0.9828 - val_loss: 3.0536 - val_accuracy: 0.5862\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0467 - accuracy: 0.9914 - val_loss: 3.4086 - val_accuracy: 0.5862\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0778 - accuracy: 0.9655 - val_loss: 3.5404 - val_accuracy: 0.5862\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0921 - accuracy: 0.9569 - val_loss: 3.5849 - val_accuracy: 0.5862\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0470 - accuracy: 0.9828 - val_loss: 3.4419 - val_accuracy: 0.5862\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0616 - accuracy: 0.9828 - val_loss: 3.3444 - val_accuracy: 0.6552\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0739 - accuracy: 0.9741 - val_loss: 3.5429 - val_accuracy: 0.5862\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0676 - accuracy: 0.9741 - val_loss: 3.4496 - val_accuracy: 0.6207\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0783 - accuracy: 0.9655 - val_loss: 3.3305 - val_accuracy: 0.6552\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0234 - accuracy: 0.9914 - val_loss: 3.4022 - val_accuracy: 0.5862\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0973 - accuracy: 0.9483 - val_loss: 3.2349 - val_accuracy: 0.6207\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0766 - accuracy: 0.9741 - val_loss: 3.9024 - val_accuracy: 0.6207\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0354 - accuracy: 0.9914 - val_loss: 4.6533 - val_accuracy: 0.5862\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0267 - accuracy: 1.0000 - val_loss: 5.1578 - val_accuracy: 0.5862\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0492 - accuracy: 0.9914 - val_loss: 5.5285 - val_accuracy: 0.6207\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0245 - accuracy: 0.9914 - val_loss: 5.9545 - val_accuracy: 0.5862\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0189 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0301 - accuracy: 0.9914 - val_loss: 6.1347 - val_accuracy: 0.5862\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0148 - accuracy: 1.0000 - val_loss: 6.1681 - val_accuracy: 0.6207\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0235 - accuracy: 0.9828 - val_loss: 6.4441 - val_accuracy: 0.5862\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 6.8056 - val_accuracy: 0.5862\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0383 - accuracy: 0.9741 - val_loss: 6.9909 - val_accuracy: 0.5862\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0137 - accuracy: 1.0000 - val_loss: 7.4600 - val_accuracy: 0.5517\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0782 - accuracy: 0.9655 - val_loss: 7.0446 - val_accuracy: 0.5862\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1356 - accuracy: 0.9655 - val_loss: 6.8582 - val_accuracy: 0.5172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2366 - accuracy: 0.90 - 0s 163us/sample - loss: 0.1362 - accuracy: 0.9483 - val_loss: 6.8892 - val_accuracy: 0.5862\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0801 - accuracy: 0.9828 - val_loss: 6.5315 - val_accuracy: 0.6207\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1552 - accuracy: 0.90 - 0s 146us/sample - loss: 0.0586 - accuracy: 0.9655 - val_loss: 6.2100 - val_accuracy: 0.5862\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0491 - accuracy: 0.9828 - val_loss: 6.0315 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: ffbbe048416e10337c8c7584ebb7b312</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7241379022598267</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 60</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 24</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 24</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7057 - accuracy: 0.34 - 1s 5ms/sample - loss: 0.6749 - accuracy: 0.5690 - val_loss: 0.6347 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6055 - accuracy: 0.68 - 0s 301us/sample - loss: 0.6249 - accuracy: 0.6638 - val_loss: 0.6118 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5566 - accuracy: 0.68 - 0s 155us/sample - loss: 0.5957 - accuracy: 0.6638 - val_loss: 0.6003 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5926 - accuracy: 0.65 - 0s 164us/sample - loss: 0.5783 - accuracy: 0.7155 - val_loss: 0.6167 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7239 - accuracy: 0.59 - 0s 1ms/sample - loss: 0.5898 - accuracy: 0.7241 - val_loss: 0.5973 - val_accuracy: 0.6897\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4799 - accuracy: 0.81 - 0s 138us/sample - loss: 0.5507 - accuracy: 0.7414 - val_loss: 0.6035 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3905 - accuracy: 0.87 - 0s 146us/sample - loss: 0.5379 - accuracy: 0.7241 - val_loss: 0.6167 - val_accuracy: 0.6207\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.68 - 0s 163us/sample - loss: 0.5137 - accuracy: 0.7586 - val_loss: 0.6489 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4614 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4984 - accuracy: 0.7672 - val_loss: 0.6806 - val_accuracy: 0.5862\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4542 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4845 - accuracy: 0.7931 - val_loss: 0.7166 - val_accuracy: 0.6552\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6389 - accuracy: 0.68 - 0s 138us/sample - loss: 0.5207 - accuracy: 0.7500 - val_loss: 0.6515 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5601 - accuracy: 0.68 - 0s 146us/sample - loss: 0.4805 - accuracy: 0.7845 - val_loss: 0.6537 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3681 - accuracy: 0.90 - 0s 138us/sample - loss: 0.4786 - accuracy: 0.8017 - val_loss: 0.7045 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4548 - accuracy: 0.75 - 0s 137us/sample - loss: 0.4767 - accuracy: 0.7586 - val_loss: 0.7642 - val_accuracy: 0.6207\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.84 - 0s 137us/sample - loss: 0.4608 - accuracy: 0.7845 - val_loss: 0.7010 - val_accuracy: 0.6897\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4039 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4345 - accuracy: 0.8017 - val_loss: 0.7526 - val_accuracy: 0.6207\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4436 - accuracy: 0.81 - 0s 137us/sample - loss: 0.4508 - accuracy: 0.7931 - val_loss: 0.7063 - val_accuracy: 0.6897\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3126 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4444 - accuracy: 0.8017 - val_loss: 0.7078 - val_accuracy: 0.6552\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.84 - 0s 129us/sample - loss: 0.4128 - accuracy: 0.8103 - val_loss: 0.8471 - val_accuracy: 0.6207\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4656 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4171 - accuracy: 0.8190 - val_loss: 0.8452 - val_accuracy: 0.6552\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2468 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4255 - accuracy: 0.7845 - val_loss: 0.8406 - val_accuracy: 0.6897\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.81 - 0s 173us/sample - loss: 0.4030 - accuracy: 0.8190 - val_loss: 0.8016 - val_accuracy: 0.6552\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4794 - accuracy: 0.78 - 0s 172us/sample - loss: 0.3792 - accuracy: 0.8276 - val_loss: 0.8050 - val_accuracy: 0.6552\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3645 - accuracy: 0.84 - 0s 172us/sample - loss: 0.3660 - accuracy: 0.8362 - val_loss: 0.9959 - val_accuracy: 0.6207\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5060 - accuracy: 0.68 - 0s 146us/sample - loss: 0.3439 - accuracy: 0.8362 - val_loss: 1.0287 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6223 - accuracy: 0.65 - 0s 146us/sample - loss: 0.3610 - accuracy: 0.8362 - val_loss: 1.1243 - val_accuracy: 0.6207\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3233 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3117 - accuracy: 0.8534 - val_loss: 1.2631 - val_accuracy: 0.6552\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3186 - accuracy: 0.8793 - val_loss: 1.2104 - val_accuracy: 0.6552\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3841 - accuracy: 0.8103 - val_loss: 1.2036 - val_accuracy: 0.6207\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4770 - accuracy: 0.75 - 0s 164us/sample - loss: 0.3515 - accuracy: 0.8276 - val_loss: 0.9413 - val_accuracy: 0.6207\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.68 - 0s 146us/sample - loss: 0.3521 - accuracy: 0.8276 - val_loss: 1.0183 - val_accuracy: 0.6207\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2906 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3025 - accuracy: 0.8621 - val_loss: 1.0594 - val_accuracy: 0.6207\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2748 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2746 - accuracy: 0.8879 - val_loss: 1.1708 - val_accuracy: 0.6552\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2900 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2545 - accuracy: 0.9052 - val_loss: 1.3162 - val_accuracy: 0.6552\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2453 - accuracy: 0.8966 - val_loss: 1.4360 - val_accuracy: 0.6552\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2290 - accuracy: 0.8879 - val_loss: 1.2551 - val_accuracy: 0.5172\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3577 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2666 - accuracy: 0.8966 - val_loss: 1.4163 - val_accuracy: 0.6897\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.84 - 0s 155us/sample - loss: 0.2250 - accuracy: 0.8621 - val_loss: 1.2332 - val_accuracy: 0.5862\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2260 - accuracy: 0.9138 - val_loss: 1.4011 - val_accuracy: 0.6552\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3784 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2583 - accuracy: 0.8793 - val_loss: 1.5493 - val_accuracy: 0.6207\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1868 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1921 - accuracy: 0.9052 - val_loss: 1.7714 - val_accuracy: 0.5862\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.90 - 0s 137us/sample - loss: 0.2014 - accuracy: 0.9138 - val_loss: 1.6801 - val_accuracy: 0.6552\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2255 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2273 - accuracy: 0.8966 - val_loss: 1.6430 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2814 - accuracy: 0.93 - 0s 120us/sample - loss: 0.2508 - accuracy: 0.9052 - val_loss: 1.7000 - val_accuracy: 0.6897\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.96 - 0s 120us/sample - loss: 0.2031 - accuracy: 0.9138 - val_loss: 1.0027 - val_accuracy: 0.6552\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1324 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1963 - accuracy: 0.9310 - val_loss: 1.0190 - val_accuracy: 0.6552\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1418 - accuracy: 0.9569 - val_loss: 1.2603 - val_accuracy: 0.6552\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.84 - 0s 129us/sample - loss: 0.1455 - accuracy: 0.9397 - val_loss: 1.7677 - val_accuracy: 0.6552\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1358 - accuracy: 0.9483 - val_loss: 2.9451 - val_accuracy: 0.6552\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1938 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2123 - accuracy: 0.9224 - val_loss: 2.1084 - val_accuracy: 0.6552\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1484 - accuracy: 0.9224 - val_loss: 1.8497 - val_accuracy: 0.6552\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2284 - accuracy: 0.9310 - val_loss: 1.3784 - val_accuracy: 0.6897\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1426 - accuracy: 0.93 - 0s 2ms/sample - loss: 0.1769 - accuracy: 0.9224 - val_loss: 1.6382 - val_accuracy: 0.7241\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2088 - accuracy: 0.90 - 0s 258us/sample - loss: 0.2690 - accuracy: 0.8966 - val_loss: 1.5735 - val_accuracy: 0.5862\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3672 - accuracy: 0.81 - 0s 163us/sample - loss: 0.2479 - accuracy: 0.8966 - val_loss: 1.1012 - val_accuracy: 0.7241\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1817 - accuracy: 0.90 - 0s 1ms/sample - loss: 0.2471 - accuracy: 0.8879 - val_loss: 1.1507 - val_accuracy: 0.7586\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.96 - 0s 258us/sample - loss: 0.2176 - accuracy: 0.9224 - val_loss: 1.3060 - val_accuracy: 0.6552\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.87 - 0s 198us/sample - loss: 0.2036 - accuracy: 0.9224 - val_loss: 1.3517 - val_accuracy: 0.6897\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2008 - accuracy: 0.90 - 0s 164us/sample - loss: 0.1631 - accuracy: 0.9224 - val_loss: 1.2401 - val_accuracy: 0.7241\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1424 - accuracy: 0.9741 - val_loss: 1.3369 - val_accuracy: 0.7241\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1116 - accuracy: 0.9655 - val_loss: 1.8136 - val_accuracy: 0.6897\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1022 - accuracy: 0.9655 - val_loss: 1.6955 - val_accuracy: 0.6552\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0820 - accuracy: 0.9741 - val_loss: 1.8946 - val_accuracy: 0.6552\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0707 - accuracy: 0.9741 - val_loss: 2.2089 - val_accuracy: 0.6207\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0895 - accuracy: 0.9569 - val_loss: 2.1958 - val_accuracy: 0.6552\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0803 - accuracy: 0.9655 - val_loss: 2.1104 - val_accuracy: 0.6552\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0919 - accuracy: 0.9483 - val_loss: 2.2520 - val_accuracy: 0.6207\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1084 - accuracy: 0.9569 - val_loss: 2.7618 - val_accuracy: 0.6552\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2625 - accuracy: 0.9310 - val_loss: 2.3690 - val_accuracy: 0.6897\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 1.00 - 0s 138us/sample - loss: 0.2120 - accuracy: 0.9138 - val_loss: 1.5817 - val_accuracy: 0.5172\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6498 - accuracy: 0.78 - 0s 129us/sample - loss: 0.3073 - accuracy: 0.9138 - val_loss: 1.1511 - val_accuracy: 0.6897\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1916 - accuracy: 0.9138 - val_loss: 1.2689 - val_accuracy: 0.7241\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2070 - accuracy: 0.90 - 0s 137us/sample - loss: 0.1730 - accuracy: 0.9138 - val_loss: 1.4837 - val_accuracy: 0.6552\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1380 - accuracy: 0.9397 - val_loss: 1.6126 - val_accuracy: 0.6552\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0366 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1236 - accuracy: 0.9569 - val_loss: 1.7280 - val_accuracy: 0.5862\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1544 - accuracy: 0.9310 - val_loss: 1.8281 - val_accuracy: 0.6207\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1178 - accuracy: 0.9569 - val_loss: 1.7000 - val_accuracy: 0.6207\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.96 - 0s 137us/sample - loss: 0.1100 - accuracy: 0.9655 - val_loss: 1.7630 - val_accuracy: 0.6207\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0632 - accuracy: 0.9741 - val_loss: 1.9628 - val_accuracy: 0.6552\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2528 - accuracy: 0.87 - 0s 155us/sample - loss: 0.0962 - accuracy: 0.9569 - val_loss: 1.9675 - val_accuracy: 0.6552\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0776 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0553 - accuracy: 0.9828 - val_loss: 2.0262 - val_accuracy: 0.6207\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0487 - accuracy: 0.9914 - val_loss: 2.1167 - val_accuracy: 0.6207\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0477 - accuracy: 0.9828 - val_loss: 2.2572 - val_accuracy: 0.6207\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.96 - 0s 137us/sample - loss: 0.0381 - accuracy: 0.9914 - val_loss: 2.2972 - val_accuracy: 0.5517\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0385 - accuracy: 1.0000 - val_loss: 2.4972 - val_accuracy: 0.6207\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0298 - accuracy: 0.9914 - val_loss: 2.7128 - val_accuracy: 0.6207\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0240 - accuracy: 1.0000 - val_loss: 2.7504 - val_accuracy: 0.5862\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0240 - accuracy: 0.9914 - val_loss: 2.8252 - val_accuracy: 0.5862\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0215 - accuracy: 1.0000 - val_loss: 3.0413 - val_accuracy: 0.5862\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 1.00 - 0s 112us/sample - loss: 0.0160 - accuracy: 1.0000 - val_loss: 3.0688 - val_accuracy: 0.5862\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 3.1157 - val_accuracy: 0.5862\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0171 - accuracy: 1.0000 - val_loss: 3.3719 - val_accuracy: 0.5862\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0123 - accuracy: 1.0000 - val_loss: 3.4613 - val_accuracy: 0.5862\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 3.4630 - val_accuracy: 0.5862\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0175 - accuracy: 0.9914 - val_loss: 3.7599 - val_accuracy: 0.5862\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0279 - accuracy: 0.9914 - val_loss: 3.8285 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0429 - accuracy: 0.9828 - val_loss: 3.2219 - val_accuracy: 0.6207\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0748 - accuracy: 0.9655 - val_loss: 3.2114 - val_accuracy: 0.6207\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0614 - accuracy: 0.9741 - val_loss: 2.9977 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0590 - accuracy: 0.9828 - val_loss: 2.7265 - val_accuracy: 0.6552\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0246 - accuracy: 1.0000 - val_loss: 2.7031 - val_accuracy: 0.6207\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0252 - accuracy: 1.0000 - val_loss: 2.7084 - val_accuracy: 0.6552\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 2.9374 - val_accuracy: 0.5862\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 3.1267 - val_accuracy: 0.6207\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 3.3482 - val_accuracy: 0.6207\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 3.4694 - val_accuracy: 0.6207\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0087 - accuracy: 1.0000 - val_loss: 3.5237 - val_accuracy: 0.5862\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.7820 - val_accuracy: 0.5862\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.9489 - val_accuracy: 0.5862\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.0125 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 4.0387 - val_accuracy: 0.5862\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.1216 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.2049 - val_accuracy: 0.5862\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8724e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.2606 - val_accuracy: 0.5862\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 4.3548 - val_accuracy: 0.5862\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.4056 - val_accuracy: 0.5862\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.4155 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.4666 - val_accuracy: 0.5862\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8812e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.5165 - val_accuracy: 0.5862\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.5625 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.2943e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.6244 - val_accuracy: 0.5862\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8346e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.6681 - val_accuracy: 0.5862\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.6880 - val_accuracy: 0.5862\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.7204 - val_accuracy: 0.5862\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.7555 - val_accuracy: 0.5862\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.7737 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.8157 - val_accuracy: 0.5862\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 129us/sample - loss: 9.9022e-04 - accuracy: 1.0000 - val_loss: 4.8450 - val_accuracy: 0.5862\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1352e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 9.9142e-04 - accuracy: 1.0000 - val_loss: 4.8633 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 163us/sample - loss: 9.7463e-04 - accuracy: 1.0000 - val_loss: 4.9002 - val_accuracy: 0.5862\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3786e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.0056e-04 - accuracy: 1.0000 - val_loss: 4.9079 - val_accuracy: 0.5862\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2186e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 9.0193e-04 - accuracy: 1.0000 - val_loss: 4.9375 - val_accuracy: 0.5862\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2840e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 8.4370e-04 - accuracy: 1.0000 - val_loss: 4.9740 - val_accuracy: 0.5862\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2722e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 8.1214e-04 - accuracy: 1.0000 - val_loss: 5.0068 - val_accuracy: 0.5862\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 120us/sample - loss: 7.9945e-04 - accuracy: 1.0000 - val_loss: 5.0391 - val_accuracy: 0.5862\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5943e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.4665e-04 - accuracy: 1.0000 - val_loss: 5.0576 - val_accuracy: 0.5862\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5571e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 7.0870e-04 - accuracy: 1.0000 - val_loss: 5.0720 - val_accuracy: 0.5862\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5040e-04 - accuracy: 1.00 - 0s 103us/sample - loss: 6.9327e-04 - accuracy: 1.0000 - val_loss: 5.0933 - val_accuracy: 0.5862\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8256e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 6.8032e-04 - accuracy: 1.0000 - val_loss: 5.1174 - val_accuracy: 0.5862\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1805e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.4111e-04 - accuracy: 1.0000 - val_loss: 5.1439 - val_accuracy: 0.5862\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8912e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 6.2553e-04 - accuracy: 1.0000 - val_loss: 5.1672 - val_accuracy: 0.5862\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6754e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 6.0313e-04 - accuracy: 1.0000 - val_loss: 5.1846 - val_accuracy: 0.5862\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6528e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.9390e-04 - accuracy: 1.0000 - val_loss: 5.2024 - val_accuracy: 0.5862\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1100e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.7573e-04 - accuracy: 1.0000 - val_loss: 5.2188 - val_accuracy: 0.5862\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6092e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.6876e-04 - accuracy: 1.0000 - val_loss: 5.2429 - val_accuracy: 0.5862\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8044e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.6304e-04 - accuracy: 1.0000 - val_loss: 5.2494 - val_accuracy: 0.5862\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3439e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.5373e-04 - accuracy: 1.0000 - val_loss: 5.2782 - val_accuracy: 0.5862\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0779e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.2324e-04 - accuracy: 1.0000 - val_loss: 5.2925 - val_accuracy: 0.5862\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 129us/sample - loss: 5.0313e-04 - accuracy: 1.0000 - val_loss: 5.3026 - val_accuracy: 0.5862\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.5979e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.8923e-04 - accuracy: 1.0000 - val_loss: 5.3152 - val_accuracy: 0.5862\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4406e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.8140e-04 - accuracy: 1.0000 - val_loss: 5.3335 - val_accuracy: 0.5862\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5556e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.7096e-04 - accuracy: 1.0000 - val_loss: 5.3469 - val_accuracy: 0.5862\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6435e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.6714e-04 - accuracy: 1.0000 - val_loss: 5.3681 - val_accuracy: 0.5862\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0991e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 4.4724e-04 - accuracy: 1.0000 - val_loss: 5.3817 - val_accuracy: 0.5862\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3220e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.5208e-04 - accuracy: 1.0000 - val_loss: 5.3932 - val_accuracy: 0.5862\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0340e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.3907e-04 - accuracy: 1.0000 - val_loss: 5.4207 - val_accuracy: 0.5862\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6899e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 4.3370e-04 - accuracy: 1.0000 - val_loss: 5.4365 - val_accuracy: 0.5862\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7368e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.2239e-04 - accuracy: 1.0000 - val_loss: 5.4414 - val_accuracy: 0.5862\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0055e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.0764e-04 - accuracy: 1.0000 - val_loss: 5.4502 - val_accuracy: 0.5862\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5029e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.9210e-04 - accuracy: 1.0000 - val_loss: 5.4621 - val_accuracy: 0.5862\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1264e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.8216e-04 - accuracy: 1.0000 - val_loss: 5.4758 - val_accuracy: 0.5862\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4098e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.8431e-04 - accuracy: 1.0000 - val_loss: 5.4929 - val_accuracy: 0.5862\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9849e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.6960e-04 - accuracy: 1.0000 - val_loss: 5.4982 - val_accuracy: 0.5862\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1250e-04 - accuracy: 1.00 - 0s 112us/sample - loss: 3.6761e-04 - accuracy: 1.0000 - val_loss: 5.5122 - val_accuracy: 0.5862\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6504e-05 - accuracy: 1.00 - 0s 120us/sample - loss: 3.6089e-04 - accuracy: 1.0000 - val_loss: 5.5248 - val_accuracy: 0.5862\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9107e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.5132e-04 - accuracy: 1.0000 - val_loss: 5.5380 - val_accuracy: 0.5862\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2085e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.4271e-04 - accuracy: 1.0000 - val_loss: 5.5525 - val_accuracy: 0.5862\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7595e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.4299e-04 - accuracy: 1.0000 - val_loss: 5.5639 - val_accuracy: 0.5862\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1188e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.2988e-04 - accuracy: 1.0000 - val_loss: 5.5799 - val_accuracy: 0.5862\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2960e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.3136e-04 - accuracy: 1.0000 - val_loss: 5.6085 - val_accuracy: 0.5862\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7404e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.3345e-04 - accuracy: 1.0000 - val_loss: 5.6224 - val_accuracy: 0.5862\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1713e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.1374e-04 - accuracy: 1.0000 - val_loss: 5.6201 - val_accuracy: 0.5862\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5879e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.0369e-04 - accuracy: 1.0000 - val_loss: 5.6217 - val_accuracy: 0.5862\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.9301e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 3.1716e-04 - accuracy: 1.0000 - val_loss: 5.6266 - val_accuracy: 0.5862\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5436e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.9800e-04 - accuracy: 1.0000 - val_loss: 5.6484 - val_accuracy: 0.5862\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1802e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.8854e-04 - accuracy: 1.0000 - val_loss: 5.6679 - val_accuracy: 0.5862\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.6221e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.8532e-04 - accuracy: 1.0000 - val_loss: 5.6869 - val_accuracy: 0.5862\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.9612e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.7866e-04 - accuracy: 1.0000 - val_loss: 5.6959 - val_accuracy: 0.5862\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9485e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.7488e-04 - accuracy: 1.0000 - val_loss: 5.7020 - val_accuracy: 0.5862\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0426e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.6777e-04 - accuracy: 1.0000 - val_loss: 5.7025 - val_accuracy: 0.5862\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7567e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 2.6649e-04 - accuracy: 1.0000 - val_loss: 5.7115 - val_accuracy: 0.5862\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3845e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.6530e-04 - accuracy: 1.0000 - val_loss: 5.7215 - val_accuracy: 0.5862\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3187e-05 - accuracy: 1.00 - 0s 120us/sample - loss: 2.5969e-04 - accuracy: 1.0000 - val_loss: 5.7390 - val_accuracy: 0.5862\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6376e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.5899e-04 - accuracy: 1.0000 - val_loss: 5.7562 - val_accuracy: 0.5862\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1772e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.5068e-04 - accuracy: 1.0000 - val_loss: 5.7653 - val_accuracy: 0.5862\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4656e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.4945e-04 - accuracy: 1.0000 - val_loss: 5.7690 - val_accuracy: 0.5862\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5683e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 2.4098e-04 - accuracy: 1.0000 - val_loss: 5.7813 - val_accuracy: 0.5862\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9302e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.4212e-04 - accuracy: 1.0000 - val_loss: 5.7909 - val_accuracy: 0.5862\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6038e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.3646e-04 - accuracy: 1.0000 - val_loss: 5.8113 - val_accuracy: 0.5862\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7472e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 2.3269e-04 - accuracy: 1.0000 - val_loss: 5.8237 - val_accuracy: 0.5862\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1773e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.2761e-04 - accuracy: 1.0000 - val_loss: 5.8293 - val_accuracy: 0.5862\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8789e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.2277e-04 - accuracy: 1.0000 - val_loss: 5.8338 - val_accuracy: 0.5862\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0769e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.1845e-04 - accuracy: 1.0000 - val_loss: 5.8408 - val_accuracy: 0.5862\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8899e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 2.2056e-04 - accuracy: 1.0000 - val_loss: 5.8470 - val_accuracy: 0.5862\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5415e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.1669e-04 - accuracy: 1.0000 - val_loss: 5.8638 - val_accuracy: 0.5862\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4988e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 2.0972e-04 - accuracy: 1.0000 - val_loss: 5.8738 - val_accuracy: 0.5862\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1536e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.0571e-04 - accuracy: 1.0000 - val_loss: 5.8796 - val_accuracy: 0.5862\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7883e-05 - accuracy: 1.00 - 0s 120us/sample - loss: 2.0649e-04 - accuracy: 1.0000 - val_loss: 5.8878 - val_accuracy: 0.5862\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0467e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 2.0464e-04 - accuracy: 1.0000 - val_loss: 5.9020 - val_accuracy: 0.5862\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1375e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.9597e-04 - accuracy: 1.0000 - val_loss: 5.9087 - val_accuracy: 0.5862\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6973 - accuracy: 0.46 - 0s 3ms/sample - loss: 0.6686 - accuracy: 0.5862 - val_loss: 0.6277 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6220 - accuracy: 0.65 - 0s 155us/sample - loss: 0.6216 - accuracy: 0.6638 - val_loss: 0.6047 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5958 - accuracy: 0.65 - 0s 146us/sample - loss: 0.5845 - accuracy: 0.6552 - val_loss: 0.5869 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5385 - accuracy: 0.68 - 0s 189us/sample - loss: 0.5979 - accuracy: 0.7069 - val_loss: 0.5685 - val_accuracy: 0.6897\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5964 - accuracy: 0.71 - 0s 172us/sample - loss: 0.5895 - accuracy: 0.7069 - val_loss: 0.5899 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5882 - accuracy: 0.68 - 0s 206us/sample - loss: 0.5766 - accuracy: 0.7241 - val_loss: 0.6173 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.62 - 0s 181us/sample - loss: 0.5521 - accuracy: 0.7155 - val_loss: 0.5995 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5952 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5316 - accuracy: 0.7586 - val_loss: 0.6092 - val_accuracy: 0.6897\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5081 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5080 - accuracy: 0.7586 - val_loss: 0.6316 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5562 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4776 - accuracy: 0.7759 - val_loss: 0.6816 - val_accuracy: 0.6552\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3880 - accuracy: 0.78 - 0s 155us/sample - loss: 0.4958 - accuracy: 0.7500 - val_loss: 0.6875 - val_accuracy: 0.6897\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3563 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4511 - accuracy: 0.7759 - val_loss: 0.7253 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5195 - accuracy: 0.71 - 0s 120us/sample - loss: 0.4528 - accuracy: 0.7672 - val_loss: 0.7108 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4488 - accuracy: 0.78 - 0s 129us/sample - loss: 0.4230 - accuracy: 0.7845 - val_loss: 0.7741 - val_accuracy: 0.6207\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4301 - accuracy: 0.8103 - val_loss: 0.7864 - val_accuracy: 0.6897\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3944 - accuracy: 0.81 - 0s 137us/sample - loss: 0.4103 - accuracy: 0.7931 - val_loss: 0.7786 - val_accuracy: 0.6552\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4314 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4595 - accuracy: 0.7845 - val_loss: 0.8294 - val_accuracy: 0.6552\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3112 - accuracy: 0.87 - 0s 129us/sample - loss: 0.4496 - accuracy: 0.7845 - val_loss: 0.7250 - val_accuracy: 0.6897\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.68 - 0s 138us/sample - loss: 0.4200 - accuracy: 0.7931 - val_loss: 0.7456 - val_accuracy: 0.6207\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4523 - accuracy: 0.75 - 0s 137us/sample - loss: 0.4218 - accuracy: 0.7759 - val_loss: 0.7351 - val_accuracy: 0.6207\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2475 - accuracy: 0.96 - 0s 138us/sample - loss: 0.4173 - accuracy: 0.7845 - val_loss: 0.7636 - val_accuracy: 0.6552\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3692 - accuracy: 0.8190 - val_loss: 0.8787 - val_accuracy: 0.6207\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3951 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3588 - accuracy: 0.8448 - val_loss: 0.8415 - val_accuracy: 0.5862\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3545 - accuracy: 0.87 - 0s 181us/sample - loss: 0.3354 - accuracy: 0.8362 - val_loss: 1.0380 - val_accuracy: 0.5862\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.87 - 0s 172us/sample - loss: 0.3003 - accuracy: 0.8707 - val_loss: 1.1473 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3466 - accuracy: 0.78 - 0s 146us/sample - loss: 0.2771 - accuracy: 0.8707 - val_loss: 1.4848 - val_accuracy: 0.5862\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3442 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2777 - accuracy: 0.8534 - val_loss: 1.4533 - val_accuracy: 0.6207\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 1.00 - 0s 146us/sample - loss: 0.2533 - accuracy: 0.8793 - val_loss: 1.6585 - val_accuracy: 0.6207\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2396 - accuracy: 0.8966 - val_loss: 1.9479 - val_accuracy: 0.5862\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1839 - accuracy: 0.9224 - val_loss: 1.9417 - val_accuracy: 0.6207\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.84 - 0s 138us/sample - loss: 0.1965 - accuracy: 0.8966 - val_loss: 2.1094 - val_accuracy: 0.5517\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2261 - accuracy: 0.9224 - val_loss: 2.2740 - val_accuracy: 0.6207\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1892 - accuracy: 0.9310 - val_loss: 2.3420 - val_accuracy: 0.6207\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1727 - accuracy: 0.9052 - val_loss: 2.5309 - val_accuracy: 0.5172\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2708 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2099 - accuracy: 0.8966 - val_loss: 2.5928 - val_accuracy: 0.6552\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1825 - accuracy: 0.9138 - val_loss: 2.4986 - val_accuracy: 0.6207\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2012 - accuracy: 0.90 - 0s 120us/sample - loss: 0.1613 - accuracy: 0.9224 - val_loss: 2.5237 - val_accuracy: 0.6207\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1372 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1288 - accuracy: 0.9569 - val_loss: 2.5502 - val_accuracy: 0.6207\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1036 - accuracy: 0.9569 - val_loss: 3.0499 - val_accuracy: 0.6207\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1746 - accuracy: 0.90 - 0s 120us/sample - loss: 0.1278 - accuracy: 0.9397 - val_loss: 3.1567 - val_accuracy: 0.5862\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1016 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1162 - accuracy: 0.9483 - val_loss: 3.3175 - val_accuracy: 0.5517\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1212 - accuracy: 0.9397 - val_loss: 3.7122 - val_accuracy: 0.6207\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1903 - accuracy: 0.9138 - val_loss: 3.9774 - val_accuracy: 0.5172\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2986 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2037 - accuracy: 0.9052 - val_loss: 4.0140 - val_accuracy: 0.6207\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1495 - accuracy: 0.9224 - val_loss: 3.6556 - val_accuracy: 0.5862\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.93 - 0s 207us/sample - loss: 0.1271 - accuracy: 0.9569 - val_loss: 3.6684 - val_accuracy: 0.6207\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 1.00 - 0s 181us/sample - loss: 0.1446 - accuracy: 0.9397 - val_loss: 3.9786 - val_accuracy: 0.5862\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1224 - accuracy: 0.9310 - val_loss: 4.0968 - val_accuracy: 0.6207\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0801 - accuracy: 0.9569 - val_loss: 4.0983 - val_accuracy: 0.6207\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0903 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0630 - accuracy: 0.9828 - val_loss: 4.1537 - val_accuracy: 0.5862\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0573 - accuracy: 0.9828 - val_loss: 4.4794 - val_accuracy: 0.6207\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0519 - accuracy: 0.9828 - val_loss: 4.7911 - val_accuracy: 0.5862\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0442 - accuracy: 0.9914 - val_loss: 5.1524 - val_accuracy: 0.5862\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0335 - accuracy: 0.9914 - val_loss: 5.5185 - val_accuracy: 0.5862\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0344 - accuracy: 0.9914 - val_loss: 5.7444 - val_accuracy: 0.5862\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0291 - accuracy: 0.9914 - val_loss: 6.1141 - val_accuracy: 0.5862\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.96 - 0s 172us/sample - loss: 0.0283 - accuracy: 0.9914 - val_loss: 6.2538 - val_accuracy: 0.5862\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0215 - accuracy: 0.9914 - val_loss: 6.4541 - val_accuracy: 0.5862\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0157 - accuracy: 1.0000 - val_loss: 6.6468 - val_accuracy: 0.5862\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0191 - accuracy: 0.9914 - val_loss: 6.6080 - val_accuracy: 0.5862\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0213 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0299 - accuracy: 0.9914 - val_loss: 6.8934 - val_accuracy: 0.5862\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0183 - accuracy: 1.0000 - val_loss: 6.9910 - val_accuracy: 0.5862\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0205 - accuracy: 0.9914 - val_loss: 7.0638 - val_accuracy: 0.5862\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0233 - accuracy: 0.9914 - val_loss: 7.2378 - val_accuracy: 0.5862\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0142 - accuracy: 1.0000 - val_loss: 7.3042 - val_accuracy: 0.5862\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 7.3816 - val_accuracy: 0.5862\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 1.00 - 0s 189us/sample - loss: 0.0149 - accuracy: 0.9914 - val_loss: 7.6385 - val_accuracy: 0.5862\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 164us/sample - loss: 0.0171 - accuracy: 1.0000 - val_loss: 7.5295 - val_accuracy: 0.5517\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0876 - accuracy: 0.9828 - val_loss: 7.6668 - val_accuracy: 0.6207\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.96 - 0s 181us/sample - loss: 0.1113 - accuracy: 0.9483 - val_loss: 6.9332 - val_accuracy: 0.5517\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 181us/sample - loss: 0.0391 - accuracy: 0.9828 - val_loss: 6.1946 - val_accuracy: 0.5862\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 1.00 - 0s 172us/sample - loss: 0.1047 - accuracy: 0.9655 - val_loss: 6.7089 - val_accuracy: 0.4828\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 1.00 - 0s 172us/sample - loss: 0.1509 - accuracy: 0.9483 - val_loss: 6.7096 - val_accuracy: 0.6552\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.96 - 0s 181us/sample - loss: 0.1457 - accuracy: 0.9397 - val_loss: 5.8447 - val_accuracy: 0.5862\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1932 - accuracy: 0.9483 - val_loss: 5.8761 - val_accuracy: 0.4828\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2469 - accuracy: 0.87 - 0s 163us/sample - loss: 0.2176 - accuracy: 0.9224 - val_loss: 6.3554 - val_accuracy: 0.5172\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2182 - accuracy: 0.8793 - val_loss: 6.0368 - val_accuracy: 0.6207\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2900 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2958 - accuracy: 0.8793 - val_loss: 5.2089 - val_accuracy: 0.4483\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.87 - 0s 163us/sample - loss: 0.2438 - accuracy: 0.8534 - val_loss: 4.5178 - val_accuracy: 0.5862\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2719 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1794 - accuracy: 0.9224 - val_loss: 4.0830 - val_accuracy: 0.6552\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1337 - accuracy: 0.9569 - val_loss: 3.8059 - val_accuracy: 0.5517\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1282 - accuracy: 0.9655 - val_loss: 3.8486 - val_accuracy: 0.5862\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0916 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0810 - accuracy: 0.9828 - val_loss: 4.0654 - val_accuracy: 0.6207\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0927 - accuracy: 0.9569 - val_loss: 4.2409 - val_accuracy: 0.6207\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0688 - accuracy: 0.9741 - val_loss: 4.5151 - val_accuracy: 0.5862\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0668 - accuracy: 0.9828 - val_loss: 4.8921 - val_accuracy: 0.5862\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0904 - accuracy: 0.9569 - val_loss: 5.0020 - val_accuracy: 0.5862\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0583 - accuracy: 0.9741 - val_loss: 5.2415 - val_accuracy: 0.5862\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 1.00 - 0s 180us/sample - loss: 0.0605 - accuracy: 0.9828 - val_loss: 5.3736 - val_accuracy: 0.5862\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0411 - accuracy: 0.9828 - val_loss: 5.5113 - val_accuracy: 0.5862\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0385 - accuracy: 0.9914 - val_loss: 5.8340 - val_accuracy: 0.5862\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0303 - accuracy: 1.0000 - val_loss: 6.0266 - val_accuracy: 0.5862\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 1.00 - 0s 232us/sample - loss: 0.0272 - accuracy: 1.0000 - val_loss: 6.1324 - val_accuracy: 0.5862\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0225 - accuracy: 1.0000 - val_loss: 6.4031 - val_accuracy: 0.5862\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0291 - accuracy: 0.9828 - val_loss: 6.4655 - val_accuracy: 0.5862\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0155 - accuracy: 1.0000 - val_loss: 6.8669 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0270 - accuracy: 0.9914 - val_loss: 6.7842 - val_accuracy: 0.5862\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0206 - accuracy: 0.9914 - val_loss: 6.8614 - val_accuracy: 0.5862\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0211 - accuracy: 0.9914 - val_loss: 7.1555 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0206 - accuracy: 1.0000 - val_loss: 7.1213 - val_accuracy: 0.5862\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0276 - accuracy: 0.9914 - val_loss: 7.1128 - val_accuracy: 0.5862\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0286 - accuracy: 0.9914 - val_loss: 7.4787 - val_accuracy: 0.5862\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0562 - accuracy: 0.9741 - val_loss: 7.4816 - val_accuracy: 0.5862\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1689 - accuracy: 0.9655 - val_loss: 7.2977 - val_accuracy: 0.5862\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0876 - accuracy: 0.9569 - val_loss: 7.1362 - val_accuracy: 0.5172\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0457 - accuracy: 0.9828 - val_loss: 6.9811 - val_accuracy: 0.6552\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1475 - accuracy: 0.9397 - val_loss: 6.6535 - val_accuracy: 0.4828\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 1.00 - 0s 189us/sample - loss: 0.2555 - accuracy: 0.9052 - val_loss: 6.5224 - val_accuracy: 0.5862\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1238 - accuracy: 0.9569 - val_loss: 6.2571 - val_accuracy: 0.5517\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0742 - accuracy: 0.9741 - val_loss: 5.7092 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0487 - accuracy: 0.9914 - val_loss: 5.7532 - val_accuracy: 0.5862\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0377 - accuracy: 0.9828 - val_loss: 6.0060 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0452 - accuracy: 0.9741 - val_loss: 6.0260 - val_accuracy: 0.5862\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0429 - accuracy: 0.9914 - val_loss: 6.0007 - val_accuracy: 0.5862\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0357 - accuracy: 0.9914 - val_loss: 6.3829 - val_accuracy: 0.5862\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0288 - accuracy: 1.0000 - val_loss: 6.6407 - val_accuracy: 0.5862\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7105 - accuracy: 0.40 - 0s 3ms/sample - loss: 0.6816 - accuracy: 0.6121 - val_loss: 0.6295 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5038 - accuracy: 0.81 - 0s 146us/sample - loss: 0.6350 - accuracy: 0.6638 - val_loss: 0.6210 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6701 - accuracy: 0.56 - 0s 164us/sample - loss: 0.6315 - accuracy: 0.6638 - val_loss: 0.6192 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6182 - accuracy: 0.68 - 0s 146us/sample - loss: 0.5957 - accuracy: 0.6638 - val_loss: 0.6050 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5691 - accuracy: 0.65 - 0s 164us/sample - loss: 0.5970 - accuracy: 0.6983 - val_loss: 0.5755 - val_accuracy: 0.6897\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5989 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5642 - accuracy: 0.7155 - val_loss: 0.5800 - val_accuracy: 0.6897\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5424 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5551 - accuracy: 0.7414 - val_loss: 0.5835 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5317 - accuracy: 0.78 - 0s 155us/sample - loss: 0.5343 - accuracy: 0.7328 - val_loss: 0.5927 - val_accuracy: 0.5862\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4165 - accuracy: 0.87 - 0s 164us/sample - loss: 0.5050 - accuracy: 0.7500 - val_loss: 0.5984 - val_accuracy: 0.6207\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4012 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4899 - accuracy: 0.7672 - val_loss: 0.6361 - val_accuracy: 0.5862\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5451 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4774 - accuracy: 0.7759 - val_loss: 0.6356 - val_accuracy: 0.6897\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5010 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4719 - accuracy: 0.7586 - val_loss: 0.6490 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4764 - accuracy: 0.71 - 0s 138us/sample - loss: 0.4372 - accuracy: 0.7672 - val_loss: 0.6645 - val_accuracy: 0.6897\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5290 - accuracy: 0.75 - 0s 155us/sample - loss: 0.4286 - accuracy: 0.7759 - val_loss: 0.7095 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4622 - accuracy: 0.75 - 0s 137us/sample - loss: 0.4058 - accuracy: 0.8017 - val_loss: 0.6933 - val_accuracy: 0.6897\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4384 - accuracy: 0.75 - 0s 155us/sample - loss: 0.3954 - accuracy: 0.7931 - val_loss: 0.7603 - val_accuracy: 0.6552\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5745 - accuracy: 0.65 - 0s 155us/sample - loss: 0.3825 - accuracy: 0.8017 - val_loss: 0.8257 - val_accuracy: 0.6552\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.87 - 0s 138us/sample - loss: 0.4081 - accuracy: 0.8190 - val_loss: 0.9383 - val_accuracy: 0.6552\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.96 - 0s 138us/sample - loss: 0.3630 - accuracy: 0.8362 - val_loss: 1.0626 - val_accuracy: 0.5862\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3076 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3421 - accuracy: 0.8362 - val_loss: 0.9276 - val_accuracy: 0.6207\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2245 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3445 - accuracy: 0.8448 - val_loss: 1.0784 - val_accuracy: 0.5862\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3290 - accuracy: 0.8276 - val_loss: 0.9895 - val_accuracy: 0.6552\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3478 - accuracy: 0.8362 - val_loss: 1.2597 - val_accuracy: 0.6207\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3797 - accuracy: 0.87 - 0s 198us/sample - loss: 0.3788 - accuracy: 0.8103 - val_loss: 1.1314 - val_accuracy: 0.6207\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.87 - 0s 198us/sample - loss: 0.3084 - accuracy: 0.8534 - val_loss: 1.2096 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 1.00 - 0s 146us/sample - loss: 0.2956 - accuracy: 0.8707 - val_loss: 1.0432 - val_accuracy: 0.6552\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.71 - 0s 155us/sample - loss: 0.2750 - accuracy: 0.8707 - val_loss: 1.0839 - val_accuracy: 0.6207\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2314 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2731 - accuracy: 0.8793 - val_loss: 1.1953 - val_accuracy: 0.5862\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2379 - accuracy: 0.8966 - val_loss: 1.2782 - val_accuracy: 0.6207\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1954 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2065 - accuracy: 0.9224 - val_loss: 1.4748 - val_accuracy: 0.6207\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2921 - accuracy: 0.87 - 0s 129us/sample - loss: 0.1951 - accuracy: 0.9397 - val_loss: 1.6484 - val_accuracy: 0.6207\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1942 - accuracy: 0.9224 - val_loss: 1.7864 - val_accuracy: 0.6207\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1946 - accuracy: 0.9224 - val_loss: 1.8264 - val_accuracy: 0.6552\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1485 - accuracy: 0.9569 - val_loss: 2.0718 - val_accuracy: 0.6207\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1470 - accuracy: 0.9397 - val_loss: 2.2797 - val_accuracy: 0.6207\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1156 - accuracy: 0.9569 - val_loss: 2.3687 - val_accuracy: 0.5862\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1047 - accuracy: 0.9655 - val_loss: 2.5807 - val_accuracy: 0.5862\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1065 - accuracy: 0.9741 - val_loss: 2.8458 - val_accuracy: 0.5862\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1033 - accuracy: 0.9569 - val_loss: 2.8804 - val_accuracy: 0.6207\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3931 - accuracy: 0.81 - 0s 267us/sample - loss: 0.1773 - accuracy: 0.9224 - val_loss: 2.9132 - val_accuracy: 0.6552\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4546 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2220 - accuracy: 0.9224 - val_loss: 2.9342 - val_accuracy: 0.6207\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1188 - accuracy: 0.9397 - val_loss: 2.7059 - val_accuracy: 0.5862\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 1.00 - 0s 146us/sample - loss: 0.2109 - accuracy: 0.9397 - val_loss: 2.5993 - val_accuracy: 0.6207\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1070 - accuracy: 0.9655 - val_loss: 2.8958 - val_accuracy: 0.6207\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1603 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1489 - accuracy: 0.9483 - val_loss: 2.9367 - val_accuracy: 0.6207\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1392 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2277 - accuracy: 0.8966 - val_loss: 2.6771 - val_accuracy: 0.6552\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1906 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2166 - accuracy: 0.9224 - val_loss: 2.2701 - val_accuracy: 0.6897\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3355 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1875 - accuracy: 0.9310 - val_loss: 2.4405 - val_accuracy: 0.6552\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1667 - accuracy: 0.9224 - val_loss: 2.4500 - val_accuracy: 0.6207\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1498 - accuracy: 0.9138 - val_loss: 2.4758 - val_accuracy: 0.6207\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1305 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1255 - accuracy: 0.9655 - val_loss: 2.6170 - val_accuracy: 0.6207\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1196 - accuracy: 0.9397 - val_loss: 2.6921 - val_accuracy: 0.6207\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1250 - accuracy: 0.93 - 0s 137us/sample - loss: 0.1115 - accuracy: 0.9655 - val_loss: 2.8979 - val_accuracy: 0.6207\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0339 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1251 - accuracy: 0.9483 - val_loss: 3.1688 - val_accuracy: 0.6207\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 1.00 - 0s 137us/sample - loss: 0.1629 - accuracy: 0.9224 - val_loss: 3.0679 - val_accuracy: 0.6207\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0974 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1488 - accuracy: 0.9397 - val_loss: 2.9033 - val_accuracy: 0.6552\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2749 - accuracy: 0.84 - 0s 138us/sample - loss: 0.1444 - accuracy: 0.9310 - val_loss: 3.0374 - val_accuracy: 0.6207\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1100 - accuracy: 0.9655 - val_loss: 2.9492 - val_accuracy: 0.6552\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1025 - accuracy: 0.9569 - val_loss: 3.0848 - val_accuracy: 0.6552\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.93 - 0s 137us/sample - loss: 0.0623 - accuracy: 0.9655 - val_loss: 3.3258 - val_accuracy: 0.6207\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0564 - accuracy: 0.9914 - val_loss: 3.5881 - val_accuracy: 0.6207\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0518 - accuracy: 0.9828 - val_loss: 3.6614 - val_accuracy: 0.6552\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0455 - accuracy: 0.9828 - val_loss: 3.7151 - val_accuracy: 0.6552\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0315 - accuracy: 1.0000 - val_loss: 3.9939 - val_accuracy: 0.6207\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0356 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0314 - accuracy: 0.9914 - val_loss: 4.2179 - val_accuracy: 0.6207\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0293 - accuracy: 1.0000 - val_loss: 4.3282 - val_accuracy: 0.6552\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0200 - accuracy: 1.0000 - val_loss: 4.5291 - val_accuracy: 0.6552\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0388 - accuracy: 0.9828 - val_loss: 4.7099 - val_accuracy: 0.6207\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0539 - accuracy: 0.9741 - val_loss: 4.7665 - val_accuracy: 0.6552\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0733 - accuracy: 0.9655 - val_loss: 4.8372 - val_accuracy: 0.6552\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1203 - accuracy: 0.9569 - val_loss: 5.1541 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1793 - accuracy: 0.9483 - val_loss: 4.5864 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2478 - accuracy: 0.9310 - val_loss: 4.2223 - val_accuracy: 0.6207\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1670 - accuracy: 0.93 - 0s 137us/sample - loss: 0.2226 - accuracy: 0.9310 - val_loss: 4.1004 - val_accuracy: 0.6207\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1140 - accuracy: 0.9655 - val_loss: 3.8563 - val_accuracy: 0.6207\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0934 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0787 - accuracy: 0.9655 - val_loss: 3.6910 - val_accuracy: 0.6207\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1302 - accuracy: 0.9569 - val_loss: 3.5804 - val_accuracy: 0.6552\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0822 - accuracy: 0.9741 - val_loss: 3.4558 - val_accuracy: 0.6552\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0537 - accuracy: 0.9828 - val_loss: 3.4633 - val_accuracy: 0.6552\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0513 - accuracy: 0.9828 - val_loss: 3.7980 - val_accuracy: 0.6207\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0480 - accuracy: 0.9914 - val_loss: 3.9633 - val_accuracy: 0.6207\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0423 - accuracy: 0.9828 - val_loss: 4.0707 - val_accuracy: 0.6552\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0284 - accuracy: 0.9914 - val_loss: 4.1746 - val_accuracy: 0.6552\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0219 - accuracy: 1.0000 - val_loss: 4.2670 - val_accuracy: 0.6552\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0187 - accuracy: 1.0000 - val_loss: 4.4388 - val_accuracy: 0.6552\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0207 - accuracy: 1.0000 - val_loss: 4.5549 - val_accuracy: 0.6207\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0197 - accuracy: 0.9914 - val_loss: 4.6889 - val_accuracy: 0.6552\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 4.8142 - val_accuracy: 0.6207\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0109 - accuracy: 1.0000 - val_loss: 4.9254 - val_accuracy: 0.6207\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 5.0131 - val_accuracy: 0.6552\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 5.0958 - val_accuracy: 0.6552\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 5.1805 - val_accuracy: 0.6552\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 5.2679 - val_accuracy: 0.6552\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 5.3603 - val_accuracy: 0.6552\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 5.4355 - val_accuracy: 0.6552\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 5.4963 - val_accuracy: 0.6552\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 5.5436 - val_accuracy: 0.6552\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 5.5896 - val_accuracy: 0.6552\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 5.6365 - val_accuracy: 0.6552\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 5.6831 - val_accuracy: 0.6552\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.7278 - val_accuracy: 0.6552\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.1077e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 5.7696 - val_accuracy: 0.6552\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 5.8085 - val_accuracy: 0.6552\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0207e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 5.8464 - val_accuracy: 0.6552\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 5.8845 - val_accuracy: 0.6552\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.9184 - val_accuracy: 0.6552\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 5.9473 - val_accuracy: 0.6552\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.5356e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 5.9756 - val_accuracy: 0.6552\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 146us/sample - loss: 9.6382e-04 - accuracy: 1.0000 - val_loss: 6.0035 - val_accuracy: 0.6552\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8431e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.2130e-04 - accuracy: 1.0000 - val_loss: 6.0310 - val_accuracy: 0.6552\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 137us/sample - loss: 8.9920e-04 - accuracy: 1.0000 - val_loss: 6.0626 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 146us/sample - loss: 8.3239e-04 - accuracy: 1.0000 - val_loss: 6.0950 - val_accuracy: 0.6552\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5851e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.7433e-04 - accuracy: 1.0000 - val_loss: 6.1256 - val_accuracy: 0.6552\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3946e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.8710e-04 - accuracy: 1.0000 - val_loss: 6.1542 - val_accuracy: 0.6552\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9914e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.2939e-04 - accuracy: 1.0000 - val_loss: 6.1833 - val_accuracy: 0.6552\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2475e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.8016e-04 - accuracy: 1.0000 - val_loss: 6.2108 - val_accuracy: 0.6552\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7807e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.6492e-04 - accuracy: 1.0000 - val_loss: 6.2384 - val_accuracy: 0.6552\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6120e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.5252e-04 - accuracy: 1.0000 - val_loss: 6.2639 - val_accuracy: 0.6552\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4827e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.0889e-04 - accuracy: 1.0000 - val_loss: 6.2864 - val_accuracy: 0.6552\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4837e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.9059e-04 - accuracy: 1.0000 - val_loss: 6.3114 - val_accuracy: 0.6552\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6266e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.7241e-04 - accuracy: 1.0000 - val_loss: 6.3352 - val_accuracy: 0.6552\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0163e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.4119e-04 - accuracy: 1.0000 - val_loss: 6.3618 - val_accuracy: 0.6552\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4620e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.2036e-04 - accuracy: 1.0000 - val_loss: 6.3880 - val_accuracy: 0.6552\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2283e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.0721e-04 - accuracy: 1.0000 - val_loss: 6.4127 - val_accuracy: 0.6552\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7873e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.0859e-04 - accuracy: 1.0000 - val_loss: 6.4408 - val_accuracy: 0.6552\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8272e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.7465e-04 - accuracy: 1.0000 - val_loss: 6.4655 - val_accuracy: 0.6552\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3287e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.5746e-04 - accuracy: 1.0000 - val_loss: 6.4913 - val_accuracy: 0.6552\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8657e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.3396e-04 - accuracy: 1.0000 - val_loss: 6.5170 - val_accuracy: 0.6552\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1442e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.2398e-04 - accuracy: 1.0000 - val_loss: 6.5414 - val_accuracy: 0.6552\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6935e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.1437e-04 - accuracy: 1.0000 - val_loss: 6.5660 - val_accuracy: 0.6552\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4982e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.9598e-04 - accuracy: 1.0000 - val_loss: 6.5921 - val_accuracy: 0.6552\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4937e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.8682e-04 - accuracy: 1.0000 - val_loss: 6.6187 - val_accuracy: 0.6552\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8562e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 3.7236e-04 - accuracy: 1.0000 - val_loss: 6.6482 - val_accuracy: 0.6552\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5322e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.7245e-04 - accuracy: 1.0000 - val_loss: 6.6770 - val_accuracy: 0.6552\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0872e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.5269e-04 - accuracy: 1.0000 - val_loss: 6.7029 - val_accuracy: 0.6552\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0291e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.3793e-04 - accuracy: 1.0000 - val_loss: 6.7280 - val_accuracy: 0.6552\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3278e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.2976e-04 - accuracy: 1.0000 - val_loss: 6.7544 - val_accuracy: 0.6552\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7889e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.2039e-04 - accuracy: 1.0000 - val_loss: 6.7834 - val_accuracy: 0.6552\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1048e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.0871e-04 - accuracy: 1.0000 - val_loss: 6.8116 - val_accuracy: 0.6552\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4008e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.9712e-04 - accuracy: 1.0000 - val_loss: 6.8400 - val_accuracy: 0.6552\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0796e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.9257e-04 - accuracy: 1.0000 - val_loss: 6.8703 - val_accuracy: 0.6552\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2348e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.8251e-04 - accuracy: 1.0000 - val_loss: 6.9018 - val_accuracy: 0.6552\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1335e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.7948e-04 - accuracy: 1.0000 - val_loss: 6.9324 - val_accuracy: 0.6552\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3345e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.7114e-04 - accuracy: 1.0000 - val_loss: 6.9627 - val_accuracy: 0.6552\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5747e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.5864e-04 - accuracy: 1.0000 - val_loss: 6.9866 - val_accuracy: 0.6552\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0618e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.5104e-04 - accuracy: 1.0000 - val_loss: 7.0168 - val_accuracy: 0.6552\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2050e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.4344e-04 - accuracy: 1.0000 - val_loss: 7.0467 - val_accuracy: 0.6552\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8191e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.3518e-04 - accuracy: 1.0000 - val_loss: 7.0785 - val_accuracy: 0.6552\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1484e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.2917e-04 - accuracy: 1.0000 - val_loss: 7.1114 - val_accuracy: 0.6552\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2658e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.2442e-04 - accuracy: 1.0000 - val_loss: 7.1388 - val_accuracy: 0.6552\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9621e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.1567e-04 - accuracy: 1.0000 - val_loss: 7.1725 - val_accuracy: 0.6552\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6196e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.1082e-04 - accuracy: 1.0000 - val_loss: 7.2032 - val_accuracy: 0.6552\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6517e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.0337e-04 - accuracy: 1.0000 - val_loss: 7.2300 - val_accuracy: 0.6552\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4260e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.9761e-04 - accuracy: 1.0000 - val_loss: 7.2607 - val_accuracy: 0.6552\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4406e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.9094e-04 - accuracy: 1.0000 - val_loss: 7.2889 - val_accuracy: 0.6552\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0556e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 1.8987e-04 - accuracy: 1.0000 - val_loss: 7.3183 - val_accuracy: 0.6552\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5947e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.8260e-04 - accuracy: 1.0000 - val_loss: 7.3501 - val_accuracy: 0.6552\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3603e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.7674e-04 - accuracy: 1.0000 - val_loss: 7.3827 - val_accuracy: 0.6552\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1462e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.7169e-04 - accuracy: 1.0000 - val_loss: 7.4176 - val_accuracy: 0.6552\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2778e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.6557e-04 - accuracy: 1.0000 - val_loss: 7.4481 - val_accuracy: 0.6552\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2191e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.6267e-04 - accuracy: 1.0000 - val_loss: 7.4783 - val_accuracy: 0.6552\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8173e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.5863e-04 - accuracy: 1.0000 - val_loss: 7.5145 - val_accuracy: 0.6552\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7088e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5476e-04 - accuracy: 1.0000 - val_loss: 7.5457 - val_accuracy: 0.6552\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2588e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.4984e-04 - accuracy: 1.0000 - val_loss: 7.5700 - val_accuracy: 0.6552\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7881e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4463e-04 - accuracy: 1.0000 - val_loss: 7.5998 - val_accuracy: 0.6552\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4073e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4376e-04 - accuracy: 1.0000 - val_loss: 7.6264 - val_accuracy: 0.6552\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0467e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.3826e-04 - accuracy: 1.0000 - val_loss: 7.6627 - val_accuracy: 0.6552\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8695e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3318e-04 - accuracy: 1.0000 - val_loss: 7.6948 - val_accuracy: 0.6552\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4509e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.3166e-04 - accuracy: 1.0000 - val_loss: 7.7226 - val_accuracy: 0.6552\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9946e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.2791e-04 - accuracy: 1.0000 - val_loss: 7.7583 - val_accuracy: 0.6552\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0187e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.2307e-04 - accuracy: 1.0000 - val_loss: 7.7886 - val_accuracy: 0.6552\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0463e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.1972e-04 - accuracy: 1.0000 - val_loss: 7.8161 - val_accuracy: 0.6552\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3867e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.1777e-04 - accuracy: 1.0000 - val_loss: 7.8452 - val_accuracy: 0.6552\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4390e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.1436e-04 - accuracy: 1.0000 - val_loss: 7.8771 - val_accuracy: 0.6552\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7397e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1127e-04 - accuracy: 1.0000 - val_loss: 7.9092 - val_accuracy: 0.6552\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4768e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0899e-04 - accuracy: 1.0000 - val_loss: 7.9421 - val_accuracy: 0.6552\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2917e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.0588e-04 - accuracy: 1.0000 - val_loss: 7.9702 - val_accuracy: 0.6552\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8623e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0317e-04 - accuracy: 1.0000 - val_loss: 8.0007 - val_accuracy: 0.6552\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4589e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0115e-04 - accuracy: 1.0000 - val_loss: 8.0279 - val_accuracy: 0.6552\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5678e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 9.8361e-05 - accuracy: 1.0000 - val_loss: 8.0524 - val_accuracy: 0.6552\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.8655e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 9.6056e-05 - accuracy: 1.0000 - val_loss: 8.0788 - val_accuracy: 0.6552\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4708e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.3383e-05 - accuracy: 1.0000 - val_loss: 8.1043 - val_accuracy: 0.6552\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1916e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 9.1157e-05 - accuracy: 1.0000 - val_loss: 8.1329 - val_accuracy: 0.6552\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5172e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 9.0710e-05 - accuracy: 1.0000 - val_loss: 8.1611 - val_accuracy: 0.6552\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1376e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.7262e-05 - accuracy: 1.0000 - val_loss: 8.1910 - val_accuracy: 0.6552\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9210e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.5304e-05 - accuracy: 1.0000 - val_loss: 8.2206 - val_accuracy: 0.6552\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9445e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 8.3593e-05 - accuracy: 1.0000 - val_loss: 8.2492 - val_accuracy: 0.6552\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6110e-04 - accuracy: 1.00 - 0s 198us/sample - loss: 8.1762e-05 - accuracy: 1.0000 - val_loss: 8.2789 - val_accuracy: 0.6552\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.6151e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.0830e-05 - accuracy: 1.0000 - val_loss: 8.3082 - val_accuracy: 0.6552\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0114e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 7.8574e-05 - accuracy: 1.0000 - val_loss: 8.3323 - val_accuracy: 0.6552\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5625e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 7.6281e-05 - accuracy: 1.0000 - val_loss: 8.3567 - val_accuracy: 0.6552\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4322e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.5566e-05 - accuracy: 1.0000 - val_loss: 8.3840 - val_accuracy: 0.6552\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1423e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 7.3185e-05 - accuracy: 1.0000 - val_loss: 8.4089 - val_accuracy: 0.6552\n",
      "Epoch 194/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 5.4082e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.2465e-05 - accuracy: 1.0000 - val_loss: 8.4310 - val_accuracy: 0.6552\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6047e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.0380e-05 - accuracy: 1.0000 - val_loss: 8.4564 - val_accuracy: 0.6552\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7301e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 6.9091e-05 - accuracy: 1.0000 - val_loss: 8.4856 - val_accuracy: 0.6552\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3394e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 6.8063e-05 - accuracy: 1.0000 - val_loss: 8.5155 - val_accuracy: 0.6552\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7134e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.6459e-05 - accuracy: 1.0000 - val_loss: 8.5423 - val_accuracy: 0.6552\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4134e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.5061e-05 - accuracy: 1.0000 - val_loss: 8.5662 - val_accuracy: 0.6552\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4405e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.3502e-05 - accuracy: 1.0000 - val_loss: 8.5889 - val_accuracy: 0.6552\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 1s - loss: 0.6922 - accuracy: 0.56 - 1s 7ms/sample - loss: 0.6809 - accuracy: 0.6034 - val_loss: 0.6321 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6716 - accuracy: 0.56 - 0s 163us/sample - loss: 0.6276 - accuracy: 0.6638 - val_loss: 0.6171 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4935 - accuracy: 0.71 - 0s 146us/sample - loss: 0.6406 - accuracy: 0.6638 - val_loss: 0.6102 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6265 - accuracy: 0.59 - 0s 146us/sample - loss: 0.6136 - accuracy: 0.6638 - val_loss: 0.6525 - val_accuracy: 0.7241\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.71 - 0s 146us/sample - loss: 0.6337 - accuracy: 0.7328 - val_loss: 0.6321 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6128 - accuracy: 0.75 - 0s 146us/sample - loss: 0.5978 - accuracy: 0.6810 - val_loss: 0.6040 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6405 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5769 - accuracy: 0.6983 - val_loss: 0.6197 - val_accuracy: 0.5862\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.87 - 0s 146us/sample - loss: 0.5427 - accuracy: 0.7155 - val_loss: 0.6226 - val_accuracy: 0.6207\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5163 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5638 - accuracy: 0.7155 - val_loss: 0.6087 - val_accuracy: 0.5862\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5342 - accuracy: 0.75 - 0s 146us/sample - loss: 0.5372 - accuracy: 0.7672 - val_loss: 0.6584 - val_accuracy: 0.6207\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5904 - accuracy: 0.65 - 0s 146us/sample - loss: 0.5321 - accuracy: 0.7414 - val_loss: 0.6017 - val_accuracy: 0.6207\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6466 - accuracy: 0.62 - 0s 146us/sample - loss: 0.5283 - accuracy: 0.7328 - val_loss: 0.6128 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5107 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5041 - accuracy: 0.7586 - val_loss: 0.6382 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6491 - accuracy: 0.65 - 0s 155us/sample - loss: 0.4900 - accuracy: 0.7672 - val_loss: 0.6831 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5429 - accuracy: 0.71 - 0s 146us/sample - loss: 0.4735 - accuracy: 0.7672 - val_loss: 0.6634 - val_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4461 - accuracy: 0.75 - 0s 163us/sample - loss: 0.4583 - accuracy: 0.7586 - val_loss: 0.6451 - val_accuracy: 0.6552\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.81 - 0s 172us/sample - loss: 0.4506 - accuracy: 0.7931 - val_loss: 0.6660 - val_accuracy: 0.6552\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3470 - accuracy: 0.84 - 0s 172us/sample - loss: 0.4336 - accuracy: 0.7845 - val_loss: 0.6835 - val_accuracy: 0.6552\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4698 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4293 - accuracy: 0.7931 - val_loss: 0.6677 - val_accuracy: 0.6552\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2866 - accuracy: 0.90 - 0s 138us/sample - loss: 0.4316 - accuracy: 0.7931 - val_loss: 0.6677 - val_accuracy: 0.6897\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5088 - accuracy: 0.71 - 0s 155us/sample - loss: 0.3994 - accuracy: 0.8103 - val_loss: 0.7799 - val_accuracy: 0.6552\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3943 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3803 - accuracy: 0.8190 - val_loss: 0.7305 - val_accuracy: 0.6897\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3558 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3660 - accuracy: 0.8190 - val_loss: 0.7782 - val_accuracy: 0.6897\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3776 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3783 - accuracy: 0.8362 - val_loss: 0.7695 - val_accuracy: 0.6897\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2818 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3336 - accuracy: 0.8534 - val_loss: 0.9795 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3837 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3604 - accuracy: 0.8362 - val_loss: 0.9499 - val_accuracy: 0.6897\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3437 - accuracy: 0.8017 - val_loss: 0.9017 - val_accuracy: 0.6552\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4103 - accuracy: 0.78 - 0s 137us/sample - loss: 0.3595 - accuracy: 0.7931 - val_loss: 1.0139 - val_accuracy: 0.7241\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3330 - accuracy: 0.8276 - val_loss: 0.9483 - val_accuracy: 0.6897\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5498 - accuracy: 0.71 - 0s 155us/sample - loss: 0.3431 - accuracy: 0.8448 - val_loss: 0.8956 - val_accuracy: 0.6897\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2086 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3068 - accuracy: 0.8448 - val_loss: 0.9337 - val_accuracy: 0.6897\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2664 - accuracy: 0.8793 - val_loss: 1.1551 - val_accuracy: 0.6207\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2190 - accuracy: 0.93 - 0s 146us/sample - loss: 0.3137 - accuracy: 0.8621 - val_loss: 1.1458 - val_accuracy: 0.6897\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1305 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2327 - accuracy: 0.9310 - val_loss: 1.0840 - val_accuracy: 0.7241\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2456 - accuracy: 0.8879 - val_loss: 1.2694 - val_accuracy: 0.6552\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1825 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2364 - accuracy: 0.8879 - val_loss: 1.3313 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2489 - accuracy: 0.9052 - val_loss: 1.5829 - val_accuracy: 0.6207\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2249 - accuracy: 0.8966 - val_loss: 1.4314 - val_accuracy: 0.6207\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1683 - accuracy: 0.9310 - val_loss: 1.6290 - val_accuracy: 0.5862\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2045 - accuracy: 0.87 - 0s 163us/sample - loss: 0.1690 - accuracy: 0.9052 - val_loss: 1.8535 - val_accuracy: 0.6897\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2337 - accuracy: 0.9138 - val_loss: 1.4435 - val_accuracy: 0.6897\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2862 - accuracy: 0.8793 - val_loss: 1.3373 - val_accuracy: 0.6207\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1855 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2433 - accuracy: 0.8793 - val_loss: 1.2042 - val_accuracy: 0.5862\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1589 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2260 - accuracy: 0.8879 - val_loss: 1.1023 - val_accuracy: 0.6552\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2041 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1794 - accuracy: 0.9138 - val_loss: 1.3895 - val_accuracy: 0.6207\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 1.00 - 0s 181us/sample - loss: 0.1665 - accuracy: 0.9397 - val_loss: 1.5053 - val_accuracy: 0.7241\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1758 - accuracy: 0.9052 - val_loss: 1.6072 - val_accuracy: 0.5172\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1816 - accuracy: 0.9310 - val_loss: 1.4747 - val_accuracy: 0.7241\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.93 - 0s 189us/sample - loss: 0.1821 - accuracy: 0.9310 - val_loss: 1.5225 - val_accuracy: 0.7241\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1817 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1203 - accuracy: 0.9569 - val_loss: 1.5175 - val_accuracy: 0.6897\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1365 - accuracy: 0.93 - 0s 137us/sample - loss: 0.0870 - accuracy: 0.9741 - val_loss: 1.6866 - val_accuracy: 0.6897\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0958 - accuracy: 0.9828 - val_loss: 1.9421 - val_accuracy: 0.6897\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0788 - accuracy: 0.9828 - val_loss: 2.1593 - val_accuracy: 0.6897\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 1.00 - 0s 181us/sample - loss: 0.0939 - accuracy: 0.9569 - val_loss: 2.4257 - val_accuracy: 0.5172\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2661 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1515 - accuracy: 0.9310 - val_loss: 2.1574 - val_accuracy: 0.6897\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1058 - accuracy: 0.9397 - val_loss: 2.2122 - val_accuracy: 0.4828\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1012 - accuracy: 0.9483 - val_loss: 2.1033 - val_accuracy: 0.6207\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1138 - accuracy: 0.9397 - val_loss: 2.0116 - val_accuracy: 0.6552\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1092 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1025 - accuracy: 0.9483 - val_loss: 2.0383 - val_accuracy: 0.6207\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0698 - accuracy: 0.9828 - val_loss: 2.0977 - val_accuracy: 0.7241\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1502 - accuracy: 0.90 - 0s 155us/sample - loss: 0.0760 - accuracy: 0.9569 - val_loss: 2.3504 - val_accuracy: 0.6207\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2622 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1072 - accuracy: 0.9741 - val_loss: 2.0022 - val_accuracy: 0.6552\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1357 - accuracy: 0.93 - 0s 172us/sample - loss: 0.0774 - accuracy: 0.9569 - val_loss: 1.8647 - val_accuracy: 0.6207\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0400 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0659 - accuracy: 0.9828 - val_loss: 2.1703 - val_accuracy: 0.6897\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0928 - accuracy: 0.9655 - val_loss: 2.4837 - val_accuracy: 0.5862\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0390 - accuracy: 1.0000 - val_loss: 2.2203 - val_accuracy: 0.6552\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0450 - accuracy: 0.9828 - val_loss: 2.2638 - val_accuracy: 0.6897\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 189us/sample - loss: 0.0333 - accuracy: 0.9914 - val_loss: 2.4196 - val_accuracy: 0.6552\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0305 - accuracy: 0.9914 - val_loss: 2.6320 - val_accuracy: 0.6552\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0565 - accuracy: 0.9828 - val_loss: 2.7374 - val_accuracy: 0.6897\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0437 - accuracy: 0.9828 - val_loss: 2.7646 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0286 - accuracy: 0.9914 - val_loss: 2.8199 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0297 - accuracy: 0.9914 - val_loss: 2.8336 - val_accuracy: 0.6552\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0265 - accuracy: 1.0000 - val_loss: 2.9067 - val_accuracy: 0.6207\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.8895 - val_accuracy: 0.6897\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.9585 - val_accuracy: 0.6552\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 3.1417 - val_accuracy: 0.6552\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 3.2971 - val_accuracy: 0.6552\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 3.3792 - val_accuracy: 0.6552\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.4319 - val_accuracy: 0.6552\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.4726 - val_accuracy: 0.6552\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.5397 - val_accuracy: 0.6552\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.6021 - val_accuracy: 0.6552\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.6580 - val_accuracy: 0.6552\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.7239 - val_accuracy: 0.6207\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.7705 - val_accuracy: 0.6207\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0043e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.8150 - val_accuracy: 0.6207\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.8667 - val_accuracy: 0.6207\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.9076 - val_accuracy: 0.6207\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.9509 - val_accuracy: 0.6207\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.9791 - val_accuracy: 0.6207\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.0103 - val_accuracy: 0.6207\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.0442 - val_accuracy: 0.6207\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5558e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 9.9581e-04 - accuracy: 1.0000 - val_loss: 4.0785 - val_accuracy: 0.6207\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8267e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 9.3912e-04 - accuracy: 1.0000 - val_loss: 4.1127 - val_accuracy: 0.6207\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.2170e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 9.0517e-04 - accuracy: 1.0000 - val_loss: 4.1443 - val_accuracy: 0.6207\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 8.7333e-04 - accuracy: 1.0000 - val_loss: 4.1722 - val_accuracy: 0.6207\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6230e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 8.3519e-04 - accuracy: 1.0000 - val_loss: 4.1971 - val_accuracy: 0.6207\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9902e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.2943e-04 - accuracy: 1.0000 - val_loss: 4.2186 - val_accuracy: 0.6207\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 138us/sample - loss: 7.8927e-04 - accuracy: 1.0000 - val_loss: 4.2520 - val_accuracy: 0.6207\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8190e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.4347e-04 - accuracy: 1.0000 - val_loss: 4.2829 - val_accuracy: 0.6207\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8694e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.0036e-04 - accuracy: 1.0000 - val_loss: 4.2986 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 6.8757e-04 - accuracy: 1.0000 - val_loss: 4.3180 - val_accuracy: 0.6207\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9188e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.6843e-04 - accuracy: 1.0000 - val_loss: 4.3430 - val_accuracy: 0.6207\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8068e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.4110e-04 - accuracy: 1.0000 - val_loss: 4.3710 - val_accuracy: 0.6207\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.4655e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.1462e-04 - accuracy: 1.0000 - val_loss: 4.3931 - val_accuracy: 0.6207\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9657e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 6.0418e-04 - accuracy: 1.0000 - val_loss: 4.4156 - val_accuracy: 0.6207\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0542e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.7690e-04 - accuracy: 1.0000 - val_loss: 4.4363 - val_accuracy: 0.6207\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1785e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.6061e-04 - accuracy: 1.0000 - val_loss: 4.4549 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7259e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 5.6169e-04 - accuracy: 1.0000 - val_loss: 4.4753 - val_accuracy: 0.6207\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5728e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.3629e-04 - accuracy: 1.0000 - val_loss: 4.4960 - val_accuracy: 0.6207\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.8231e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.1389e-04 - accuracy: 1.0000 - val_loss: 4.5146 - val_accuracy: 0.6207\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8281e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.0590e-04 - accuracy: 1.0000 - val_loss: 4.5332 - val_accuracy: 0.6207\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9676e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.9575e-04 - accuracy: 1.0000 - val_loss: 4.5472 - val_accuracy: 0.6207\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9344e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.6940e-04 - accuracy: 1.0000 - val_loss: 4.5675 - val_accuracy: 0.6207\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7953e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.5953e-04 - accuracy: 1.0000 - val_loss: 4.5916 - val_accuracy: 0.6207\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5657e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.5292e-04 - accuracy: 1.0000 - val_loss: 4.6127 - val_accuracy: 0.6207\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1812e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.3622e-04 - accuracy: 1.0000 - val_loss: 4.6269 - val_accuracy: 0.6207\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7234e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.2988e-04 - accuracy: 1.0000 - val_loss: 4.6322 - val_accuracy: 0.6207\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3269e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.4078e-04 - accuracy: 1.0000 - val_loss: 4.6403 - val_accuracy: 0.6207\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4442e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 4.1765e-04 - accuracy: 1.0000 - val_loss: 4.6633 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1556e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.9627e-04 - accuracy: 1.0000 - val_loss: 4.6836 - val_accuracy: 0.6207\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8486e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.9547e-04 - accuracy: 1.0000 - val_loss: 4.6990 - val_accuracy: 0.6207\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9059e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.8430e-04 - accuracy: 1.0000 - val_loss: 4.7055 - val_accuracy: 0.6207\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2238e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.6459e-04 - accuracy: 1.0000 - val_loss: 4.7164 - val_accuracy: 0.6207\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3177e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.5574e-04 - accuracy: 1.0000 - val_loss: 4.7355 - val_accuracy: 0.6207\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3420e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.4005e-04 - accuracy: 1.0000 - val_loss: 4.7480 - val_accuracy: 0.6207\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6943e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.2773e-04 - accuracy: 1.0000 - val_loss: 4.7616 - val_accuracy: 0.6207\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9043e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.2083e-04 - accuracy: 1.0000 - val_loss: 4.7728 - val_accuracy: 0.6207\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5509e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.1239e-04 - accuracy: 1.0000 - val_loss: 4.7812 - val_accuracy: 0.6207\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5694e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.0547e-04 - accuracy: 1.0000 - val_loss: 4.7901 - val_accuracy: 0.6207\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3831e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.9247e-04 - accuracy: 1.0000 - val_loss: 4.8042 - val_accuracy: 0.6207\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4892e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.8808e-04 - accuracy: 1.0000 - val_loss: 4.8159 - val_accuracy: 0.6207\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0295e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.8080e-04 - accuracy: 1.0000 - val_loss: 4.8263 - val_accuracy: 0.6207\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1078e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.7544e-04 - accuracy: 1.0000 - val_loss: 4.8345 - val_accuracy: 0.6207\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3349e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.6601e-04 - accuracy: 1.0000 - val_loss: 4.8394 - val_accuracy: 0.6207\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2305e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.4975e-04 - accuracy: 1.0000 - val_loss: 4.8523 - val_accuracy: 0.6207\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9081e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.4714e-04 - accuracy: 1.0000 - val_loss: 4.8646 - val_accuracy: 0.6207\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4525e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.3922e-04 - accuracy: 1.0000 - val_loss: 4.8788 - val_accuracy: 0.6207\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0814e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.3131e-04 - accuracy: 1.0000 - val_loss: 4.8981 - val_accuracy: 0.6207\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1543e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.2572e-04 - accuracy: 1.0000 - val_loss: 4.9127 - val_accuracy: 0.6207\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6296e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.1469e-04 - accuracy: 1.0000 - val_loss: 4.9302 - val_accuracy: 0.6207\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9354e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.0698e-04 - accuracy: 1.0000 - val_loss: 4.9490 - val_accuracy: 0.6207\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0338e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.0074e-04 - accuracy: 1.0000 - val_loss: 4.9690 - val_accuracy: 0.6207\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3480e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 1.9779e-04 - accuracy: 1.0000 - val_loss: 4.9888 - val_accuracy: 0.6207\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6992e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.9295e-04 - accuracy: 1.0000 - val_loss: 5.0060 - val_accuracy: 0.6207\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0812e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.8584e-04 - accuracy: 1.0000 - val_loss: 5.0142 - val_accuracy: 0.6207\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4432e-04 - accuracy: 1.00 - 0s 189us/sample - loss: 1.7794e-04 - accuracy: 1.0000 - val_loss: 5.0310 - val_accuracy: 0.6207\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0904e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7232e-04 - accuracy: 1.0000 - val_loss: 5.0404 - val_accuracy: 0.6207\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4484e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6679e-04 - accuracy: 1.0000 - val_loss: 5.0513 - val_accuracy: 0.6207\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.1918e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.6506e-04 - accuracy: 1.0000 - val_loss: 5.0635 - val_accuracy: 0.6207\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3165e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.6009e-04 - accuracy: 1.0000 - val_loss: 5.0785 - val_accuracy: 0.6207\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6275e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.5528e-04 - accuracy: 1.0000 - val_loss: 5.0946 - val_accuracy: 0.6207\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0116e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5237e-04 - accuracy: 1.0000 - val_loss: 5.1123 - val_accuracy: 0.6207\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9105e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5017e-04 - accuracy: 1.0000 - val_loss: 5.1332 - val_accuracy: 0.6207\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7202e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.4968e-04 - accuracy: 1.0000 - val_loss: 5.1541 - val_accuracy: 0.6207\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.6191e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.4295e-04 - accuracy: 1.0000 - val_loss: 5.1661 - val_accuracy: 0.6207\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2270e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3988e-04 - accuracy: 1.0000 - val_loss: 5.1773 - val_accuracy: 0.6207\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9663e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.4186e-04 - accuracy: 1.0000 - val_loss: 5.1873 - val_accuracy: 0.6207\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9854e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3630e-04 - accuracy: 1.0000 - val_loss: 5.2027 - val_accuracy: 0.6207\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6157e-05 - accuracy: 1.00 - 0s 137us/sample - loss: 1.3189e-04 - accuracy: 1.0000 - val_loss: 5.2183 - val_accuracy: 0.6207\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6385e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2770e-04 - accuracy: 1.0000 - val_loss: 5.2278 - val_accuracy: 0.6207\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7140e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.2436e-04 - accuracy: 1.0000 - val_loss: 5.2370 - val_accuracy: 0.6207\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8556e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.2497e-04 - accuracy: 1.0000 - val_loss: 5.2452 - val_accuracy: 0.6207\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7137e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 1.2212e-04 - accuracy: 1.0000 - val_loss: 5.2580 - val_accuracy: 0.6207\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.1199e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1936e-04 - accuracy: 1.0000 - val_loss: 5.2708 - val_accuracy: 0.6207\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6471e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.1770e-04 - accuracy: 1.0000 - val_loss: 5.2807 - val_accuracy: 0.6207\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5695e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1481e-04 - accuracy: 1.0000 - val_loss: 5.2905 - val_accuracy: 0.6207\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1109e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1302e-04 - accuracy: 1.0000 - val_loss: 5.3032 - val_accuracy: 0.6207\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9768e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0968e-04 - accuracy: 1.0000 - val_loss: 5.3087 - val_accuracy: 0.6207\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3980e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0893e-04 - accuracy: 1.0000 - val_loss: 5.3152 - val_accuracy: 0.6207\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0280e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.0692e-04 - accuracy: 1.0000 - val_loss: 5.3216 - val_accuracy: 0.6207\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0280e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 1.0510e-04 - accuracy: 1.0000 - val_loss: 5.3275 - val_accuracy: 0.6207\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5128e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.0360e-04 - accuracy: 1.0000 - val_loss: 5.3374 - val_accuracy: 0.6207\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1566e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.0259e-04 - accuracy: 1.0000 - val_loss: 5.3493 - val_accuracy: 0.6207\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7587e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0017e-04 - accuracy: 1.0000 - val_loss: 5.3585 - val_accuracy: 0.6207\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4971e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 9.8255e-05 - accuracy: 1.0000 - val_loss: 5.3691 - val_accuracy: 0.6207\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4308e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 9.8928e-05 - accuracy: 1.0000 - val_loss: 5.3791 - val_accuracy: 0.6207\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9739e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 9.7346e-05 - accuracy: 1.0000 - val_loss: 5.3852 - val_accuracy: 0.6207\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0987e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 9.5000e-05 - accuracy: 1.0000 - val_loss: 5.3921 - val_accuracy: 0.6207\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2309e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 9.3365e-05 - accuracy: 1.0000 - val_loss: 5.4008 - val_accuracy: 0.6207\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4249e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 9.1913e-05 - accuracy: 1.0000 - val_loss: 5.4084 - val_accuracy: 0.6207\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3670e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 9.1494e-05 - accuracy: 1.0000 - val_loss: 5.4121 - val_accuracy: 0.6207\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7846e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.0885e-05 - accuracy: 1.0000 - val_loss: 5.4193 - val_accuracy: 0.6207\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6929e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.8530e-05 - accuracy: 1.0000 - val_loss: 5.4308 - val_accuracy: 0.6207\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9017e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 8.6915e-05 - accuracy: 1.0000 - val_loss: 5.4448 - val_accuracy: 0.6207\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4430e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.6700e-05 - accuracy: 1.0000 - val_loss: 5.4575 - val_accuracy: 0.6207\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3981e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.5549e-05 - accuracy: 1.0000 - val_loss: 5.4627 - val_accuracy: 0.6207\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4379e-05 - accuracy: 1.00 - 0s 198us/sample - loss: 8.3736e-05 - accuracy: 1.0000 - val_loss: 5.4664 - val_accuracy: 0.6207\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4372e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.2551e-05 - accuracy: 1.0000 - val_loss: 5.4729 - val_accuracy: 0.6207\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8959e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.2504e-05 - accuracy: 1.0000 - val_loss: 5.4859 - val_accuracy: 0.6207\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3746e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 8.0350e-05 - accuracy: 1.0000 - val_loss: 5.4937 - val_accuracy: 0.6207\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2510e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.9305e-05 - accuracy: 1.0000 - val_loss: 5.5031 - val_accuracy: 0.6207\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0817e-04 - accuracy: 1.00 - 0s 189us/sample - loss: 8.0327e-05 - accuracy: 1.0000 - val_loss: 5.5060 - val_accuracy: 0.6207\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.1471e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 7.9159e-05 - accuracy: 1.0000 - val_loss: 5.5156 - val_accuracy: 0.6207\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0971e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.5846e-05 - accuracy: 1.0000 - val_loss: 5.5292 - val_accuracy: 0.6207\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2174e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.9753e-05 - accuracy: 1.0000 - val_loss: 5.5377 - val_accuracy: 0.6207\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7977e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.6734e-05 - accuracy: 1.0000 - val_loss: 5.5428 - val_accuracy: 0.6207\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1133e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.3907e-05 - accuracy: 1.0000 - val_loss: 5.5516 - val_accuracy: 0.6207\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6562e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.3036e-05 - accuracy: 1.0000 - val_loss: 5.5591 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 456d66a05bef237eeaa6e54355cd78ea</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7155171632766724</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 72</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 108</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 108</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6967 - accuracy: 0.34 - 1s 5ms/sample - loss: 0.6553 - accuracy: 0.5603 - val_loss: 0.6499 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6351 - accuracy: 0.65 - 0s 241us/sample - loss: 0.6213 - accuracy: 0.6552 - val_loss: 0.6237 - val_accuracy: 0.6207\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5541 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5968 - accuracy: 0.6810 - val_loss: 0.6086 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6088 - accuracy: 0.65 - 0s 172us/sample - loss: 0.5801 - accuracy: 0.6897 - val_loss: 0.5909 - val_accuracy: 0.6207\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5851 - accuracy: 0.65 - 0s 181us/sample - loss: 0.5539 - accuracy: 0.7328 - val_loss: 0.6151 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6120 - accuracy: 0.68 - 0s 163us/sample - loss: 0.5617 - accuracy: 0.7155 - val_loss: 0.5993 - val_accuracy: 0.5862\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4712 - accuracy: 0.78 - 0s 155us/sample - loss: 0.5341 - accuracy: 0.7586 - val_loss: 0.6102 - val_accuracy: 0.6207\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5189 - accuracy: 0.7414 - val_loss: 0.6759 - val_accuracy: 0.6207\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.81 - 0s 146us/sample - loss: 0.5293 - accuracy: 0.7586 - val_loss: 0.6557 - val_accuracy: 0.6207\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5015 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5370 - accuracy: 0.7414 - val_loss: 0.6613 - val_accuracy: 0.6207\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4532 - accuracy: 0.75 - 0s 155us/sample - loss: 0.4934 - accuracy: 0.7672 - val_loss: 0.6992 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.90 - 0s 146us/sample - loss: 0.4854 - accuracy: 0.7586 - val_loss: 0.6674 - val_accuracy: 0.6207\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5703 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4850 - accuracy: 0.7672 - val_loss: 0.6716 - val_accuracy: 0.6207\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3516 - accuracy: 0.87 - 0s 129us/sample - loss: 0.4697 - accuracy: 0.7845 - val_loss: 0.7072 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4629 - accuracy: 0.7672 - val_loss: 0.7314 - val_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.81 - 0s 2ms/sample - loss: 0.4363 - accuracy: 0.8017 - val_loss: 0.7340 - val_accuracy: 0.6897\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2565 - accuracy: 0.90 - 0s 249us/sample - loss: 0.4458 - accuracy: 0.8103 - val_loss: 0.6948 - val_accuracy: 0.6552\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4407 - accuracy: 0.78 - 0s 1ms/sample - loss: 0.4179 - accuracy: 0.8103 - val_loss: 0.7170 - val_accuracy: 0.7241\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4390 - accuracy: 0.81 - 0s 275us/sample - loss: 0.3974 - accuracy: 0.8190 - val_loss: 0.7581 - val_accuracy: 0.6897\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2397 - accuracy: 0.96 - 0s 146us/sample - loss: 0.3810 - accuracy: 0.8362 - val_loss: 0.8484 - val_accuracy: 0.6897\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3942 - accuracy: 0.8103 - val_loss: 0.9172 - val_accuracy: 0.6552\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3897 - accuracy: 0.81 - 0s 1ms/sample - loss: 0.3924 - accuracy: 0.8017 - val_loss: 0.8648 - val_accuracy: 0.7586\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.81 - 0s 241us/sample - loss: 0.4555 - accuracy: 0.7759 - val_loss: 0.7455 - val_accuracy: 0.6897\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2957 - accuracy: 0.90 - 0s 172us/sample - loss: 0.3272 - accuracy: 0.8879 - val_loss: 0.8721 - val_accuracy: 0.5862\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3650 - accuracy: 0.8362 - val_loss: 0.8195 - val_accuracy: 0.6897\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.68 - 0s 146us/sample - loss: 0.3712 - accuracy: 0.8276 - val_loss: 0.8593 - val_accuracy: 0.6552\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3634 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3616 - accuracy: 0.8448 - val_loss: 0.9251 - val_accuracy: 0.6207\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3360 - accuracy: 0.8448 - val_loss: 0.8388 - val_accuracy: 0.6897\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3358 - accuracy: 0.81 - 0s 163us/sample - loss: 0.3505 - accuracy: 0.8276 - val_loss: 0.9117 - val_accuracy: 0.6552\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3020 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3168 - accuracy: 0.8793 - val_loss: 0.9628 - val_accuracy: 0.6552\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3232 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3347 - accuracy: 0.8621 - val_loss: 1.0447 - val_accuracy: 0.6207\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2597 - accuracy: 0.8879 - val_loss: 1.0854 - val_accuracy: 0.6552\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3073 - accuracy: 0.81 - 0s 155us/sample - loss: 0.2680 - accuracy: 0.8879 - val_loss: 1.1694 - val_accuracy: 0.6552\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 0.81 - 0s 172us/sample - loss: 0.2470 - accuracy: 0.9052 - val_loss: 1.3993 - val_accuracy: 0.6207\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2169 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2444 - accuracy: 0.8879 - val_loss: 1.4754 - val_accuracy: 0.5862\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2360 - accuracy: 0.8793 - val_loss: 1.5305 - val_accuracy: 0.6207\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1758 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2219 - accuracy: 0.9138 - val_loss: 1.5731 - val_accuracy: 0.6207\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1713 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2121 - accuracy: 0.9138 - val_loss: 1.6618 - val_accuracy: 0.6552\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2068 - accuracy: 0.9052 - val_loss: 1.7119 - val_accuracy: 0.5862\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1480 - accuracy: 0.93 - 0s 172us/sample - loss: 0.2133 - accuracy: 0.8966 - val_loss: 1.8691 - val_accuracy: 0.5517\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0746 - accuracy: 0.96 - 0s 147us/sample - loss: 0.2031 - accuracy: 0.9052 - val_loss: 1.9716 - val_accuracy: 0.5862\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 1.00 - 0s 155us/sample - loss: 0.2078 - accuracy: 0.9310 - val_loss: 1.8002 - val_accuracy: 0.5862\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1642 - accuracy: 0.9310 - val_loss: 2.0085 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1376 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2049 - accuracy: 0.9224 - val_loss: 2.1214 - val_accuracy: 0.6207\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1225 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1758 - accuracy: 0.9310 - val_loss: 2.1576 - val_accuracy: 0.5862\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1228 - accuracy: 0.9397 - val_loss: 2.5235 - val_accuracy: 0.5862\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2112 - accuracy: 0.8707 - val_loss: 2.5565 - val_accuracy: 0.5517\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1896 - accuracy: 0.9138 - val_loss: 2.2632 - val_accuracy: 0.6207\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2018 - accuracy: 0.9224 - val_loss: 2.1345 - val_accuracy: 0.5862\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1444 - accuracy: 0.9310 - val_loss: 2.1140 - val_accuracy: 0.6552\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1213 - accuracy: 0.9655 - val_loss: 2.4293 - val_accuracy: 0.5517\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1633 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1303 - accuracy: 0.9397 - val_loss: 2.4645 - val_accuracy: 0.6207\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1082 - accuracy: 0.9483 - val_loss: 2.7287 - val_accuracy: 0.4828\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2061 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1483 - accuracy: 0.9310 - val_loss: 2.5745 - val_accuracy: 0.6552\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1260 - accuracy: 0.9483 - val_loss: 3.0225 - val_accuracy: 0.4828\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4591 - accuracy: 0.87 - 0s 189us/sample - loss: 0.2141 - accuracy: 0.9397 - val_loss: 3.0011 - val_accuracy: 0.5862\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1221 - accuracy: 0.90 - 0s 163us/sample - loss: 0.0841 - accuracy: 0.9655 - val_loss: 3.3124 - val_accuracy: 0.5172\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 1.00 - 0s 181us/sample - loss: 0.1376 - accuracy: 0.9569 - val_loss: 3.6129 - val_accuracy: 0.5517\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1120 - accuracy: 0.9569 - val_loss: 3.3771 - val_accuracy: 0.5517\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0660 - accuracy: 0.9828 - val_loss: 3.3706 - val_accuracy: 0.5862\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0631 - accuracy: 0.9741 - val_loss: 3.2360 - val_accuracy: 0.5862\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0564 - accuracy: 0.9741 - val_loss: 3.5087 - val_accuracy: 0.5862\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0798 - accuracy: 0.9655 - val_loss: 3.2980 - val_accuracy: 0.5862\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1144 - accuracy: 0.9569 - val_loss: 3.5419 - val_accuracy: 0.5862\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0967 - accuracy: 0.9569 - val_loss: 3.7120 - val_accuracy: 0.5517\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0770 - accuracy: 0.9741 - val_loss: 3.7528 - val_accuracy: 0.5862\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0514 - accuracy: 0.9914 - val_loss: 3.9499 - val_accuracy: 0.5517\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0820 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0740 - accuracy: 0.9741 - val_loss: 3.9247 - val_accuracy: 0.5862\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0240 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0773 - accuracy: 0.9741 - val_loss: 4.0939 - val_accuracy: 0.5517\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0469 - accuracy: 0.9741 - val_loss: 3.6957 - val_accuracy: 0.5172\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1507 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0905 - accuracy: 0.9569 - val_loss: 3.9427 - val_accuracy: 0.5517\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0766 - accuracy: 0.9655 - val_loss: 4.1621 - val_accuracy: 0.5517\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0583 - accuracy: 0.9655 - val_loss: 4.2177 - val_accuracy: 0.5862\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0618 - accuracy: 0.9741 - val_loss: 4.1736 - val_accuracy: 0.5172\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0820 - accuracy: 0.9655 - val_loss: 4.3555 - val_accuracy: 0.5517\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1151 - accuracy: 0.9569 - val_loss: 4.1891 - val_accuracy: 0.5517\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1831 - accuracy: 0.9569 - val_loss: 3.9125 - val_accuracy: 0.5862\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1788 - accuracy: 0.9397 - val_loss: 3.4619 - val_accuracy: 0.6552\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1972 - accuracy: 0.9483 - val_loss: 3.2784 - val_accuracy: 0.5517\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0325 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0700 - accuracy: 0.9741 - val_loss: 3.2928 - val_accuracy: 0.5172\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.96 - 0s 137us/sample - loss: 0.2026 - accuracy: 0.9397 - val_loss: 3.0165 - val_accuracy: 0.5172\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1369 - accuracy: 0.9397 - val_loss: 2.7387 - val_accuracy: 0.5517\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0762 - accuracy: 0.9914 - val_loss: 2.5424 - val_accuracy: 0.5862\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0592 - accuracy: 0.9914 - val_loss: 2.4981 - val_accuracy: 0.6207\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0546 - accuracy: 0.9914 - val_loss: 2.7115 - val_accuracy: 0.6207\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0372 - accuracy: 1.0000 - val_loss: 2.9283 - val_accuracy: 0.5862\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0433 - accuracy: 0.9914 - val_loss: 3.1253 - val_accuracy: 0.5172\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0509 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0510 - accuracy: 0.9914 - val_loss: 3.5583 - val_accuracy: 0.5517\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0265 - accuracy: 0.9914 - val_loss: 3.5648 - val_accuracy: 0.5517\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0582 - accuracy: 0.9741 - val_loss: 3.7890 - val_accuracy: 0.5862\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.96 - 0s 181us/sample - loss: 0.0532 - accuracy: 0.9655 - val_loss: 4.0163 - val_accuracy: 0.5517\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0444 - accuracy: 0.9914 - val_loss: 3.8800 - val_accuracy: 0.5172\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0361 - accuracy: 0.9828 - val_loss: 4.2350 - val_accuracy: 0.5862\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0640 - accuracy: 0.9741 - val_loss: 4.2855 - val_accuracy: 0.5172\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0405 - accuracy: 0.9914 - val_loss: 4.1787 - val_accuracy: 0.5517\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0324 - accuracy: 0.9914 - val_loss: 4.3124 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0304 - accuracy: 0.9828 - val_loss: 4.5301 - val_accuracy: 0.5517\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0407 - accuracy: 0.9741 - val_loss: 4.4703 - val_accuracy: 0.5517\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0206 - accuracy: 0.9914 - val_loss: 4.4226 - val_accuracy: 0.6207\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0594 - accuracy: 0.9828 - val_loss: 4.6321 - val_accuracy: 0.5862\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1630 - accuracy: 0.9483 - val_loss: 4.7187 - val_accuracy: 0.5517\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1467 - accuracy: 0.9569 - val_loss: 4.4316 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1149 - accuracy: 0.9569 - val_loss: 4.1659 - val_accuracy: 0.5517\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0665 - accuracy: 0.9741 - val_loss: 4.2489 - val_accuracy: 0.5517\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0728 - accuracy: 0.9655 - val_loss: 3.5224 - val_accuracy: 0.5862\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1044 - accuracy: 0.9655 - val_loss: 3.4790 - val_accuracy: 0.5862\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0567 - accuracy: 0.9828 - val_loss: 3.9260 - val_accuracy: 0.5517\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1086 - accuracy: 0.9655 - val_loss: 3.9798 - val_accuracy: 0.4828\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0898 - accuracy: 0.9741 - val_loss: 3.7787 - val_accuracy: 0.5862\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1144 - accuracy: 0.9483 - val_loss: 3.9789 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1224 - accuracy: 0.9397 - val_loss: 4.1801 - val_accuracy: 0.5517\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1216 - accuracy: 0.9483 - val_loss: 3.7584 - val_accuracy: 0.5517\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0752 - accuracy: 0.9741 - val_loss: 3.5334 - val_accuracy: 0.5517\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0837 - accuracy: 0.9741 - val_loss: 3.4431 - val_accuracy: 0.6207\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1583 - accuracy: 0.9569 - val_loss: 3.5768 - val_accuracy: 0.5517\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1010 - accuracy: 0.9655 - val_loss: 3.3174 - val_accuracy: 0.6207\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0714 - accuracy: 0.9741 - val_loss: 3.2299 - val_accuracy: 0.6207\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1399 - accuracy: 0.9655 - val_loss: 3.2976 - val_accuracy: 0.5517\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0975 - accuracy: 0.9483 - val_loss: 3.5728 - val_accuracy: 0.5172\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1265 - accuracy: 0.9483 - val_loss: 3.3773 - val_accuracy: 0.6207\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0865 - accuracy: 0.9655 - val_loss: 3.2356 - val_accuracy: 0.5862\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0426 - accuracy: 0.9914 - val_loss: 3.2949 - val_accuracy: 0.5517\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0994 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0733 - accuracy: 0.9741 - val_loss: 3.2343 - val_accuracy: 0.5862\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0467 - accuracy: 0.9914 - val_loss: 3.3756 - val_accuracy: 0.5862\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0330 - accuracy: 1.0000 - val_loss: 3.8392 - val_accuracy: 0.5172\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0420 - accuracy: 0.9914 - val_loss: 3.9517 - val_accuracy: 0.5517\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0171 - accuracy: 1.0000 - val_loss: 3.9413 - val_accuracy: 0.5862\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0231 - accuracy: 1.0000 - val_loss: 4.1043 - val_accuracy: 0.5862\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0137 - accuracy: 1.0000 - val_loss: 4.3616 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.00 - 0s 198us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 4.5153 - val_accuracy: 0.5517\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 4.6392 - val_accuracy: 0.5517\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 4.7638 - val_accuracy: 0.5862\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 4.9093 - val_accuracy: 0.5517\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 5.0604 - val_accuracy: 0.5517\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 5.1987 - val_accuracy: 0.5517\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 5.2925 - val_accuracy: 0.5517\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 5.3870 - val_accuracy: 0.5517\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.4902 - val_accuracy: 0.5517\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.6259 - val_accuracy: 0.5517\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 5.7693 - val_accuracy: 0.5517\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2333e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.8757 - val_accuracy: 0.5517\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.0113 - val_accuracy: 0.5517\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 6.1889 - val_accuracy: 0.5517\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.5892e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.3774 - val_accuracy: 0.5517\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4353e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.5418 - val_accuracy: 0.5517\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 6.6992 - val_accuracy: 0.5517\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9269e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.9046 - val_accuracy: 0.5517\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 146us/sample - loss: 9.5347e-04 - accuracy: 1.0000 - val_loss: 7.0967 - val_accuracy: 0.5517\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 155us/sample - loss: 8.8513e-04 - accuracy: 1.0000 - val_loss: 7.3077 - val_accuracy: 0.5517\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7937e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 7.3134e-04 - accuracy: 1.0000 - val_loss: 7.4623 - val_accuracy: 0.5517\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 155us/sample - loss: 6.4272e-04 - accuracy: 1.0000 - val_loss: 7.6093 - val_accuracy: 0.5517\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 155us/sample - loss: 5.8554e-04 - accuracy: 1.0000 - val_loss: 7.7810 - val_accuracy: 0.5517\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7775e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.1015e-04 - accuracy: 1.0000 - val_loss: 7.9499 - val_accuracy: 0.5517\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7810e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.5751e-04 - accuracy: 1.0000 - val_loss: 8.0957 - val_accuracy: 0.5517\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0277e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.1748e-04 - accuracy: 1.0000 - val_loss: 8.2324 - val_accuracy: 0.5517\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4913e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.7544e-04 - accuracy: 1.0000 - val_loss: 8.3497 - val_accuracy: 0.5517\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7977e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.5759e-04 - accuracy: 1.0000 - val_loss: 8.4495 - val_accuracy: 0.5517\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9041e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.2979e-04 - accuracy: 1.0000 - val_loss: 8.5664 - val_accuracy: 0.5517\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7188e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 3.0574e-04 - accuracy: 1.0000 - val_loss: 8.6797 - val_accuracy: 0.5517\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9809e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.7797e-04 - accuracy: 1.0000 - val_loss: 8.7848 - val_accuracy: 0.5517\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3375e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.6349e-04 - accuracy: 1.0000 - val_loss: 8.8840 - val_accuracy: 0.5517\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5753e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 2.4668e-04 - accuracy: 1.0000 - val_loss: 8.9645 - val_accuracy: 0.5517\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2346e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 2.3456e-04 - accuracy: 1.0000 - val_loss: 9.0357 - val_accuracy: 0.5517\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7922e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.2025e-04 - accuracy: 1.0000 - val_loss: 9.1128 - val_accuracy: 0.5517\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1136e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.1158e-04 - accuracy: 1.0000 - val_loss: 9.1973 - val_accuracy: 0.5517\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4875e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.9950e-04 - accuracy: 1.0000 - val_loss: 9.2772 - val_accuracy: 0.5517\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3560e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.8932e-04 - accuracy: 1.0000 - val_loss: 9.3511 - val_accuracy: 0.5517\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6401e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8159e-04 - accuracy: 1.0000 - val_loss: 9.4087 - val_accuracy: 0.5517\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2206e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.7427e-04 - accuracy: 1.0000 - val_loss: 9.4672 - val_accuracy: 0.5517\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4072e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.6770e-04 - accuracy: 1.0000 - val_loss: 9.5525 - val_accuracy: 0.5517\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2513e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5788e-04 - accuracy: 1.0000 - val_loss: 9.6233 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0127e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.5445e-04 - accuracy: 1.0000 - val_loss: 9.6848 - val_accuracy: 0.5517\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1192e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.4549e-04 - accuracy: 1.0000 - val_loss: 9.7310 - val_accuracy: 0.5517\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3549e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.4207e-04 - accuracy: 1.0000 - val_loss: 9.7863 - val_accuracy: 0.5517\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2546e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.3542e-04 - accuracy: 1.0000 - val_loss: 9.8397 - val_accuracy: 0.5517\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.9850e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.3173e-04 - accuracy: 1.0000 - val_loss: 9.9004 - val_accuracy: 0.5517\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1657e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.2666e-04 - accuracy: 1.0000 - val_loss: 9.9497 - val_accuracy: 0.5517\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1447e-04 - accuracy: 1.00 - 0s 284us/sample - loss: 1.2305e-04 - accuracy: 1.0000 - val_loss: 10.0025 - val_accuracy: 0.5517\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0103e-05 - accuracy: 1.00 - 0s 610us/sample - loss: 1.1850e-04 - accuracy: 1.0000 - val_loss: 10.0540 - val_accuracy: 0.5517\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3287e-04 - accuracy: 1.00 - 0s 550us/sample - loss: 1.1453e-04 - accuracy: 1.0000 - val_loss: 10.1059 - val_accuracy: 0.5517\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4374e-04 - accuracy: 1.00 - 0s 516us/sample - loss: 1.1128e-04 - accuracy: 1.0000 - val_loss: 10.1515 - val_accuracy: 0.5517\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1303e-04 - accuracy: 1.00 - 0s 542us/sample - loss: 1.0806e-04 - accuracy: 1.0000 - val_loss: 10.1961 - val_accuracy: 0.5517\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4990e-04 - accuracy: 1.00 - 0s 481us/sample - loss: 1.0566e-04 - accuracy: 1.0000 - val_loss: 10.2556 - val_accuracy: 0.5517\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4745e-04 - accuracy: 1.00 - 0s 516us/sample - loss: 1.0134e-04 - accuracy: 1.0000 - val_loss: 10.2992 - val_accuracy: 0.5517\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4022e-05 - accuracy: 1.00 - 0s 533us/sample - loss: 9.7839e-05 - accuracy: 1.0000 - val_loss: 10.3478 - val_accuracy: 0.5517\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3976e-05 - accuracy: 1.00 - 0s 550us/sample - loss: 9.4868e-05 - accuracy: 1.0000 - val_loss: 10.3964 - val_accuracy: 0.5517\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6937e-05 - accuracy: 1.00 - 0s 490us/sample - loss: 9.1684e-05 - accuracy: 1.0000 - val_loss: 10.4453 - val_accuracy: 0.5517\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9234e-05 - accuracy: 1.00 - 0s 533us/sample - loss: 8.9437e-05 - accuracy: 1.0000 - val_loss: 10.4875 - val_accuracy: 0.5517\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3285e-05 - accuracy: 1.00 - 0s 559us/sample - loss: 8.6825e-05 - accuracy: 1.0000 - val_loss: 10.5216 - val_accuracy: 0.5517\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1179e-05 - accuracy: 1.00 - 0s 507us/sample - loss: 8.4873e-05 - accuracy: 1.0000 - val_loss: 10.5546 - val_accuracy: 0.5517\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7984e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 8.2513e-05 - accuracy: 1.0000 - val_loss: 10.6073 - val_accuracy: 0.5517\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2332e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.9793e-05 - accuracy: 1.0000 - val_loss: 10.6538 - val_accuracy: 0.5517\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0326e-05 - accuracy: 1.00 - 0s 181us/sample - loss: 7.8589e-05 - accuracy: 1.0000 - val_loss: 10.6978 - val_accuracy: 0.5517\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.1272e-05 - accuracy: 1.00 - 0s 206us/sample - loss: 7.6239e-05 - accuracy: 1.0000 - val_loss: 10.7306 - val_accuracy: 0.5517\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2188e-05 - accuracy: 1.00 - 0s 206us/sample - loss: 7.3835e-05 - accuracy: 1.0000 - val_loss: 10.7668 - val_accuracy: 0.5517\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5303e-05 - accuracy: 1.00 - 0s 198us/sample - loss: 7.1836e-05 - accuracy: 1.0000 - val_loss: 10.8008 - val_accuracy: 0.5517\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3290e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 6.9846e-05 - accuracy: 1.0000 - val_loss: 10.8461 - val_accuracy: 0.5517\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4634e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 6.7858e-05 - accuracy: 1.0000 - val_loss: 10.8891 - val_accuracy: 0.5517\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4385e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.6127e-05 - accuracy: 1.0000 - val_loss: 10.9325 - val_accuracy: 0.5517\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1260e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 6.4559e-05 - accuracy: 1.0000 - val_loss: 10.9655 - val_accuracy: 0.5517\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 1s - loss: 0.6921 - accuracy: 0.50 - 0s 4ms/sample - loss: 0.6537 - accuracy: 0.5862 - val_loss: 0.6476 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6109 - accuracy: 0.68 - 0s 146us/sample - loss: 0.6644 - accuracy: 0.6638 - val_loss: 0.6226 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5491 - accuracy: 0.75 - 0s 146us/sample - loss: 0.6062 - accuracy: 0.6638 - val_loss: 0.6268 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6064 - accuracy: 0.75 - 0s 138us/sample - loss: 0.6119 - accuracy: 0.6897 - val_loss: 0.6049 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5820 - accuracy: 0.7328 - val_loss: 0.5961 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6612 - accuracy: 0.62 - 0s 146us/sample - loss: 0.5645 - accuracy: 0.6983 - val_loss: 0.5855 - val_accuracy: 0.6207\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5984 - accuracy: 0.68 - 0s 146us/sample - loss: 0.5452 - accuracy: 0.7500 - val_loss: 0.6103 - val_accuracy: 0.6207\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5749 - accuracy: 0.62 - 0s 155us/sample - loss: 0.5582 - accuracy: 0.6810 - val_loss: 0.6505 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5883 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5457 - accuracy: 0.7672 - val_loss: 0.6393 - val_accuracy: 0.6552\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.75 - 0s 163us/sample - loss: 0.5132 - accuracy: 0.7328 - val_loss: 0.6450 - val_accuracy: 0.6552\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5503 - accuracy: 0.75 - 0s 163us/sample - loss: 0.5035 - accuracy: 0.7759 - val_loss: 0.6630 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.68 - 0s 155us/sample - loss: 0.4905 - accuracy: 0.7500 - val_loss: 0.7195 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2936 - accuracy: 0.90 - 0s 129us/sample - loss: 0.4773 - accuracy: 0.7586 - val_loss: 0.7816 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5644 - accuracy: 0.68 - 0s 138us/sample - loss: 0.4654 - accuracy: 0.7759 - val_loss: 0.7925 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5353 - accuracy: 0.71 - 0s 120us/sample - loss: 0.4606 - accuracy: 0.8017 - val_loss: 0.8281 - val_accuracy: 0.6897\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3640 - accuracy: 0.87 - 0s 120us/sample - loss: 0.4597 - accuracy: 0.7931 - val_loss: 0.8447 - val_accuracy: 0.6897\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.81 - 0s 129us/sample - loss: 0.4480 - accuracy: 0.7931 - val_loss: 0.7929 - val_accuracy: 0.6897\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3375 - accuracy: 0.84 - 0s 120us/sample - loss: 0.4533 - accuracy: 0.7586 - val_loss: 0.7929 - val_accuracy: 0.6897\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4866 - accuracy: 0.81 - 0s 120us/sample - loss: 0.4509 - accuracy: 0.8190 - val_loss: 0.8485 - val_accuracy: 0.7241\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3279 - accuracy: 0.87 - 0s 129us/sample - loss: 0.4317 - accuracy: 0.8017 - val_loss: 0.9318 - val_accuracy: 0.6897\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4112 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3939 - accuracy: 0.7845 - val_loss: 1.0110 - val_accuracy: 0.6207\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3156 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3933 - accuracy: 0.7931 - val_loss: 1.0101 - val_accuracy: 0.6897\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3790 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3874 - accuracy: 0.8362 - val_loss: 1.0501 - val_accuracy: 0.6207\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3314 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3763 - accuracy: 0.8276 - val_loss: 1.0353 - val_accuracy: 0.6897\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3653 - accuracy: 0.81 - 0s 181us/sample - loss: 0.3614 - accuracy: 0.8534 - val_loss: 1.1581 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3313 - accuracy: 0.78 - 0s 155us/sample - loss: 0.3397 - accuracy: 0.8190 - val_loss: 1.2778 - val_accuracy: 0.7241\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3055 - accuracy: 0.84 - 0s 172us/sample - loss: 0.3467 - accuracy: 0.8362 - val_loss: 1.3025 - val_accuracy: 0.6897\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2546 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3304 - accuracy: 0.8793 - val_loss: 1.3357 - val_accuracy: 0.6897\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2781 - accuracy: 0.90 - 0s 181us/sample - loss: 0.3145 - accuracy: 0.8448 - val_loss: 1.5422 - val_accuracy: 0.6552\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.87 - 0s 189us/sample - loss: 0.3282 - accuracy: 0.8362 - val_loss: 1.7673 - val_accuracy: 0.6552\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2842 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3238 - accuracy: 0.8534 - val_loss: 1.5602 - val_accuracy: 0.6897\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5880 - accuracy: 0.65 - 0s 163us/sample - loss: 0.3656 - accuracy: 0.7931 - val_loss: 1.4262 - val_accuracy: 0.6897\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3429 - accuracy: 0.8276 - val_loss: 1.4427 - val_accuracy: 0.5862\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3138 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2912 - accuracy: 0.8621 - val_loss: 1.4332 - val_accuracy: 0.6897\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.78 - 0s 155us/sample - loss: 0.2844 - accuracy: 0.8707 - val_loss: 1.8642 - val_accuracy: 0.6552\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2877 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2847 - accuracy: 0.8707 - val_loss: 1.5883 - val_accuracy: 0.6897\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2804 - accuracy: 0.84 - 0s 120us/sample - loss: 0.2241 - accuracy: 0.8793 - val_loss: 1.9410 - val_accuracy: 0.6552\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2290 - accuracy: 0.8879 - val_loss: 1.9577 - val_accuracy: 0.6897\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.87 - 0s 120us/sample - loss: 0.2675 - accuracy: 0.8534 - val_loss: 2.0564 - val_accuracy: 0.6552\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2831 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2078 - accuracy: 0.9138 - val_loss: 2.0668 - val_accuracy: 0.6897\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1769 - accuracy: 0.9310 - val_loss: 2.4093 - val_accuracy: 0.6207\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1263 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1543 - accuracy: 0.9310 - val_loss: 2.4477 - val_accuracy: 0.6552\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0741 - accuracy: 1.00 - 0s 120us/sample - loss: 0.1195 - accuracy: 0.9655 - val_loss: 2.8722 - val_accuracy: 0.6207\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1450 - accuracy: 0.9569 - val_loss: 2.9837 - val_accuracy: 0.6552\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0958 - accuracy: 0.90 - 0s 120us/sample - loss: 0.1385 - accuracy: 0.9224 - val_loss: 3.3780 - val_accuracy: 0.6552\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1647 - accuracy: 0.9310 - val_loss: 3.8106 - val_accuracy: 0.6207\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.93 - 0s 120us/sample - loss: 0.2189 - accuracy: 0.9224 - val_loss: 4.1773 - val_accuracy: 0.5517\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.90 - 0s 120us/sample - loss: 0.1562 - accuracy: 0.9397 - val_loss: 3.5695 - val_accuracy: 0.6897\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1534 - accuracy: 0.9569 - val_loss: 3.4883 - val_accuracy: 0.6552\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1336 - accuracy: 0.9655 - val_loss: 3.2578 - val_accuracy: 0.6207\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.90 - 0s 120us/sample - loss: 0.1354 - accuracy: 0.9483 - val_loss: 3.5555 - val_accuracy: 0.6552\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0948 - accuracy: 0.9741 - val_loss: 4.0128 - val_accuracy: 0.6207\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1045 - accuracy: 0.9483 - val_loss: 4.1778 - val_accuracy: 0.6207\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1055 - accuracy: 0.9397 - val_loss: 4.1186 - val_accuracy: 0.6552\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1149 - accuracy: 0.9655 - val_loss: 4.3783 - val_accuracy: 0.5862\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0763 - accuracy: 0.9655 - val_loss: 4.8662 - val_accuracy: 0.6207\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4071 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2133 - accuracy: 0.9310 - val_loss: 4.2600 - val_accuracy: 0.5862\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0965 - accuracy: 0.9655 - val_loss: 4.2891 - val_accuracy: 0.6552\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0928 - accuracy: 0.9655 - val_loss: 4.1758 - val_accuracy: 0.6552\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0668 - accuracy: 0.9741 - val_loss: 4.2782 - val_accuracy: 0.6552\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0575 - accuracy: 0.9828 - val_loss: 4.7072 - val_accuracy: 0.6552\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0592 - accuracy: 0.9655 - val_loss: 5.1496 - val_accuracy: 0.6552\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0395 - accuracy: 0.9914 - val_loss: 5.1309 - val_accuracy: 0.6552\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0666 - accuracy: 0.9569 - val_loss: 5.3123 - val_accuracy: 0.6552\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0819 - accuracy: 0.9397 - val_loss: 5.5637 - val_accuracy: 0.5862\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0431 - accuracy: 0.9828 - val_loss: 5.1354 - val_accuracy: 0.6207\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0379 - accuracy: 0.9828 - val_loss: 5.3168 - val_accuracy: 0.6207\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0313 - accuracy: 0.9914 - val_loss: 5.9144 - val_accuracy: 0.5862\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0381 - accuracy: 0.96 - 0s 112us/sample - loss: 0.0283 - accuracy: 0.9828 - val_loss: 5.5938 - val_accuracy: 0.6207\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0669 - accuracy: 0.9741 - val_loss: 5.7834 - val_accuracy: 0.5862\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.00 - 0s 112us/sample - loss: 0.0970 - accuracy: 0.9569 - val_loss: 5.9558 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.00 - 0s 120us/sample - loss: 0.1269 - accuracy: 0.9483 - val_loss: 5.7055 - val_accuracy: 0.6552\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0688 - accuracy: 0.9655 - val_loss: 5.2437 - val_accuracy: 0.6552\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0432 - accuracy: 0.9914 - val_loss: 5.7774 - val_accuracy: 0.6552\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0296 - accuracy: 0.9914 - val_loss: 6.2483 - val_accuracy: 0.6207\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0351 - accuracy: 0.9914 - val_loss: 6.4170 - val_accuracy: 0.6207\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0226 - accuracy: 0.9914 - val_loss: 6.3382 - val_accuracy: 0.6552\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0176 - accuracy: 1.0000 - val_loss: 6.2439 - val_accuracy: 0.6552\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0128 - accuracy: 1.0000 - val_loss: 6.2703 - val_accuracy: 0.6552\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0115 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 6.3746 - val_accuracy: 0.6552\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - 0s 112us/sample - loss: 0.0072 - accuracy: 1.0000 - val_loss: 6.4574 - val_accuracy: 0.6552\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 6.5631 - val_accuracy: 0.6552\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 6.6977 - val_accuracy: 0.6207\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 6.8135 - val_accuracy: 0.6207\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 6.8958 - val_accuracy: 0.6207\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.9880 - val_accuracy: 0.6207\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 7.0641 - val_accuracy: 0.6207\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 7.1496 - val_accuracy: 0.6207\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 189us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.2207 - val_accuracy: 0.6207\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4221e-04 - accuracy: 1.00 - 0s 112us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 7.2841 - val_accuracy: 0.6207\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.3342 - val_accuracy: 0.6207\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3748e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.3834 - val_accuracy: 0.6207\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1886e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 7.4295 - val_accuracy: 0.6207\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 129us/sample - loss: 9.6949e-04 - accuracy: 1.0000 - val_loss: 7.4790 - val_accuracy: 0.6207\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6765e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 8.7925e-04 - accuracy: 1.0000 - val_loss: 7.5217 - val_accuracy: 0.6207\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.8904e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 8.6100e-04 - accuracy: 1.0000 - val_loss: 7.5679 - val_accuracy: 0.6207\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8626e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.0951e-04 - accuracy: 1.0000 - val_loss: 7.6038 - val_accuracy: 0.6207\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.1040e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.5976e-04 - accuracy: 1.0000 - val_loss: 7.6372 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6076e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.3652e-04 - accuracy: 1.0000 - val_loss: 7.6676 - val_accuracy: 0.6207\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 129us/sample - loss: 7.0621e-04 - accuracy: 1.0000 - val_loss: 7.7053 - val_accuracy: 0.6207\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.8484e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 6.7446e-04 - accuracy: 1.0000 - val_loss: 7.7399 - val_accuracy: 0.6207\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2767e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.4458e-04 - accuracy: 1.0000 - val_loss: 7.7702 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3915e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.2049e-04 - accuracy: 1.0000 - val_loss: 7.8016 - val_accuracy: 0.6207\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0961e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 6.0199e-04 - accuracy: 1.0000 - val_loss: 7.8291 - val_accuracy: 0.6207\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8727e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.8164e-04 - accuracy: 1.0000 - val_loss: 7.8517 - val_accuracy: 0.6207\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2766e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 5.5397e-04 - accuracy: 1.0000 - val_loss: 7.8754 - val_accuracy: 0.6207\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5467e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.4088e-04 - accuracy: 1.0000 - val_loss: 7.8972 - val_accuracy: 0.6207\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4719e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.2665e-04 - accuracy: 1.0000 - val_loss: 7.9214 - val_accuracy: 0.6207\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0868e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.0456e-04 - accuracy: 1.0000 - val_loss: 7.9529 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.2518e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 4.8763e-04 - accuracy: 1.0000 - val_loss: 7.9838 - val_accuracy: 0.6207\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0109e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 4.7510e-04 - accuracy: 1.0000 - val_loss: 8.0118 - val_accuracy: 0.6207\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7444e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 4.5964e-04 - accuracy: 1.0000 - val_loss: 8.0374 - val_accuracy: 0.6207\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7928e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 4.4831e-04 - accuracy: 1.0000 - val_loss: 8.0609 - val_accuracy: 0.6207\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2387e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.3250e-04 - accuracy: 1.0000 - val_loss: 8.0868 - val_accuracy: 0.6207\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9118e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.2155e-04 - accuracy: 1.0000 - val_loss: 8.1086 - val_accuracy: 0.6552\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8838e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.1124e-04 - accuracy: 1.0000 - val_loss: 8.1363 - val_accuracy: 0.6207\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.2848e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.9640e-04 - accuracy: 1.0000 - val_loss: 8.1631 - val_accuracy: 0.6552\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4394e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.8695e-04 - accuracy: 1.0000 - val_loss: 8.1915 - val_accuracy: 0.6552\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0678e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.6982e-04 - accuracy: 1.0000 - val_loss: 8.2202 - val_accuracy: 0.6552\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7975e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.6129e-04 - accuracy: 1.0000 - val_loss: 8.2475 - val_accuracy: 0.6207\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1840e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.5880e-04 - accuracy: 1.0000 - val_loss: 8.2716 - val_accuracy: 0.6207\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1412e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.5116e-04 - accuracy: 1.0000 - val_loss: 8.2958 - val_accuracy: 0.6552\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5366e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.3837e-04 - accuracy: 1.0000 - val_loss: 8.3211 - val_accuracy: 0.6552\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0103e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.3145e-04 - accuracy: 1.0000 - val_loss: 8.3422 - val_accuracy: 0.6552\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7933e-05 - accuracy: 1.00 - 0s 120us/sample - loss: 3.2054e-04 - accuracy: 1.0000 - val_loss: 8.3661 - val_accuracy: 0.6552\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4340e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.1271e-04 - accuracy: 1.0000 - val_loss: 8.3883 - val_accuracy: 0.6552\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3594e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.0656e-04 - accuracy: 1.0000 - val_loss: 8.4125 - val_accuracy: 0.6552\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4154e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.9726e-04 - accuracy: 1.0000 - val_loss: 8.4379 - val_accuracy: 0.6552\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5456e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.9164e-04 - accuracy: 1.0000 - val_loss: 8.4616 - val_accuracy: 0.6552\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6399e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.8487e-04 - accuracy: 1.0000 - val_loss: 8.4853 - val_accuracy: 0.6552\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9124e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 2.7813e-04 - accuracy: 1.0000 - val_loss: 8.5108 - val_accuracy: 0.6552\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2506e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.7250e-04 - accuracy: 1.0000 - val_loss: 8.5342 - val_accuracy: 0.6552\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6217e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 2.6747e-04 - accuracy: 1.0000 - val_loss: 8.5566 - val_accuracy: 0.6552\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3712e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.6072e-04 - accuracy: 1.0000 - val_loss: 8.5802 - val_accuracy: 0.6552\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1151e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 2.5502e-04 - accuracy: 1.0000 - val_loss: 8.6051 - val_accuracy: 0.6552\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0178e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.4858e-04 - accuracy: 1.0000 - val_loss: 8.6310 - val_accuracy: 0.6552\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1762e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.4381e-04 - accuracy: 1.0000 - val_loss: 8.6556 - val_accuracy: 0.6552\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9107e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.3991e-04 - accuracy: 1.0000 - val_loss: 8.6787 - val_accuracy: 0.6552\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6269e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.3328e-04 - accuracy: 1.0000 - val_loss: 8.7032 - val_accuracy: 0.6552\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6814e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.2827e-04 - accuracy: 1.0000 - val_loss: 8.7278 - val_accuracy: 0.6552\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7550e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.2426e-04 - accuracy: 1.0000 - val_loss: 8.7542 - val_accuracy: 0.6552\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8563e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.2043e-04 - accuracy: 1.0000 - val_loss: 8.7800 - val_accuracy: 0.6552\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0926e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 2.1925e-04 - accuracy: 1.0000 - val_loss: 8.8017 - val_accuracy: 0.6552\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1922e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 2.0957e-04 - accuracy: 1.0000 - val_loss: 8.8267 - val_accuracy: 0.6552\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6440e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.0642e-04 - accuracy: 1.0000 - val_loss: 8.8514 - val_accuracy: 0.6552\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8610e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.0139e-04 - accuracy: 1.0000 - val_loss: 8.8741 - val_accuracy: 0.6552\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.9380e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.9776e-04 - accuracy: 1.0000 - val_loss: 8.8970 - val_accuracy: 0.6552\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5452e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.9460e-04 - accuracy: 1.0000 - val_loss: 8.9232 - val_accuracy: 0.6552\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6458e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.8984e-04 - accuracy: 1.0000 - val_loss: 8.9474 - val_accuracy: 0.6552\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6651e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 1.8588e-04 - accuracy: 1.0000 - val_loss: 8.9703 - val_accuracy: 0.6552\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5625e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.8351e-04 - accuracy: 1.0000 - val_loss: 8.9941 - val_accuracy: 0.6552\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7533e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.7901e-04 - accuracy: 1.0000 - val_loss: 9.0194 - val_accuracy: 0.6552\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0857e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.7475e-04 - accuracy: 1.0000 - val_loss: 9.0430 - val_accuracy: 0.6552\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6234e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.7221e-04 - accuracy: 1.0000 - val_loss: 9.0650 - val_accuracy: 0.6552\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7781e-04 - accuracy: 1.00 - 0s 164us/sample - loss: 1.6881e-04 - accuracy: 1.0000 - val_loss: 9.0885 - val_accuracy: 0.6552\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0907e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6504e-04 - accuracy: 1.0000 - val_loss: 9.1137 - val_accuracy: 0.6552\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3193e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.6143e-04 - accuracy: 1.0000 - val_loss: 9.1376 - val_accuracy: 0.6552\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4814e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.5946e-04 - accuracy: 1.0000 - val_loss: 9.1609 - val_accuracy: 0.6552\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3682e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5659e-04 - accuracy: 1.0000 - val_loss: 9.1844 - val_accuracy: 0.6552\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8573e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5453e-04 - accuracy: 1.0000 - val_loss: 9.2080 - val_accuracy: 0.6552\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9430e-05 - accuracy: 1.00 - 0s 120us/sample - loss: 1.5005e-04 - accuracy: 1.0000 - val_loss: 9.2325 - val_accuracy: 0.6552\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3087e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4807e-04 - accuracy: 1.0000 - val_loss: 9.2561 - val_accuracy: 0.6552\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0681e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4487e-04 - accuracy: 1.0000 - val_loss: 9.2815 - val_accuracy: 0.6552\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2913e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.4298e-04 - accuracy: 1.0000 - val_loss: 9.3062 - val_accuracy: 0.6552\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5926e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.3986e-04 - accuracy: 1.0000 - val_loss: 9.3287 - val_accuracy: 0.6552\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9276e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 1.3768e-04 - accuracy: 1.0000 - val_loss: 9.3524 - val_accuracy: 0.6552\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0017e-04 - accuracy: 1.00 - 0s 112us/sample - loss: 1.3529e-04 - accuracy: 1.0000 - val_loss: 9.3743 - val_accuracy: 0.6552\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6437e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.3202e-04 - accuracy: 1.0000 - val_loss: 9.3984 - val_accuracy: 0.6552\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4824e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.3042e-04 - accuracy: 1.0000 - val_loss: 9.4235 - val_accuracy: 0.6552\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9638e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.2743e-04 - accuracy: 1.0000 - val_loss: 9.4472 - val_accuracy: 0.6552\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2506e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.2572e-04 - accuracy: 1.0000 - val_loss: 9.4716 - val_accuracy: 0.6552\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8287e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.2374e-04 - accuracy: 1.0000 - val_loss: 9.4947 - val_accuracy: 0.6552\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2975e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.2221e-04 - accuracy: 1.0000 - val_loss: 9.5181 - val_accuracy: 0.6552\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2552e-05 - accuracy: 1.00 - 0s 249us/sample - loss: 1.1940e-04 - accuracy: 1.0000 - val_loss: 9.5401 - val_accuracy: 0.6552\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0792e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1764e-04 - accuracy: 1.0000 - val_loss: 9.5606 - val_accuracy: 0.6552\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0521e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1533e-04 - accuracy: 1.0000 - val_loss: 9.5826 - val_accuracy: 0.6552\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.9209e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1364e-04 - accuracy: 1.0000 - val_loss: 9.6036 - val_accuracy: 0.6552\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5983e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1196e-04 - accuracy: 1.0000 - val_loss: 9.6264 - val_accuracy: 0.6552\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2982e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0981e-04 - accuracy: 1.0000 - val_loss: 9.6475 - val_accuracy: 0.6552\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3493e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.0878e-04 - accuracy: 1.0000 - val_loss: 9.6705 - val_accuracy: 0.6552\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 8.9846e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0684e-04 - accuracy: 1.0000 - val_loss: 9.6913 - val_accuracy: 0.6552\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4044e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.0497e-04 - accuracy: 1.0000 - val_loss: 9.7163 - val_accuracy: 0.6552\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1627e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.0376e-04 - accuracy: 1.0000 - val_loss: 9.7417 - val_accuracy: 0.6552\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9123e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0165e-04 - accuracy: 1.0000 - val_loss: 9.7649 - val_accuracy: 0.6552\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2361e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 9.9623e-05 - accuracy: 1.0000 - val_loss: 9.7880 - val_accuracy: 0.6552\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6891e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 9.7993e-05 - accuracy: 1.0000 - val_loss: 9.8113 - val_accuracy: 0.6552\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3454e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 9.6344e-05 - accuracy: 1.0000 - val_loss: 9.8324 - val_accuracy: 0.6552\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4445e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 9.4929e-05 - accuracy: 1.0000 - val_loss: 9.8534 - val_accuracy: 0.6552\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0156e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 9.3712e-05 - accuracy: 1.0000 - val_loss: 9.8747 - val_accuracy: 0.6552\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.9604e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 9.2403e-05 - accuracy: 1.0000 - val_loss: 9.8976 - val_accuracy: 0.6552\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1725e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 9.0663e-05 - accuracy: 1.0000 - val_loss: 9.9207 - val_accuracy: 0.6552\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8128e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.9181e-05 - accuracy: 1.0000 - val_loss: 9.9436 - val_accuracy: 0.6552\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5466e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 8.8052e-05 - accuracy: 1.0000 - val_loss: 9.9649 - val_accuracy: 0.6552\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0357e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 8.6854e-05 - accuracy: 1.0000 - val_loss: 9.9863 - val_accuracy: 0.6552\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6944e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 8.5417e-05 - accuracy: 1.0000 - val_loss: 10.0074 - val_accuracy: 0.6552\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0357e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 8.4571e-05 - accuracy: 1.0000 - val_loss: 10.0282 - val_accuracy: 0.6552\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8752e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.3107e-05 - accuracy: 1.0000 - val_loss: 10.0499 - val_accuracy: 0.6552\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3913e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.1771e-05 - accuracy: 1.0000 - val_loss: 10.0727 - val_accuracy: 0.6552\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4082e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.0601e-05 - accuracy: 1.0000 - val_loss: 10.0951 - val_accuracy: 0.6552\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5290e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.9368e-05 - accuracy: 1.0000 - val_loss: 10.1167 - val_accuracy: 0.6552\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 1s - loss: 0.6882 - accuracy: 0.62 - 0s 4ms/sample - loss: 0.6441 - accuracy: 0.6638 - val_loss: 0.6325 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5133 - accuracy: 0.78 - 0s 129us/sample - loss: 0.6061 - accuracy: 0.6638 - val_loss: 0.6280 - val_accuracy: 0.6897\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6031 - accuracy: 0.65 - 0s 111us/sample - loss: 0.6195 - accuracy: 0.6724 - val_loss: 0.6241 - val_accuracy: 0.6207\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6278 - accuracy: 0.71 - 0s 112us/sample - loss: 0.5911 - accuracy: 0.6983 - val_loss: 0.6305 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5537 - accuracy: 0.68 - 0s 120us/sample - loss: 0.5897 - accuracy: 0.7069 - val_loss: 0.6095 - val_accuracy: 0.5862\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5743 - accuracy: 0.62 - 0s 120us/sample - loss: 0.5705 - accuracy: 0.7069 - val_loss: 0.6014 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6440 - accuracy: 0.62 - 0s 121us/sample - loss: 0.5490 - accuracy: 0.7500 - val_loss: 0.6022 - val_accuracy: 0.6897\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4732 - accuracy: 0.78 - 0s 129us/sample - loss: 0.5336 - accuracy: 0.7414 - val_loss: 0.6222 - val_accuracy: 0.6207\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5874 - accuracy: 0.68 - 0s 129us/sample - loss: 0.5497 - accuracy: 0.7241 - val_loss: 0.6362 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5196 - accuracy: 0.7500 - val_loss: 0.6503 - val_accuracy: 0.6207\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5063 - accuracy: 0.7155 - val_loss: 0.6468 - val_accuracy: 0.6207\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5342 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4819 - accuracy: 0.7586 - val_loss: 0.6893 - val_accuracy: 0.6207\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4913 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4776 - accuracy: 0.7586 - val_loss: 0.6881 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3782 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4344 - accuracy: 0.7586 - val_loss: 0.7298 - val_accuracy: 0.6207\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3937 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4390 - accuracy: 0.7845 - val_loss: 0.7677 - val_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4277 - accuracy: 0.7759 - val_loss: 0.8090 - val_accuracy: 0.6207\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2962 - accuracy: 0.90 - 0s 163us/sample - loss: 0.3971 - accuracy: 0.8017 - val_loss: 0.7700 - val_accuracy: 0.6207\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3626 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3973 - accuracy: 0.8017 - val_loss: 0.8281 - val_accuracy: 0.6552\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3778 - accuracy: 0.81 - 0s 172us/sample - loss: 0.3997 - accuracy: 0.7759 - val_loss: 0.8651 - val_accuracy: 0.5862\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4151 - accuracy: 0.78 - 0s 163us/sample - loss: 0.3990 - accuracy: 0.7931 - val_loss: 0.8223 - val_accuracy: 0.6207\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2671 - accuracy: 0.87 - 0s 146us/sample - loss: 0.4111 - accuracy: 0.8276 - val_loss: 0.8317 - val_accuracy: 0.6552\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3172 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4068 - accuracy: 0.8190 - val_loss: 0.8293 - val_accuracy: 0.6552\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4126 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3784 - accuracy: 0.8276 - val_loss: 0.9181 - val_accuracy: 0.7241\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5086 - accuracy: 0.71 - 0s 120us/sample - loss: 0.3802 - accuracy: 0.8017 - val_loss: 0.8819 - val_accuracy: 0.6207\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3099 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3229 - accuracy: 0.8362 - val_loss: 0.8694 - val_accuracy: 0.6897\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2490 - accuracy: 0.87 - 0s 120us/sample - loss: 0.3195 - accuracy: 0.8362 - val_loss: 0.9514 - val_accuracy: 0.6552\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.81 - 0s 129us/sample - loss: 0.2867 - accuracy: 0.8966 - val_loss: 1.1309 - val_accuracy: 0.6552\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3069 - accuracy: 0.8448 - val_loss: 1.1150 - val_accuracy: 0.6207\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3259 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3012 - accuracy: 0.8534 - val_loss: 0.9678 - val_accuracy: 0.6552\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3165 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2589 - accuracy: 0.8879 - val_loss: 1.1766 - val_accuracy: 0.6897\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2089 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2516 - accuracy: 0.8707 - val_loss: 1.2215 - val_accuracy: 0.6552\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1192 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2187 - accuracy: 0.9138 - val_loss: 1.2906 - val_accuracy: 0.6207\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2770 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2151 - accuracy: 0.9138 - val_loss: 1.3690 - val_accuracy: 0.6207\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3065 - accuracy: 0.78 - 0s 138us/sample - loss: 0.2042 - accuracy: 0.9052 - val_loss: 1.6019 - val_accuracy: 0.6552\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1724 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1873 - accuracy: 0.9310 - val_loss: 1.6560 - val_accuracy: 0.5862\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1581 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1568 - accuracy: 0.9569 - val_loss: 2.1730 - val_accuracy: 0.5517\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1692 - accuracy: 0.9310 - val_loss: 2.0972 - val_accuracy: 0.5172\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 1.00 - 0s 138us/sample - loss: 0.2420 - accuracy: 0.9310 - val_loss: 1.7059 - val_accuracy: 0.6207\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1977 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2675 - accuracy: 0.8879 - val_loss: 1.6747 - val_accuracy: 0.6207\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2805 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2618 - accuracy: 0.8793 - val_loss: 1.6774 - val_accuracy: 0.6552\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3913 - accuracy: 0.78 - 0s 138us/sample - loss: 0.2270 - accuracy: 0.8879 - val_loss: 1.7631 - val_accuracy: 0.6552\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1984 - accuracy: 0.9224 - val_loss: 1.8311 - val_accuracy: 0.6207\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2662 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2059 - accuracy: 0.8879 - val_loss: 1.7936 - val_accuracy: 0.5862\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1484 - accuracy: 0.9569 - val_loss: 1.6125 - val_accuracy: 0.5862\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.90 - 0s 163us/sample - loss: 0.1502 - accuracy: 0.9310 - val_loss: 1.9309 - val_accuracy: 0.5172\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1674 - accuracy: 0.9397 - val_loss: 2.1986 - val_accuracy: 0.6207\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2958 - accuracy: 0.8621 - val_loss: 2.0170 - val_accuracy: 0.4828\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2613 - accuracy: 0.84 - 0s 155us/sample - loss: 0.2099 - accuracy: 0.8966 - val_loss: 1.7256 - val_accuracy: 0.5862\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3707 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2511 - accuracy: 0.9138 - val_loss: 1.6840 - val_accuracy: 0.6207\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1517 - accuracy: 0.9483 - val_loss: 1.7731 - val_accuracy: 0.5862\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1276 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1517 - accuracy: 0.9397 - val_loss: 2.0931 - val_accuracy: 0.5862\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1342 - accuracy: 0.9483 - val_loss: 2.1626 - val_accuracy: 0.5862\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1322 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1052 - accuracy: 0.9741 - val_loss: 2.4238 - val_accuracy: 0.5862\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0971 - accuracy: 0.9655 - val_loss: 2.6177 - val_accuracy: 0.5517\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0806 - accuracy: 0.9828 - val_loss: 3.0032 - val_accuracy: 0.6207\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0633 - accuracy: 0.9741 - val_loss: 3.2806 - val_accuracy: 0.6207\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0491 - accuracy: 0.9828 - val_loss: 3.5678 - val_accuracy: 0.6207\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0406 - accuracy: 0.9828 - val_loss: 3.8638 - val_accuracy: 0.6207\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0400 - accuracy: 0.9914 - val_loss: 3.8713 - val_accuracy: 0.6207\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0350 - accuracy: 0.9914 - val_loss: 4.2668 - val_accuracy: 0.6207\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0277 - accuracy: 1.0000 - val_loss: 4.4070 - val_accuracy: 0.5862\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0223 - accuracy: 0.9914 - val_loss: 4.5863 - val_accuracy: 0.6207\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0278 - accuracy: 0.9914 - val_loss: 4.7942 - val_accuracy: 0.5862\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1230 - accuracy: 0.9655 - val_loss: 5.1618 - val_accuracy: 0.6207\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2936 - accuracy: 0.8966 - val_loss: 4.4956 - val_accuracy: 0.5517\n",
      "Epoch 66/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.3575 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2435 - accuracy: 0.9310 - val_loss: 3.8456 - val_accuracy: 0.5862\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.93 - 0s 249us/sample - loss: 0.2505 - accuracy: 0.8966 - val_loss: 3.2367 - val_accuracy: 0.5862\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1997 - accuracy: 0.93 - 0s 447us/sample - loss: 0.2152 - accuracy: 0.9052 - val_loss: 2.9127 - val_accuracy: 0.5517\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1579 - accuracy: 0.96 - 0s 464us/sample - loss: 0.1901 - accuracy: 0.9310 - val_loss: 3.3452 - val_accuracy: 0.5172\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 0.96 - 0s 490us/sample - loss: 0.1712 - accuracy: 0.9397 - val_loss: 3.5598 - val_accuracy: 0.5862\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.96 - 0s 430us/sample - loss: 0.1182 - accuracy: 0.9483 - val_loss: 3.3607 - val_accuracy: 0.5862\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1553 - accuracy: 0.96 - 0s 499us/sample - loss: 0.1550 - accuracy: 0.9483 - val_loss: 3.3380 - val_accuracy: 0.5517\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2908 - accuracy: 0.90 - 0s 456us/sample - loss: 0.1600 - accuracy: 0.9483 - val_loss: 3.3771 - val_accuracy: 0.5862\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 1.00 - 0s 404us/sample - loss: 0.0964 - accuracy: 0.9741 - val_loss: 3.4246 - val_accuracy: 0.5862\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.96 - 0s 430us/sample - loss: 0.0786 - accuracy: 0.9741 - val_loss: 3.7318 - val_accuracy: 0.5862\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.93 - 0s 507us/sample - loss: 0.0649 - accuracy: 0.9741 - val_loss: 4.0113 - val_accuracy: 0.5862\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.96 - 0s 482us/sample - loss: 0.0550 - accuracy: 0.9741 - val_loss: 4.3433 - val_accuracy: 0.5862\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 1.00 - 0s 481us/sample - loss: 0.0457 - accuracy: 0.9914 - val_loss: 4.6915 - val_accuracy: 0.5862\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 1.00 - 0s 430us/sample - loss: 0.0411 - accuracy: 0.9914 - val_loss: 5.1562 - val_accuracy: 0.5862\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 0.96 - 0s 456us/sample - loss: 0.0438 - accuracy: 0.9741 - val_loss: 5.5259 - val_accuracy: 0.5862\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 1.00 - 0s 464us/sample - loss: 0.0393 - accuracy: 0.9914 - val_loss: 5.6804 - val_accuracy: 0.5862\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0352 - accuracy: 0.9828 - val_loss: 6.0273 - val_accuracy: 0.5862\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0296 - accuracy: 0.9914 - val_loss: 6.0007 - val_accuracy: 0.5862\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0276 - accuracy: 0.9914 - val_loss: 6.1583 - val_accuracy: 0.5517\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0224 - accuracy: 0.9914 - val_loss: 6.4777 - val_accuracy: 0.5862\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0285 - accuracy: 0.9828 - val_loss: 6.5333 - val_accuracy: 0.5862\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0175 - accuracy: 0.9914 - val_loss: 6.2969 - val_accuracy: 0.5172\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0964 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0583 - accuracy: 0.9741 - val_loss: 6.8934 - val_accuracy: 0.5862\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0395 - accuracy: 0.9914 - val_loss: 6.5802 - val_accuracy: 0.5172\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0366 - accuracy: 0.9828 - val_loss: 6.6534 - val_accuracy: 0.5862\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0443 - accuracy: 0.9828 - val_loss: 6.7491 - val_accuracy: 0.5862\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0463 - accuracy: 0.9741 - val_loss: 6.8095 - val_accuracy: 0.4828\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0309 - accuracy: 0.9828 - val_loss: 7.0462 - val_accuracy: 0.5862\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0300 - accuracy: 0.9828 - val_loss: 6.7963 - val_accuracy: 0.5862\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0291 - accuracy: 0.9914 - val_loss: 6.7393 - val_accuracy: 0.5862\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0200 - accuracy: 0.9914 - val_loss: 6.9812 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0226 - accuracy: 0.9914 - val_loss: 7.0284 - val_accuracy: 0.5862\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0153 - accuracy: 0.9914 - val_loss: 6.7242 - val_accuracy: 0.5862\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0167 - accuracy: 0.9914 - val_loss: 6.7576 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0168 - accuracy: 0.9914 - val_loss: 7.0385 - val_accuracy: 0.5862\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0152 - accuracy: 0.9914 - val_loss: 7.1913 - val_accuracy: 0.5862\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0130 - accuracy: 1.0000 - val_loss: 7.1789 - val_accuracy: 0.5862\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0126 - accuracy: 1.0000 - val_loss: 7.2387 - val_accuracy: 0.5862\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0134 - accuracy: 0.9914 - val_loss: 7.3019 - val_accuracy: 0.5862\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0118 - accuracy: 0.9914 - val_loss: 7.5276 - val_accuracy: 0.5862\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 7.6469 - val_accuracy: 0.5862\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 1.00 - 0s 413us/sample - loss: 0.0140 - accuracy: 0.9914 - val_loss: 7.6899 - val_accuracy: 0.5862\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1028e-04 - accuracy: 1.00 - 0s 447us/sample - loss: 0.0207 - accuracy: 0.9914 - val_loss: 7.6141 - val_accuracy: 0.5862\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0118 - accuracy: 0.9914 - val_loss: 7.8480 - val_accuracy: 0.5862\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 7.9541 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5574e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0094 - accuracy: 1.0000 - val_loss: 7.9236 - val_accuracy: 0.5862\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 7.9292 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0112 - accuracy: 0.9914 - val_loss: 8.0588 - val_accuracy: 0.5862\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0116 - accuracy: 0.9914 - val_loss: 8.0596 - val_accuracy: 0.5862\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0145 - accuracy: 0.9914 - val_loss: 8.2101 - val_accuracy: 0.5862\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6789e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0078 - accuracy: 0.9914 - val_loss: 8.1018 - val_accuracy: 0.5862\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 8.2696 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4560e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 8.3205 - val_accuracy: 0.5862\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 206us/sample - loss: 0.0046 - accuracy: 1.0000 - val_loss: 8.2993 - val_accuracy: 0.5862\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7857e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0082 - accuracy: 0.9914 - val_loss: 8.3489 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6966e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 8.5493 - val_accuracy: 0.5862\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0092 - accuracy: 0.9914 - val_loss: 8.2878 - val_accuracy: 0.5862\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0082 - accuracy: 0.9914 - val_loss: 8.5115 - val_accuracy: 0.5862\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.2082e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 8.5633 - val_accuracy: 0.5862\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 8.3975 - val_accuracy: 0.5862\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0251 - accuracy: 0.9914 - val_loss: 8.6509 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0258 - accuracy: 0.9914 - val_loss: 8.8714 - val_accuracy: 0.5862\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1355 - accuracy: 0.93 - 0s 172us/sample - loss: 0.0486 - accuracy: 0.9741 - val_loss: 8.0809 - val_accuracy: 0.5862\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0226 - accuracy: 0.9914 - val_loss: 8.7213 - val_accuracy: 0.5862\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4473 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1793 - accuracy: 0.9569 - val_loss: 7.1735 - val_accuracy: 0.5517\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.93 - 0s 120us/sample - loss: 0.2036 - accuracy: 0.9310 - val_loss: 6.7802 - val_accuracy: 0.5862\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2859 - accuracy: 0.9138 - val_loss: 5.5191 - val_accuracy: 0.5862\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0910 - accuracy: 0.9655 - val_loss: 4.9174 - val_accuracy: 0.5172\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.96 - 0s 138us/sample - loss: 0.3266 - accuracy: 0.9138 - val_loss: 3.9864 - val_accuracy: 0.5862\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2626 - accuracy: 0.9138 - val_loss: 3.4350 - val_accuracy: 0.5862\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1164 - accuracy: 0.9569 - val_loss: 3.6454 - val_accuracy: 0.5517\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 1.00 - 0s 120us/sample - loss: 0.1029 - accuracy: 0.9569 - val_loss: 3.8793 - val_accuracy: 0.5517\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0784 - accuracy: 0.9914 - val_loss: 3.9106 - val_accuracy: 0.5862\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0603 - accuracy: 0.9914 - val_loss: 4.2335 - val_accuracy: 0.5862\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0468 - accuracy: 0.9914 - val_loss: 4.6896 - val_accuracy: 0.5862\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0366 - accuracy: 1.0000 - val_loss: 5.0889 - val_accuracy: 0.5517\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0263 - accuracy: 1.0000 - val_loss: 5.4786 - val_accuracy: 0.5862\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0256 - accuracy: 0.9914 - val_loss: 5.7518 - val_accuracy: 0.5517\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0183 - accuracy: 1.0000 - val_loss: 6.0714 - val_accuracy: 0.5517\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0128 - accuracy: 1.0000 - val_loss: 6.4512 - val_accuracy: 0.5517\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0154 - accuracy: 1.0000 - val_loss: 6.7978 - val_accuracy: 0.5517\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 1.00 - 0s 112us/sample - loss: 0.0092 - accuracy: 1.0000 - val_loss: 7.0481 - val_accuracy: 0.5517\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0099 - accuracy: 1.0000 - val_loss: 7.3266 - val_accuracy: 0.5517\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0060 - accuracy: 1.0000 - val_loss: 7.5694 - val_accuracy: 0.5517\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 7.8041 - val_accuracy: 0.5517\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0043 - accuracy: 1.0000 - val_loss: 8.0124 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 8.2311 - val_accuracy: 0.5517\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 112us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 8.3460 - val_accuracy: 0.5517\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 8.6108 - val_accuracy: 0.5517\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 112us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 8.7705 - val_accuracy: 0.5517\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 8.8499 - val_accuracy: 0.5517\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 8.9453 - val_accuracy: 0.5517\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 9.0860 - val_accuracy: 0.5517\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 9.3659 - val_accuracy: 0.5517\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 9.3804 - val_accuracy: 0.5517\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.3802 - val_accuracy: 0.5517\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 9.4799 - val_accuracy: 0.5517\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5930e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.6161 - val_accuracy: 0.5517\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.7383 - val_accuracy: 0.5517\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0150e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 9.6910e-04 - accuracy: 1.0000 - val_loss: 9.8057 - val_accuracy: 0.5517\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4341e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 8.9019e-04 - accuracy: 1.0000 - val_loss: 9.8536 - val_accuracy: 0.5517\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0785e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 8.8237e-04 - accuracy: 1.0000 - val_loss: 9.9193 - val_accuracy: 0.5517\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3649e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.2836e-04 - accuracy: 1.0000 - val_loss: 10.0114 - val_accuracy: 0.5517\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 8.5187e-04 - accuracy: 1.0000 - val_loss: 10.1100 - val_accuracy: 0.5517\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9391e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.3663e-04 - accuracy: 1.0000 - val_loss: 10.1477 - val_accuracy: 0.5517\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6056e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.8811e-04 - accuracy: 1.0000 - val_loss: 10.1731 - val_accuracy: 0.5517\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.4377e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 7.0259e-04 - accuracy: 1.0000 - val_loss: 10.2832 - val_accuracy: 0.5517\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5285e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.3434e-04 - accuracy: 1.0000 - val_loss: 10.3799 - val_accuracy: 0.5517\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5000e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.8071e-04 - accuracy: 1.0000 - val_loss: 10.4017 - val_accuracy: 0.5517\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1906e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.0291e-04 - accuracy: 1.0000 - val_loss: 10.4456 - val_accuracy: 0.5517\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7875e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.8586e-04 - accuracy: 1.0000 - val_loss: 10.4923 - val_accuracy: 0.5517\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 5.7149e-04 - accuracy: 1.0000 - val_loss: 10.5590 - val_accuracy: 0.5517\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9442e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.3879e-04 - accuracy: 1.0000 - val_loss: 10.6133 - val_accuracy: 0.5517\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2769e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.2533e-04 - accuracy: 1.0000 - val_loss: 10.6616 - val_accuracy: 0.5517\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1254e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.1769e-04 - accuracy: 1.0000 - val_loss: 10.6840 - val_accuracy: 0.5517\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5512e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.0685e-04 - accuracy: 1.0000 - val_loss: 10.7446 - val_accuracy: 0.5517\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4597e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.7573e-04 - accuracy: 1.0000 - val_loss: 10.7927 - val_accuracy: 0.5517\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9227e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.6531e-04 - accuracy: 1.0000 - val_loss: 10.8418 - val_accuracy: 0.5517\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1209e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.4615e-04 - accuracy: 1.0000 - val_loss: 10.8759 - val_accuracy: 0.5517\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0008e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 4.3321e-04 - accuracy: 1.0000 - val_loss: 10.9085 - val_accuracy: 0.5517\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3994e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.2308e-04 - accuracy: 1.0000 - val_loss: 10.9550 - val_accuracy: 0.5517\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6501e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.1350e-04 - accuracy: 1.0000 - val_loss: 11.0039 - val_accuracy: 0.5517\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2649e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 4.0082e-04 - accuracy: 1.0000 - val_loss: 11.0429 - val_accuracy: 0.5517\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1544e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.8755e-04 - accuracy: 1.0000 - val_loss: 11.0829 - val_accuracy: 0.5517\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3071e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.7813e-04 - accuracy: 1.0000 - val_loss: 11.1251 - val_accuracy: 0.5517\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0866e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.7209e-04 - accuracy: 1.0000 - val_loss: 11.1598 - val_accuracy: 0.5517\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7818e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.7261e-04 - accuracy: 1.0000 - val_loss: 11.2049 - val_accuracy: 0.5517\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4321e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.6184e-04 - accuracy: 1.0000 - val_loss: 11.2180 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7139e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.5252e-04 - accuracy: 1.0000 - val_loss: 11.2480 - val_accuracy: 0.5517\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5679e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.4147e-04 - accuracy: 1.0000 - val_loss: 11.2972 - val_accuracy: 0.5517\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3284e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.3720e-04 - accuracy: 1.0000 - val_loss: 11.3506 - val_accuracy: 0.5517\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6123e-04 - accuracy: 1.00 - 0s 249us/sample - loss: 3.2689e-04 - accuracy: 1.0000 - val_loss: 11.3884 - val_accuracy: 0.5517\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9706e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.1262e-04 - accuracy: 1.0000 - val_loss: 11.3999 - val_accuracy: 0.5517\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2519e-04 - accuracy: 1.00 - 0s 112us/sample - loss: 3.2225e-04 - accuracy: 1.0000 - val_loss: 11.4184 - val_accuracy: 0.5517\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2626e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.1060e-04 - accuracy: 1.0000 - val_loss: 11.4625 - val_accuracy: 0.5517\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6998 - accuracy: 0.43 - 0s 3ms/sample - loss: 0.6356 - accuracy: 0.6293 - val_loss: 0.7106 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6217 - accuracy: 0.71 - 0s 163us/sample - loss: 0.6552 - accuracy: 0.6638 - val_loss: 0.6360 - val_accuracy: 0.6897\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6030 - accuracy: 0.75 - 0s 155us/sample - loss: 0.6199 - accuracy: 0.6810 - val_loss: 0.6064 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6292 - accuracy: 0.65 - 0s 129us/sample - loss: 0.5912 - accuracy: 0.6724 - val_loss: 0.6144 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6057 - accuracy: 0.65 - 0s 181us/sample - loss: 0.5895 - accuracy: 0.6983 - val_loss: 0.5963 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5669 - accuracy: 0.75 - 0s 172us/sample - loss: 0.5671 - accuracy: 0.7069 - val_loss: 0.5812 - val_accuracy: 0.6897\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5882 - accuracy: 0.68 - 0s 146us/sample - loss: 0.5468 - accuracy: 0.7241 - val_loss: 0.5868 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5020 - accuracy: 0.81 - 0s 138us/sample - loss: 0.5233 - accuracy: 0.7672 - val_loss: 0.5986 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6833 - accuracy: 0.65 - 0s 129us/sample - loss: 0.5073 - accuracy: 0.7672 - val_loss: 0.6162 - val_accuracy: 0.6552\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5090 - accuracy: 0.75 - 0s 138us/sample - loss: 0.5048 - accuracy: 0.7500 - val_loss: 0.6632 - val_accuracy: 0.5862\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4517 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4989 - accuracy: 0.7500 - val_loss: 0.6552 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4729 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4601 - accuracy: 0.7759 - val_loss: 0.6985 - val_accuracy: 0.5862\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4768 - accuracy: 0.75 - 0s 172us/sample - loss: 0.4668 - accuracy: 0.7845 - val_loss: 0.6918 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4603 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4482 - accuracy: 0.7845 - val_loss: 0.6667 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4612 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4319 - accuracy: 0.8017 - val_loss: 0.7432 - val_accuracy: 0.6207\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3798 - accuracy: 0.81 - 0s 137us/sample - loss: 0.4082 - accuracy: 0.8190 - val_loss: 0.8984 - val_accuracy: 0.5862\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.78 - 0s 129us/sample - loss: 0.3870 - accuracy: 0.8103 - val_loss: 0.8042 - val_accuracy: 0.6897\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2351 - accuracy: 0.93 - 0s 129us/sample - loss: 0.3755 - accuracy: 0.8190 - val_loss: 1.0331 - val_accuracy: 0.5517\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3872 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4124 - accuracy: 0.7931 - val_loss: 0.9060 - val_accuracy: 0.6897\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4955 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4150 - accuracy: 0.8190 - val_loss: 0.9804 - val_accuracy: 0.5862\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4444 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3927 - accuracy: 0.8103 - val_loss: 0.7691 - val_accuracy: 0.6897\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3964 - accuracy: 0.8534 - val_loss: 0.8491 - val_accuracy: 0.6897\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3844 - accuracy: 0.81 - 0s 137us/sample - loss: 0.3636 - accuracy: 0.8276 - val_loss: 0.8932 - val_accuracy: 0.6552\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3360 - accuracy: 0.8448 - val_loss: 0.9301 - val_accuracy: 0.6897\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3277 - accuracy: 0.8276 - val_loss: 0.9811 - val_accuracy: 0.7241\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3718 - accuracy: 0.8190 - val_loss: 1.1232 - val_accuracy: 0.6552\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3239 - accuracy: 0.8190 - val_loss: 0.9913 - val_accuracy: 0.7241\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3013 - accuracy: 0.8448 - val_loss: 0.9904 - val_accuracy: 0.6552\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2433 - accuracy: 0.84 - 0s 120us/sample - loss: 0.2656 - accuracy: 0.8793 - val_loss: 1.0979 - val_accuracy: 0.6897\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2808 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2635 - accuracy: 0.8707 - val_loss: 1.2482 - val_accuracy: 0.7241\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1544 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2209 - accuracy: 0.8966 - val_loss: 1.3856 - val_accuracy: 0.6897\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2203 - accuracy: 0.9052 - val_loss: 1.6654 - val_accuracy: 0.5862\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3497 - accuracy: 0.8190 - val_loss: 1.4032 - val_accuracy: 0.6897\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 1.00 - 0s 138us/sample - loss: 0.2138 - accuracy: 0.9138 - val_loss: 1.3733 - val_accuracy: 0.5862\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1938 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2133 - accuracy: 0.9224 - val_loss: 1.3303 - val_accuracy: 0.6552\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2420 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2450 - accuracy: 0.8707 - val_loss: 1.3449 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2830 - accuracy: 0.81 - 0s 138us/sample - loss: 0.1735 - accuracy: 0.9397 - val_loss: 1.3419 - val_accuracy: 0.6897\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.81 - 0s 120us/sample - loss: 0.1923 - accuracy: 0.9138 - val_loss: 1.5820 - val_accuracy: 0.6207\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1485 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1476 - accuracy: 0.9483 - val_loss: 1.7783 - val_accuracy: 0.6207\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1712 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1462 - accuracy: 0.9397 - val_loss: 1.6793 - val_accuracy: 0.6552\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1570 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1415 - accuracy: 0.9310 - val_loss: 1.9225 - val_accuracy: 0.5862\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1639 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1138 - accuracy: 0.9569 - val_loss: 1.8883 - val_accuracy: 0.6552\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1952 - accuracy: 0.87 - 0s 129us/sample - loss: 0.1215 - accuracy: 0.9310 - val_loss: 2.2229 - val_accuracy: 0.5517\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1057 - accuracy: 0.9569 - val_loss: 2.0590 - val_accuracy: 0.6207\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0878 - accuracy: 0.9655 - val_loss: 2.5572 - val_accuracy: 0.5172\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1559 - accuracy: 0.9310 - val_loss: 2.3536 - val_accuracy: 0.6552\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0975 - accuracy: 0.9483 - val_loss: 2.6464 - val_accuracy: 0.5862\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2019 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1165 - accuracy: 0.9138 - val_loss: 2.3497 - val_accuracy: 0.6897\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1250 - accuracy: 0.9655 - val_loss: 2.4887 - val_accuracy: 0.5517\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0716 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0911 - accuracy: 0.9741 - val_loss: 2.2928 - val_accuracy: 0.6552\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1305 - accuracy: 0.9397 - val_loss: 2.7529 - val_accuracy: 0.5172\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1251 - accuracy: 0.9483 - val_loss: 2.4197 - val_accuracy: 0.6897\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2287 - accuracy: 0.9052 - val_loss: 2.9911 - val_accuracy: 0.5172\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2163 - accuracy: 0.8966 - val_loss: 1.8746 - val_accuracy: 0.6897\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1104 - accuracy: 0.9483 - val_loss: 2.2610 - val_accuracy: 0.5172\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0965 - accuracy: 0.9655 - val_loss: 2.5496 - val_accuracy: 0.5862\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0762 - accuracy: 0.9655 - val_loss: 2.3882 - val_accuracy: 0.6552\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0676 - accuracy: 0.9655 - val_loss: 2.6959 - val_accuracy: 0.5517\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0614 - accuracy: 0.9741 - val_loss: 2.7198 - val_accuracy: 0.5862\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0496 - accuracy: 0.9741 - val_loss: 2.9094 - val_accuracy: 0.5517\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0447 - accuracy: 0.9914 - val_loss: 2.9367 - val_accuracy: 0.6207\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0312 - accuracy: 1.0000 - val_loss: 3.0382 - val_accuracy: 0.6207\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0313 - accuracy: 1.0000 - val_loss: 3.1958 - val_accuracy: 0.6207\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0367 - accuracy: 0.9914 - val_loss: 3.2789 - val_accuracy: 0.6207\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0194 - accuracy: 1.0000 - val_loss: 3.4857 - val_accuracy: 0.5172\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0429 - accuracy: 0.9655 - val_loss: 3.2197 - val_accuracy: 0.5517\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0825 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0408 - accuracy: 0.9914 - val_loss: 3.3067 - val_accuracy: 0.6207\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0245 - accuracy: 0.9914 - val_loss: 3.5907 - val_accuracy: 0.5517\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0596 - accuracy: 0.9741 - val_loss: 3.4746 - val_accuracy: 0.6207\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1051 - accuracy: 0.9655 - val_loss: 3.6022 - val_accuracy: 0.5862\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0855 - accuracy: 0.9655 - val_loss: 3.5358 - val_accuracy: 0.5862\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0462 - accuracy: 0.9655 - val_loss: 3.2880 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0367 - accuracy: 0.9914 - val_loss: 3.5578 - val_accuracy: 0.6207\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0283 - accuracy: 0.9914 - val_loss: 3.1608 - val_accuracy: 0.5517\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0643 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0285 - accuracy: 0.9914 - val_loss: 3.0268 - val_accuracy: 0.5862\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0249 - accuracy: 0.9914 - val_loss: 3.3593 - val_accuracy: 0.5517\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0194 - accuracy: 1.0000 - val_loss: 3.7195 - val_accuracy: 0.5517\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 3.7881 - val_accuracy: 0.5862\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0159 - accuracy: 0.9914 - val_loss: 3.9943 - val_accuracy: 0.5862\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0141 - accuracy: 0.9914 - val_loss: 4.1747 - val_accuracy: 0.5517\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0170 - accuracy: 0.9914 - val_loss: 4.1910 - val_accuracy: 0.5517\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0086 - accuracy: 1.0000 - val_loss: 4.0453 - val_accuracy: 0.5862\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0292 - accuracy: 0.9914 - val_loss: 4.1968 - val_accuracy: 0.6207\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0192 - accuracy: 0.9914 - val_loss: 4.5830 - val_accuracy: 0.5517\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0218 - accuracy: 0.9914 - val_loss: 4.6180 - val_accuracy: 0.5517\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0096 - accuracy: 1.0000 - val_loss: 4.5480 - val_accuracy: 0.5517\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0087 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0050 - accuracy: 1.0000 - val_loss: 4.5625 - val_accuracy: 0.5517\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 4.5248 - val_accuracy: 0.5517\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 4.6343 - val_accuracy: 0.5862\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0236 - accuracy: 0.9914 - val_loss: 4.5298 - val_accuracy: 0.5517\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0445 - accuracy: 0.9914 - val_loss: 4.3561 - val_accuracy: 0.5517\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.2710 - val_accuracy: 0.6207\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0107 - accuracy: 1.0000 - val_loss: 4.4746 - val_accuracy: 0.5517\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0045 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 4.5961 - val_accuracy: 0.5517\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0168 - accuracy: 0.9914 - val_loss: 4.4758 - val_accuracy: 0.5862\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0234 - accuracy: 0.9828 - val_loss: 4.3662 - val_accuracy: 0.5517\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1048 - accuracy: 0.9655 - val_loss: 3.2636 - val_accuracy: 0.6897\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2691 - accuracy: 0.9397 - val_loss: 3.2296 - val_accuracy: 0.6207\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1260 - accuracy: 0.9569 - val_loss: 3.1376 - val_accuracy: 0.6552\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1386 - accuracy: 0.9397 - val_loss: 2.7354 - val_accuracy: 0.5172\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1314 - accuracy: 0.9483 - val_loss: 2.8451 - val_accuracy: 0.6207\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 1.00 - 0s 138us/sample - loss: 0.2506 - accuracy: 0.9483 - val_loss: 3.6542 - val_accuracy: 0.4828\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1404 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3851 - accuracy: 0.8534 - val_loss: 3.9625 - val_accuracy: 0.6552\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7381 - accuracy: 0.84 - 0s 137us/sample - loss: 0.6122 - accuracy: 0.8534 - val_loss: 3.6049 - val_accuracy: 0.5517\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1827 - accuracy: 0.9138 - val_loss: 2.7640 - val_accuracy: 0.4828\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2329 - accuracy: 0.9138 - val_loss: 2.3254 - val_accuracy: 0.5862\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2040 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2019 - accuracy: 0.9397 - val_loss: 2.1213 - val_accuracy: 0.5517\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1661 - accuracy: 0.9397 - val_loss: 2.2013 - val_accuracy: 0.5517\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1374 - accuracy: 0.9655 - val_loss: 2.2856 - val_accuracy: 0.5862\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1420 - accuracy: 0.96 - 0s 137us/sample - loss: 0.1123 - accuracy: 0.9655 - val_loss: 2.5588 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.87 - 0s 129us/sample - loss: 0.0812 - accuracy: 0.9655 - val_loss: 2.9067 - val_accuracy: 0.5862\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0574 - accuracy: 0.9828 - val_loss: 3.1863 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0655 - accuracy: 0.9914 - val_loss: 3.4624 - val_accuracy: 0.6207\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0537 - accuracy: 0.9741 - val_loss: 3.7034 - val_accuracy: 0.6207\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0535 - accuracy: 0.9741 - val_loss: 3.8435 - val_accuracy: 0.5172\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0448 - accuracy: 0.9914 - val_loss: 3.9653 - val_accuracy: 0.6207\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0299 - accuracy: 0.9914 - val_loss: 4.0375 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0258 - accuracy: 1.0000 - val_loss: 4.2624 - val_accuracy: 0.5862\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0224 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0225 - accuracy: 0.9914 - val_loss: 4.4950 - val_accuracy: 0.5862\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0287 - accuracy: 0.9914 - val_loss: 4.4664 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 4.6988 - val_accuracy: 0.6207\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0179 - accuracy: 1.0000 - val_loss: 4.7611 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.96 - 0s 137us/sample - loss: 0.0212 - accuracy: 0.9914 - val_loss: 4.8176 - val_accuracy: 0.6207\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0163 - accuracy: 1.0000 - val_loss: 4.9707 - val_accuracy: 0.6207\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0123 - accuracy: 1.0000 - val_loss: 5.1118 - val_accuracy: 0.5172\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0256 - accuracy: 0.9914 - val_loss: 5.1868 - val_accuracy: 0.5517\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0122 - accuracy: 1.0000 - val_loss: 5.2153 - val_accuracy: 0.6207\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0141 - accuracy: 0.9914 - val_loss: 5.4063 - val_accuracy: 0.5517\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0115 - accuracy: 1.0000 - val_loss: 5.4972 - val_accuracy: 0.6207\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 5.5095 - val_accuracy: 0.5862\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 5.7081 - val_accuracy: 0.5517\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0045 - accuracy: 1.0000 - val_loss: 5.8325 - val_accuracy: 0.5517\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.8672 - val_accuracy: 0.5517\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 5.9173 - val_accuracy: 0.5517\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3136e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 6.0074 - val_accuracy: 0.5517\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 6.0906 - val_accuracy: 0.5517\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.1822e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.1692 - val_accuracy: 0.5517\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3895e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.2151 - val_accuracy: 0.5517\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.2749 - val_accuracy: 0.5517\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 6.3202 - val_accuracy: 0.5517\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.3452 - val_accuracy: 0.5517\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0577e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.3809 - val_accuracy: 0.5517\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 6.4221 - val_accuracy: 0.5517\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.4729 - val_accuracy: 0.5517\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4344e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.5127 - val_accuracy: 0.5517\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.5349 - val_accuracy: 0.5517\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 129us/sample - loss: 9.6386e-04 - accuracy: 1.0000 - val_loss: 6.5701 - val_accuracy: 0.5517\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 129us/sample - loss: 8.7040e-04 - accuracy: 1.0000 - val_loss: 6.5856 - val_accuracy: 0.5517\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3031e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.3329e-04 - accuracy: 1.0000 - val_loss: 6.6118 - val_accuracy: 0.5517\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 138us/sample - loss: 9.5170e-04 - accuracy: 1.0000 - val_loss: 6.6822 - val_accuracy: 0.5517\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0758e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.1942e-04 - accuracy: 1.0000 - val_loss: 6.6980 - val_accuracy: 0.5517\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 7.7205e-04 - accuracy: 1.0000 - val_loss: 6.6922 - val_accuracy: 0.5517\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0463e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.2701e-04 - accuracy: 1.0000 - val_loss: 6.7184 - val_accuracy: 0.5517\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8125e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.0643e-04 - accuracy: 1.0000 - val_loss: 6.7640 - val_accuracy: 0.5517\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6224e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 6.9000e-04 - accuracy: 1.0000 - val_loss: 6.8118 - val_accuracy: 0.5517\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0980e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.5962e-04 - accuracy: 1.0000 - val_loss: 6.8235 - val_accuracy: 0.5517\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 138us/sample - loss: 5.7937e-04 - accuracy: 1.0000 - val_loss: 6.8243 - val_accuracy: 0.5517\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6548e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.9924e-04 - accuracy: 1.0000 - val_loss: 6.8406 - val_accuracy: 0.5517\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7197e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 5.8750e-04 - accuracy: 1.0000 - val_loss: 6.9067 - val_accuracy: 0.5517\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0701e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.3000e-04 - accuracy: 1.0000 - val_loss: 6.9407 - val_accuracy: 0.5517\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8394e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.0260e-04 - accuracy: 1.0000 - val_loss: 6.8979 - val_accuracy: 0.5517\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5920e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.5864e-04 - accuracy: 1.0000 - val_loss: 6.9124 - val_accuracy: 0.5517\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3797e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 5.7937e-04 - accuracy: 1.0000 - val_loss: 7.0236 - val_accuracy: 0.5517\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 138us/sample - loss: 9.5688e-04 - accuracy: 1.0000 - val_loss: 7.0569 - val_accuracy: 0.5517\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2551e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.7840e-04 - accuracy: 1.0000 - val_loss: 6.9906 - val_accuracy: 0.5517\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0378e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.7279e-04 - accuracy: 1.0000 - val_loss: 6.9850 - val_accuracy: 0.5517\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4696e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 6.1676e-04 - accuracy: 1.0000 - val_loss: 7.0413 - val_accuracy: 0.5517\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 4.6605e-04 - accuracy: 1.0000 - val_loss: 7.1167 - val_accuracy: 0.5862\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8526e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.4806e-04 - accuracy: 1.0000 - val_loss: 7.1483 - val_accuracy: 0.5862\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3815e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.0014e-04 - accuracy: 1.0000 - val_loss: 7.1313 - val_accuracy: 0.5517\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8857e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.0248e-04 - accuracy: 1.0000 - val_loss: 7.1194 - val_accuracy: 0.5517\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4405e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.5697e-04 - accuracy: 1.0000 - val_loss: 7.1481 - val_accuracy: 0.5517\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8269e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.0635e-04 - accuracy: 1.0000 - val_loss: 7.1814 - val_accuracy: 0.5517\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7749e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.4483e-04 - accuracy: 1.0000 - val_loss: 7.2215 - val_accuracy: 0.5862\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0945e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.4882e-04 - accuracy: 1.0000 - val_loss: 7.2549 - val_accuracy: 0.5862\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3020e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 3.4674e-04 - accuracy: 1.0000 - val_loss: 7.2694 - val_accuracy: 0.5862\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6028e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.2115e-04 - accuracy: 1.0000 - val_loss: 7.2815 - val_accuracy: 0.5517\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7256e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.9264e-04 - accuracy: 1.0000 - val_loss: 7.2809 - val_accuracy: 0.5517\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7512e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.2415e-04 - accuracy: 1.0000 - val_loss: 7.2830 - val_accuracy: 0.5517\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2883e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.2580e-04 - accuracy: 1.0000 - val_loss: 7.3069 - val_accuracy: 0.5862\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9526e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.9168e-04 - accuracy: 1.0000 - val_loss: 7.3336 - val_accuracy: 0.5862\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.6933e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 2.8481e-04 - accuracy: 1.0000 - val_loss: 7.3719 - val_accuracy: 0.5862\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3801e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 2.9410e-04 - accuracy: 1.0000 - val_loss: 7.3977 - val_accuracy: 0.5862\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4942e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.9359e-04 - accuracy: 1.0000 - val_loss: 7.3970 - val_accuracy: 0.5862\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.5483e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 2.6008e-04 - accuracy: 1.0000 - val_loss: 7.4141 - val_accuracy: 0.5862\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7872e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.5754e-04 - accuracy: 1.0000 - val_loss: 7.4318 - val_accuracy: 0.5862\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3283e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.4646e-04 - accuracy: 1.0000 - val_loss: 7.4481 - val_accuracy: 0.5862\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5665e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.4154e-04 - accuracy: 1.0000 - val_loss: 7.4637 - val_accuracy: 0.5862\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5686e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.3572e-04 - accuracy: 1.0000 - val_loss: 7.4784 - val_accuracy: 0.5862\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4528e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.3019e-04 - accuracy: 1.0000 - val_loss: 7.4950 - val_accuracy: 0.5862\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3811e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 2.2868e-04 - accuracy: 1.0000 - val_loss: 7.5087 - val_accuracy: 0.5862\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7601e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.2199e-04 - accuracy: 1.0000 - val_loss: 7.5262 - val_accuracy: 0.5862\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1531e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.2301e-04 - accuracy: 1.0000 - val_loss: 7.5438 - val_accuracy: 0.5862\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6937e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.1458e-04 - accuracy: 1.0000 - val_loss: 7.5521 - val_accuracy: 0.5862\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5142e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.1155e-04 - accuracy: 1.0000 - val_loss: 7.5589 - val_accuracy: 0.5862\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6031e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.1176e-04 - accuracy: 1.0000 - val_loss: 7.5700 - val_accuracy: 0.5862\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1882e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.0085e-04 - accuracy: 1.0000 - val_loss: 7.5877 - val_accuracy: 0.5862\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.5093e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.9718e-04 - accuracy: 1.0000 - val_loss: 7.6086 - val_accuracy: 0.5862\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3283e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.9337e-04 - accuracy: 1.0000 - val_loss: 7.6230 - val_accuracy: 0.5862\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3245e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.9046e-04 - accuracy: 1.0000 - val_loss: 7.6391 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 29bd216864bb47a06bf18856d1f65063</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7327585220336914</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 60</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 36</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 108</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LOG_DIR=f\"first_year\\{int(time.time())}\"\n",
    "\n",
    "tuner= RandomSearch(\n",
    "    build_model,\n",
    "    objective=kt.Objective(\"val_accuracy\",direction='max'),\n",
    "    max_trials=4,\n",
    "    executions_per_trial=4,\n",
    "    directory=LOG_DIR\n",
    ")\n",
    "\n",
    "earlyStopping =EarlyStopping(monitor='loss', patience=50, verbose=0, mode='min')\n",
    "#mcp_save = ModelCheckpoint('mp.hdf5', save_best_only=True, monitor='loss', mode='min')\n",
    "#reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=7, verbose=1,min_delta=0.01, mode='min')\n",
    "\n",
    "tuner.search(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_test,y_test),\n",
    "    epochs=200,\n",
    "    callbacks=[earlyStopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_units': 108, 'n_layers': 2, 'dense_0_units': 96, 'dense_1_units': 60, 'dense_2_units': 36}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Results in first_year\\1584343600\\untitled_project</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Objective(name='val_accuracy', direction='max')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 29bd216864bb47a06bf18856d1f65063</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7327585220336914</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 60</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 36</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 108</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: ffbbe048416e10337c8c7584ebb7b312</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7241379022598267</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 60</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 24</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 24</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 3f6eb9de5a37b0589415e39d1d143fc1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7155171632766724</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 84</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 456d66a05bef237eeaa6e54355cd78ea</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7155171632766724</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 72</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 96</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 108</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 108</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "\n",
    "print(tuner.results_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.6736842105263158  Accuracy: 0.7586206896551724\n"
     ]
    }
   ],
   "source": [
    "best_model=tuner.get_best_models()[0]\n",
    "\n",
    "y_pred=best_model.predict(X_test)\n",
    "y_pred[y_pred<0.5]=0\n",
    "y_pred[y_pred>0.5]=1\n",
    "auc_nn=metrics.roc_auc_score(y_test,y_pred)\n",
    "acc_nn=metrics.accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(\"AUC:\",auc_nn,\" Accuracy:\",acc_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \"2 years before\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset is comprised of 145 rows and 12 columns. We have 49 bankrupted companies and 96 companies that still operate.\n"
     ]
    }
   ],
   "source": [
    "df2=pd.read_csv(\"2 years before.csv\")\n",
    "df2['final'][df2['final']=='Bankrupted']=0\n",
    "df2['final'][df2['final']=='Non-Bankrupted']=1\n",
    "df2.head()\n",
    "\n",
    "bankruptcies=df2['final'][df2['final']==0].count()\n",
    "rows=df2.shape[0]\n",
    "columns=df2.shape[1]\n",
    "print(f'Our dataset is comprised of {rows} rows and {columns} columns. We have {bankruptcies} bankrupted companies and {rows-bankruptcies} companies that still operate.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(333)\n",
    "\n",
    "X=df2.iloc[:,0:-1].values\n",
    "Y=df2.iloc[:,-1]\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=43) \n",
    "X_train=preprocessing.normalize(X_train)\n",
    "X_test=preprocessing.normalize(X_test)\n",
    "y_train=y_train.astype(int)\n",
    "y_test=y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_2(hp):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Int(\"input_units\",min_value=11,max_value=110,step=11),input_shape=(11,),activation='relu'))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\",1,4)):\n",
    "    \n",
    "        model.add(Dense(hp.Int(f\"dense_{i}_units\",min_value=11,max_value=110,step=11),activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    model.compile(Adam(lr=0.01),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do NOT run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6901 - accuracy: 0.62 - 1s 5ms/sample - loss: 0.6705 - accuracy: 0.6638 - val_loss: 0.6397 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5915 - accuracy: 0.75 - 0s 232us/sample - loss: 0.6354 - accuracy: 0.6638 - val_loss: 0.6310 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7024 - accuracy: 0.59 - 0s 189us/sample - loss: 0.6239 - accuracy: 0.6638 - val_loss: 0.6249 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6271 - accuracy: 0.65 - 0s 172us/sample - loss: 0.6172 - accuracy: 0.6638 - val_loss: 0.6169 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5990 - accuracy: 0.68 - 0s 181us/sample - loss: 0.6108 - accuracy: 0.6638 - val_loss: 0.6083 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6949 - accuracy: 0.59 - 0s 172us/sample - loss: 0.6057 - accuracy: 0.6638 - val_loss: 0.6047 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6533 - accuracy: 0.62 - 0s 163us/sample - loss: 0.6010 - accuracy: 0.6638 - val_loss: 0.6021 - val_accuracy: 0.6207\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5741 - accuracy: 0.68 - 0s 1ms/sample - loss: 0.5987 - accuracy: 0.6983 - val_loss: 0.6011 - val_accuracy: 0.6897\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6176 - accuracy: 0.71 - 0s 172us/sample - loss: 0.5942 - accuracy: 0.7069 - val_loss: 0.5898 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5368 - accuracy: 0.78 - 0s 181us/sample - loss: 0.5908 - accuracy: 0.6983 - val_loss: 0.5867 - val_accuracy: 0.6897\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6094 - accuracy: 0.65 - 0s 1ms/sample - loss: 0.5841 - accuracy: 0.7069 - val_loss: 0.5878 - val_accuracy: 0.7241\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6174 - accuracy: 0.65 - 0s 340us/sample - loss: 0.5847 - accuracy: 0.7069 - val_loss: 0.5827 - val_accuracy: 0.7241\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5454 - accuracy: 0.75 - 0s 181us/sample - loss: 0.5733 - accuracy: 0.7155 - val_loss: 0.5747 - val_accuracy: 0.7241\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.71 - 0s 163us/sample - loss: 0.5680 - accuracy: 0.7328 - val_loss: 0.5739 - val_accuracy: 0.7241\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4404 - accuracy: 0.78 - 0s 166us/sample - loss: 0.5626 - accuracy: 0.6983 - val_loss: 0.5738 - val_accuracy: 0.6897\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.75 - 0s 172us/sample - loss: 0.5805 - accuracy: 0.7241 - val_loss: 0.5676 - val_accuracy: 0.7241\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6317 - accuracy: 0.65 - 0s 163us/sample - loss: 0.5752 - accuracy: 0.7155 - val_loss: 0.6014 - val_accuracy: 0.6552\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4922 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5385 - accuracy: 0.7414 - val_loss: 0.5754 - val_accuracy: 0.7241\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5665 - accuracy: 0.75 - 0s 158us/sample - loss: 0.5407 - accuracy: 0.7414 - val_loss: 0.5854 - val_accuracy: 0.6552\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.81 - 0s 180us/sample - loss: 0.5362 - accuracy: 0.7328 - val_loss: 0.5948 - val_accuracy: 0.7241\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4141 - accuracy: 0.87 - 0s 163us/sample - loss: 0.5273 - accuracy: 0.7500 - val_loss: 0.6426 - val_accuracy: 0.6897\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5579 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5289 - accuracy: 0.7586 - val_loss: 0.5826 - val_accuracy: 0.6897\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.62 - 0s 146us/sample - loss: 0.5146 - accuracy: 0.7672 - val_loss: 0.5761 - val_accuracy: 0.6897\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4372 - accuracy: 0.81 - 0s 163us/sample - loss: 0.5174 - accuracy: 0.7500 - val_loss: 0.6070 - val_accuracy: 0.6207\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5035 - accuracy: 0.7586 - val_loss: 0.5888 - val_accuracy: 0.6897\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4057 - accuracy: 0.87 - 0s 1ms/sample - loss: 0.5242 - accuracy: 0.7672 - val_loss: 0.5670 - val_accuracy: 0.7586\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4260 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4943 - accuracy: 0.7500 - val_loss: 0.6158 - val_accuracy: 0.7241\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4264 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4934 - accuracy: 0.7759 - val_loss: 0.6181 - val_accuracy: 0.6897\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5062 - accuracy: 0.65 - 0s 172us/sample - loss: 0.4875 - accuracy: 0.7328 - val_loss: 0.6202 - val_accuracy: 0.6897\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5018 - accuracy: 0.71 - 0s 206us/sample - loss: 0.4849 - accuracy: 0.7586 - val_loss: 0.6472 - val_accuracy: 0.7586\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3808 - accuracy: 0.84 - 0s 172us/sample - loss: 0.4701 - accuracy: 0.7845 - val_loss: 0.6295 - val_accuracy: 0.7586\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4794 - accuracy: 0.75 - 0s 172us/sample - loss: 0.4678 - accuracy: 0.7845 - val_loss: 0.6330 - val_accuracy: 0.6897\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4912 - accuracy: 0.75 - 0s 155us/sample - loss: 0.4741 - accuracy: 0.7586 - val_loss: 0.6856 - val_accuracy: 0.7241\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4747 - accuracy: 0.71 - 0s 181us/sample - loss: 0.4586 - accuracy: 0.7845 - val_loss: 0.7207 - val_accuracy: 0.7241\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3476 - accuracy: 0.93 - 0s 155us/sample - loss: 0.4529 - accuracy: 0.7845 - val_loss: 0.7116 - val_accuracy: 0.6897\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4769 - accuracy: 0.81 - 0s 172us/sample - loss: 0.4590 - accuracy: 0.8103 - val_loss: 0.7121 - val_accuracy: 0.7241\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3833 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4333 - accuracy: 0.7845 - val_loss: 0.7320 - val_accuracy: 0.7586\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4032 - accuracy: 0.78 - 0s 172us/sample - loss: 0.4478 - accuracy: 0.7672 - val_loss: 0.7549 - val_accuracy: 0.7241\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4357 - accuracy: 0.84 - 0s 172us/sample - loss: 0.4197 - accuracy: 0.7931 - val_loss: 0.7292 - val_accuracy: 0.6897\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4719 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4229 - accuracy: 0.7931 - val_loss: 0.7329 - val_accuracy: 0.7241\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.84 - 0s 2ms/sample - loss: 0.4127 - accuracy: 0.8190 - val_loss: 0.8078 - val_accuracy: 0.7931\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4804 - accuracy: 0.75 - 0s 172us/sample - loss: 0.4219 - accuracy: 0.8190 - val_loss: 0.7448 - val_accuracy: 0.7241\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4233 - accuracy: 0.8276 - val_loss: 0.8161 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.71 - 0s 155us/sample - loss: 0.4511 - accuracy: 0.7931 - val_loss: 0.8907 - val_accuracy: 0.6897\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3768 - accuracy: 0.78 - 0s 163us/sample - loss: 0.3989 - accuracy: 0.8103 - val_loss: 0.6997 - val_accuracy: 0.7586\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4211 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4145 - accuracy: 0.7845 - val_loss: 0.7539 - val_accuracy: 0.7241\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3899 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3931 - accuracy: 0.8448 - val_loss: 0.7595 - val_accuracy: 0.7241\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 1.00 - 0s 129us/sample - loss: 0.3798 - accuracy: 0.8534 - val_loss: 0.8093 - val_accuracy: 0.7241\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3269 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3754 - accuracy: 0.8448 - val_loss: 0.9022 - val_accuracy: 0.7241\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.90 - 0s 120us/sample - loss: 0.3638 - accuracy: 0.8448 - val_loss: 0.9247 - val_accuracy: 0.7241\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2638 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3605 - accuracy: 0.8448 - val_loss: 0.9533 - val_accuracy: 0.7241\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2885 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3585 - accuracy: 0.8448 - val_loss: 0.9347 - val_accuracy: 0.7241\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3562 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3449 - accuracy: 0.8621 - val_loss: 0.9725 - val_accuracy: 0.7241\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3371 - accuracy: 0.8707 - val_loss: 0.9641 - val_accuracy: 0.7241\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3198 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3412 - accuracy: 0.8448 - val_loss: 1.0018 - val_accuracy: 0.7241\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3319 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3242 - accuracy: 0.8793 - val_loss: 1.0183 - val_accuracy: 0.7241\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3312 - accuracy: 0.8793 - val_loss: 1.0690 - val_accuracy: 0.7241\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.84 - 0s 137us/sample - loss: 0.3275 - accuracy: 0.8534 - val_loss: 1.0821 - val_accuracy: 0.7241\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3264 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3321 - accuracy: 0.8621 - val_loss: 1.0569 - val_accuracy: 0.7241\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3141 - accuracy: 0.87 - 0s 137us/sample - loss: 0.3273 - accuracy: 0.8448 - val_loss: 1.1179 - val_accuracy: 0.6897\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3164 - accuracy: 0.8707 - val_loss: 1.1681 - val_accuracy: 0.7586\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2303 - accuracy: 0.93 - 0s 134us/sample - loss: 0.3383 - accuracy: 0.8534 - val_loss: 1.1390 - val_accuracy: 0.7241\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2985 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3148 - accuracy: 0.8707 - val_loss: 1.1614 - val_accuracy: 0.7241\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4396 - accuracy: 0.78 - 0s 163us/sample - loss: 0.2940 - accuracy: 0.8793 - val_loss: 1.1528 - val_accuracy: 0.7586\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.93 - 0s 163us/sample - loss: 0.3325 - accuracy: 0.8793 - val_loss: 1.1717 - val_accuracy: 0.7586\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3252 - accuracy: 0.8534 - val_loss: 1.1118 - val_accuracy: 0.7241\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2428 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3000 - accuracy: 0.8793 - val_loss: 1.3162 - val_accuracy: 0.7241\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2875 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3139 - accuracy: 0.8621 - val_loss: 1.1870 - val_accuracy: 0.7241\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2796 - accuracy: 0.8879 - val_loss: 1.0877 - val_accuracy: 0.7241\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3598 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2898 - accuracy: 0.8966 - val_loss: 1.1681 - val_accuracy: 0.7586\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3070 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3424 - accuracy: 0.8534 - val_loss: 1.2187 - val_accuracy: 0.7586\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3329 - accuracy: 0.84 - 0s 155us/sample - loss: 0.2824 - accuracy: 0.8793 - val_loss: 1.2067 - val_accuracy: 0.6552\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.87 - 0s 172us/sample - loss: 0.2889 - accuracy: 0.8707 - val_loss: 1.1846 - val_accuracy: 0.7241\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2887 - accuracy: 0.8966 - val_loss: 1.3080 - val_accuracy: 0.7586\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1883 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3341 - accuracy: 0.8707 - val_loss: 1.2859 - val_accuracy: 0.7241\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3296 - accuracy: 0.8448 - val_loss: 1.2095 - val_accuracy: 0.7241\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2888 - accuracy: 0.8707 - val_loss: 1.3540 - val_accuracy: 0.6897\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2642 - accuracy: 0.8707 - val_loss: 1.3627 - val_accuracy: 0.7241\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1934 - accuracy: 0.93 - 0s 146us/sample - loss: 0.3156 - accuracy: 0.8621 - val_loss: 1.4157 - val_accuracy: 0.7586\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2329 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2482 - accuracy: 0.9138 - val_loss: 1.3567 - val_accuracy: 0.7241\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.87 - 0s 166us/sample - loss: 0.2613 - accuracy: 0.9224 - val_loss: 1.3113 - val_accuracy: 0.7241\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2601 - accuracy: 0.9052 - val_loss: 1.3881 - val_accuracy: 0.7586\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.93 - 0s 189us/sample - loss: 0.2667 - accuracy: 0.9052 - val_loss: 1.4279 - val_accuracy: 0.7241\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.87 - 0s 189us/sample - loss: 0.2710 - accuracy: 0.8448 - val_loss: 1.4296 - val_accuracy: 0.7586\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2473 - accuracy: 0.90 - 0s 181us/sample - loss: 0.2582 - accuracy: 0.9138 - val_loss: 1.3937 - val_accuracy: 0.7241\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.96 - 0s 198us/sample - loss: 0.2508 - accuracy: 0.9138 - val_loss: 1.4112 - val_accuracy: 0.7241\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4395 - accuracy: 0.78 - 0s 163us/sample - loss: 0.2739 - accuracy: 0.8793 - val_loss: 1.5389 - val_accuracy: 0.7586\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2245 - accuracy: 0.90 - 0s 172us/sample - loss: 0.2907 - accuracy: 0.8793 - val_loss: 1.5819 - val_accuracy: 0.7241\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2185 - accuracy: 0.9138 - val_loss: 1.5374 - val_accuracy: 0.6552\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3469 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2729 - accuracy: 0.8879 - val_loss: 1.5663 - val_accuracy: 0.7586\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1758 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2201 - accuracy: 0.9224 - val_loss: 1.6686 - val_accuracy: 0.7586\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2148 - accuracy: 0.9138 - val_loss: 1.6190 - val_accuracy: 0.7241\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2638 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2068 - accuracy: 0.9224 - val_loss: 1.5819 - val_accuracy: 0.7241\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2085 - accuracy: 0.9224 - val_loss: 1.6189 - val_accuracy: 0.7586\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2958 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2016 - accuracy: 0.9224 - val_loss: 1.6589 - val_accuracy: 0.7586\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2123 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2079 - accuracy: 0.9138 - val_loss: 1.6819 - val_accuracy: 0.7586\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1786 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1910 - accuracy: 0.9224 - val_loss: 1.6806 - val_accuracy: 0.7241\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2200 - accuracy: 0.9310 - val_loss: 1.6726 - val_accuracy: 0.7586\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1890 - accuracy: 0.9224 - val_loss: 1.7763 - val_accuracy: 0.7586\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1993 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1945 - accuracy: 0.9224 - val_loss: 1.8701 - val_accuracy: 0.7241\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2205 - accuracy: 0.9310 - val_loss: 1.8391 - val_accuracy: 0.7241\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.84 - 0s 120us/sample - loss: 0.1968 - accuracy: 0.8879 - val_loss: 1.8677 - val_accuracy: 0.7241\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.81 - 0s 138us/sample - loss: 0.1765 - accuracy: 0.9138 - val_loss: 1.9193 - val_accuracy: 0.7241\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1125 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1894 - accuracy: 0.9224 - val_loss: 1.9431 - val_accuracy: 0.7586\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0990 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1756 - accuracy: 0.9397 - val_loss: 1.9752 - val_accuracy: 0.7586\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1740 - accuracy: 0.9310 - val_loss: 1.9265 - val_accuracy: 0.7586\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1763 - accuracy: 0.9397 - val_loss: 1.9102 - val_accuracy: 0.6897\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1753 - accuracy: 0.9310 - val_loss: 2.0303 - val_accuracy: 0.7241\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.87 - 0s 163us/sample - loss: 0.1772 - accuracy: 0.9138 - val_loss: 2.0334 - val_accuracy: 0.7241\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.90 - 0s 224us/sample - loss: 0.1697 - accuracy: 0.9310 - val_loss: 2.0269 - val_accuracy: 0.7241\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2162 - accuracy: 0.87 - 0s 163us/sample - loss: 0.1769 - accuracy: 0.9310 - val_loss: 2.0524 - val_accuracy: 0.7586\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1672 - accuracy: 0.9224 - val_loss: 2.1552 - val_accuracy: 0.6897\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1494 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1599 - accuracy: 0.9224 - val_loss: 2.1004 - val_accuracy: 0.7586\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1899 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1566 - accuracy: 0.9310 - val_loss: 2.1820 - val_accuracy: 0.7586\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1431 - accuracy: 0.9310 - val_loss: 2.1463 - val_accuracy: 0.7586\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 0.93 - 0s 137us/sample - loss: 0.1367 - accuracy: 0.9310 - val_loss: 2.1620 - val_accuracy: 0.7241\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1648 - accuracy: 0.9224 - val_loss: 2.2686 - val_accuracy: 0.6897\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.84 - 0s 137us/sample - loss: 0.1407 - accuracy: 0.9138 - val_loss: 2.2752 - val_accuracy: 0.7586\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.87 - 0s 146us/sample - loss: 0.1511 - accuracy: 0.9224 - val_loss: 2.2815 - val_accuracy: 0.6897\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1614 - accuracy: 0.9397 - val_loss: 2.2496 - val_accuracy: 0.7241\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1603 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1465 - accuracy: 0.9397 - val_loss: 2.4570 - val_accuracy: 0.6207\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1473 - accuracy: 0.9397 - val_loss: 2.4126 - val_accuracy: 0.7586\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1444 - accuracy: 0.9397 - val_loss: 2.4221 - val_accuracy: 0.6552\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1773 - accuracy: 0.9310 - val_loss: 2.4493 - val_accuracy: 0.7241\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2779 - accuracy: 0.87 - 0s 120us/sample - loss: 0.1803 - accuracy: 0.9224 - val_loss: 2.5288 - val_accuracy: 0.6207\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.96 - 0s 133us/sample - loss: 0.1978 - accuracy: 0.9397 - val_loss: 2.3860 - val_accuracy: 0.7241\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1566 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1905 - accuracy: 0.9052 - val_loss: 2.3981 - val_accuracy: 0.7241\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2157 - accuracy: 0.9138 - val_loss: 2.4758 - val_accuracy: 0.7586\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1371 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1364 - accuracy: 0.9397 - val_loss: 2.5079 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1896 - accuracy: 0.84 - 0s 129us/sample - loss: 0.1521 - accuracy: 0.9052 - val_loss: 2.4455 - val_accuracy: 0.7241\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1302 - accuracy: 0.9397 - val_loss: 2.3622 - val_accuracy: 0.7586\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1284 - accuracy: 0.9655 - val_loss: 2.4250 - val_accuracy: 0.6897\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1581 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1224 - accuracy: 0.9310 - val_loss: 2.5609 - val_accuracy: 0.7586\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1589 - accuracy: 0.9310 - val_loss: 2.6169 - val_accuracy: 0.6897\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1187 - accuracy: 0.9655 - val_loss: 2.4665 - val_accuracy: 0.7586\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1211 - accuracy: 0.9310 - val_loss: 2.4957 - val_accuracy: 0.7241\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1085 - accuracy: 0.9483 - val_loss: 2.5292 - val_accuracy: 0.7241\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0991 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1032 - accuracy: 0.9483 - val_loss: 2.5803 - val_accuracy: 0.7586\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0997 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1177 - accuracy: 0.9483 - val_loss: 2.7806 - val_accuracy: 0.7241\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.96 - 0s 134us/sample - loss: 0.1046 - accuracy: 0.9655 - val_loss: 2.9610 - val_accuracy: 0.7241\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0803 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1000 - accuracy: 0.9655 - val_loss: 2.8260 - val_accuracy: 0.7586\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1091 - accuracy: 0.9483 - val_loss: 2.7084 - val_accuracy: 0.6552\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 1.00 - 0s 120us/sample - loss: 0.1518 - accuracy: 0.9310 - val_loss: 3.0971 - val_accuracy: 0.6552\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1553 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2144 - accuracy: 0.9052 - val_loss: 3.9736 - val_accuracy: 0.6897\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2947 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2852 - accuracy: 0.8879 - val_loss: 2.6018 - val_accuracy: 0.7586\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.93 - 0s 146us/sample - loss: 0.3730 - accuracy: 0.8793 - val_loss: 2.2844 - val_accuracy: 0.6552\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.96 - 0s 146us/sample - loss: 0.3484 - accuracy: 0.8534 - val_loss: 2.1407 - val_accuracy: 0.6552\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2644 - accuracy: 0.9052 - val_loss: 2.3367 - val_accuracy: 0.6897\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3040 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2160 - accuracy: 0.9138 - val_loss: 2.7449 - val_accuracy: 0.7241\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3090 - accuracy: 0.8966 - val_loss: 2.3185 - val_accuracy: 0.6897\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2609 - accuracy: 0.87 - 0s 120us/sample - loss: 0.1547 - accuracy: 0.9483 - val_loss: 2.8308 - val_accuracy: 0.6207\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1608 - accuracy: 0.9310 - val_loss: 2.9155 - val_accuracy: 0.7241\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1586 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1567 - accuracy: 0.9224 - val_loss: 2.9084 - val_accuracy: 0.6552\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1181 - accuracy: 0.9655 - val_loss: 2.7654 - val_accuracy: 0.7241\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1238 - accuracy: 0.9483 - val_loss: 2.7101 - val_accuracy: 0.6897\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1155 - accuracy: 0.9655 - val_loss: 2.8300 - val_accuracy: 0.6552\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1117 - accuracy: 0.9483 - val_loss: 2.9011 - val_accuracy: 0.6897\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0942 - accuracy: 0.9569 - val_loss: 2.9133 - val_accuracy: 0.6897\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.93 - 0s 172us/sample - loss: 0.1050 - accuracy: 0.9569 - val_loss: 2.8894 - val_accuracy: 0.6897\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.96 - 0s 151us/sample - loss: 0.0942 - accuracy: 0.9569 - val_loss: 2.9167 - val_accuracy: 0.6897\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1088 - accuracy: 0.9569 - val_loss: 2.9901 - val_accuracy: 0.6552\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1126 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1125 - accuracy: 0.9483 - val_loss: 2.8617 - val_accuracy: 0.6552\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1428 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1174 - accuracy: 0.9741 - val_loss: 2.8727 - val_accuracy: 0.6552\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1274 - accuracy: 0.9569 - val_loss: 3.0557 - val_accuracy: 0.7241\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.93 - 0s 142us/sample - loss: 0.1210 - accuracy: 0.9397 - val_loss: 3.0624 - val_accuracy: 0.7241\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0714 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0848 - accuracy: 0.9655 - val_loss: 2.9542 - val_accuracy: 0.5862\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1176 - accuracy: 0.9655 - val_loss: 2.8688 - val_accuracy: 0.6897\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1610 - accuracy: 0.9224 - val_loss: 2.9617 - val_accuracy: 0.6207\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1433 - accuracy: 0.9483 - val_loss: 3.1986 - val_accuracy: 0.6897\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1245 - accuracy: 0.9483 - val_loss: 3.2471 - val_accuracy: 0.7241\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0838 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0926 - accuracy: 0.9569 - val_loss: 3.1818 - val_accuracy: 0.6552\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1061 - accuracy: 0.9483 - val_loss: 3.2255 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1057 - accuracy: 0.9397 - val_loss: 3.2466 - val_accuracy: 0.6897\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1245 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0876 - accuracy: 0.9569 - val_loss: 3.1438 - val_accuracy: 0.6897\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0964 - accuracy: 0.9655 - val_loss: 3.1325 - val_accuracy: 0.6207\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1038 - accuracy: 0.9569 - val_loss: 3.2426 - val_accuracy: 0.6897\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0869 - accuracy: 0.9655 - val_loss: 3.3740 - val_accuracy: 0.6897\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1030 - accuracy: 0.9569 - val_loss: 3.3211 - val_accuracy: 0.6552\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0928 - accuracy: 0.9741 - val_loss: 3.2053 - val_accuracy: 0.6552\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0896 - accuracy: 0.9569 - val_loss: 3.2087 - val_accuracy: 0.6552\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1378 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0823 - accuracy: 0.9655 - val_loss: 3.3249 - val_accuracy: 0.6897\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1163 - accuracy: 0.9483 - val_loss: 3.3025 - val_accuracy: 0.6897\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0804 - accuracy: 0.9828 - val_loss: 3.2718 - val_accuracy: 0.6552\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0926 - accuracy: 0.9655 - val_loss: 3.2400 - val_accuracy: 0.6552\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1664 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0917 - accuracy: 0.9655 - val_loss: 3.2539 - val_accuracy: 0.5862\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1001 - accuracy: 0.9655 - val_loss: 3.3463 - val_accuracy: 0.7241\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1159 - accuracy: 0.9397 - val_loss: 3.2493 - val_accuracy: 0.6897\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0934 - accuracy: 0.9741 - val_loss: 3.3152 - val_accuracy: 0.6552\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0842 - accuracy: 0.9655 - val_loss: 3.4648 - val_accuracy: 0.7241\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1201 - accuracy: 0.9483 - val_loss: 3.4433 - val_accuracy: 0.6897\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0771 - accuracy: 0.9828 - val_loss: 3.2435 - val_accuracy: 0.6552\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0930 - accuracy: 0.9655 - val_loss: 3.2357 - val_accuracy: 0.7241\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0993 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1120 - accuracy: 0.9483 - val_loss: 3.3102 - val_accuracy: 0.6552\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 1.00 - 0s 120us/sample - loss: 0.1033 - accuracy: 0.9569 - val_loss: 3.3340 - val_accuracy: 0.6897\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0572 - accuracy: 0.9914 - val_loss: 3.3543 - val_accuracy: 0.6552\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0994 - accuracy: 0.9483 - val_loss: 3.2898 - val_accuracy: 0.6897\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0950 - accuracy: 0.9310 - val_loss: 3.4365 - val_accuracy: 0.6897\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0968 - accuracy: 0.9741 - val_loss: 3.4277 - val_accuracy: 0.6552\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0772 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1065 - accuracy: 0.9741 - val_loss: 3.3040 - val_accuracy: 0.6552\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0699 - accuracy: 0.9828 - val_loss: 3.3555 - val_accuracy: 0.6897\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7014 - accuracy: 0.25 - 0s 3ms/sample - loss: 0.6834 - accuracy: 0.5259 - val_loss: 0.6541 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7011 - accuracy: 0.50 - 0s 172us/sample - loss: 0.6356 - accuracy: 0.6638 - val_loss: 0.6332 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5332 - accuracy: 0.78 - 0s 157us/sample - loss: 0.6485 - accuracy: 0.6638 - val_loss: 0.6447 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7097 - accuracy: 0.59 - 0s 163us/sample - loss: 0.6282 - accuracy: 0.6638 - val_loss: 0.6252 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.68 - 0s 163us/sample - loss: 0.6132 - accuracy: 0.6638 - val_loss: 0.6252 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6458 - accuracy: 0.62 - 0s 155us/sample - loss: 0.6163 - accuracy: 0.6724 - val_loss: 0.6223 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5524 - accuracy: 0.78 - 0s 151us/sample - loss: 0.6112 - accuracy: 0.6724 - val_loss: 0.6096 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5085 - accuracy: 0.78 - 0s 163us/sample - loss: 0.6080 - accuracy: 0.6724 - val_loss: 0.6072 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5842 - accuracy: 0.68 - 0s 155us/sample - loss: 0.6018 - accuracy: 0.6724 - val_loss: 0.6051 - val_accuracy: 0.6552\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5769 - accuracy: 0.78 - 0s 155us/sample - loss: 0.6030 - accuracy: 0.6638 - val_loss: 0.6017 - val_accuracy: 0.6897\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5729 - accuracy: 0.71 - 0s 172us/sample - loss: 0.5964 - accuracy: 0.6810 - val_loss: 0.5981 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5767 - accuracy: 0.65 - 0s 146us/sample - loss: 0.5934 - accuracy: 0.6724 - val_loss: 0.5937 - val_accuracy: 0.6897\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6138 - accuracy: 0.65 - 0s 138us/sample - loss: 0.5845 - accuracy: 0.6810 - val_loss: 0.5943 - val_accuracy: 0.6897\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5297 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5845 - accuracy: 0.6983 - val_loss: 0.5921 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6492 - accuracy: 0.62 - 0s 146us/sample - loss: 0.5824 - accuracy: 0.7241 - val_loss: 0.5981 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5548 - accuracy: 0.81 - 0s 155us/sample - loss: 0.5693 - accuracy: 0.6983 - val_loss: 0.5850 - val_accuracy: 0.6552\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5003 - accuracy: 0.81 - 0s 138us/sample - loss: 0.5663 - accuracy: 0.7328 - val_loss: 0.5779 - val_accuracy: 0.7586\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5363 - accuracy: 0.75 - 0s 129us/sample - loss: 0.5513 - accuracy: 0.7241 - val_loss: 0.5654 - val_accuracy: 0.6552\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5848 - accuracy: 0.71 - 0s 129us/sample - loss: 0.5425 - accuracy: 0.7241 - val_loss: 0.5697 - val_accuracy: 0.6552\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4907 - accuracy: 0.81 - 0s 138us/sample - loss: 0.5345 - accuracy: 0.7672 - val_loss: 0.5635 - val_accuracy: 0.6552\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5329 - accuracy: 0.75 - 0s 144us/sample - loss: 0.5242 - accuracy: 0.7500 - val_loss: 0.5467 - val_accuracy: 0.7241\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5343 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5163 - accuracy: 0.7414 - val_loss: 0.5476 - val_accuracy: 0.6552\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.71 - 0s 138us/sample - loss: 0.5049 - accuracy: 0.7414 - val_loss: 0.5554 - val_accuracy: 0.6552\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5062 - accuracy: 0.65 - 0s 129us/sample - loss: 0.5019 - accuracy: 0.7328 - val_loss: 0.5513 - val_accuracy: 0.6897\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5233 - accuracy: 0.68 - 0s 129us/sample - loss: 0.5078 - accuracy: 0.7414 - val_loss: 0.5778 - val_accuracy: 0.6897\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4801 - accuracy: 0.7845 - val_loss: 0.5890 - val_accuracy: 0.6897\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3879 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4854 - accuracy: 0.7672 - val_loss: 0.5602 - val_accuracy: 0.7586\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4551 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4578 - accuracy: 0.7759 - val_loss: 0.6274 - val_accuracy: 0.6897\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5489 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4881 - accuracy: 0.7931 - val_loss: 0.5761 - val_accuracy: 0.7241\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4894 - accuracy: 0.7500 - val_loss: 0.6031 - val_accuracy: 0.6897\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4334 - accuracy: 0.8190 - val_loss: 0.6631 - val_accuracy: 0.6897\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3361 - accuracy: 0.90 - 0s 138us/sample - loss: 0.4334 - accuracy: 0.8190 - val_loss: 0.6030 - val_accuracy: 0.7241\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5153 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4239 - accuracy: 0.8103 - val_loss: 0.6815 - val_accuracy: 0.6897\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3376 - accuracy: 0.93 - 0s 138us/sample - loss: 0.4180 - accuracy: 0.8190 - val_loss: 0.6964 - val_accuracy: 0.7241\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.90 - 0s 129us/sample - loss: 0.4102 - accuracy: 0.8276 - val_loss: 0.7330 - val_accuracy: 0.7241\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3528 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3979 - accuracy: 0.8190 - val_loss: 0.7589 - val_accuracy: 0.6897\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4765 - accuracy: 0.71 - 0s 129us/sample - loss: 0.4144 - accuracy: 0.8017 - val_loss: 0.8102 - val_accuracy: 0.6552\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3235 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3903 - accuracy: 0.8362 - val_loss: 0.8314 - val_accuracy: 0.6207\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4196 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3847 - accuracy: 0.8448 - val_loss: 0.8068 - val_accuracy: 0.6552\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2678 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3843 - accuracy: 0.8190 - val_loss: 0.9057 - val_accuracy: 0.6552\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3037 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3745 - accuracy: 0.8534 - val_loss: 0.8225 - val_accuracy: 0.6552\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4724 - accuracy: 0.75 - 0s 155us/sample - loss: 0.3775 - accuracy: 0.8276 - val_loss: 0.8663 - val_accuracy: 0.6552\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3549 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3663 - accuracy: 0.8534 - val_loss: 0.8634 - val_accuracy: 0.6897\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.78 - 0s 155us/sample - loss: 0.3660 - accuracy: 0.8362 - val_loss: 0.9435 - val_accuracy: 0.6552\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3391 - accuracy: 0.87 - 0s 181us/sample - loss: 0.3479 - accuracy: 0.8621 - val_loss: 0.9519 - val_accuracy: 0.6552\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.96 - 0s 155us/sample - loss: 0.3486 - accuracy: 0.8362 - val_loss: 0.9806 - val_accuracy: 0.6552\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3322 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3557 - accuracy: 0.8534 - val_loss: 1.0387 - val_accuracy: 0.7586\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4015 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3515 - accuracy: 0.8362 - val_loss: 0.9955 - val_accuracy: 0.6897\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2778 - accuracy: 0.87 - 0s 137us/sample - loss: 0.3382 - accuracy: 0.8103 - val_loss: 1.0496 - val_accuracy: 0.6897\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3334 - accuracy: 0.84 - 0s 163us/sample - loss: 0.3210 - accuracy: 0.8448 - val_loss: 1.0133 - val_accuracy: 0.7241\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2499 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3562 - accuracy: 0.8190 - val_loss: 1.2793 - val_accuracy: 0.5862\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.75 - 0s 137us/sample - loss: 0.4336 - accuracy: 0.7586 - val_loss: 1.0085 - val_accuracy: 0.7586\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3036 - accuracy: 0.87 - 0s 138us/sample - loss: 0.5516 - accuracy: 0.7931 - val_loss: 0.9940 - val_accuracy: 0.6897\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.93 - 0s 129us/sample - loss: 0.3610 - accuracy: 0.8534 - val_loss: 1.1810 - val_accuracy: 0.6897\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.90 - 0s 146us/sample - loss: 0.4105 - accuracy: 0.8190 - val_loss: 1.0072 - val_accuracy: 0.7586\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3511 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3686 - accuracy: 0.8276 - val_loss: 0.9433 - val_accuracy: 0.6897\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.93 - 0s 155us/sample - loss: 0.3458 - accuracy: 0.8621 - val_loss: 0.9152 - val_accuracy: 0.6897\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3734 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3243 - accuracy: 0.8621 - val_loss: 0.9630 - val_accuracy: 0.7241\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.78 - 0s 129us/sample - loss: 0.3319 - accuracy: 0.8276 - val_loss: 1.0280 - val_accuracy: 0.7241\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3268 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3447 - accuracy: 0.8621 - val_loss: 1.0636 - val_accuracy: 0.7586\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.87 - 0s 206us/sample - loss: 0.3819 - accuracy: 0.8103 - val_loss: 1.0865 - val_accuracy: 0.7241\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4684 - accuracy: 0.71 - 0s 163us/sample - loss: 0.3343 - accuracy: 0.8190 - val_loss: 1.0111 - val_accuracy: 0.7241\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.78 - 0s 146us/sample - loss: 0.3342 - accuracy: 0.8276 - val_loss: 1.2154 - val_accuracy: 0.6207\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3975 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3349 - accuracy: 0.8276 - val_loss: 1.0670 - val_accuracy: 0.6897\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2882 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3428 - accuracy: 0.8276 - val_loss: 1.0802 - val_accuracy: 0.7586\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3164 - accuracy: 0.8534 - val_loss: 1.1612 - val_accuracy: 0.7241\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2598 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3093 - accuracy: 0.8534 - val_loss: 1.1531 - val_accuracy: 0.7931\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2971 - accuracy: 0.8534 - val_loss: 1.1739 - val_accuracy: 0.7586\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2884 - accuracy: 0.8707 - val_loss: 1.1664 - val_accuracy: 0.7241\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2749 - accuracy: 0.8707 - val_loss: 1.2139 - val_accuracy: 0.7241\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1595 - accuracy: 1.00 - 0s 146us/sample - loss: 0.2719 - accuracy: 0.9052 - val_loss: 1.2697 - val_accuracy: 0.7241\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2915 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2664 - accuracy: 0.9052 - val_loss: 1.3178 - val_accuracy: 0.7241\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2316 - accuracy: 0.90 - 0s 143us/sample - loss: 0.2546 - accuracy: 0.8879 - val_loss: 1.3432 - val_accuracy: 0.7586\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2719 - accuracy: 0.8793 - val_loss: 1.3208 - val_accuracy: 0.7241\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1574 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2639 - accuracy: 0.8534 - val_loss: 1.3744 - val_accuracy: 0.6552\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2911 - accuracy: 0.81 - 0s 155us/sample - loss: 0.2602 - accuracy: 0.8621 - val_loss: 1.3263 - val_accuracy: 0.7586\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2442 - accuracy: 0.8966 - val_loss: 1.3363 - val_accuracy: 0.7586\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2533 - accuracy: 0.8879 - val_loss: 1.4225 - val_accuracy: 0.7241\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2561 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2286 - accuracy: 0.9052 - val_loss: 1.4194 - val_accuracy: 0.7931\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2427 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2244 - accuracy: 0.9224 - val_loss: 1.5277 - val_accuracy: 0.7586\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2494 - accuracy: 0.8793 - val_loss: 1.4808 - val_accuracy: 0.7241\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.84 - 0s 155us/sample - loss: 0.2232 - accuracy: 0.8966 - val_loss: 1.5337 - val_accuracy: 0.7586\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2579 - accuracy: 0.8879 - val_loss: 1.6013 - val_accuracy: 0.6552\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2928 - accuracy: 0.8276 - val_loss: 1.4179 - val_accuracy: 0.7586\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2876 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3426 - accuracy: 0.8362 - val_loss: 1.5169 - val_accuracy: 0.7241\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1974 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2901 - accuracy: 0.8448 - val_loss: 1.5113 - val_accuracy: 0.7586\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2571 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2309 - accuracy: 0.8879 - val_loss: 1.5703 - val_accuracy: 0.7586\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1780 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2099 - accuracy: 0.9483 - val_loss: 1.5880 - val_accuracy: 0.7241\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2066 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2033 - accuracy: 0.9310 - val_loss: 1.5366 - val_accuracy: 0.7586\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1973 - accuracy: 0.9224 - val_loss: 1.4795 - val_accuracy: 0.7586\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2290 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1907 - accuracy: 0.9224 - val_loss: 1.4919 - val_accuracy: 0.7586\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.96 - 0s 143us/sample - loss: 0.1859 - accuracy: 0.9310 - val_loss: 1.5510 - val_accuracy: 0.7241\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1861 - accuracy: 0.9224 - val_loss: 1.5831 - val_accuracy: 0.7241\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1761 - accuracy: 0.9397 - val_loss: 1.5242 - val_accuracy: 0.7241\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1774 - accuracy: 0.9397 - val_loss: 1.5661 - val_accuracy: 0.7931\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1801 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1973 - accuracy: 0.8966 - val_loss: 1.7147 - val_accuracy: 0.6552\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.90 - 0s 125us/sample - loss: 0.2112 - accuracy: 0.9224 - val_loss: 1.5316 - val_accuracy: 0.7241\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2048 - accuracy: 0.8879 - val_loss: 1.6846 - val_accuracy: 0.6897\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.90 - 0s 137us/sample - loss: 0.1799 - accuracy: 0.8966 - val_loss: 1.5898 - val_accuracy: 0.7586\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3257 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2560 - accuracy: 0.8621 - val_loss: 1.6832 - val_accuracy: 0.6897\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2050 - accuracy: 0.8966 - val_loss: 1.5708 - val_accuracy: 0.7241\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.1455 - accuracy: 0.90 - 0s 158us/sample - loss: 0.1516 - accuracy: 0.9397 - val_loss: 1.6655 - val_accuracy: 0.6897\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1684 - accuracy: 0.9397 - val_loss: 1.6024 - val_accuracy: 0.6897\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1442 - accuracy: 0.9569 - val_loss: 1.5848 - val_accuracy: 0.6552\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.87 - 0s 129us/sample - loss: 0.1586 - accuracy: 0.9224 - val_loss: 1.5806 - val_accuracy: 0.6552\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1536 - accuracy: 0.9310 - val_loss: 1.7632 - val_accuracy: 0.6897\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1745 - accuracy: 0.9224 - val_loss: 1.5799 - val_accuracy: 0.7586\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1609 - accuracy: 0.9397 - val_loss: 1.5714 - val_accuracy: 0.6552\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1560 - accuracy: 0.9655 - val_loss: 1.5673 - val_accuracy: 0.7241\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1723 - accuracy: 0.8966 - val_loss: 1.7685 - val_accuracy: 0.7586\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1346 - accuracy: 0.9483 - val_loss: 1.8194 - val_accuracy: 0.6552\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1408 - accuracy: 0.9397 - val_loss: 1.6374 - val_accuracy: 0.7586\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1261 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1455 - accuracy: 0.9569 - val_loss: 1.5652 - val_accuracy: 0.6897\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1536 - accuracy: 0.90 - 0s 163us/sample - loss: 0.1249 - accuracy: 0.9310 - val_loss: 1.6575 - val_accuracy: 0.7241\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1780 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1401 - accuracy: 0.9310 - val_loss: 1.7519 - val_accuracy: 0.6552\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0947 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1156 - accuracy: 0.9655 - val_loss: 1.8302 - val_accuracy: 0.6552\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 1.00 - 0s 120us/sample - loss: 0.1085 - accuracy: 0.9741 - val_loss: 1.7982 - val_accuracy: 0.7241\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1089 - accuracy: 0.9483 - val_loss: 1.7620 - val_accuracy: 0.7586\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1285 - accuracy: 0.9655 - val_loss: 1.9508 - val_accuracy: 0.6552\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1166 - accuracy: 0.9569 - val_loss: 1.6912 - val_accuracy: 0.7586\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2082 - accuracy: 0.8966 - val_loss: 1.8209 - val_accuracy: 0.6552\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1181 - accuracy: 0.9741 - val_loss: 1.8026 - val_accuracy: 0.7241\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1302 - accuracy: 0.9655 - val_loss: 1.8048 - val_accuracy: 0.7241\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0583 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1106 - accuracy: 0.9483 - val_loss: 1.8097 - val_accuracy: 0.6552\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0968 - accuracy: 0.9655 - val_loss: 1.7701 - val_accuracy: 0.7586\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1197 - accuracy: 0.9569 - val_loss: 1.8794 - val_accuracy: 0.6207\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1220 - accuracy: 0.9310 - val_loss: 1.9046 - val_accuracy: 0.7586\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2080 - accuracy: 0.84 - 0s 138us/sample - loss: 0.1182 - accuracy: 0.9483 - val_loss: 1.9313 - val_accuracy: 0.6897\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0925 - accuracy: 0.9828 - val_loss: 1.8814 - val_accuracy: 0.7241\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1412 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1148 - accuracy: 0.9569 - val_loss: 1.9890 - val_accuracy: 0.6897\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1170 - accuracy: 0.9397 - val_loss: 2.0012 - val_accuracy: 0.7241\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1336 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1436 - accuracy: 0.9741 - val_loss: 1.9614 - val_accuracy: 0.7586\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1658 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1523 - accuracy: 0.9224 - val_loss: 1.9752 - val_accuracy: 0.6897\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0789 - accuracy: 0.9914 - val_loss: 1.9275 - val_accuracy: 0.7241\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.87 - 0s 146us/sample - loss: 0.1410 - accuracy: 0.9138 - val_loss: 2.0056 - val_accuracy: 0.6897\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0894 - accuracy: 0.9828 - val_loss: 1.9993 - val_accuracy: 0.6897\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0953 - accuracy: 0.9741 - val_loss: 2.0875 - val_accuracy: 0.7586\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1778 - accuracy: 0.9138 - val_loss: 2.5040 - val_accuracy: 0.6207\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2848 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2529 - accuracy: 0.8879 - val_loss: 2.0131 - val_accuracy: 0.7586\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2021 - accuracy: 0.90 - 0s 120us/sample - loss: 0.3449 - accuracy: 0.8879 - val_loss: 2.2494 - val_accuracy: 0.6552\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2572 - accuracy: 0.8793 - val_loss: 1.9450 - val_accuracy: 0.7241\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1237 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2094 - accuracy: 0.8966 - val_loss: 1.9845 - val_accuracy: 0.6207\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1372 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2101 - accuracy: 0.9052 - val_loss: 1.8534 - val_accuracy: 0.6552\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2070 - accuracy: 0.9310 - val_loss: 1.8850 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1078 - accuracy: 0.9828 - val_loss: 2.1074 - val_accuracy: 0.6552\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0773 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1208 - accuracy: 0.9397 - val_loss: 2.1254 - val_accuracy: 0.6552\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1112 - accuracy: 0.9655 - val_loss: 2.2348 - val_accuracy: 0.6207\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0851 - accuracy: 0.9741 - val_loss: 2.2064 - val_accuracy: 0.6897\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1103 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1180 - accuracy: 0.9397 - val_loss: 2.3303 - val_accuracy: 0.6552\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0975 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0949 - accuracy: 0.9655 - val_loss: 2.2935 - val_accuracy: 0.6897\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0743 - accuracy: 0.9828 - val_loss: 2.2326 - val_accuracy: 0.6552\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0878 - accuracy: 0.9828 - val_loss: 2.2995 - val_accuracy: 0.5862\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0818 - accuracy: 0.9828 - val_loss: 2.4241 - val_accuracy: 0.6552\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0748 - accuracy: 0.9828 - val_loss: 2.4100 - val_accuracy: 0.6207\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0681 - accuracy: 0.9914 - val_loss: 2.4424 - val_accuracy: 0.6207\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0612 - accuracy: 0.9914 - val_loss: 2.4442 - val_accuracy: 0.7241\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0672 - accuracy: 0.9741 - val_loss: 2.5481 - val_accuracy: 0.6552\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0880 - accuracy: 0.9655 - val_loss: 2.5117 - val_accuracy: 0.7241\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1036 - accuracy: 0.9569 - val_loss: 2.5951 - val_accuracy: 0.6207\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0766 - accuracy: 0.9741 - val_loss: 2.5392 - val_accuracy: 0.6897\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0540 - accuracy: 0.9914 - val_loss: 2.4725 - val_accuracy: 0.6897\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0568 - accuracy: 1.0000 - val_loss: 2.5231 - val_accuracy: 0.6897\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0871 - accuracy: 0.9741 - val_loss: 2.5250 - val_accuracy: 0.7241\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0703 - accuracy: 1.0000 - val_loss: 2.5816 - val_accuracy: 0.6552\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0901 - accuracy: 0.9483 - val_loss: 2.5860 - val_accuracy: 0.6897\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1251 - accuracy: 0.9569 - val_loss: 2.5330 - val_accuracy: 0.6552\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0790 - accuracy: 0.9741 - val_loss: 2.5779 - val_accuracy: 0.6897\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0920 - accuracy: 0.9655 - val_loss: 2.5030 - val_accuracy: 0.6207\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 1.00 - 0s 154us/sample - loss: 0.1172 - accuracy: 0.9569 - val_loss: 2.5260 - val_accuracy: 0.6897\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1038 - accuracy: 0.9655 - val_loss: 2.5226 - val_accuracy: 0.7241\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0713 - accuracy: 0.9828 - val_loss: 2.6245 - val_accuracy: 0.6897\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0553 - accuracy: 0.9828 - val_loss: 2.5893 - val_accuracy: 0.6552\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0683 - accuracy: 0.9655 - val_loss: 2.5577 - val_accuracy: 0.6897\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0447 - accuracy: 1.00 - 0s 168us/sample - loss: 0.0671 - accuracy: 0.9828 - val_loss: 2.5468 - val_accuracy: 0.7241\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1676 - accuracy: 0.9310 - val_loss: 2.6872 - val_accuracy: 0.6897\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0406 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1258 - accuracy: 0.9483 - val_loss: 2.5561 - val_accuracy: 0.7241\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1711 - accuracy: 0.9138 - val_loss: 2.6395 - val_accuracy: 0.6552\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1223 - accuracy: 0.9569 - val_loss: 2.4878 - val_accuracy: 0.7241\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0641 - accuracy: 0.9828 - val_loss: 2.4958 - val_accuracy: 0.7241\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0495 - accuracy: 0.9828 - val_loss: 2.6439 - val_accuracy: 0.6552\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0649 - accuracy: 0.9741 - val_loss: 2.6545 - val_accuracy: 0.6552\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0638 - accuracy: 0.9828 - val_loss: 2.6816 - val_accuracy: 0.6897\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0441 - accuracy: 0.9914 - val_loss: 2.6842 - val_accuracy: 0.6552\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0590 - accuracy: 0.9828 - val_loss: 2.6347 - val_accuracy: 0.7586\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0712 - accuracy: 0.9828 - val_loss: 2.8363 - val_accuracy: 0.6207\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0835 - accuracy: 0.9828 - val_loss: 2.7145 - val_accuracy: 0.7241\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0873 - accuracy: 0.9655 - val_loss: 2.6715 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0452 - accuracy: 0.9828 - val_loss: 2.8483 - val_accuracy: 0.5862\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0893 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0484 - accuracy: 0.9828 - val_loss: 2.6475 - val_accuracy: 0.6897\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0406 - accuracy: 0.9828 - val_loss: 2.7021 - val_accuracy: 0.6552\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0342 - accuracy: 0.9828 - val_loss: 2.7998 - val_accuracy: 0.6207\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 1.00 - 0s 198us/sample - loss: 0.0265 - accuracy: 0.9914 - val_loss: 2.7683 - val_accuracy: 0.6897\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0274 - accuracy: 1.0000 - val_loss: 2.8054 - val_accuracy: 0.6897\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0256 - accuracy: 1.0000 - val_loss: 2.8917 - val_accuracy: 0.6207\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.9174 - val_accuracy: 0.6552\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0212 - accuracy: 1.0000 - val_loss: 2.9453 - val_accuracy: 0.6207\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0209 - accuracy: 1.0000 - val_loss: 2.9711 - val_accuracy: 0.6207\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0190 - accuracy: 1.0000 - val_loss: 2.9877 - val_accuracy: 0.6552\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0161 - accuracy: 1.0000 - val_loss: 3.0147 - val_accuracy: 0.6207\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0166 - accuracy: 1.0000 - val_loss: 3.0402 - val_accuracy: 0.6207\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6969 - accuracy: 0.34 - 0s 3ms/sample - loss: 0.6854 - accuracy: 0.5862 - val_loss: 0.6664 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6684 - accuracy: 0.65 - 0s 146us/sample - loss: 0.6498 - accuracy: 0.6638 - val_loss: 0.6385 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5763 - accuracy: 0.75 - 0s 189us/sample - loss: 0.6419 - accuracy: 0.6638 - val_loss: 0.6420 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5283 - accuracy: 0.75 - 0s 146us/sample - loss: 0.6114 - accuracy: 0.6638 - val_loss: 0.6215 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6078 - accuracy: 0.68 - 0s 146us/sample - loss: 0.6216 - accuracy: 0.6724 - val_loss: 0.6176 - val_accuracy: 0.7241\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6596 - accuracy: 0.59 - 0s 189us/sample - loss: 0.5946 - accuracy: 0.6897 - val_loss: 0.6032 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5478 - accuracy: 0.71 - 0s 189us/sample - loss: 0.6020 - accuracy: 0.6897 - val_loss: 0.6079 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5534 - accuracy: 0.75 - 0s 163us/sample - loss: 0.5942 - accuracy: 0.6897 - val_loss: 0.5850 - val_accuracy: 0.6897\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5778 - accuracy: 0.68 - 0s 155us/sample - loss: 0.5786 - accuracy: 0.6897 - val_loss: 0.5893 - val_accuracy: 0.7586\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6818 - accuracy: 0.50 - 0s 163us/sample - loss: 0.6036 - accuracy: 0.6810 - val_loss: 0.5830 - val_accuracy: 0.7586\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6007 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5647 - accuracy: 0.6983 - val_loss: 0.5894 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5514 - accuracy: 0.71 - 0s 146us/sample - loss: 0.5946 - accuracy: 0.6897 - val_loss: 0.5852 - val_accuracy: 0.6897\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.78 - 0s 138us/sample - loss: 0.5553 - accuracy: 0.7241 - val_loss: 0.5817 - val_accuracy: 0.6897\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5910 - accuracy: 0.68 - 0s 138us/sample - loss: 0.5834 - accuracy: 0.6897 - val_loss: 0.5777 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5218 - accuracy: 0.81 - 0s 129us/sample - loss: 0.5540 - accuracy: 0.7500 - val_loss: 0.5623 - val_accuracy: 0.6897\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4891 - accuracy: 0.78 - 0s 138us/sample - loss: 0.5596 - accuracy: 0.7155 - val_loss: 0.5570 - val_accuracy: 0.7241\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5736 - accuracy: 0.68 - 0s 138us/sample - loss: 0.5493 - accuracy: 0.7328 - val_loss: 0.5881 - val_accuracy: 0.6207\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6173 - accuracy: 0.62 - 0s 138us/sample - loss: 0.5397 - accuracy: 0.7414 - val_loss: 0.5590 - val_accuracy: 0.7241\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4717 - accuracy: 0.78 - 0s 129us/sample - loss: 0.5299 - accuracy: 0.7500 - val_loss: 0.5569 - val_accuracy: 0.7241\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6479 - accuracy: 0.68 - 0s 163us/sample - loss: 0.5324 - accuracy: 0.7586 - val_loss: 0.5734 - val_accuracy: 0.6552\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5483 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5335 - accuracy: 0.7328 - val_loss: 0.5696 - val_accuracy: 0.6552\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6105 - accuracy: 0.68 - 0s 198us/sample - loss: 0.5060 - accuracy: 0.7241 - val_loss: 0.5556 - val_accuracy: 0.7241\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4475 - accuracy: 0.81 - 0s 155us/sample - loss: 0.5246 - accuracy: 0.7500 - val_loss: 0.5658 - val_accuracy: 0.6897\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4817 - accuracy: 0.71 - 0s 172us/sample - loss: 0.4944 - accuracy: 0.7500 - val_loss: 0.6247 - val_accuracy: 0.7241\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.84 - 0s 163us/sample - loss: 0.4920 - accuracy: 0.7586 - val_loss: 0.5876 - val_accuracy: 0.6897\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6485 - accuracy: 0.68 - 0s 155us/sample - loss: 0.4891 - accuracy: 0.7500 - val_loss: 0.6111 - val_accuracy: 0.7586\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5346 - accuracy: 0.68 - 0s 146us/sample - loss: 0.4699 - accuracy: 0.7500 - val_loss: 0.6114 - val_accuracy: 0.7241\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3873 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4658 - accuracy: 0.7586 - val_loss: 0.6950 - val_accuracy: 0.6897\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.71 - 0s 155us/sample - loss: 0.4780 - accuracy: 0.7500 - val_loss: 0.6920 - val_accuracy: 0.7586\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4770 - accuracy: 0.78 - 0s 155us/sample - loss: 0.4571 - accuracy: 0.7845 - val_loss: 0.6424 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.78 - 0s 163us/sample - loss: 0.4514 - accuracy: 0.7759 - val_loss: 0.6863 - val_accuracy: 0.7586\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4755 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4591 - accuracy: 0.7845 - val_loss: 0.6988 - val_accuracy: 0.7241\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.75 - 0s 120us/sample - loss: 0.4340 - accuracy: 0.7759 - val_loss: 0.7523 - val_accuracy: 0.7241\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4666 - accuracy: 0.68 - 0s 129us/sample - loss: 0.4291 - accuracy: 0.7845 - val_loss: 0.8412 - val_accuracy: 0.6897\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4364 - accuracy: 0.78 - 0s 155us/sample - loss: 0.4568 - accuracy: 0.8103 - val_loss: 0.7503 - val_accuracy: 0.7586\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3670 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4368 - accuracy: 0.7759 - val_loss: 0.7400 - val_accuracy: 0.6897\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4143 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4245 - accuracy: 0.7931 - val_loss: 0.8160 - val_accuracy: 0.7586\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3795 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4301 - accuracy: 0.8190 - val_loss: 0.8022 - val_accuracy: 0.7586\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3904 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4127 - accuracy: 0.8276 - val_loss: 0.9430 - val_accuracy: 0.6897\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3705 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3934 - accuracy: 0.8448 - val_loss: 0.9652 - val_accuracy: 0.7241\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4587 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4061 - accuracy: 0.7931 - val_loss: 0.8932 - val_accuracy: 0.7586\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4637 - accuracy: 0.75 - 0s 138us/sample - loss: 0.3832 - accuracy: 0.8276 - val_loss: 0.9113 - val_accuracy: 0.7586\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3987 - accuracy: 0.8103 - val_loss: 0.9695 - val_accuracy: 0.6897\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4225 - accuracy: 0.75 - 0s 146us/sample - loss: 0.3921 - accuracy: 0.8017 - val_loss: 0.9684 - val_accuracy: 0.7586\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4303 - accuracy: 0.75 - 0s 120us/sample - loss: 0.3702 - accuracy: 0.8276 - val_loss: 0.9341 - val_accuracy: 0.7586\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2971 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3800 - accuracy: 0.8190 - val_loss: 0.9437 - val_accuracy: 0.7586\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2544 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3454 - accuracy: 0.8276 - val_loss: 1.0919 - val_accuracy: 0.6897\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3838 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3642 - accuracy: 0.8362 - val_loss: 1.0138 - val_accuracy: 0.7586\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3640 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3453 - accuracy: 0.8276 - val_loss: 1.0472 - val_accuracy: 0.7586\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3545 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3474 - accuracy: 0.8448 - val_loss: 1.1469 - val_accuracy: 0.7241\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3971 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3368 - accuracy: 0.8448 - val_loss: 1.2063 - val_accuracy: 0.7241\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3408 - accuracy: 0.8448 - val_loss: 1.2146 - val_accuracy: 0.7586\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4114 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3322 - accuracy: 0.8621 - val_loss: 1.1826 - val_accuracy: 0.7586\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3097 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3316 - accuracy: 0.8362 - val_loss: 1.2087 - val_accuracy: 0.6897\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2981 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3339 - accuracy: 0.8276 - val_loss: 1.3923 - val_accuracy: 0.7586\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2939 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3087 - accuracy: 0.8621 - val_loss: 1.3488 - val_accuracy: 0.6897\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4066 - accuracy: 0.71 - 0s 137us/sample - loss: 0.3095 - accuracy: 0.8707 - val_loss: 1.2938 - val_accuracy: 0.7586\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2960 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2937 - accuracy: 0.8707 - val_loss: 1.3322 - val_accuracy: 0.7241\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2980 - accuracy: 0.8879 - val_loss: 1.2693 - val_accuracy: 0.7586\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3747 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3466 - accuracy: 0.8448 - val_loss: 1.3618 - val_accuracy: 0.6897\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2933 - accuracy: 0.84 - 0s 155us/sample - loss: 0.2925 - accuracy: 0.8793 - val_loss: 1.3901 - val_accuracy: 0.7931\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3641 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3060 - accuracy: 0.8707 - val_loss: 1.4509 - val_accuracy: 0.7931\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4016 - accuracy: 0.75 - 0s 138us/sample - loss: 0.2933 - accuracy: 0.8707 - val_loss: 1.3930 - val_accuracy: 0.7586\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3334 - accuracy: 0.8534 - val_loss: 1.4003 - val_accuracy: 0.7241\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2861 - accuracy: 0.8707 - val_loss: 1.4317 - val_accuracy: 0.7931\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2925 - accuracy: 0.8966 - val_loss: 1.4762 - val_accuracy: 0.7931\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2387 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2677 - accuracy: 0.8793 - val_loss: 1.5421 - val_accuracy: 0.6897\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2697 - accuracy: 0.8448 - val_loss: 1.5144 - val_accuracy: 0.7241\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2513 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2610 - accuracy: 0.9052 - val_loss: 1.6467 - val_accuracy: 0.6897\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2046 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2627 - accuracy: 0.8879 - val_loss: 1.5724 - val_accuracy: 0.7586\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2739 - accuracy: 0.8793 - val_loss: 1.7242 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3174 - accuracy: 0.78 - 0s 146us/sample - loss: 0.2803 - accuracy: 0.8534 - val_loss: 1.6065 - val_accuracy: 0.7931\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3713 - accuracy: 0.81 - 0s 145us/sample - loss: 0.2582 - accuracy: 0.8966 - val_loss: 1.5513 - val_accuracy: 0.7586\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1545 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2500 - accuracy: 0.8966 - val_loss: 1.6420 - val_accuracy: 0.7586\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2127 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2264 - accuracy: 0.9052 - val_loss: 1.7183 - val_accuracy: 0.7586\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2382 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2196 - accuracy: 0.8966 - val_loss: 1.7403 - val_accuracy: 0.7241\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 1.00 - 0s 138us/sample - loss: 0.2316 - accuracy: 0.9052 - val_loss: 1.8101 - val_accuracy: 0.7241\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1986 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2282 - accuracy: 0.9138 - val_loss: 1.8414 - val_accuracy: 0.7241\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2462 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2274 - accuracy: 0.8966 - val_loss: 1.7916 - val_accuracy: 0.6552\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2346 - accuracy: 0.8879 - val_loss: 1.9604 - val_accuracy: 0.7241\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1424 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2021 - accuracy: 0.9310 - val_loss: 1.9276 - val_accuracy: 0.6897\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2677 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2232 - accuracy: 0.8793 - val_loss: 1.9167 - val_accuracy: 0.6897\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.81 - 0s 129us/sample - loss: 0.1962 - accuracy: 0.9052 - val_loss: 1.8835 - val_accuracy: 0.7586\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2273 - accuracy: 0.9052 - val_loss: 2.1120 - val_accuracy: 0.6897\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1994 - accuracy: 0.93 - 0s 155us/sample - loss: 0.3210 - accuracy: 0.8448 - val_loss: 1.9361 - val_accuracy: 0.7586\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2598 - accuracy: 0.8707 - val_loss: 2.0416 - val_accuracy: 0.6207\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2475 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2284 - accuracy: 0.9138 - val_loss: 1.8565 - val_accuracy: 0.7931\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2634 - accuracy: 0.9138 - val_loss: 1.9672 - val_accuracy: 0.7586\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1929 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2178 - accuracy: 0.9138 - val_loss: 1.9654 - val_accuracy: 0.6897\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1665 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2078 - accuracy: 0.8966 - val_loss: 1.9078 - val_accuracy: 0.6552\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2035 - accuracy: 0.9138 - val_loss: 1.8859 - val_accuracy: 0.7586\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1706 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2147 - accuracy: 0.9052 - val_loss: 1.9100 - val_accuracy: 0.6897\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2477 - accuracy: 0.8966 - val_loss: 1.8399 - val_accuracy: 0.7241\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2968 - accuracy: 0.84 - 0s 146us/sample - loss: 0.1840 - accuracy: 0.9224 - val_loss: 1.8842 - val_accuracy: 0.7586\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1331 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2097 - accuracy: 0.9224 - val_loss: 2.0666 - val_accuracy: 0.6552\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2223 - accuracy: 0.90 - 0s 181us/sample - loss: 0.2948 - accuracy: 0.8534 - val_loss: 1.9470 - val_accuracy: 0.7241\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2979 - accuracy: 0.8793 - val_loss: 1.9190 - val_accuracy: 0.7931\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2507 - accuracy: 0.8621 - val_loss: 2.1791 - val_accuracy: 0.6897\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1913 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2766 - accuracy: 0.8707 - val_loss: 1.8745 - val_accuracy: 0.7586\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3553 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2477 - accuracy: 0.8966 - val_loss: 2.1684 - val_accuracy: 0.6552\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2538 - accuracy: 0.8793 - val_loss: 2.0894 - val_accuracy: 0.6897\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2358 - accuracy: 0.8534 - val_loss: 2.0793 - val_accuracy: 0.7241\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1999 - accuracy: 0.9224 - val_loss: 2.2922 - val_accuracy: 0.6552\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1996 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3055 - accuracy: 0.8879 - val_loss: 1.6051 - val_accuracy: 0.6897\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1558 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2549 - accuracy: 0.9138 - val_loss: 1.9086 - val_accuracy: 0.6207\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1764 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2427 - accuracy: 0.8966 - val_loss: 1.9660 - val_accuracy: 0.7586\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2073 - accuracy: 0.90 - 0s 120us/sample - loss: 0.1988 - accuracy: 0.9224 - val_loss: 1.7692 - val_accuracy: 0.6897\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2378 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2206 - accuracy: 0.8879 - val_loss: 1.8742 - val_accuracy: 0.6552\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2624 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2135 - accuracy: 0.9138 - val_loss: 1.7059 - val_accuracy: 0.6552\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1460 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1735 - accuracy: 0.9397 - val_loss: 1.8295 - val_accuracy: 0.6552\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1874 - accuracy: 0.9224 - val_loss: 1.9023 - val_accuracy: 0.6552\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1538 - accuracy: 0.9483 - val_loss: 1.9170 - val_accuracy: 0.6897\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1620 - accuracy: 0.9483 - val_loss: 2.0267 - val_accuracy: 0.6552\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1901 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1720 - accuracy: 0.9483 - val_loss: 2.0431 - val_accuracy: 0.6207\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1330 - accuracy: 0.9397 - val_loss: 1.9240 - val_accuracy: 0.6897\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1638 - accuracy: 0.9310 - val_loss: 2.0724 - val_accuracy: 0.5172\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.2413 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1448 - accuracy: 0.9569 - val_loss: 2.0947 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1187 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1257 - accuracy: 0.9569 - val_loss: 2.0950 - val_accuracy: 0.6897\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1194 - accuracy: 0.9655 - val_loss: 2.1448 - val_accuracy: 0.5517\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1240 - accuracy: 0.9310 - val_loss: 2.1157 - val_accuracy: 0.6897\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0848 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1317 - accuracy: 0.9397 - val_loss: 2.1186 - val_accuracy: 0.6897\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1662 - accuracy: 0.87 - 0s 129us/sample - loss: 0.1194 - accuracy: 0.9397 - val_loss: 2.3195 - val_accuracy: 0.5517\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1193 - accuracy: 0.9483 - val_loss: 2.2845 - val_accuracy: 0.6897\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1205 - accuracy: 0.9569 - val_loss: 2.2468 - val_accuracy: 0.5862\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1269 - accuracy: 0.9483 - val_loss: 2.2406 - val_accuracy: 0.5517\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1386 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1609 - accuracy: 0.9310 - val_loss: 2.2471 - val_accuracy: 0.5517\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1109 - accuracy: 0.9397 - val_loss: 2.2099 - val_accuracy: 0.6897\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1000 - accuracy: 0.9569 - val_loss: 2.5006 - val_accuracy: 0.5517\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1309 - accuracy: 0.9397 - val_loss: 2.3840 - val_accuracy: 0.6207\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0420 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1437 - accuracy: 0.9310 - val_loss: 2.3472 - val_accuracy: 0.6207\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1124 - accuracy: 0.9828 - val_loss: 2.3531 - val_accuracy: 0.5517\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1066 - accuracy: 0.9655 - val_loss: 2.2224 - val_accuracy: 0.6897\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1507 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1260 - accuracy: 0.9310 - val_loss: 2.3929 - val_accuracy: 0.5172\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0497 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1691 - accuracy: 0.9138 - val_loss: 2.3709 - val_accuracy: 0.5862\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1322 - accuracy: 0.9397 - val_loss: 2.3893 - val_accuracy: 0.5517\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0909 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1446 - accuracy: 0.9310 - val_loss: 2.4761 - val_accuracy: 0.5862\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1298 - accuracy: 0.9483 - val_loss: 2.3002 - val_accuracy: 0.6897\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1363 - accuracy: 0.9224 - val_loss: 2.6004 - val_accuracy: 0.5517\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2293 - accuracy: 0.87 - 0s 137us/sample - loss: 0.1674 - accuracy: 0.9224 - val_loss: 2.3299 - val_accuracy: 0.6897\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.96 - 0s 130us/sample - loss: 0.1162 - accuracy: 0.9397 - val_loss: 2.6366 - val_accuracy: 0.5517\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1552 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1204 - accuracy: 0.9569 - val_loss: 2.3931 - val_accuracy: 0.6897\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0192 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1128 - accuracy: 0.9397 - val_loss: 2.6044 - val_accuracy: 0.6207\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1228 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1095 - accuracy: 0.9569 - val_loss: 2.6474 - val_accuracy: 0.6897\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0893 - accuracy: 0.9828 - val_loss: 2.5785 - val_accuracy: 0.6552\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1128 - accuracy: 0.9483 - val_loss: 2.6795 - val_accuracy: 0.6207\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0837 - accuracy: 0.9828 - val_loss: 2.5868 - val_accuracy: 0.7241\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0985 - accuracy: 0.9483 - val_loss: 2.8444 - val_accuracy: 0.5517\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1060 - accuracy: 0.9569 - val_loss: 2.5960 - val_accuracy: 0.5862\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0734 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0882 - accuracy: 0.9741 - val_loss: 2.5591 - val_accuracy: 0.6552\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0731 - accuracy: 0.9914 - val_loss: 2.7708 - val_accuracy: 0.5862\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0972 - accuracy: 0.9655 - val_loss: 2.6617 - val_accuracy: 0.6897\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0721 - accuracy: 0.9828 - val_loss: 2.8171 - val_accuracy: 0.6207\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0807 - accuracy: 0.9828 - val_loss: 2.8054 - val_accuracy: 0.5862\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0819 - accuracy: 0.9741 - val_loss: 2.8651 - val_accuracy: 0.5862\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0756 - accuracy: 0.9741 - val_loss: 3.0428 - val_accuracy: 0.5862\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0890 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0676 - accuracy: 0.9741 - val_loss: 2.8575 - val_accuracy: 0.5862\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0823 - accuracy: 0.9655 - val_loss: 2.9973 - val_accuracy: 0.5517\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0830 - accuracy: 0.9569 - val_loss: 2.9202 - val_accuracy: 0.6897\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0861 - accuracy: 0.9655 - val_loss: 2.9231 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0626 - accuracy: 0.9828 - val_loss: 3.2915 - val_accuracy: 0.5517\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0812 - accuracy: 0.9655 - val_loss: 3.0136 - val_accuracy: 0.6552\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0693 - accuracy: 0.9741 - val_loss: 3.0915 - val_accuracy: 0.6207\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 1.00 - 0s 133us/sample - loss: 0.0604 - accuracy: 0.9914 - val_loss: 3.0565 - val_accuracy: 0.6207\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0652 - accuracy: 0.9741 - val_loss: 3.0443 - val_accuracy: 0.6207\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0501 - accuracy: 1.0000 - val_loss: 3.2753 - val_accuracy: 0.5862\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0643 - accuracy: 0.9741 - val_loss: 3.1670 - val_accuracy: 0.6207\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0674 - accuracy: 0.9828 - val_loss: 3.1395 - val_accuracy: 0.6207\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0438 - accuracy: 1.00 - 0s 133us/sample - loss: 0.0563 - accuracy: 0.9828 - val_loss: 3.4050 - val_accuracy: 0.5172\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0576 - accuracy: 0.9914 - val_loss: 3.1729 - val_accuracy: 0.6552\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0544 - accuracy: 0.9914 - val_loss: 3.2964 - val_accuracy: 0.5862\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0557 - accuracy: 0.9741 - val_loss: 3.2983 - val_accuracy: 0.5862\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0395 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0506 - accuracy: 0.9828 - val_loss: 3.2730 - val_accuracy: 0.5862\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 0.96 - 0s 137us/sample - loss: 0.0594 - accuracy: 0.9828 - val_loss: 3.4092 - val_accuracy: 0.5517\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0647 - accuracy: 0.9741 - val_loss: 3.3465 - val_accuracy: 0.6552\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0544 - accuracy: 0.9828 - val_loss: 3.2471 - val_accuracy: 0.6552\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0539 - accuracy: 0.9828 - val_loss: 3.4119 - val_accuracy: 0.6207\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0545 - accuracy: 0.9741 - val_loss: 3.2919 - val_accuracy: 0.6207\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0451 - accuracy: 0.9914 - val_loss: 3.6221 - val_accuracy: 0.6207\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0662 - accuracy: 0.9741 - val_loss: 3.3162 - val_accuracy: 0.6552\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0640 - accuracy: 0.9741 - val_loss: 3.5121 - val_accuracy: 0.6207\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0486 - accuracy: 0.9828 - val_loss: 3.6339 - val_accuracy: 0.5862\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0406 - accuracy: 0.9828 - val_loss: 3.3798 - val_accuracy: 0.6552\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0508 - accuracy: 0.9828 - val_loss: 3.6683 - val_accuracy: 0.5862\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0769 - accuracy: 0.9569 - val_loss: 3.2912 - val_accuracy: 0.6552\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0719 - accuracy: 0.9483 - val_loss: 3.3279 - val_accuracy: 0.6552\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0588 - accuracy: 0.9828 - val_loss: 3.8016 - val_accuracy: 0.5862\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0927 - accuracy: 0.9828 - val_loss: 3.3471 - val_accuracy: 0.6897\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 1.00 - 0s 181us/sample - loss: 0.0800 - accuracy: 0.9741 - val_loss: 3.6178 - val_accuracy: 0.5862\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1463 - accuracy: 0.9655 - val_loss: 3.3783 - val_accuracy: 0.5862\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.96 - 0s 181us/sample - loss: 0.1368 - accuracy: 0.9483 - val_loss: 3.9274 - val_accuracy: 0.5862\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1583 - accuracy: 0.9052 - val_loss: 3.2306 - val_accuracy: 0.6897\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1438 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2189 - accuracy: 0.9052 - val_loss: 3.2231 - val_accuracy: 0.5862\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 1.00 - 0s 172us/sample - loss: 0.1085 - accuracy: 0.9655 - val_loss: 2.8218 - val_accuracy: 0.6897\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5486 - accuracy: 0.90 - 0s 172us/sample - loss: 0.2237 - accuracy: 0.9397 - val_loss: 3.4919 - val_accuracy: 0.5862\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.96 - 0s 172us/sample - loss: 0.0861 - accuracy: 0.9483 - val_loss: 3.5467 - val_accuracy: 0.6897\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0831 - accuracy: 0.9741 - val_loss: 3.7727 - val_accuracy: 0.6207\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1059 - accuracy: 0.9483 - val_loss: 3.5680 - val_accuracy: 0.6897\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0739 - accuracy: 0.9655 - val_loss: 3.3710 - val_accuracy: 0.6897\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0619 - accuracy: 0.9828 - val_loss: 3.5917 - val_accuracy: 0.5517\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0610 - accuracy: 0.9914 - val_loss: 3.6036 - val_accuracy: 0.5517\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6903 - accuracy: 0.56 - 0s 3ms/sample - loss: 0.6737 - accuracy: 0.6207 - val_loss: 0.6422 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6383 - accuracy: 0.68 - 0s 172us/sample - loss: 0.6324 - accuracy: 0.6638 - val_loss: 0.6314 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5298 - accuracy: 0.75 - 0s 172us/sample - loss: 0.6240 - accuracy: 0.6638 - val_loss: 0.6179 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5760 - accuracy: 0.65 - 0s 155us/sample - loss: 0.6130 - accuracy: 0.6638 - val_loss: 0.6194 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5122 - accuracy: 0.81 - 0s 155us/sample - loss: 0.6134 - accuracy: 0.6638 - val_loss: 0.6028 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6311 - accuracy: 0.65 - 0s 163us/sample - loss: 0.6054 - accuracy: 0.6724 - val_loss: 0.5959 - val_accuracy: 0.6897\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5341 - accuracy: 0.75 - 0s 164us/sample - loss: 0.6009 - accuracy: 0.6897 - val_loss: 0.5952 - val_accuracy: 0.7241\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6497 - accuracy: 0.62 - 0s 163us/sample - loss: 0.6009 - accuracy: 0.7069 - val_loss: 0.5980 - val_accuracy: 0.7241\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6198 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5931 - accuracy: 0.6983 - val_loss: 0.5869 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7331 - accuracy: 0.53 - 0s 163us/sample - loss: 0.5885 - accuracy: 0.6983 - val_loss: 0.5818 - val_accuracy: 0.6897\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6073 - accuracy: 0.71 - 0s 159us/sample - loss: 0.5816 - accuracy: 0.7069 - val_loss: 0.5727 - val_accuracy: 0.7241\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6613 - accuracy: 0.62 - 0s 155us/sample - loss: 0.5790 - accuracy: 0.7069 - val_loss: 0.5733 - val_accuracy: 0.7241\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5948 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5701 - accuracy: 0.7155 - val_loss: 0.5611 - val_accuracy: 0.7586\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5731 - accuracy: 0.75 - 0s 146us/sample - loss: 0.5641 - accuracy: 0.7328 - val_loss: 0.5638 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6716 - accuracy: 0.59 - 0s 138us/sample - loss: 0.5738 - accuracy: 0.7155 - val_loss: 0.5658 - val_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4448 - accuracy: 0.81 - 0s 142us/sample - loss: 0.5661 - accuracy: 0.7241 - val_loss: 0.5607 - val_accuracy: 0.6552\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5495 - accuracy: 0.7155 - val_loss: 0.5820 - val_accuracy: 0.6552\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4841 - accuracy: 0.81 - 0s 146us/sample - loss: 0.5436 - accuracy: 0.7414 - val_loss: 0.5628 - val_accuracy: 0.6897\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5798 - accuracy: 0.68 - 0s 146us/sample - loss: 0.5389 - accuracy: 0.7328 - val_loss: 0.5656 - val_accuracy: 0.7241\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6580 - accuracy: 0.59 - 0s 138us/sample - loss: 0.5329 - accuracy: 0.7241 - val_loss: 0.5589 - val_accuracy: 0.7241\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4894 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5216 - accuracy: 0.7500 - val_loss: 0.5418 - val_accuracy: 0.7241\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.81 - 0s 155us/sample - loss: 0.5173 - accuracy: 0.7500 - val_loss: 0.5924 - val_accuracy: 0.7241\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5400 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5148 - accuracy: 0.7328 - val_loss: 0.5852 - val_accuracy: 0.7586\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4458 - accuracy: 0.75 - 0s 163us/sample - loss: 0.5082 - accuracy: 0.7672 - val_loss: 0.5705 - val_accuracy: 0.7931\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4670 - accuracy: 0.78 - 0s 139us/sample - loss: 0.5038 - accuracy: 0.7414 - val_loss: 0.6508 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5412 - accuracy: 0.71 - 0s 138us/sample - loss: 0.4846 - accuracy: 0.7672 - val_loss: 0.6170 - val_accuracy: 0.7931\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4875 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4812 - accuracy: 0.7845 - val_loss: 0.6628 - val_accuracy: 0.7241\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5225 - accuracy: 0.68 - 0s 163us/sample - loss: 0.4555 - accuracy: 0.7931 - val_loss: 0.6806 - val_accuracy: 0.7586\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4586 - accuracy: 0.8017 - val_loss: 0.7004 - val_accuracy: 0.7586\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3332 - accuracy: 0.87 - 0s 129us/sample - loss: 0.4327 - accuracy: 0.7931 - val_loss: 0.8063 - val_accuracy: 0.6897\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3752 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4330 - accuracy: 0.7931 - val_loss: 0.8009 - val_accuracy: 0.7241\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4561 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4304 - accuracy: 0.7759 - val_loss: 0.8241 - val_accuracy: 0.6897\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3759 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4287 - accuracy: 0.8017 - val_loss: 0.8387 - val_accuracy: 0.7241\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3611 - accuracy: 0.87 - 0s 146us/sample - loss: 0.4257 - accuracy: 0.8190 - val_loss: 0.9330 - val_accuracy: 0.6897\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3809 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3870 - accuracy: 0.8276 - val_loss: 0.9000 - val_accuracy: 0.7241\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3991 - accuracy: 0.8103 - val_loss: 1.0672 - val_accuracy: 0.6897\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3408 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3834 - accuracy: 0.8103 - val_loss: 1.0616 - val_accuracy: 0.7241\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4241 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3712 - accuracy: 0.8621 - val_loss: 1.0995 - val_accuracy: 0.6897\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3443 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3606 - accuracy: 0.8707 - val_loss: 1.0761 - val_accuracy: 0.6552\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3407 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3877 - accuracy: 0.8362 - val_loss: 1.1518 - val_accuracy: 0.6897\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3390 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3439 - accuracy: 0.8621 - val_loss: 1.2507 - val_accuracy: 0.6897\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3917 - accuracy: 0.78 - 0s 146us/sample - loss: 0.3653 - accuracy: 0.8362 - val_loss: 1.2285 - val_accuracy: 0.7586\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3644 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4294 - accuracy: 0.8017 - val_loss: 1.8237 - val_accuracy: 0.4828\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6753 - accuracy: 0.50 - 0s 155us/sample - loss: 0.5266 - accuracy: 0.6724 - val_loss: 1.0687 - val_accuracy: 0.7586\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.84 - 0s 163us/sample - loss: 0.4255 - accuracy: 0.8103 - val_loss: 1.2166 - val_accuracy: 0.6897\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3885 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3906 - accuracy: 0.8621 - val_loss: 1.1961 - val_accuracy: 0.6897\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3612 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3507 - accuracy: 0.8707 - val_loss: 1.1882 - val_accuracy: 0.7586\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4172 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3535 - accuracy: 0.8534 - val_loss: 1.2628 - val_accuracy: 0.7241\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3815 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3516 - accuracy: 0.8621 - val_loss: 1.3195 - val_accuracy: 0.6897\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.90 - 0s 163us/sample - loss: 0.3295 - accuracy: 0.8707 - val_loss: 1.2959 - val_accuracy: 0.7241\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3458 - accuracy: 0.8793 - val_loss: 1.4747 - val_accuracy: 0.6552\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2537 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3339 - accuracy: 0.8621 - val_loss: 1.4085 - val_accuracy: 0.7241\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.96 - 0s 138us/sample - loss: 0.3158 - accuracy: 0.8621 - val_loss: 1.5265 - val_accuracy: 0.6207\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3167 - accuracy: 0.8966 - val_loss: 1.4562 - val_accuracy: 0.6897\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3141 - accuracy: 0.8707 - val_loss: 1.5105 - val_accuracy: 0.6897\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2741 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3059 - accuracy: 0.8966 - val_loss: 1.6097 - val_accuracy: 0.6552\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3064 - accuracy: 0.8879 - val_loss: 1.5592 - val_accuracy: 0.7241\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3186 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3344 - accuracy: 0.8534 - val_loss: 1.6006 - val_accuracy: 0.6552\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3001 - accuracy: 0.9052 - val_loss: 1.5811 - val_accuracy: 0.6552\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2501 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2863 - accuracy: 0.8966 - val_loss: 1.7142 - val_accuracy: 0.6552\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3589 - accuracy: 0.87 - 0s 120us/sample - loss: 0.2944 - accuracy: 0.9052 - val_loss: 1.7168 - val_accuracy: 0.7241\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2860 - accuracy: 0.9052 - val_loss: 1.7911 - val_accuracy: 0.6207\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2378 - accuracy: 0.93 - 0s 181us/sample - loss: 0.2977 - accuracy: 0.9138 - val_loss: 1.7201 - val_accuracy: 0.6552\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3997 - accuracy: 0.84 - 0s 198us/sample - loss: 0.2754 - accuracy: 0.9224 - val_loss: 1.7386 - val_accuracy: 0.6552\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.93 - 0s 181us/sample - loss: 0.2577 - accuracy: 0.9052 - val_loss: 1.7191 - val_accuracy: 0.7241\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3061 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2744 - accuracy: 0.8879 - val_loss: 1.9733 - val_accuracy: 0.6207\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2783 - accuracy: 0.9052 - val_loss: 1.8369 - val_accuracy: 0.7241\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3413 - accuracy: 0.8362 - val_loss: 1.9511 - val_accuracy: 0.6552\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3209 - accuracy: 0.8621 - val_loss: 1.8935 - val_accuracy: 0.7241\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1720 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2654 - accuracy: 0.8966 - val_loss: 1.8812 - val_accuracy: 0.6552\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1870 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2577 - accuracy: 0.9224 - val_loss: 1.9312 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2120 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2555 - accuracy: 0.9224 - val_loss: 2.0256 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1895 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2559 - accuracy: 0.9052 - val_loss: 1.9809 - val_accuracy: 0.6552\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.81 - 0s 138us/sample - loss: 0.2436 - accuracy: 0.9224 - val_loss: 2.0294 - val_accuracy: 0.6552\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2466 - accuracy: 0.9052 - val_loss: 2.1067 - val_accuracy: 0.6552\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2506 - accuracy: 0.90 - 0s 141us/sample - loss: 0.2785 - accuracy: 0.8793 - val_loss: 2.1179 - val_accuracy: 0.6897\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3032 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2633 - accuracy: 0.8793 - val_loss: 2.3287 - val_accuracy: 0.6207\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2909 - accuracy: 0.84 - 0s 172us/sample - loss: 0.2957 - accuracy: 0.8707 - val_loss: 1.9749 - val_accuracy: 0.6897\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2950 - accuracy: 0.90 - 0s 172us/sample - loss: 0.3110 - accuracy: 0.8534 - val_loss: 2.1690 - val_accuracy: 0.6552\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2977 - accuracy: 0.87 - 0s 138us/sample - loss: 0.4113 - accuracy: 0.8190 - val_loss: 1.9964 - val_accuracy: 0.7241\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2290 - accuracy: 0.90 - 0s 142us/sample - loss: 0.4563 - accuracy: 0.8103 - val_loss: 2.0675 - val_accuracy: 0.7241\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3001 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3019 - accuracy: 0.8707 - val_loss: 2.2561 - val_accuracy: 0.6207\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3921 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2989 - accuracy: 0.8966 - val_loss: 1.8676 - val_accuracy: 0.7241\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1945 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3131 - accuracy: 0.8621 - val_loss: 1.8324 - val_accuracy: 0.6897\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2862 - accuracy: 0.8879 - val_loss: 1.9951 - val_accuracy: 0.6552\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2659 - accuracy: 0.8879 - val_loss: 2.1016 - val_accuracy: 0.6552\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1923 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2427 - accuracy: 0.9224 - val_loss: 2.1224 - val_accuracy: 0.6552\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.81 - 0s 129us/sample - loss: 0.2302 - accuracy: 0.9138 - val_loss: 2.1635 - val_accuracy: 0.6897\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2250 - accuracy: 0.9224 - val_loss: 2.1371 - val_accuracy: 0.6552\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1563 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2236 - accuracy: 0.9224 - val_loss: 2.2572 - val_accuracy: 0.6552\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1788 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2239 - accuracy: 0.9138 - val_loss: 2.3141 - val_accuracy: 0.6552\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2378 - accuracy: 0.8966 - val_loss: 2.3518 - val_accuracy: 0.6552\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2621 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2534 - accuracy: 0.9138 - val_loss: 2.3649 - val_accuracy: 0.6552\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1954 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2337 - accuracy: 0.8879 - val_loss: 2.3504 - val_accuracy: 0.6897\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2487 - accuracy: 0.8966 - val_loss: 2.4865 - val_accuracy: 0.6207\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2832 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2134 - accuracy: 0.9138 - val_loss: 2.4255 - val_accuracy: 0.6897\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2572 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2005 - accuracy: 0.9138 - val_loss: 2.5007 - val_accuracy: 0.6552\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1984 - accuracy: 0.9397 - val_loss: 2.4398 - val_accuracy: 0.6897\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2089 - accuracy: 0.9224 - val_loss: 2.4953 - val_accuracy: 0.6897\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1317 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1750 - accuracy: 0.9397 - val_loss: 2.4824 - val_accuracy: 0.6897\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1824 - accuracy: 0.9483 - val_loss: 2.5232 - val_accuracy: 0.6897\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1347 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1723 - accuracy: 0.9224 - val_loss: 2.6881 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1798 - accuracy: 0.9397 - val_loss: 2.7116 - val_accuracy: 0.6552\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1225 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1678 - accuracy: 0.9397 - val_loss: 2.7768 - val_accuracy: 0.6207\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1150 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1596 - accuracy: 0.9397 - val_loss: 2.7339 - val_accuracy: 0.6897\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1692 - accuracy: 0.9310 - val_loss: 2.8744 - val_accuracy: 0.5862\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1992 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1502 - accuracy: 0.9483 - val_loss: 2.8575 - val_accuracy: 0.6552\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.93 - 0s 215us/sample - loss: 0.1592 - accuracy: 0.9483 - val_loss: 2.9377 - val_accuracy: 0.6552\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1652 - accuracy: 0.9397 - val_loss: 2.9715 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1642 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1511 - accuracy: 0.9397 - val_loss: 3.0505 - val_accuracy: 0.6207\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1719 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1684 - accuracy: 0.9397 - val_loss: 2.9753 - val_accuracy: 0.6552\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1432 - accuracy: 0.9483 - val_loss: 3.0045 - val_accuracy: 0.6207\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1692 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1694 - accuracy: 0.9310 - val_loss: 3.0531 - val_accuracy: 0.6552\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2014 - accuracy: 0.9052 - val_loss: 3.0805 - val_accuracy: 0.6897\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1346 - accuracy: 0.9655 - val_loss: 3.2856 - val_accuracy: 0.5517\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1442 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1494 - accuracy: 0.9397 - val_loss: 3.1010 - val_accuracy: 0.6897\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.87 - 0s 146us/sample - loss: 0.1524 - accuracy: 0.9397 - val_loss: 3.1394 - val_accuracy: 0.6552\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1277 - accuracy: 0.9569 - val_loss: 3.2421 - val_accuracy: 0.6552\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1410 - accuracy: 0.9397 - val_loss: 3.1952 - val_accuracy: 0.6552\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0771 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1238 - accuracy: 0.9483 - val_loss: 3.2414 - val_accuracy: 0.6552\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1262 - accuracy: 0.9483 - val_loss: 3.3014 - val_accuracy: 0.6552\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1199 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1279 - accuracy: 0.9569 - val_loss: 3.3868 - val_accuracy: 0.6552\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.84 - 0s 138us/sample - loss: 0.1255 - accuracy: 0.9397 - val_loss: 3.4302 - val_accuracy: 0.6552\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1111 - accuracy: 0.9655 - val_loss: 3.3768 - val_accuracy: 0.6552\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1154 - accuracy: 0.9655 - val_loss: 3.5122 - val_accuracy: 0.6552\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0766 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1112 - accuracy: 0.9569 - val_loss: 3.3891 - val_accuracy: 0.6897\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0526 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1405 - accuracy: 0.9310 - val_loss: 3.6467 - val_accuracy: 0.5862\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1128 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1444 - accuracy: 0.9224 - val_loss: 3.5776 - val_accuracy: 0.6897\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2413 - accuracy: 0.84 - 0s 155us/sample - loss: 0.1722 - accuracy: 0.8966 - val_loss: 3.6088 - val_accuracy: 0.5517\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1892 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1773 - accuracy: 0.9310 - val_loss: 3.4042 - val_accuracy: 0.6897\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1994 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1488 - accuracy: 0.9310 - val_loss: 3.6420 - val_accuracy: 0.6897\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2367 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1430 - accuracy: 0.9397 - val_loss: 3.5153 - val_accuracy: 0.6897\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1591 - accuracy: 0.9397 - val_loss: 3.5068 - val_accuracy: 0.6207\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1360 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1194 - accuracy: 0.9483 - val_loss: 3.8276 - val_accuracy: 0.6207\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1146 - accuracy: 0.9741 - val_loss: 3.7896 - val_accuracy: 0.6207\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0953 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1183 - accuracy: 0.9310 - val_loss: 3.7196 - val_accuracy: 0.6552\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1004 - accuracy: 0.9655 - val_loss: 3.7435 - val_accuracy: 0.6552\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1172 - accuracy: 0.9569 - val_loss: 3.9849 - val_accuracy: 0.6207\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1140 - accuracy: 0.9569 - val_loss: 3.9271 - val_accuracy: 0.6897\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1152 - accuracy: 0.9569 - val_loss: 4.0477 - val_accuracy: 0.6552\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 1.00 - 0s 120us/sample - loss: 0.1122 - accuracy: 0.9569 - val_loss: 3.9564 - val_accuracy: 0.6897\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0868 - accuracy: 0.9741 - val_loss: 3.9331 - val_accuracy: 0.6552\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0906 - accuracy: 0.9655 - val_loss: 4.0912 - val_accuracy: 0.6207\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0872 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0933 - accuracy: 0.9655 - val_loss: 4.0855 - val_accuracy: 0.6552\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0768 - accuracy: 0.9828 - val_loss: 4.1458 - val_accuracy: 0.6552\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0754 - accuracy: 0.9828 - val_loss: 4.2119 - val_accuracy: 0.6552\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0409 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0779 - accuracy: 0.9828 - val_loss: 4.2495 - val_accuracy: 0.6552\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0730 - accuracy: 0.9828 - val_loss: 4.3120 - val_accuracy: 0.6552\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0768 - accuracy: 0.9741 - val_loss: 4.4073 - val_accuracy: 0.6552\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0739 - accuracy: 0.9655 - val_loss: 4.3397 - val_accuracy: 0.6552\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0704 - accuracy: 0.9741 - val_loss: 4.4399 - val_accuracy: 0.6552\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0629 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0699 - accuracy: 0.9741 - val_loss: 4.4934 - val_accuracy: 0.6897\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0782 - accuracy: 0.9741 - val_loss: 4.5477 - val_accuracy: 0.6897\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0684 - accuracy: 0.9828 - val_loss: 4.6059 - val_accuracy: 0.5517\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0787 - accuracy: 0.9741 - val_loss: 4.6122 - val_accuracy: 0.6552\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0575 - accuracy: 0.9914 - val_loss: 4.4884 - val_accuracy: 0.6552\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0782 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0710 - accuracy: 0.9828 - val_loss: 4.8015 - val_accuracy: 0.5862\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0797 - accuracy: 0.9655 - val_loss: 4.5734 - val_accuracy: 0.6897\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1644 - accuracy: 0.9310 - val_loss: 5.0075 - val_accuracy: 0.5517\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1369 - accuracy: 0.9224 - val_loss: 4.5797 - val_accuracy: 0.6207\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.90 - 0s 137us/sample - loss: 0.1246 - accuracy: 0.9483 - val_loss: 4.7461 - val_accuracy: 0.6207\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1054 - accuracy: 0.9569 - val_loss: 4.5419 - val_accuracy: 0.6552\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0477 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0894 - accuracy: 0.9655 - val_loss: 4.4123 - val_accuracy: 0.6552\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0721 - accuracy: 0.9828 - val_loss: 4.4445 - val_accuracy: 0.6207\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0618 - accuracy: 0.9828 - val_loss: 4.5045 - val_accuracy: 0.6897\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0727 - accuracy: 0.9655 - val_loss: 4.7681 - val_accuracy: 0.6207\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0580 - accuracy: 0.9914 - val_loss: 4.5359 - val_accuracy: 0.6207\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0748 - accuracy: 0.9828 - val_loss: 4.6045 - val_accuracy: 0.5862\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0324 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1630 - accuracy: 0.9397 - val_loss: 5.2993 - val_accuracy: 0.6207\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.93 - 0s 120us/sample - loss: 0.2206 - accuracy: 0.9138 - val_loss: 4.8709 - val_accuracy: 0.5862\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3188 - accuracy: 0.8362 - val_loss: 4.2601 - val_accuracy: 0.6207\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3132 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3806 - accuracy: 0.8793 - val_loss: 4.1399 - val_accuracy: 0.6552\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0950 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2125 - accuracy: 0.9310 - val_loss: 4.3020 - val_accuracy: 0.6207\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3547 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3241 - accuracy: 0.8966 - val_loss: 4.5932 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3051 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2779 - accuracy: 0.8879 - val_loss: 4.1343 - val_accuracy: 0.6897\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3043 - accuracy: 0.8793 - val_loss: 4.3743 - val_accuracy: 0.6552\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3253 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2167 - accuracy: 0.9052 - val_loss: 4.4011 - val_accuracy: 0.5862\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1534 - accuracy: 0.96 - 0s 137us/sample - loss: 0.1789 - accuracy: 0.9310 - val_loss: 3.9657 - val_accuracy: 0.6207\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1514 - accuracy: 0.9310 - val_loss: 3.8273 - val_accuracy: 0.5862\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1177 - accuracy: 0.9569 - val_loss: 3.7223 - val_accuracy: 0.5862\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1444 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0948 - accuracy: 0.9655 - val_loss: 3.4191 - val_accuracy: 0.6552\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1250 - accuracy: 0.9569 - val_loss: 3.7150 - val_accuracy: 0.6207\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1096 - accuracy: 0.9655 - val_loss: 3.7597 - val_accuracy: 0.6552\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1275 - accuracy: 0.9655 - val_loss: 3.8231 - val_accuracy: 0.6897\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1017 - accuracy: 0.9655 - val_loss: 4.1818 - val_accuracy: 0.6207\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0660 - accuracy: 0.9828 - val_loss: 4.1389 - val_accuracy: 0.6552\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0916 - accuracy: 0.9655 - val_loss: 4.4125 - val_accuracy: 0.6552\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0918 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0861 - accuracy: 0.9741 - val_loss: 4.4107 - val_accuracy: 0.6552\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0715 - accuracy: 0.9828 - val_loss: 4.2883 - val_accuracy: 0.6897\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0633 - accuracy: 0.9828 - val_loss: 4.4831 - val_accuracy: 0.5862\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0696 - accuracy: 0.9741 - val_loss: 4.3752 - val_accuracy: 0.6897\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0547 - accuracy: 0.9828 - val_loss: 4.4302 - val_accuracy: 0.6552\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0889 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0492 - accuracy: 0.9828 - val_loss: 4.5045 - val_accuracy: 0.6207\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0464 - accuracy: 0.9914 - val_loss: 4.5188 - val_accuracy: 0.6897\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0462 - accuracy: 0.9914 - val_loss: 4.5833 - val_accuracy: 0.6207\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0478 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0473 - accuracy: 0.9914 - val_loss: 4.6495 - val_accuracy: 0.6207\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0450 - accuracy: 0.9914 - val_loss: 4.6229 - val_accuracy: 0.6897\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0411 - accuracy: 0.9914 - val_loss: 4.7072 - val_accuracy: 0.6552\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0418 - accuracy: 0.9914 - val_loss: 4.6966 - val_accuracy: 0.6552\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0417 - accuracy: 0.9914 - val_loss: 4.7192 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 2986b97d0d7a3d208988c06d3a630eb4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7931034564971924</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_units: 99</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6877 - accuracy: 0.65 - 0s 4ms/sample - loss: 0.6743 - accuracy: 0.6724 - val_loss: 0.6564 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.62 - 0s 275us/sample - loss: 0.6466 - accuracy: 0.6638 - val_loss: 0.6456 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6639 - accuracy: 0.59 - 0s 146us/sample - loss: 0.6379 - accuracy: 0.6638 - val_loss: 0.6313 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6653 - accuracy: 0.56 - 0s 155us/sample - loss: 0.6196 - accuracy: 0.6638 - val_loss: 0.6180 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.68 - 0s 164us/sample - loss: 0.6136 - accuracy: 0.6638 - val_loss: 0.6108 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6574 - accuracy: 0.59 - 0s 1ms/sample - loss: 0.6137 - accuracy: 0.6724 - val_loss: 0.6080 - val_accuracy: 0.6897\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6067 - accuracy: 0.62 - 0s 301us/sample - loss: 0.6010 - accuracy: 0.7069 - val_loss: 0.5999 - val_accuracy: 0.6897\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5695 - accuracy: 0.71 - 0s 163us/sample - loss: 0.5884 - accuracy: 0.6897 - val_loss: 0.5838 - val_accuracy: 0.6897\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6290 - accuracy: 0.68 - 0s 164us/sample - loss: 0.5813 - accuracy: 0.6983 - val_loss: 0.5798 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4889 - accuracy: 0.78 - 0s 1ms/sample - loss: 0.5707 - accuracy: 0.7155 - val_loss: 0.5898 - val_accuracy: 0.7241\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4807 - accuracy: 0.87 - 0s 163us/sample - loss: 0.5749 - accuracy: 0.7414 - val_loss: 0.5988 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5582 - accuracy: 0.68 - 0s 155us/sample - loss: 0.5602 - accuracy: 0.7241 - val_loss: 0.6076 - val_accuracy: 0.6897\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4906 - accuracy: 0.78 - 0s 172us/sample - loss: 0.5584 - accuracy: 0.7241 - val_loss: 0.6106 - val_accuracy: 0.7241\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5315 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5383 - accuracy: 0.7414 - val_loss: 0.6457 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5323 - accuracy: 0.75 - 0s 163us/sample - loss: 0.5258 - accuracy: 0.7586 - val_loss: 0.6548 - val_accuracy: 0.7241\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5135 - accuracy: 0.78 - 0s 1ms/sample - loss: 0.5210 - accuracy: 0.7500 - val_loss: 0.6604 - val_accuracy: 0.7931\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4348 - accuracy: 0.84 - 0s 293us/sample - loss: 0.5042 - accuracy: 0.7586 - val_loss: 0.7090 - val_accuracy: 0.7931\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.75 - 0s 163us/sample - loss: 0.4922 - accuracy: 0.7500 - val_loss: 0.7302 - val_accuracy: 0.7931\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5036 - accuracy: 0.75 - 0s 155us/sample - loss: 0.4827 - accuracy: 0.7845 - val_loss: 0.8249 - val_accuracy: 0.6897\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4608 - accuracy: 0.7759 - val_loss: 0.8228 - val_accuracy: 0.7931\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.75 - 0s 1ms/sample - loss: 0.4732 - accuracy: 0.7672 - val_loss: 0.8670 - val_accuracy: 0.8276\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4851 - accuracy: 0.81 - 0s 267us/sample - loss: 0.4523 - accuracy: 0.8103 - val_loss: 1.0459 - val_accuracy: 0.7586\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4401 - accuracy: 0.7931 - val_loss: 1.0130 - val_accuracy: 0.7241\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4331 - accuracy: 0.78 - 0s 164us/sample - loss: 0.4365 - accuracy: 0.7931 - val_loss: 1.0455 - val_accuracy: 0.7586\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4159 - accuracy: 0.8103 - val_loss: 1.1416 - val_accuracy: 0.7586\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3858 - accuracy: 0.87 - 0s 138us/sample - loss: 0.4195 - accuracy: 0.8103 - val_loss: 1.1764 - val_accuracy: 0.7586\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5246 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4204 - accuracy: 0.7931 - val_loss: 1.2446 - val_accuracy: 0.7586\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3666 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4048 - accuracy: 0.8190 - val_loss: 1.2979 - val_accuracy: 0.7241\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4079 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3889 - accuracy: 0.8190 - val_loss: 1.3208 - val_accuracy: 0.7586\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3323 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3803 - accuracy: 0.8103 - val_loss: 1.3844 - val_accuracy: 0.7241\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4018 - accuracy: 0.8103 - val_loss: 1.2603 - val_accuracy: 0.7586\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2757 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3714 - accuracy: 0.8190 - val_loss: 1.3389 - val_accuracy: 0.7241\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2404 - accuracy: 0.93 - 0s 155us/sample - loss: 0.3658 - accuracy: 0.8534 - val_loss: 1.5076 - val_accuracy: 0.7586\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4190 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3735 - accuracy: 0.8276 - val_loss: 1.3077 - val_accuracy: 0.7586\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5090 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3735 - accuracy: 0.8362 - val_loss: 1.2780 - val_accuracy: 0.7586\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.87 - 0s 168us/sample - loss: 0.3601 - accuracy: 0.8362 - val_loss: 1.5386 - val_accuracy: 0.6897\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4951 - accuracy: 0.75 - 0s 163us/sample - loss: 0.3573 - accuracy: 0.8448 - val_loss: 1.5944 - val_accuracy: 0.7586\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5716 - accuracy: 0.68 - 0s 155us/sample - loss: 0.3746 - accuracy: 0.8362 - val_loss: 1.5549 - val_accuracy: 0.6897\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2784 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3617 - accuracy: 0.8448 - val_loss: 1.5646 - val_accuracy: 0.7586\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4180 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3869 - accuracy: 0.8448 - val_loss: 1.7174 - val_accuracy: 0.7241\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2825 - accuracy: 0.93 - 0s 141us/sample - loss: 0.3667 - accuracy: 0.8103 - val_loss: 1.4919 - val_accuracy: 0.7586\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2807 - accuracy: 0.87 - 0s 155us/sample - loss: 0.4007 - accuracy: 0.8362 - val_loss: 1.6561 - val_accuracy: 0.6897\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3301 - accuracy: 0.87 - 0s 120us/sample - loss: 0.3689 - accuracy: 0.8362 - val_loss: 1.7870 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3526 - accuracy: 0.8534 - val_loss: 1.8295 - val_accuracy: 0.7586\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3133 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3406 - accuracy: 0.8448 - val_loss: 1.8883 - val_accuracy: 0.7241\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3352 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3482 - accuracy: 0.8707 - val_loss: 1.9181 - val_accuracy: 0.7586\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3366 - accuracy: 0.8621 - val_loss: 2.0374 - val_accuracy: 0.7241\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2519 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3246 - accuracy: 0.8707 - val_loss: 1.9804 - val_accuracy: 0.7241\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2850 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3327 - accuracy: 0.8621 - val_loss: 2.0017 - val_accuracy: 0.7586\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2626 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3166 - accuracy: 0.8793 - val_loss: 2.1400 - val_accuracy: 0.6897\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3531 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3155 - accuracy: 0.8621 - val_loss: 2.0421 - val_accuracy: 0.7241\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3203 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3032 - accuracy: 0.8793 - val_loss: 2.0817 - val_accuracy: 0.7241\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.93 - 0s 129us/sample - loss: 0.3056 - accuracy: 0.8621 - val_loss: 2.2863 - val_accuracy: 0.6897\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3730 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3040 - accuracy: 0.8707 - val_loss: 2.3457 - val_accuracy: 0.7241\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2911 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2735 - accuracy: 0.8966 - val_loss: 2.4359 - val_accuracy: 0.6897\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2837 - accuracy: 0.8879 - val_loss: 2.5397 - val_accuracy: 0.7586\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3526 - accuracy: 0.81 - 0s 206us/sample - loss: 0.3647 - accuracy: 0.8448 - val_loss: 2.5380 - val_accuracy: 0.6552\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2925 - accuracy: 0.8793 - val_loss: 1.9387 - val_accuracy: 0.7241\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2658 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3456 - accuracy: 0.8362 - val_loss: 2.0241 - val_accuracy: 0.7241\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2401 - accuracy: 0.87 - 0s 143us/sample - loss: 0.3029 - accuracy: 0.8362 - val_loss: 2.6609 - val_accuracy: 0.6552\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3699 - accuracy: 0.8448 - val_loss: 1.8528 - val_accuracy: 0.7241\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3165 - accuracy: 0.8621 - val_loss: 1.8282 - val_accuracy: 0.7586\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.93 - 0s 129us/sample - loss: 0.3329 - accuracy: 0.8707 - val_loss: 1.6459 - val_accuracy: 0.6897\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4450 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3424 - accuracy: 0.8621 - val_loss: 1.6897 - val_accuracy: 0.7241\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3765 - accuracy: 0.81 - 0s 135us/sample - loss: 0.3027 - accuracy: 0.8621 - val_loss: 2.3762 - val_accuracy: 0.6552\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3728 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3322 - accuracy: 0.8448 - val_loss: 1.9791 - val_accuracy: 0.7241\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2725 - accuracy: 0.9052 - val_loss: 2.0625 - val_accuracy: 0.6552\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3630 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3122 - accuracy: 0.8276 - val_loss: 2.1067 - val_accuracy: 0.7241\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2428 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2510 - accuracy: 0.9138 - val_loss: 2.4612 - val_accuracy: 0.6552\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2698 - accuracy: 0.8966 - val_loss: 2.2395 - val_accuracy: 0.7241\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3305 - accuracy: 0.8707 - val_loss: 2.3877 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2540 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3392 - accuracy: 0.8276 - val_loss: 2.4048 - val_accuracy: 0.7586\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1853 - accuracy: 0.93 - 0s 146us/sample - loss: 0.3047 - accuracy: 0.8362 - val_loss: 2.4297 - val_accuracy: 0.7241\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1901 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2738 - accuracy: 0.8879 - val_loss: 2.5795 - val_accuracy: 0.6897\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.78 - 0s 155us/sample - loss: 0.2824 - accuracy: 0.8966 - val_loss: 2.3126 - val_accuracy: 0.7241\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2294 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2492 - accuracy: 0.8966 - val_loss: 2.3469 - val_accuracy: 0.7241\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1962 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2295 - accuracy: 0.9138 - val_loss: 2.5346 - val_accuracy: 0.6897\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2227 - accuracy: 0.9310 - val_loss: 2.6456 - val_accuracy: 0.7241\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1500 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2081 - accuracy: 0.8879 - val_loss: 2.7994 - val_accuracy: 0.6552\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2059 - accuracy: 0.9483 - val_loss: 2.8353 - val_accuracy: 0.6897\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2173 - accuracy: 0.9310 - val_loss: 2.8176 - val_accuracy: 0.7241\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3421 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2454 - accuracy: 0.8621 - val_loss: 2.9206 - val_accuracy: 0.7241\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2237 - accuracy: 0.9138 - val_loss: 2.8745 - val_accuracy: 0.6897\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2001 - accuracy: 0.9052 - val_loss: 3.1288 - val_accuracy: 0.7586\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1951 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1966 - accuracy: 0.9224 - val_loss: 3.2062 - val_accuracy: 0.7586\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.96 - 0s 198us/sample - loss: 0.1651 - accuracy: 0.9397 - val_loss: 3.2913 - val_accuracy: 0.6552\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1842 - accuracy: 0.93 - 0s 215us/sample - loss: 0.1673 - accuracy: 0.9310 - val_loss: 3.3448 - val_accuracy: 0.6897\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.93 - 0s 189us/sample - loss: 0.1539 - accuracy: 0.9397 - val_loss: 3.5605 - val_accuracy: 0.7241\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1538 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1622 - accuracy: 0.9483 - val_loss: 3.5389 - val_accuracy: 0.7241\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 1.00 - 0s 181us/sample - loss: 0.1535 - accuracy: 0.9483 - val_loss: 3.8662 - val_accuracy: 0.6207\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2690 - accuracy: 0.84 - 0s 181us/sample - loss: 0.2159 - accuracy: 0.9052 - val_loss: 3.3272 - val_accuracy: 0.7241\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2808 - accuracy: 0.84 - 0s 172us/sample - loss: 0.3491 - accuracy: 0.8707 - val_loss: 3.9110 - val_accuracy: 0.6207\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.93 - 0s 189us/sample - loss: 0.2942 - accuracy: 0.9052 - val_loss: 3.7951 - val_accuracy: 0.7241\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4625 - accuracy: 0.84 - 0s 163us/sample - loss: 0.2683 - accuracy: 0.8966 - val_loss: 3.9670 - val_accuracy: 0.6897\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2372 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2300 - accuracy: 0.9138 - val_loss: 3.9476 - val_accuracy: 0.6897\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2541 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2187 - accuracy: 0.9138 - val_loss: 4.0117 - val_accuracy: 0.7586\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1887 - accuracy: 0.9224 - val_loss: 3.8952 - val_accuracy: 0.6552\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1893 - accuracy: 0.9224 - val_loss: 3.9282 - val_accuracy: 0.6552\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1852 - accuracy: 0.9224 - val_loss: 4.0077 - val_accuracy: 0.7241\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1370 - accuracy: 0.93 - 0s 172us/sample - loss: 0.2305 - accuracy: 0.8879 - val_loss: 4.0425 - val_accuracy: 0.6897\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.90 - 0s 181us/sample - loss: 0.2213 - accuracy: 0.9138 - val_loss: 3.9953 - val_accuracy: 0.6897\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.96 - 0s 224us/sample - loss: 0.1928 - accuracy: 0.9483 - val_loss: 4.1492 - val_accuracy: 0.6897\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3077 - accuracy: 0.87 - 0s 181us/sample - loss: 0.2039 - accuracy: 0.9224 - val_loss: 4.3235 - val_accuracy: 0.6552\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1893 - accuracy: 0.93 - 0s 172us/sample - loss: 0.1441 - accuracy: 0.9569 - val_loss: 4.3551 - val_accuracy: 0.6897\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1784 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1985 - accuracy: 0.9052 - val_loss: 4.4445 - val_accuracy: 0.6897\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1929 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1769 - accuracy: 0.9397 - val_loss: 4.4817 - val_accuracy: 0.6897\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 1.00 - 0s 163us/sample - loss: 0.2185 - accuracy: 0.9138 - val_loss: 4.5953 - val_accuracy: 0.7241\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1674 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1975 - accuracy: 0.9052 - val_loss: 4.4314 - val_accuracy: 0.6552\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0721 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1731 - accuracy: 0.9397 - val_loss: 4.3167 - val_accuracy: 0.7241\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2525 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1533 - accuracy: 0.9397 - val_loss: 4.5596 - val_accuracy: 0.6552\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1312 - accuracy: 0.9741 - val_loss: 4.6210 - val_accuracy: 0.6897\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1824 - accuracy: 0.90 - 0s 147us/sample - loss: 0.1340 - accuracy: 0.9397 - val_loss: 4.6724 - val_accuracy: 0.6207\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1452 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1194 - accuracy: 0.9483 - val_loss: 4.7665 - val_accuracy: 0.6552\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.96 - 0s 137us/sample - loss: 0.1033 - accuracy: 0.9655 - val_loss: 4.8625 - val_accuracy: 0.6552\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.96 - 0s 168us/sample - loss: 0.1154 - accuracy: 0.9483 - val_loss: 4.9615 - val_accuracy: 0.6552\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - 0s 161us/sample - loss: 0.0963 - accuracy: 0.9741 - val_loss: 5.1583 - val_accuracy: 0.5862\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1117 - accuracy: 0.9483 - val_loss: 5.2318 - val_accuracy: 0.6897\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0847 - accuracy: 0.9569 - val_loss: 5.4295 - val_accuracy: 0.6207\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 1.00 - 0s 153us/sample - loss: 0.1117 - accuracy: 0.9741 - val_loss: 5.4530 - val_accuracy: 0.6897\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1288 - accuracy: 0.9397 - val_loss: 5.7193 - val_accuracy: 0.6207\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1137 - accuracy: 0.9655 - val_loss: 5.6660 - val_accuracy: 0.6897\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 0.96 - 0s 181us/sample - loss: 0.1289 - accuracy: 0.9397 - val_loss: 5.6517 - val_accuracy: 0.6552\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 1.00 - 0s 172us/sample - loss: 0.1075 - accuracy: 0.9741 - val_loss: 5.7365 - val_accuracy: 0.6552\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1355 - accuracy: 0.9569 - val_loss: 5.8883 - val_accuracy: 0.6552\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1272 - accuracy: 0.9569 - val_loss: 6.1862 - val_accuracy: 0.6897\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1562 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1432 - accuracy: 0.9397 - val_loss: 5.9874 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 0.96 - 0s 181us/sample - loss: 0.1577 - accuracy: 0.9224 - val_loss: 5.8459 - val_accuracy: 0.6897\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 1.00 - 0s 206us/sample - loss: 0.1482 - accuracy: 0.9397 - val_loss: 5.9120 - val_accuracy: 0.6207\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0634 - accuracy: 1.00 - 0s 180us/sample - loss: 0.1845 - accuracy: 0.9397 - val_loss: 5.3273 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.93 - 0s 198us/sample - loss: 0.1543 - accuracy: 0.9224 - val_loss: 5.1705 - val_accuracy: 0.6897\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.93 - 0s 181us/sample - loss: 0.1537 - accuracy: 0.9224 - val_loss: 5.1997 - val_accuracy: 0.7241\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1613 - accuracy: 0.90 - 0s 275us/sample - loss: 0.1883 - accuracy: 0.9138 - val_loss: 5.2146 - val_accuracy: 0.7241\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1543 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1447 - accuracy: 0.9310 - val_loss: 5.4503 - val_accuracy: 0.6552\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1471 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1987 - accuracy: 0.9397 - val_loss: 5.0602 - val_accuracy: 0.6552\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.87 - 0s 198us/sample - loss: 0.1964 - accuracy: 0.9310 - val_loss: 5.1351 - val_accuracy: 0.7241\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3611 - accuracy: 0.90 - 0s 206us/sample - loss: 0.2333 - accuracy: 0.9310 - val_loss: 5.0610 - val_accuracy: 0.6897\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.93 - 0s 175us/sample - loss: 0.1841 - accuracy: 0.9224 - val_loss: 5.5766 - val_accuracy: 0.6207\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.93 - 0s 189us/sample - loss: 0.1531 - accuracy: 0.9052 - val_loss: 5.8178 - val_accuracy: 0.7241\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.96 - 0s 206us/sample - loss: 0.1481 - accuracy: 0.9310 - val_loss: 5.6031 - val_accuracy: 0.7241\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1141 - accuracy: 0.96 - 0s 198us/sample - loss: 0.1341 - accuracy: 0.9397 - val_loss: 5.4971 - val_accuracy: 0.6897\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.96 - 0s 181us/sample - loss: 0.1121 - accuracy: 0.9655 - val_loss: 5.3911 - val_accuracy: 0.7241\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1724 - accuracy: 0.87 - 0s 163us/sample - loss: 0.0992 - accuracy: 0.9483 - val_loss: 5.4059 - val_accuracy: 0.7241\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.96 - 0s 189us/sample - loss: 0.0860 - accuracy: 0.9655 - val_loss: 5.5170 - val_accuracy: 0.6897\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.96 - 0s 185us/sample - loss: 0.0829 - accuracy: 0.9655 - val_loss: 5.6133 - val_accuracy: 0.6897\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.93 - 0s 189us/sample - loss: 0.0793 - accuracy: 0.9655 - val_loss: 5.6678 - val_accuracy: 0.7241\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.96 - 0s 181us/sample - loss: 0.0876 - accuracy: 0.9569 - val_loss: 5.7744 - val_accuracy: 0.7241\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.93 - 0s 172us/sample - loss: 0.0739 - accuracy: 0.9741 - val_loss: 5.9030 - val_accuracy: 0.6552\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.96 - 0s 181us/sample - loss: 0.0673 - accuracy: 0.9828 - val_loss: 5.8559 - val_accuracy: 0.7241\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 1.00 - 0s 198us/sample - loss: 0.0918 - accuracy: 0.9741 - val_loss: 6.0443 - val_accuracy: 0.6207\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.96 - 0s 180us/sample - loss: 0.0879 - accuracy: 0.9655 - val_loss: 6.0394 - val_accuracy: 0.7241\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1124 - accuracy: 0.9483 - val_loss: 6.0721 - val_accuracy: 0.7241\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.90 - 0s 189us/sample - loss: 0.1069 - accuracy: 0.9483 - val_loss: 6.0780 - val_accuracy: 0.6552\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0786 - accuracy: 0.9828 - val_loss: 6.1287 - val_accuracy: 0.6897\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0623 - accuracy: 0.9828 - val_loss: 6.2411 - val_accuracy: 0.6552\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0692 - accuracy: 0.9741 - val_loss: 6.1171 - val_accuracy: 0.6897\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 1.00 - 0s 181us/sample - loss: 0.0628 - accuracy: 0.9741 - val_loss: 6.1257 - val_accuracy: 0.6552\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 1.00 - 0s 206us/sample - loss: 0.0809 - accuracy: 0.9569 - val_loss: 6.4648 - val_accuracy: 0.5862\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0638 - accuracy: 1.00 - 0s 198us/sample - loss: 0.0625 - accuracy: 0.9828 - val_loss: 6.3023 - val_accuracy: 0.7241\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.96 - 0s 172us/sample - loss: 0.0752 - accuracy: 0.9483 - val_loss: 6.4513 - val_accuracy: 0.6552\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0636 - accuracy: 0.9655 - val_loss: 6.4026 - val_accuracy: 0.6552\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0647 - accuracy: 0.9655 - val_loss: 6.4855 - val_accuracy: 0.6897\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0649 - accuracy: 0.9741 - val_loss: 6.6935 - val_accuracy: 0.6207\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0248 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0574 - accuracy: 0.9828 - val_loss: 6.4304 - val_accuracy: 0.6897\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0983 - accuracy: 0.9741 - val_loss: 6.3574 - val_accuracy: 0.6897\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0252 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0910 - accuracy: 0.9655 - val_loss: 6.4357 - val_accuracy: 0.6552\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0559 - accuracy: 0.9655 - val_loss: 6.3732 - val_accuracy: 0.6897\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0596 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1480 - accuracy: 0.9310 - val_loss: 6.5306 - val_accuracy: 0.5862\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1252 - accuracy: 0.9310 - val_loss: 6.4448 - val_accuracy: 0.6897\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 1.00 - 0s 155us/sample - loss: 0.2880 - accuracy: 0.9224 - val_loss: 6.8578 - val_accuracy: 0.5862\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2186 - accuracy: 0.9310 - val_loss: 6.5847 - val_accuracy: 0.6552\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2591 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3124 - accuracy: 0.8879 - val_loss: 6.5025 - val_accuracy: 0.6897\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1647 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1546 - accuracy: 0.9397 - val_loss: 6.5054 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4879 - accuracy: 0.81 - 0s 155us/sample - loss: 0.2116 - accuracy: 0.9224 - val_loss: 5.7473 - val_accuracy: 0.6207\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.90 - 0s 163us/sample - loss: 0.1729 - accuracy: 0.9397 - val_loss: 5.3407 - val_accuracy: 0.6897\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1786 - accuracy: 0.9138 - val_loss: 5.5953 - val_accuracy: 0.6207\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1183 - accuracy: 0.9741 - val_loss: 5.6019 - val_accuracy: 0.6897\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2273 - accuracy: 0.87 - 0s 146us/sample - loss: 0.1065 - accuracy: 0.9569 - val_loss: 5.5948 - val_accuracy: 0.6897\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0892 - accuracy: 0.9741 - val_loss: 5.6102 - val_accuracy: 0.6897\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0731 - accuracy: 0.9914 - val_loss: 5.7116 - val_accuracy: 0.6207\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0694 - accuracy: 0.9828 - val_loss: 5.8811 - val_accuracy: 0.6207\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0649 - accuracy: 0.9828 - val_loss: 6.0519 - val_accuracy: 0.7241\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0460 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0581 - accuracy: 0.9914 - val_loss: 6.2569 - val_accuracy: 0.6897\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0532 - accuracy: 0.9828 - val_loss: 6.4107 - val_accuracy: 0.6552\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0471 - accuracy: 0.9828 - val_loss: 6.5148 - val_accuracy: 0.6552\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0417 - accuracy: 0.9914 - val_loss: 6.6592 - val_accuracy: 0.6552\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0395 - accuracy: 0.9914 - val_loss: 6.8081 - val_accuracy: 0.6207\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0370 - accuracy: 0.9914 - val_loss: 6.9430 - val_accuracy: 0.6207\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0364 - accuracy: 0.9828 - val_loss: 7.1896 - val_accuracy: 0.6207\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0391 - accuracy: 0.9914 - val_loss: 7.3301 - val_accuracy: 0.6552\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0350 - accuracy: 0.9828 - val_loss: 7.4383 - val_accuracy: 0.6552\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0349 - accuracy: 0.9828 - val_loss: 7.4996 - val_accuracy: 0.6207\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 1.00 - 0s 127us/sample - loss: 0.0270 - accuracy: 0.9914 - val_loss: 7.5862 - val_accuracy: 0.6207\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0292 - accuracy: 0.9828 - val_loss: 7.5717 - val_accuracy: 0.6897\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0266 - accuracy: 0.9914 - val_loss: 7.7475 - val_accuracy: 0.6552\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0320 - accuracy: 0.9828 - val_loss: 7.8767 - val_accuracy: 0.6207\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0371 - accuracy: 0.9828 - val_loss: 7.9506 - val_accuracy: 0.6207\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0694 - accuracy: 0.9741 - val_loss: 7.8299 - val_accuracy: 0.6207\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0755 - accuracy: 0.9741 - val_loss: 8.0019 - val_accuracy: 0.6207\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0398 - accuracy: 0.9828 - val_loss: 8.1683 - val_accuracy: 0.6207\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0862 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0644 - accuracy: 0.9741 - val_loss: 7.9200 - val_accuracy: 0.7241\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 1s - loss: 0.6936 - accuracy: 0.43 - 1s 9ms/sample - loss: 0.6641 - accuracy: 0.5862 - val_loss: 0.6244 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5383 - accuracy: 0.75 - 0s 473us/sample - loss: 0.6246 - accuracy: 0.6638 - val_loss: 0.6113 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5839 - accuracy: 0.65 - 0s 456us/sample - loss: 0.6157 - accuracy: 0.6466 - val_loss: 0.6287 - val_accuracy: 0.7241\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6395 - accuracy: 0.71 - 0s 481us/sample - loss: 0.6158 - accuracy: 0.6810 - val_loss: 0.6031 - val_accuracy: 0.6897\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6901 - accuracy: 0.62 - 0s 138us/sample - loss: 0.5979 - accuracy: 0.6897 - val_loss: 0.5922 - val_accuracy: 0.6897\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4806 - accuracy: 0.81 - 0s 146us/sample - loss: 0.6018 - accuracy: 0.7069 - val_loss: 0.5924 - val_accuracy: 0.7241\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6652 - accuracy: 0.62 - 0s 138us/sample - loss: 0.6106 - accuracy: 0.6810 - val_loss: 0.6197 - val_accuracy: 0.6897\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6115 - accuracy: 0.62 - 0s 155us/sample - loss: 0.5931 - accuracy: 0.6810 - val_loss: 0.5853 - val_accuracy: 0.6897\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6774 - accuracy: 0.65 - 0s 137us/sample - loss: 0.5821 - accuracy: 0.7069 - val_loss: 0.5853 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5262 - accuracy: 0.71 - 0s 146us/sample - loss: 0.5788 - accuracy: 0.6897 - val_loss: 0.5877 - val_accuracy: 0.6552\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.75 - 0s 129us/sample - loss: 0.5692 - accuracy: 0.7069 - val_loss: 0.5901 - val_accuracy: 0.7586\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6026 - accuracy: 0.71 - 0s 138us/sample - loss: 0.5595 - accuracy: 0.7155 - val_loss: 0.5903 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5423 - accuracy: 0.68 - 0s 155us/sample - loss: 0.5467 - accuracy: 0.7414 - val_loss: 0.6014 - val_accuracy: 0.7241\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6085 - accuracy: 0.65 - 0s 146us/sample - loss: 0.5662 - accuracy: 0.6724 - val_loss: 0.6120 - val_accuracy: 0.7586\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4947 - accuracy: 0.75 - 0s 137us/sample - loss: 0.5328 - accuracy: 0.7328 - val_loss: 0.6278 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6416 - accuracy: 0.65 - 0s 129us/sample - loss: 0.5345 - accuracy: 0.7500 - val_loss: 0.6790 - val_accuracy: 0.8276\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5639 - accuracy: 0.78 - 0s 129us/sample - loss: 0.5242 - accuracy: 0.7586 - val_loss: 0.6592 - val_accuracy: 0.7241\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5280 - accuracy: 0.71 - 0s 129us/sample - loss: 0.5066 - accuracy: 0.7328 - val_loss: 0.7020 - val_accuracy: 0.7586\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4598 - accuracy: 0.78 - 0s 120us/sample - loss: 0.4740 - accuracy: 0.7586 - val_loss: 0.7847 - val_accuracy: 0.7586\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4658 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4903 - accuracy: 0.7759 - val_loss: 0.8209 - val_accuracy: 0.7586\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4099 - accuracy: 0.78 - 0s 129us/sample - loss: 0.4732 - accuracy: 0.7845 - val_loss: 0.7878 - val_accuracy: 0.7931\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4241 - accuracy: 0.81 - 0s 129us/sample - loss: 0.4472 - accuracy: 0.7586 - val_loss: 0.8201 - val_accuracy: 0.7931\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3680 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4382 - accuracy: 0.7931 - val_loss: 0.9069 - val_accuracy: 0.7931\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4212 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4254 - accuracy: 0.8190 - val_loss: 0.9304 - val_accuracy: 0.7931\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2415 - accuracy: 0.87 - 0s 138us/sample - loss: 0.4865 - accuracy: 0.7845 - val_loss: 1.1076 - val_accuracy: 0.7586\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3800 - accuracy: 0.84 - 0s 129us/sample - loss: 0.5523 - accuracy: 0.6897 - val_loss: 1.0843 - val_accuracy: 0.7586\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4210 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4425 - accuracy: 0.7931 - val_loss: 1.0527 - val_accuracy: 0.7241\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4691 - accuracy: 0.7845 - val_loss: 1.0314 - val_accuracy: 0.7586\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3195 - accuracy: 0.93 - 0s 138us/sample - loss: 0.4330 - accuracy: 0.8276 - val_loss: 1.1849 - val_accuracy: 0.6897\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.87 - 0s 138us/sample - loss: 0.4521 - accuracy: 0.8190 - val_loss: 1.1079 - val_accuracy: 0.6897\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4010 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4127 - accuracy: 0.8017 - val_loss: 1.0921 - val_accuracy: 0.8276\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4226 - accuracy: 0.8017 - val_loss: 1.1552 - val_accuracy: 0.8276\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4212 - accuracy: 0.78 - 0s 129us/sample - loss: 0.4087 - accuracy: 0.8017 - val_loss: 1.3421 - val_accuracy: 0.6897\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3861 - accuracy: 0.87 - 0s 129us/sample - loss: 0.4021 - accuracy: 0.8276 - val_loss: 1.2821 - val_accuracy: 0.7586\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3736 - accuracy: 0.8362 - val_loss: 1.4104 - val_accuracy: 0.7241\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.93 - 0s 133us/sample - loss: 0.3679 - accuracy: 0.8448 - val_loss: 1.4434 - val_accuracy: 0.7241\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4046 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3660 - accuracy: 0.8448 - val_loss: 1.4967 - val_accuracy: 0.7586\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3461 - accuracy: 0.8448 - val_loss: 1.7038 - val_accuracy: 0.6552\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3582 - accuracy: 0.8448 - val_loss: 1.5909 - val_accuracy: 0.7931\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2655 - accuracy: 0.90 - 0s 138us/sample - loss: 0.4031 - accuracy: 0.8276 - val_loss: 1.5341 - val_accuracy: 0.7586\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3829 - accuracy: 0.90 - 0s 151us/sample - loss: 0.3426 - accuracy: 0.8793 - val_loss: 1.6660 - val_accuracy: 0.7931\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3803 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3296 - accuracy: 0.8793 - val_loss: 1.7443 - val_accuracy: 0.7931\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4207 - accuracy: 0.78 - 0s 146us/sample - loss: 0.3522 - accuracy: 0.8448 - val_loss: 1.8297 - val_accuracy: 0.6897\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3136 - accuracy: 0.8707 - val_loss: 1.7840 - val_accuracy: 0.7931\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2761 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3157 - accuracy: 0.8534 - val_loss: 1.7729 - val_accuracy: 0.7586\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.75 - 0s 129us/sample - loss: 0.3289 - accuracy: 0.8534 - val_loss: 1.8979 - val_accuracy: 0.7241\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3391 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2880 - accuracy: 0.8879 - val_loss: 1.9568 - val_accuracy: 0.7931\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3909 - accuracy: 0.75 - 0s 137us/sample - loss: 0.2925 - accuracy: 0.8534 - val_loss: 2.0348 - val_accuracy: 0.7931\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2153 - accuracy: 0.93 - 0s 120us/sample - loss: 0.2811 - accuracy: 0.8793 - val_loss: 2.0961 - val_accuracy: 0.7931\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2933 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2616 - accuracy: 0.8966 - val_loss: 2.1894 - val_accuracy: 0.7586\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2758 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2839 - accuracy: 0.8793 - val_loss: 2.0705 - val_accuracy: 0.7586\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3052 - accuracy: 0.8448 - val_loss: 2.1945 - val_accuracy: 0.7241\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4873 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3600 - accuracy: 0.8276 - val_loss: 2.2371 - val_accuracy: 0.8276\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3364 - accuracy: 0.8621 - val_loss: 2.0881 - val_accuracy: 0.7241\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3150 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3255 - accuracy: 0.8448 - val_loss: 2.1208 - val_accuracy: 0.7931\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2067 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2940 - accuracy: 0.8707 - val_loss: 2.1887 - val_accuracy: 0.7586\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3544 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3047 - accuracy: 0.8707 - val_loss: 2.3183 - val_accuracy: 0.7931\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2557 - accuracy: 0.8966 - val_loss: 2.3843 - val_accuracy: 0.7241\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2644 - accuracy: 0.90 - 0s 137us/sample - loss: 0.2552 - accuracy: 0.8879 - val_loss: 2.4689 - val_accuracy: 0.7586\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.81 - 0s 138us/sample - loss: 0.2682 - accuracy: 0.8621 - val_loss: 2.5226 - val_accuracy: 0.7586\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.90 - 0s 438us/sample - loss: 0.2711 - accuracy: 0.8793 - val_loss: 2.4610 - val_accuracy: 0.6552\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.87 - 0s 172us/sample - loss: 0.2373 - accuracy: 0.8966 - val_loss: 2.4976 - val_accuracy: 0.7931\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.90 - 0s 189us/sample - loss: 0.2686 - accuracy: 0.8793 - val_loss: 2.5969 - val_accuracy: 0.7586\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.87 - 0s 206us/sample - loss: 0.2386 - accuracy: 0.9138 - val_loss: 2.6547 - val_accuracy: 0.7586\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1955 - accuracy: 0.90 - 0s 180us/sample - loss: 0.2337 - accuracy: 0.8879 - val_loss: 2.6670 - val_accuracy: 0.7586\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 0.90 - 0s 172us/sample - loss: 0.2418 - accuracy: 0.8707 - val_loss: 2.5624 - val_accuracy: 0.6552\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1412 - accuracy: 0.96 - 0s 163us/sample - loss: 0.3856 - accuracy: 0.8190 - val_loss: 2.5011 - val_accuracy: 0.7241\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1944 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2761 - accuracy: 0.9138 - val_loss: 2.3294 - val_accuracy: 0.7586\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2533 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2935 - accuracy: 0.8879 - val_loss: 2.2887 - val_accuracy: 0.7586\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.93 - 0s 120us/sample - loss: 0.3110 - accuracy: 0.8793 - val_loss: 2.2484 - val_accuracy: 0.6552\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2247 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2509 - accuracy: 0.8793 - val_loss: 2.3011 - val_accuracy: 0.7586\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2468 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2499 - accuracy: 0.8966 - val_loss: 2.4431 - val_accuracy: 0.7586\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1920 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2315 - accuracy: 0.9224 - val_loss: 2.5096 - val_accuracy: 0.7241\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2962 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2330 - accuracy: 0.8879 - val_loss: 2.5852 - val_accuracy: 0.7241\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2249 - accuracy: 0.9224 - val_loss: 2.5699 - val_accuracy: 0.7241\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2775 - accuracy: 0.87 - 0s 146us/sample - loss: 0.1936 - accuracy: 0.9310 - val_loss: 2.4496 - val_accuracy: 0.7586\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1429 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1892 - accuracy: 0.9310 - val_loss: 2.4935 - val_accuracy: 0.7241\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1253 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1794 - accuracy: 0.9310 - val_loss: 2.4457 - val_accuracy: 0.7241\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1680 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1880 - accuracy: 0.9138 - val_loss: 2.6095 - val_accuracy: 0.7241\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1562 - accuracy: 0.9397 - val_loss: 2.6341 - val_accuracy: 0.7586\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1544 - accuracy: 0.9397 - val_loss: 2.6198 - val_accuracy: 0.7586\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1606 - accuracy: 0.9310 - val_loss: 2.5674 - val_accuracy: 0.7241\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1552 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1657 - accuracy: 0.9138 - val_loss: 2.7038 - val_accuracy: 0.6897\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1648 - accuracy: 0.9483 - val_loss: 2.7002 - val_accuracy: 0.7241\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.90 - 0s 120us/sample - loss: 0.2204 - accuracy: 0.8879 - val_loss: 2.7127 - val_accuracy: 0.6552\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 1.00 - 0s 120us/sample - loss: 0.2356 - accuracy: 0.8793 - val_loss: 2.6804 - val_accuracy: 0.7241\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.90 - 0s 126us/sample - loss: 0.2725 - accuracy: 0.8966 - val_loss: 2.5203 - val_accuracy: 0.7931\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1514 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1960 - accuracy: 0.9052 - val_loss: 2.7161 - val_accuracy: 0.6897\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1461 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1921 - accuracy: 0.9224 - val_loss: 2.7837 - val_accuracy: 0.7586\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0972 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2208 - accuracy: 0.9224 - val_loss: 2.9356 - val_accuracy: 0.7241\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1773 - accuracy: 0.9052 - val_loss: 3.0571 - val_accuracy: 0.7241\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1565 - accuracy: 0.9483 - val_loss: 3.1524 - val_accuracy: 0.6897\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3018 - accuracy: 0.84 - 0s 129us/sample - loss: 0.1670 - accuracy: 0.9397 - val_loss: 3.2013 - val_accuracy: 0.7586\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1725 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1524 - accuracy: 0.9310 - val_loss: 3.2550 - val_accuracy: 0.7586\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1512 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1353 - accuracy: 0.9397 - val_loss: 3.3160 - val_accuracy: 0.7241\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1315 - accuracy: 0.9569 - val_loss: 3.2837 - val_accuracy: 0.6897\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1158 - accuracy: 0.9569 - val_loss: 3.3741 - val_accuracy: 0.7241\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1244 - accuracy: 0.9483 - val_loss: 3.3822 - val_accuracy: 0.6897\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1141 - accuracy: 0.9397 - val_loss: 3.5573 - val_accuracy: 0.6207\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1203 - accuracy: 0.9483 - val_loss: 3.4718 - val_accuracy: 0.7931\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1255 - accuracy: 0.9483 - val_loss: 3.5382 - val_accuracy: 0.5862\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1939 - accuracy: 0.9052 - val_loss: 3.2759 - val_accuracy: 0.6897\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2075 - accuracy: 0.90 - 0s 136us/sample - loss: 0.2285 - accuracy: 0.8966 - val_loss: 3.7535 - val_accuracy: 0.6552\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1973 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3852 - accuracy: 0.8448 - val_loss: 2.9745 - val_accuracy: 0.7241\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4983 - accuracy: 0.78 - 0s 163us/sample - loss: 0.4223 - accuracy: 0.8190 - val_loss: 3.2636 - val_accuracy: 0.7241\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.87 - 0s 163us/sample - loss: 0.2592 - accuracy: 0.8707 - val_loss: 3.3073 - val_accuracy: 0.6897\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3440 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3852 - accuracy: 0.8362 - val_loss: 2.2546 - val_accuracy: 0.7241\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4382 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3934 - accuracy: 0.8362 - val_loss: 1.7668 - val_accuracy: 0.6552\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.93 - 0s 146us/sample - loss: 0.3038 - accuracy: 0.8793 - val_loss: 1.6396 - val_accuracy: 0.7931\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.96 - 0s 224us/sample - loss: 0.3017 - accuracy: 0.8793 - val_loss: 1.7702 - val_accuracy: 0.8276\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2842 - accuracy: 0.8966 - val_loss: 1.9025 - val_accuracy: 0.8276\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1972 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2476 - accuracy: 0.8793 - val_loss: 2.1221 - val_accuracy: 0.6897\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.90 - 0s 3ms/sample - loss: 0.2292 - accuracy: 0.9052 - val_loss: 1.8477 - val_accuracy: 0.8621\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.87 - 0s 146us/sample - loss: 0.1970 - accuracy: 0.9397 - val_loss: 2.0127 - val_accuracy: 0.6897\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1825 - accuracy: 0.9310 - val_loss: 2.1167 - val_accuracy: 0.7241\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1743 - accuracy: 0.9224 - val_loss: 2.3417 - val_accuracy: 0.7241\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1292 - accuracy: 0.96 - 0s 137us/sample - loss: 0.1743 - accuracy: 0.9310 - val_loss: 2.3020 - val_accuracy: 0.7241\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1577 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1405 - accuracy: 0.9310 - val_loss: 2.3533 - val_accuracy: 0.7241\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1279 - accuracy: 0.9569 - val_loss: 2.5216 - val_accuracy: 0.6897\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1255 - accuracy: 0.9397 - val_loss: 2.5300 - val_accuracy: 0.7241\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1004 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1008 - accuracy: 0.9655 - val_loss: 2.5609 - val_accuracy: 0.6897\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1167 - accuracy: 0.9569 - val_loss: 2.5675 - val_accuracy: 0.7241\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1141 - accuracy: 0.96 - 0s 206us/sample - loss: 0.0971 - accuracy: 0.9741 - val_loss: 2.5719 - val_accuracy: 0.7241\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0367 - accuracy: 1.00 - 0s 215us/sample - loss: 0.1033 - accuracy: 0.9655 - val_loss: 2.8401 - val_accuracy: 0.6552\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.96 - 0s 189us/sample - loss: 0.1313 - accuracy: 0.9310 - val_loss: 2.6212 - val_accuracy: 0.7931\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0851 - accuracy: 0.93 - 0s 189us/sample - loss: 0.1446 - accuracy: 0.9310 - val_loss: 2.9105 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1337 - accuracy: 0.9483 - val_loss: 2.7765 - val_accuracy: 0.7586\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 1.00 - 0s 172us/sample - loss: 0.1049 - accuracy: 0.9655 - val_loss: 2.8476 - val_accuracy: 0.7241\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0937 - accuracy: 0.9483 - val_loss: 2.6653 - val_accuracy: 0.7586\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1110 - accuracy: 0.9483 - val_loss: 2.8106 - val_accuracy: 0.6897\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1208 - accuracy: 0.9569 - val_loss: 2.7174 - val_accuracy: 0.7241\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0832 - accuracy: 0.9655 - val_loss: 2.6843 - val_accuracy: 0.7586\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0550 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0708 - accuracy: 0.9828 - val_loss: 2.8883 - val_accuracy: 0.6552\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 1.00 - 0s 112us/sample - loss: 0.0668 - accuracy: 0.9914 - val_loss: 2.7353 - val_accuracy: 0.6897\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0531 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0782 - accuracy: 0.9569 - val_loss: 2.8345 - val_accuracy: 0.5862\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1561 - accuracy: 0.90 - 0s 120us/sample - loss: 0.0778 - accuracy: 0.9569 - val_loss: 2.7857 - val_accuracy: 0.7241\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0862 - accuracy: 0.9569 - val_loss: 3.2213 - val_accuracy: 0.6207\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 1.00 - 0s 133us/sample - loss: 0.0591 - accuracy: 0.9828 - val_loss: 2.9053 - val_accuracy: 0.7241\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0948 - accuracy: 0.9828 - val_loss: 2.8795 - val_accuracy: 0.6552\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 1.00 - 0s 181us/sample - loss: 0.0656 - accuracy: 0.9828 - val_loss: 3.0300 - val_accuracy: 0.6552\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1341 - accuracy: 0.9569 - val_loss: 3.1483 - val_accuracy: 0.6207\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1307 - accuracy: 0.9483 - val_loss: 2.7521 - val_accuracy: 0.7241\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0768 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0821 - accuracy: 0.9828 - val_loss: 2.6527 - val_accuracy: 0.7241\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3247 - accuracy: 0.84 - 0s 155us/sample - loss: 0.1534 - accuracy: 0.9310 - val_loss: 2.8844 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1890 - accuracy: 0.9138 - val_loss: 2.8808 - val_accuracy: 0.6897\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0586 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1025 - accuracy: 0.9655 - val_loss: 2.7626 - val_accuracy: 0.5862\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 1.00 - 0s 151us/sample - loss: 0.0695 - accuracy: 0.9828 - val_loss: 2.6760 - val_accuracy: 0.6552\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1585 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0845 - accuracy: 0.9655 - val_loss: 2.9664 - val_accuracy: 0.6897\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0472 - accuracy: 0.9914 - val_loss: 3.2648 - val_accuracy: 0.6897\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0499 - accuracy: 0.9914 - val_loss: 3.1488 - val_accuracy: 0.7241\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0607 - accuracy: 0.9655 - val_loss: 3.2617 - val_accuracy: 0.6552\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0702 - accuracy: 0.9655 - val_loss: 3.0099 - val_accuracy: 0.6897\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 1.00 - 0s 112us/sample - loss: 0.1060 - accuracy: 0.9397 - val_loss: 3.2695 - val_accuracy: 0.6207\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 1.00 - 0s 120us/sample - loss: 0.1520 - accuracy: 0.9397 - val_loss: 3.6349 - val_accuracy: 0.6897\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1045 - accuracy: 0.9397 - val_loss: 3.2971 - val_accuracy: 0.6897\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0687 - accuracy: 0.9914 - val_loss: 3.5179 - val_accuracy: 0.6207\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1566 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1106 - accuracy: 0.9569 - val_loss: 2.9059 - val_accuracy: 0.7241\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2249 - accuracy: 0.8707 - val_loss: 3.4978 - val_accuracy: 0.6897\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 1.00 - 0s 112us/sample - loss: 0.1410 - accuracy: 0.9224 - val_loss: 3.7042 - val_accuracy: 0.6207\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1076 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2618 - accuracy: 0.9224 - val_loss: 3.6593 - val_accuracy: 0.6207\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2584 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3364 - accuracy: 0.8793 - val_loss: 3.8755 - val_accuracy: 0.6897\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0879 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1059 - accuracy: 0.9569 - val_loss: 4.1459 - val_accuracy: 0.6897\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.93 - 0s 120us/sample - loss: 0.2400 - accuracy: 0.9052 - val_loss: 4.2574 - val_accuracy: 0.6897\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1384 - accuracy: 0.9483 - val_loss: 4.4343 - val_accuracy: 0.6552\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2066 - accuracy: 0.9138 - val_loss: 4.0959 - val_accuracy: 0.7241\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2270 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1217 - accuracy: 0.9569 - val_loss: 4.4171 - val_accuracy: 0.6897\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1107 - accuracy: 0.9741 - val_loss: 4.3827 - val_accuracy: 0.6207\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0874 - accuracy: 0.9655 - val_loss: 4.2941 - val_accuracy: 0.6897\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0853 - accuracy: 0.9828 - val_loss: 4.5630 - val_accuracy: 0.6207\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0741 - accuracy: 0.9741 - val_loss: 4.5640 - val_accuracy: 0.6897\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0688 - accuracy: 0.9655 - val_loss: 4.4225 - val_accuracy: 0.7241\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0583 - accuracy: 0.9828 - val_loss: 4.5897 - val_accuracy: 0.6897\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0645 - accuracy: 0.9741 - val_loss: 4.4947 - val_accuracy: 0.6897\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0461 - accuracy: 0.9914 - val_loss: 4.5505 - val_accuracy: 0.7241\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0426 - accuracy: 0.9914 - val_loss: 4.7262 - val_accuracy: 0.6897\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 0.96 - 0s 137us/sample - loss: 0.0409 - accuracy: 0.9914 - val_loss: 4.7112 - val_accuracy: 0.6897\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0257 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0330 - accuracy: 1.0000 - val_loss: 4.6880 - val_accuracy: 0.6897\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0319 - accuracy: 1.0000 - val_loss: 4.7374 - val_accuracy: 0.6897\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0267 - accuracy: 1.0000 - val_loss: 4.7663 - val_accuracy: 0.7241\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0302 - accuracy: 0.9914 - val_loss: 4.8233 - val_accuracy: 0.7241\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0276 - accuracy: 0.9914 - val_loss: 4.9100 - val_accuracy: 0.7241\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0361 - accuracy: 0.9914 - val_loss: 4.9610 - val_accuracy: 0.6897\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0225 - accuracy: 1.0000 - val_loss: 5.0395 - val_accuracy: 0.6897\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0212 - accuracy: 1.0000 - val_loss: 5.0474 - val_accuracy: 0.6897\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0183 - accuracy: 1.0000 - val_loss: 4.9826 - val_accuracy: 0.6897\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0187 - accuracy: 1.0000 - val_loss: 5.0304 - val_accuracy: 0.6897\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0377 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0198 - accuracy: 1.0000 - val_loss: 5.1192 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0171 - accuracy: 1.0000 - val_loss: 5.0294 - val_accuracy: 0.6897\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0216 - accuracy: 1.0000 - val_loss: 5.0818 - val_accuracy: 0.6897\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0160 - accuracy: 1.0000 - val_loss: 5.1307 - val_accuracy: 0.7241\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0175 - accuracy: 0.9914 - val_loss: 5.1199 - val_accuracy: 0.6897\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0145 - accuracy: 1.0000 - val_loss: 5.0968 - val_accuracy: 0.7241\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0158 - accuracy: 1.0000 - val_loss: 5.1920 - val_accuracy: 0.6897\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0130 - accuracy: 1.0000 - val_loss: 5.2782 - val_accuracy: 0.6897\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0149 - accuracy: 1.0000 - val_loss: 5.2102 - val_accuracy: 0.6897\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0125 - accuracy: 1.0000 - val_loss: 5.2548 - val_accuracy: 0.6897\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0125 - accuracy: 1.0000 - val_loss: 5.2790 - val_accuracy: 0.6897\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 5.3158 - val_accuracy: 0.6897\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0146 - accuracy: 0.9914 - val_loss: 5.3617 - val_accuracy: 0.7241\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0110 - accuracy: 1.0000 - val_loss: 5.3479 - val_accuracy: 0.6897\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6957 - accuracy: 0.40 - 0s 3ms/sample - loss: 0.6693 - accuracy: 0.5862 - val_loss: 0.6368 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6518 - accuracy: 0.62 - 0s 138us/sample - loss: 0.6323 - accuracy: 0.6638 - val_loss: 0.6303 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6061 - accuracy: 0.68 - 0s 146us/sample - loss: 0.6275 - accuracy: 0.6638 - val_loss: 0.6093 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6008 - accuracy: 0.65 - 0s 172us/sample - loss: 0.6064 - accuracy: 0.6638 - val_loss: 0.6004 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.75 - 0s 163us/sample - loss: 0.5983 - accuracy: 0.7069 - val_loss: 0.5976 - val_accuracy: 0.6897\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6485 - accuracy: 0.65 - 0s 163us/sample - loss: 0.5982 - accuracy: 0.7241 - val_loss: 0.5902 - val_accuracy: 0.6897\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6407 - accuracy: 0.56 - 0s 163us/sample - loss: 0.5829 - accuracy: 0.7155 - val_loss: 0.5837 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5880 - accuracy: 0.68 - 0s 155us/sample - loss: 0.5803 - accuracy: 0.7155 - val_loss: 0.5871 - val_accuracy: 0.6897\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5890 - accuracy: 0.65 - 0s 163us/sample - loss: 0.5776 - accuracy: 0.6897 - val_loss: 0.5799 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4968 - accuracy: 0.78 - 0s 163us/sample - loss: 0.5556 - accuracy: 0.7414 - val_loss: 0.5819 - val_accuracy: 0.6897\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4648 - accuracy: 0.78 - 0s 138us/sample - loss: 0.5499 - accuracy: 0.7500 - val_loss: 0.6018 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5640 - accuracy: 0.78 - 0s 138us/sample - loss: 0.5512 - accuracy: 0.7241 - val_loss: 0.6074 - val_accuracy: 0.6207\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5703 - accuracy: 0.71 - 0s 138us/sample - loss: 0.5334 - accuracy: 0.7414 - val_loss: 0.6042 - val_accuracy: 0.6897\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.65 - 0s 129us/sample - loss: 0.5236 - accuracy: 0.7241 - val_loss: 0.6142 - val_accuracy: 0.7241\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3066 - accuracy: 0.90 - 0s 129us/sample - loss: 0.5504 - accuracy: 0.7414 - val_loss: 0.6366 - val_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.75 - 0s 133us/sample - loss: 0.5043 - accuracy: 0.7414 - val_loss: 0.6582 - val_accuracy: 0.7241\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.75 - 0s 129us/sample - loss: 0.4838 - accuracy: 0.7586 - val_loss: 0.6308 - val_accuracy: 0.6552\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5672 - accuracy: 0.71 - 0s 138us/sample - loss: 0.4808 - accuracy: 0.7586 - val_loss: 0.6977 - val_accuracy: 0.7241\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4234 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4600 - accuracy: 0.7672 - val_loss: 0.7095 - val_accuracy: 0.6897\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4712 - accuracy: 0.7672 - val_loss: 0.7775 - val_accuracy: 0.7241\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.84 - 0s 129us/sample - loss: 0.4494 - accuracy: 0.7931 - val_loss: 0.7798 - val_accuracy: 0.6897\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5656 - accuracy: 0.68 - 0s 146us/sample - loss: 0.4547 - accuracy: 0.7672 - val_loss: 0.8882 - val_accuracy: 0.6552\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3918 - accuracy: 0.84 - 0s 129us/sample - loss: 0.4556 - accuracy: 0.7759 - val_loss: 0.8422 - val_accuracy: 0.7241\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5370 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4259 - accuracy: 0.7931 - val_loss: 0.9114 - val_accuracy: 0.6897\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3973 - accuracy: 0.81 - 0s 129us/sample - loss: 0.4056 - accuracy: 0.8276 - val_loss: 0.9416 - val_accuracy: 0.7931\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4251 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3925 - accuracy: 0.8534 - val_loss: 1.0455 - val_accuracy: 0.7241\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4639 - accuracy: 0.81 - 0s 137us/sample - loss: 0.3956 - accuracy: 0.8707 - val_loss: 1.1180 - val_accuracy: 0.6897\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2906 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3677 - accuracy: 0.8448 - val_loss: 1.0885 - val_accuracy: 0.6897\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4364 - accuracy: 0.84 - 0s 163us/sample - loss: 0.3687 - accuracy: 0.8448 - val_loss: 1.2258 - val_accuracy: 0.7241\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2801 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3578 - accuracy: 0.8448 - val_loss: 1.1463 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3810 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4301 - accuracy: 0.8017 - val_loss: 1.4025 - val_accuracy: 0.6552\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4343 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3956 - accuracy: 0.8103 - val_loss: 1.2960 - val_accuracy: 0.7241\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4237 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4554 - accuracy: 0.7931 - val_loss: 1.3574 - val_accuracy: 0.6552\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3876 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4701 - accuracy: 0.7931 - val_loss: 1.2071 - val_accuracy: 0.7586\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3823 - accuracy: 0.8362 - val_loss: 1.2778 - val_accuracy: 0.7586\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2689 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3546 - accuracy: 0.8534 - val_loss: 1.4508 - val_accuracy: 0.7241\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3535 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4150 - accuracy: 0.8017 - val_loss: 1.3116 - val_accuracy: 0.6897\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3593 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3697 - accuracy: 0.8276 - val_loss: 1.3426 - val_accuracy: 0.7241\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4782 - accuracy: 0.78 - 0s 120us/sample - loss: 0.3637 - accuracy: 0.8707 - val_loss: 1.6062 - val_accuracy: 0.7586\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2941 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3320 - accuracy: 0.8534 - val_loss: 1.5392 - val_accuracy: 0.6552\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2574 - accuracy: 0.90 - 0s 137us/sample - loss: 0.3121 - accuracy: 0.8879 - val_loss: 1.5820 - val_accuracy: 0.6552\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.93 - 0s 120us/sample - loss: 0.3068 - accuracy: 0.8793 - val_loss: 1.7043 - val_accuracy: 0.6897\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2420 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2958 - accuracy: 0.8793 - val_loss: 1.6104 - val_accuracy: 0.7241\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1868 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2979 - accuracy: 0.8879 - val_loss: 1.6886 - val_accuracy: 0.7241\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3851 - accuracy: 0.81 - 0s 129us/sample - loss: 0.2850 - accuracy: 0.8966 - val_loss: 1.7872 - val_accuracy: 0.6552\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1747 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2903 - accuracy: 0.9052 - val_loss: 1.9394 - val_accuracy: 0.7241\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3048 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2905 - accuracy: 0.8621 - val_loss: 1.9364 - val_accuracy: 0.6897\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2216 - accuracy: 0.90 - 0s 112us/sample - loss: 0.2774 - accuracy: 0.8707 - val_loss: 1.9916 - val_accuracy: 0.6552\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2428 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2619 - accuracy: 0.8621 - val_loss: 2.1295 - val_accuracy: 0.7241\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2816 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2717 - accuracy: 0.8879 - val_loss: 2.1031 - val_accuracy: 0.6897\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2425 - accuracy: 0.87 - 0s 120us/sample - loss: 0.2678 - accuracy: 0.8793 - val_loss: 2.1303 - val_accuracy: 0.6552\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2869 - accuracy: 0.8707 - val_loss: 2.1505 - val_accuracy: 0.6552\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3070 - accuracy: 0.84 - 0s 120us/sample - loss: 0.2560 - accuracy: 0.8879 - val_loss: 2.3449 - val_accuracy: 0.6552\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1503 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2693 - accuracy: 0.8707 - val_loss: 2.3739 - val_accuracy: 0.6552\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3384 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2588 - accuracy: 0.8793 - val_loss: 2.4250 - val_accuracy: 0.7241\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1322 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2340 - accuracy: 0.9052 - val_loss: 2.4060 - val_accuracy: 0.6552\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1149 - accuracy: 0.96 - 0s 120us/sample - loss: 0.2383 - accuracy: 0.8966 - val_loss: 2.4548 - val_accuracy: 0.6552\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3428 - accuracy: 0.81 - 0s 138us/sample - loss: 0.2428 - accuracy: 0.8793 - val_loss: 2.6748 - val_accuracy: 0.6207\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2638 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2652 - accuracy: 0.8966 - val_loss: 2.6857 - val_accuracy: 0.6552\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1918 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2713 - accuracy: 0.8879 - val_loss: 2.6749 - val_accuracy: 0.6207\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2452 - accuracy: 0.9138 - val_loss: 3.0089 - val_accuracy: 0.6897\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2363 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2395 - accuracy: 0.8707 - val_loss: 2.9564 - val_accuracy: 0.7241\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2193 - accuracy: 0.9224 - val_loss: 2.9049 - val_accuracy: 0.6207\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3070 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2158 - accuracy: 0.9138 - val_loss: 2.7392 - val_accuracy: 0.6207\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2064 - accuracy: 0.8966 - val_loss: 2.9305 - val_accuracy: 0.6207\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2123 - accuracy: 0.9397 - val_loss: 2.9303 - val_accuracy: 0.6897\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.93 - 0s 139us/sample - loss: 0.2129 - accuracy: 0.9052 - val_loss: 2.9567 - val_accuracy: 0.6552\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1305 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1835 - accuracy: 0.9224 - val_loss: 3.0616 - val_accuracy: 0.6552\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1545 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1811 - accuracy: 0.9310 - val_loss: 3.2228 - val_accuracy: 0.6207\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1963 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1887 - accuracy: 0.9224 - val_loss: 3.3200 - val_accuracy: 0.6207\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2749 - accuracy: 0.87 - 0s 112us/sample - loss: 0.2123 - accuracy: 0.9138 - val_loss: 3.3694 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.96 - 0s 124us/sample - loss: 0.1959 - accuracy: 0.9138 - val_loss: 3.4524 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1692 - accuracy: 0.9224 - val_loss: 3.5454 - val_accuracy: 0.6552\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1673 - accuracy: 0.9224 - val_loss: 3.4128 - val_accuracy: 0.6897\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1834 - accuracy: 0.9224 - val_loss: 3.5557 - val_accuracy: 0.6207\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1545 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1790 - accuracy: 0.9397 - val_loss: 3.4953 - val_accuracy: 0.6207\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1983 - accuracy: 0.9138 - val_loss: 3.7115 - val_accuracy: 0.6207\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1067 - accuracy: 0.96 - 0s 120us/sample - loss: 0.2447 - accuracy: 0.9138 - val_loss: 3.4157 - val_accuracy: 0.6207\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2680 - accuracy: 0.8966 - val_loss: 4.0981 - val_accuracy: 0.5862\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3347 - accuracy: 0.84 - 0s 120us/sample - loss: 0.2265 - accuracy: 0.8966 - val_loss: 3.5743 - val_accuracy: 0.6552\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3282 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2332 - accuracy: 0.8966 - val_loss: 3.3196 - val_accuracy: 0.6552\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1551 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2041 - accuracy: 0.9224 - val_loss: 2.9133 - val_accuracy: 0.6207\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.93 - 0s 129us/sample - loss: 0.3113 - accuracy: 0.8707 - val_loss: 3.2400 - val_accuracy: 0.6897\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1889 - accuracy: 0.84 - 0s 120us/sample - loss: 0.2201 - accuracy: 0.8879 - val_loss: 3.5126 - val_accuracy: 0.5862\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1804 - accuracy: 0.90 - 0s 112us/sample - loss: 0.2069 - accuracy: 0.9138 - val_loss: 3.6728 - val_accuracy: 0.6207\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1938 - accuracy: 0.9052 - val_loss: 3.7728 - val_accuracy: 0.6207\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2038 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1816 - accuracy: 0.9224 - val_loss: 3.4934 - val_accuracy: 0.6207\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 1.00 - 0s 120us/sample - loss: 0.1718 - accuracy: 0.9138 - val_loss: 3.1925 - val_accuracy: 0.6207\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1723 - accuracy: 0.9224 - val_loss: 3.4660 - val_accuracy: 0.5862\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1528 - accuracy: 0.9483 - val_loss: 3.3007 - val_accuracy: 0.6552\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.93 - 0s 137us/sample - loss: 0.1714 - accuracy: 0.9224 - val_loss: 3.2843 - val_accuracy: 0.6552\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1316 - accuracy: 0.9483 - val_loss: 3.2447 - val_accuracy: 0.5862\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1620 - accuracy: 0.9310 - val_loss: 3.1770 - val_accuracy: 0.6207\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1466 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1336 - accuracy: 0.9483 - val_loss: 3.6583 - val_accuracy: 0.5862\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1933 - accuracy: 0.9310 - val_loss: 3.6179 - val_accuracy: 0.5862\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1522 - accuracy: 0.9224 - val_loss: 3.7862 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1462 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1300 - accuracy: 0.9741 - val_loss: 3.9223 - val_accuracy: 0.5862\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 0.93 - 0s 116us/sample - loss: 0.1550 - accuracy: 0.9397 - val_loss: 3.7244 - val_accuracy: 0.6207\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1398 - accuracy: 0.9224 - val_loss: 4.0982 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1882 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1146 - accuracy: 0.9569 - val_loss: 3.9819 - val_accuracy: 0.5862\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1053 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1105 - accuracy: 0.9569 - val_loss: 4.0213 - val_accuracy: 0.5862\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1042 - accuracy: 0.9655 - val_loss: 4.1031 - val_accuracy: 0.6552\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1123 - accuracy: 0.93 - 0s 125us/sample - loss: 0.0954 - accuracy: 0.9569 - val_loss: 4.2355 - val_accuracy: 0.6207\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.90 - 0s 120us/sample - loss: 0.0878 - accuracy: 0.9655 - val_loss: 4.3951 - val_accuracy: 0.5862\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1010 - accuracy: 0.9828 - val_loss: 4.3539 - val_accuracy: 0.5862\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1095 - accuracy: 0.9397 - val_loss: 4.4155 - val_accuracy: 0.5862\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0681 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1327 - accuracy: 0.9655 - val_loss: 4.3946 - val_accuracy: 0.6207\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1081 - accuracy: 0.9569 - val_loss: 4.3903 - val_accuracy: 0.6207\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1558 - accuracy: 0.90 - 0s 120us/sample - loss: 0.1207 - accuracy: 0.9483 - val_loss: 4.5431 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 1.00 - 0s 112us/sample - loss: 0.0824 - accuracy: 0.9569 - val_loss: 4.3459 - val_accuracy: 0.6207\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.93 - 0s 120us/sample - loss: 0.0957 - accuracy: 0.9569 - val_loss: 4.7413 - val_accuracy: 0.5862\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0424 - accuracy: 1.00 - 0s 137us/sample - loss: 0.1167 - accuracy: 0.9483 - val_loss: 4.6292 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0862 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1666 - accuracy: 0.9052 - val_loss: 4.6778 - val_accuracy: 0.5862\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0507 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2006 - accuracy: 0.8966 - val_loss: 4.4605 - val_accuracy: 0.6552\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2822 - accuracy: 0.8793 - val_loss: 4.4164 - val_accuracy: 0.6897\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1945 - accuracy: 0.90 - 0s 121us/sample - loss: 0.2858 - accuracy: 0.8793 - val_loss: 4.3675 - val_accuracy: 0.5517\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.96 - 0s 138us/sample - loss: 0.4472 - accuracy: 0.8707 - val_loss: 3.6487 - val_accuracy: 0.6897\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.90 - 0s 129us/sample - loss: 0.4369 - accuracy: 0.8276 - val_loss: 4.3009 - val_accuracy: 0.6552\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3769 - accuracy: 0.87 - 0s 129us/sample - loss: 0.5191 - accuracy: 0.8276 - val_loss: 4.0880 - val_accuracy: 0.6552\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1865 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3190 - accuracy: 0.8534 - val_loss: 3.4645 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2929 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2490 - accuracy: 0.8879 - val_loss: 3.0188 - val_accuracy: 0.6207\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2698 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2625 - accuracy: 0.8879 - val_loss: 3.0464 - val_accuracy: 0.6897\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2507 - accuracy: 0.8879 - val_loss: 3.1919 - val_accuracy: 0.6552\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1464 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2256 - accuracy: 0.9052 - val_loss: 3.1231 - val_accuracy: 0.6552\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2454 - accuracy: 0.8966 - val_loss: 3.0005 - val_accuracy: 0.6207\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1186 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1829 - accuracy: 0.9310 - val_loss: 3.1265 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1592 - accuracy: 0.9310 - val_loss: 3.1359 - val_accuracy: 0.6552\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1011 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1600 - accuracy: 0.9310 - val_loss: 3.2464 - val_accuracy: 0.6207\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1535 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1243 - accuracy: 0.9569 - val_loss: 3.3224 - val_accuracy: 0.5862\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1590 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1286 - accuracy: 0.9397 - val_loss: 3.3237 - val_accuracy: 0.6207\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1248 - accuracy: 0.9397 - val_loss: 3.4881 - val_accuracy: 0.6207\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1103 - accuracy: 0.9483 - val_loss: 3.6636 - val_accuracy: 0.5862\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1089 - accuracy: 0.9569 - val_loss: 3.6400 - val_accuracy: 0.5862\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1645 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1075 - accuracy: 0.9397 - val_loss: 3.6909 - val_accuracy: 0.5862\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0534 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1026 - accuracy: 0.9655 - val_loss: 3.8059 - val_accuracy: 0.5517\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0523 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0974 - accuracy: 0.9569 - val_loss: 3.7850 - val_accuracy: 0.5862\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0972 - accuracy: 0.9655 - val_loss: 3.8264 - val_accuracy: 0.5862\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1118 - accuracy: 0.9569 - val_loss: 3.8165 - val_accuracy: 0.5862\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1558 - accuracy: 0.9310 - val_loss: 3.8345 - val_accuracy: 0.5862\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1889 - accuracy: 0.9483 - val_loss: 3.5480 - val_accuracy: 0.6207\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2179 - accuracy: 0.9138 - val_loss: 3.6168 - val_accuracy: 0.6207\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 1.00 - 0s 137us/sample - loss: 0.1811 - accuracy: 0.9397 - val_loss: 3.6998 - val_accuracy: 0.6552\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1608 - accuracy: 0.9224 - val_loss: 3.9369 - val_accuracy: 0.6207\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1367 - accuracy: 0.9397 - val_loss: 3.8762 - val_accuracy: 0.6207\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1138 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1489 - accuracy: 0.9310 - val_loss: 3.8563 - val_accuracy: 0.6552\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1437 - accuracy: 0.9310 - val_loss: 4.0267 - val_accuracy: 0.5862\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1688 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1184 - accuracy: 0.9397 - val_loss: 4.0456 - val_accuracy: 0.6552\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1590 - accuracy: 0.87 - 0s 129us/sample - loss: 0.1179 - accuracy: 0.9483 - val_loss: 4.1456 - val_accuracy: 0.5862\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1099 - accuracy: 0.9741 - val_loss: 4.0866 - val_accuracy: 0.5517\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1037 - accuracy: 0.9655 - val_loss: 4.1428 - val_accuracy: 0.5862\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0703 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0978 - accuracy: 0.9655 - val_loss: 4.1138 - val_accuracy: 0.5862\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0863 - accuracy: 0.9569 - val_loss: 4.3009 - val_accuracy: 0.5517\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0889 - accuracy: 0.9741 - val_loss: 4.3795 - val_accuracy: 0.5862\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1624 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0823 - accuracy: 0.9741 - val_loss: 4.3491 - val_accuracy: 0.5862\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0794 - accuracy: 0.9569 - val_loss: 4.4447 - val_accuracy: 0.5862\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0795 - accuracy: 0.9741 - val_loss: 4.5591 - val_accuracy: 0.5862\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1262 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0708 - accuracy: 0.9828 - val_loss: 4.4429 - val_accuracy: 0.6897\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0609 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0782 - accuracy: 0.9483 - val_loss: 4.6662 - val_accuracy: 0.6207\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0760 - accuracy: 0.9655 - val_loss: 4.7242 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0732 - accuracy: 0.9741 - val_loss: 4.7053 - val_accuracy: 0.6552\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0948 - accuracy: 0.9569 - val_loss: 4.9198 - val_accuracy: 0.5862\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0388 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0806 - accuracy: 0.9655 - val_loss: 4.6627 - val_accuracy: 0.6552\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1266 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1004 - accuracy: 0.9569 - val_loss: 4.9773 - val_accuracy: 0.6207\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1123 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0839 - accuracy: 0.9828 - val_loss: 4.9912 - val_accuracy: 0.6207\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0717 - accuracy: 0.9569 - val_loss: 4.7300 - val_accuracy: 0.6552\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0643 - accuracy: 0.9828 - val_loss: 5.0948 - val_accuracy: 0.5517\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1150 - accuracy: 0.9483 - val_loss: 4.9015 - val_accuracy: 0.5862\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0533 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0850 - accuracy: 0.9569 - val_loss: 4.7931 - val_accuracy: 0.5862\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1396 - accuracy: 0.9483 - val_loss: 4.6641 - val_accuracy: 0.5862\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0880 - accuracy: 0.9655 - val_loss: 4.5158 - val_accuracy: 0.6552\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0742 - accuracy: 0.9569 - val_loss: 4.9068 - val_accuracy: 0.5862\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0801 - accuracy: 0.96 - 0s 123us/sample - loss: 0.0770 - accuracy: 0.9741 - val_loss: 5.0321 - val_accuracy: 0.5862\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0608 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0666 - accuracy: 0.9914 - val_loss: 4.6979 - val_accuracy: 0.6552\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0906 - accuracy: 0.9397 - val_loss: 5.0731 - val_accuracy: 0.5517\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0650 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0857 - accuracy: 0.9655 - val_loss: 5.1096 - val_accuracy: 0.5517\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0661 - accuracy: 0.9655 - val_loss: 4.9705 - val_accuracy: 0.5862\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0593 - accuracy: 0.9828 - val_loss: 5.2995 - val_accuracy: 0.5172\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0649 - accuracy: 0.9828 - val_loss: 5.2759 - val_accuracy: 0.5517\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0598 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0588 - accuracy: 0.9828 - val_loss: 5.2192 - val_accuracy: 0.5517\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0666 - accuracy: 0.9828 - val_loss: 5.4703 - val_accuracy: 0.5862\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0550 - accuracy: 0.9741 - val_loss: 5.2390 - val_accuracy: 0.6207\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.96 - 0s 142us/sample - loss: 0.0520 - accuracy: 0.9741 - val_loss: 5.4733 - val_accuracy: 0.5862\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0500 - accuracy: 0.9828 - val_loss: 5.4694 - val_accuracy: 0.5862\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0422 - accuracy: 0.9914 - val_loss: 5.2913 - val_accuracy: 0.6552\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0467 - accuracy: 0.9828 - val_loss: 5.4346 - val_accuracy: 0.5862\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0421 - accuracy: 0.9655 - val_loss: 5.7227 - val_accuracy: 0.5517\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0509 - accuracy: 0.9828 - val_loss: 5.3948 - val_accuracy: 0.5517\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1037 - accuracy: 0.9483 - val_loss: 5.5562 - val_accuracy: 0.5862\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1631 - accuracy: 0.9310 - val_loss: 5.6137 - val_accuracy: 0.5517\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 1.00 - 0s 138us/sample - loss: 0.2246 - accuracy: 0.9224 - val_loss: 4.7117 - val_accuracy: 0.6897\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2980 - accuracy: 0.9138 - val_loss: 5.3570 - val_accuracy: 0.5862\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2019 - accuracy: 0.9224 - val_loss: 4.9053 - val_accuracy: 0.6897\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1649 - accuracy: 0.9310 - val_loss: 4.7856 - val_accuracy: 0.6552\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1747 - accuracy: 0.9224 - val_loss: 5.3704 - val_accuracy: 0.6207\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1673 - accuracy: 0.9397 - val_loss: 5.3435 - val_accuracy: 0.6897\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0573 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1094 - accuracy: 0.9483 - val_loss: 5.3863 - val_accuracy: 0.6552\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 1.00 - 0s 138us/sample - loss: 0.3194 - accuracy: 0.9138 - val_loss: 7.6065 - val_accuracy: 0.5862\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7028 - accuracy: 0.87 - 0s 137us/sample - loss: 0.9325 - accuracy: 0.9052 - val_loss: 5.2944 - val_accuracy: 0.6207\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2709 - accuracy: 0.87 - 0s 120us/sample - loss: 0.4856 - accuracy: 0.8534 - val_loss: 5.0259 - val_accuracy: 0.5517\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3441 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3598 - accuracy: 0.8276 - val_loss: 4.8739 - val_accuracy: 0.5862\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6571 - accuracy: 0.75 - 0s 3ms/sample - loss: 0.6651 - accuracy: 0.6638 - val_loss: 0.6262 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7390 - accuracy: 0.53 - 0s 155us/sample - loss: 0.6561 - accuracy: 0.6638 - val_loss: 0.6359 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6503 - accuracy: 0.62 - 0s 172us/sample - loss: 0.6167 - accuracy: 0.6638 - val_loss: 0.6133 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6315 - accuracy: 0.65 - 0s 163us/sample - loss: 0.6120 - accuracy: 0.6638 - val_loss: 0.6005 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6082 - accuracy: 0.68 - 0s 172us/sample - loss: 0.6050 - accuracy: 0.6638 - val_loss: 0.6047 - val_accuracy: 0.7586\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5789 - accuracy: 0.71 - 0s 163us/sample - loss: 0.6020 - accuracy: 0.6897 - val_loss: 0.5824 - val_accuracy: 0.6897\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6443 - accuracy: 0.68 - 0s 172us/sample - loss: 0.5883 - accuracy: 0.6897 - val_loss: 0.5787 - val_accuracy: 0.7241\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5531 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5875 - accuracy: 0.6810 - val_loss: 0.5695 - val_accuracy: 0.7586\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5635 - accuracy: 0.71 - 0s 172us/sample - loss: 0.5727 - accuracy: 0.7241 - val_loss: 0.5780 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.75 - 0s 146us/sample - loss: 0.5693 - accuracy: 0.7328 - val_loss: 0.5596 - val_accuracy: 0.7241\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4694 - accuracy: 0.81 - 0s 146us/sample - loss: 0.5565 - accuracy: 0.7586 - val_loss: 0.5729 - val_accuracy: 0.6897\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.71 - 0s 138us/sample - loss: 0.5489 - accuracy: 0.7241 - val_loss: 0.5525 - val_accuracy: 0.7241\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5591 - accuracy: 0.71 - 0s 129us/sample - loss: 0.5413 - accuracy: 0.7586 - val_loss: 0.5846 - val_accuracy: 0.6897\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.65 - 0s 138us/sample - loss: 0.5388 - accuracy: 0.7328 - val_loss: 0.5732 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.71 - 0s 138us/sample - loss: 0.5135 - accuracy: 0.7414 - val_loss: 0.6101 - val_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4528 - accuracy: 0.78 - 0s 155us/sample - loss: 0.5092 - accuracy: 0.7586 - val_loss: 0.5878 - val_accuracy: 0.6897\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6165 - accuracy: 0.65 - 0s 146us/sample - loss: 0.5197 - accuracy: 0.7586 - val_loss: 0.6063 - val_accuracy: 0.7241\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5867 - accuracy: 0.68 - 0s 198us/sample - loss: 0.4896 - accuracy: 0.7672 - val_loss: 0.6302 - val_accuracy: 0.6897\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4355 - accuracy: 0.78 - 0s 211us/sample - loss: 0.4886 - accuracy: 0.7672 - val_loss: 0.7354 - val_accuracy: 0.7241\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5623 - accuracy: 0.68 - 0s 172us/sample - loss: 0.4852 - accuracy: 0.7845 - val_loss: 0.6752 - val_accuracy: 0.8276\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4153 - accuracy: 0.81 - 0s 198us/sample - loss: 0.4812 - accuracy: 0.7586 - val_loss: 0.7983 - val_accuracy: 0.6897\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5304 - accuracy: 0.75 - 0s 172us/sample - loss: 0.5137 - accuracy: 0.7500 - val_loss: 0.7482 - val_accuracy: 0.6897\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4987 - accuracy: 0.71 - 0s 139us/sample - loss: 0.5330 - accuracy: 0.7414 - val_loss: 0.7831 - val_accuracy: 0.8276\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5210 - accuracy: 0.81 - 0s 163us/sample - loss: 0.5059 - accuracy: 0.7672 - val_loss: 0.8364 - val_accuracy: 0.7586\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.78 - 0s 189us/sample - loss: 0.4930 - accuracy: 0.7759 - val_loss: 0.7130 - val_accuracy: 0.7241\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5900 - accuracy: 0.68 - 0s 146us/sample - loss: 0.4849 - accuracy: 0.7586 - val_loss: 0.7324 - val_accuracy: 0.6897\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5490 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4611 - accuracy: 0.7586 - val_loss: 0.7915 - val_accuracy: 0.7586\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5147 - accuracy: 0.71 - 0s 146us/sample - loss: 0.4508 - accuracy: 0.7931 - val_loss: 0.8370 - val_accuracy: 0.7586\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3783 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4486 - accuracy: 0.7672 - val_loss: 0.8503 - val_accuracy: 0.7586\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3665 - accuracy: 0.81 - 0s 172us/sample - loss: 0.4274 - accuracy: 0.7931 - val_loss: 0.9981 - val_accuracy: 0.7241\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3632 - accuracy: 0.87 - 0s 155us/sample - loss: 0.4142 - accuracy: 0.7931 - val_loss: 0.9393 - val_accuracy: 0.7586\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3125 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3973 - accuracy: 0.7931 - val_loss: 1.0701 - val_accuracy: 0.7586\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4053 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3915 - accuracy: 0.8534 - val_loss: 1.1579 - val_accuracy: 0.7586\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3637 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3912 - accuracy: 0.8017 - val_loss: 1.2628 - val_accuracy: 0.7586\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4202 - accuracy: 0.84 - 0s 172us/sample - loss: 0.3713 - accuracy: 0.8448 - val_loss: 1.3417 - val_accuracy: 0.7241\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3599 - accuracy: 0.8276 - val_loss: 1.2902 - val_accuracy: 0.7586\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2883 - accuracy: 0.90 - 0s 146us/sample - loss: 0.4047 - accuracy: 0.8017 - val_loss: 1.3017 - val_accuracy: 0.7241\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3024 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3653 - accuracy: 0.8190 - val_loss: 1.4562 - val_accuracy: 0.7241\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3859 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3728 - accuracy: 0.8448 - val_loss: 1.4731 - val_accuracy: 0.7586\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2550 - accuracy: 0.90 - 0s 163us/sample - loss: 0.3485 - accuracy: 0.8362 - val_loss: 1.6048 - val_accuracy: 0.7241\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3557 - accuracy: 0.8190 - val_loss: 1.4773 - val_accuracy: 0.7586\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.84 - 0s 163us/sample - loss: 0.3620 - accuracy: 0.8448 - val_loss: 1.7489 - val_accuracy: 0.7586\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3384 - accuracy: 0.81 - 0s 163us/sample - loss: 0.3406 - accuracy: 0.8534 - val_loss: 1.7686 - val_accuracy: 0.6897\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2454 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3202 - accuracy: 0.8534 - val_loss: 1.8680 - val_accuracy: 0.7586\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3008 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3043 - accuracy: 0.8793 - val_loss: 1.7562 - val_accuracy: 0.7586\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1961 - accuracy: 0.96 - 0s 155us/sample - loss: 0.3445 - accuracy: 0.8276 - val_loss: 2.0794 - val_accuracy: 0.7241\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2931 - accuracy: 0.8707 - val_loss: 1.9675 - val_accuracy: 0.7586\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2709 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3191 - accuracy: 0.8362 - val_loss: 2.0896 - val_accuracy: 0.7931\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1730 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2884 - accuracy: 0.8879 - val_loss: 1.9822 - val_accuracy: 0.6897\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.96 - 0s 146us/sample - loss: 0.3124 - accuracy: 0.8879 - val_loss: 1.8182 - val_accuracy: 0.7586\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 1.00 - 0s 155us/sample - loss: 0.2938 - accuracy: 0.8966 - val_loss: 1.9129 - val_accuracy: 0.7241\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1945 - accuracy: 0.96 - 0s 163us/sample - loss: 0.2873 - accuracy: 0.8707 - val_loss: 2.0319 - val_accuracy: 0.7931\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2737 - accuracy: 0.8707 - val_loss: 2.0829 - val_accuracy: 0.7241\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2505 - accuracy: 0.8879 - val_loss: 2.0923 - val_accuracy: 0.7241\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2727 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2476 - accuracy: 0.8879 - val_loss: 2.2683 - val_accuracy: 0.7241\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1177 - accuracy: 1.00 - 0s 138us/sample - loss: 0.2738 - accuracy: 0.8879 - val_loss: 2.5645 - val_accuracy: 0.6552\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3424 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3060 - accuracy: 0.8793 - val_loss: 1.9938 - val_accuracy: 0.7586\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2916 - accuracy: 0.8707 - val_loss: 2.0917 - val_accuracy: 0.6552\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6226 - accuracy: 0.71 - 0s 137us/sample - loss: 0.3493 - accuracy: 0.8534 - val_loss: 1.8996 - val_accuracy: 0.7241\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1895 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2994 - accuracy: 0.8621 - val_loss: 2.2710 - val_accuracy: 0.7586\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.90 - 0s 172us/sample - loss: 0.2996 - accuracy: 0.8707 - val_loss: 2.0534 - val_accuracy: 0.7931\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2281 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2790 - accuracy: 0.8793 - val_loss: 1.6512 - val_accuracy: 0.7586\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3125 - accuracy: 0.84 - 0s 155us/sample - loss: 0.2919 - accuracy: 0.8534 - val_loss: 1.9431 - val_accuracy: 0.7241\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.93 - 0s 181us/sample - loss: 0.2773 - accuracy: 0.8966 - val_loss: 1.9810 - val_accuracy: 0.7241\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2023 - accuracy: 0.87 - 0s 172us/sample - loss: 0.2882 - accuracy: 0.8621 - val_loss: 2.2100 - val_accuracy: 0.6897\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2204 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2597 - accuracy: 0.8707 - val_loss: 1.9478 - val_accuracy: 0.7241\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1939 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2467 - accuracy: 0.9052 - val_loss: 1.8974 - val_accuracy: 0.6897\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3206 - accuracy: 0.81 - 0s 155us/sample - loss: 0.2386 - accuracy: 0.8966 - val_loss: 2.0034 - val_accuracy: 0.7241\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2741 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2396 - accuracy: 0.9052 - val_loss: 2.2676 - val_accuracy: 0.6897\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2131 - accuracy: 0.9052 - val_loss: 2.1681 - val_accuracy: 0.7241\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2455 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2409 - accuracy: 0.8707 - val_loss: 2.2567 - val_accuracy: 0.7586\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2894 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2092 - accuracy: 0.9224 - val_loss: 2.1452 - val_accuracy: 0.7586\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2224 - accuracy: 0.8966 - val_loss: 2.0510 - val_accuracy: 0.6552\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1210 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2261 - accuracy: 0.8966 - val_loss: 2.1224 - val_accuracy: 0.6897\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2207 - accuracy: 0.8966 - val_loss: 2.3951 - val_accuracy: 0.7586\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1785 - accuracy: 0.9138 - val_loss: 2.3555 - val_accuracy: 0.7241\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1958 - accuracy: 0.8879 - val_loss: 2.4974 - val_accuracy: 0.6897\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2003 - accuracy: 0.9052 - val_loss: 2.4835 - val_accuracy: 0.6897\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.84 - 0s 146us/sample - loss: 0.1845 - accuracy: 0.9052 - val_loss: 2.6450 - val_accuracy: 0.6897\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2367 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1862 - accuracy: 0.9397 - val_loss: 2.5500 - val_accuracy: 0.7241\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2144 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1636 - accuracy: 0.9483 - val_loss: 2.6323 - val_accuracy: 0.6552\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1528 - accuracy: 0.9483 - val_loss: 2.5599 - val_accuracy: 0.6897\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1213 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1585 - accuracy: 0.9224 - val_loss: 2.5384 - val_accuracy: 0.6552\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1529 - accuracy: 0.9224 - val_loss: 2.8889 - val_accuracy: 0.6552\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1377 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1590 - accuracy: 0.9310 - val_loss: 2.6085 - val_accuracy: 0.6897\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2739 - accuracy: 0.84 - 0s 146us/sample - loss: 0.1877 - accuracy: 0.9224 - val_loss: 2.8218 - val_accuracy: 0.6552\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.90 - 0s 163us/sample - loss: 0.1900 - accuracy: 0.9138 - val_loss: 2.6167 - val_accuracy: 0.7241\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1923 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2098 - accuracy: 0.8879 - val_loss: 2.7144 - val_accuracy: 0.7586\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.2169 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2308 - accuracy: 0.8966 - val_loss: 2.3660 - val_accuracy: 0.7241\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2997 - accuracy: 0.8793 - val_loss: 2.6079 - val_accuracy: 0.6897\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2164 - accuracy: 0.9138 - val_loss: 3.2394 - val_accuracy: 0.6897\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1678 - accuracy: 0.96 - 0s 133us/sample - loss: 0.2097 - accuracy: 0.8966 - val_loss: 2.8831 - val_accuracy: 0.7241\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1890 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2147 - accuracy: 0.8966 - val_loss: 2.6399 - val_accuracy: 0.7241\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1487 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1860 - accuracy: 0.9224 - val_loss: 2.6623 - val_accuracy: 0.6207\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1901 - accuracy: 0.9138 - val_loss: 2.5650 - val_accuracy: 0.6897\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1773 - accuracy: 0.9224 - val_loss: 2.8007 - val_accuracy: 0.7241\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1109 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1440 - accuracy: 0.9397 - val_loss: 2.8105 - val_accuracy: 0.6897\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1367 - accuracy: 0.9310 - val_loss: 2.8383 - val_accuracy: 0.6552\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1669 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1309 - accuracy: 0.9483 - val_loss: 3.0457 - val_accuracy: 0.6897\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1423 - accuracy: 0.9397 - val_loss: 3.3528 - val_accuracy: 0.6897\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1020 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1640 - accuracy: 0.9397 - val_loss: 3.3126 - val_accuracy: 0.6207\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2288 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1294 - accuracy: 0.9569 - val_loss: 3.3081 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1231 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1262 - accuracy: 0.9483 - val_loss: 3.2694 - val_accuracy: 0.6552\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1467 - accuracy: 0.9397 - val_loss: 3.6434 - val_accuracy: 0.6552\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1709 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1185 - accuracy: 0.9569 - val_loss: 3.5464 - val_accuracy: 0.6552\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1208 - accuracy: 0.9569 - val_loss: 3.5105 - val_accuracy: 0.6207\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0744 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1083 - accuracy: 0.9569 - val_loss: 3.4834 - val_accuracy: 0.6552\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1121 - accuracy: 0.9569 - val_loss: 3.5690 - val_accuracy: 0.6552\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0568 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1080 - accuracy: 0.9569 - val_loss: 3.5748 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1432 - accuracy: 0.9224 - val_loss: 3.5745 - val_accuracy: 0.6897\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1014 - accuracy: 0.9655 - val_loss: 4.0619 - val_accuracy: 0.6207\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1202 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1399 - accuracy: 0.9483 - val_loss: 3.4764 - val_accuracy: 0.6897\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1090 - accuracy: 0.9655 - val_loss: 3.7966 - val_accuracy: 0.6552\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1384 - accuracy: 0.9310 - val_loss: 3.4898 - val_accuracy: 0.6897\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1354 - accuracy: 0.9397 - val_loss: 3.7465 - val_accuracy: 0.6897\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1253 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1533 - accuracy: 0.9483 - val_loss: 3.4499 - val_accuracy: 0.7241\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.93 - 0s 155us/sample - loss: 0.3134 - accuracy: 0.9138 - val_loss: 4.5807 - val_accuracy: 0.6207\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2736 - accuracy: 0.9397 - val_loss: 4.2140 - val_accuracy: 0.6552\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1973 - accuracy: 0.87 - 0s 129us/sample - loss: 0.1608 - accuracy: 0.9138 - val_loss: 3.9366 - val_accuracy: 0.6207\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1219 - accuracy: 0.9569 - val_loss: 4.2852 - val_accuracy: 0.6207\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1130 - accuracy: 0.9655 - val_loss: 4.0259 - val_accuracy: 0.6897\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1115 - accuracy: 0.9569 - val_loss: 4.1435 - val_accuracy: 0.6207\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0902 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1073 - accuracy: 0.9483 - val_loss: 4.1117 - val_accuracy: 0.6552\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0463 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1437 - accuracy: 0.9397 - val_loss: 4.3308 - val_accuracy: 0.6897\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1180 - accuracy: 0.9569 - val_loss: 4.7128 - val_accuracy: 0.6552\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0927 - accuracy: 0.9483 - val_loss: 4.6409 - val_accuracy: 0.6897\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1092 - accuracy: 0.9397 - val_loss: 4.8208 - val_accuracy: 0.6552\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0860 - accuracy: 0.9741 - val_loss: 4.9946 - val_accuracy: 0.6897\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0579 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0843 - accuracy: 0.9741 - val_loss: 5.1147 - val_accuracy: 0.7241\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0805 - accuracy: 0.9828 - val_loss: 5.2055 - val_accuracy: 0.6897\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1043 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0754 - accuracy: 0.9741 - val_loss: 5.3376 - val_accuracy: 0.6552\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0748 - accuracy: 0.9741 - val_loss: 5.3687 - val_accuracy: 0.6552\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0785 - accuracy: 0.9828 - val_loss: 5.4378 - val_accuracy: 0.6552\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0684 - accuracy: 0.9828 - val_loss: 5.5972 - val_accuracy: 0.6552\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0628 - accuracy: 0.9828 - val_loss: 5.7641 - val_accuracy: 0.6897\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0607 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0732 - accuracy: 0.9828 - val_loss: 5.7932 - val_accuracy: 0.7241\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0668 - accuracy: 0.9655 - val_loss: 5.5458 - val_accuracy: 0.7241\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1143 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0850 - accuracy: 0.9741 - val_loss: 5.7376 - val_accuracy: 0.6207\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1153 - accuracy: 0.9569 - val_loss: 5.7931 - val_accuracy: 0.6897\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0536 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1376 - accuracy: 0.9310 - val_loss: 5.8150 - val_accuracy: 0.6897\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2481 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1416 - accuracy: 0.9483 - val_loss: 5.1401 - val_accuracy: 0.6552\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1619 - accuracy: 0.9224 - val_loss: 4.9807 - val_accuracy: 0.6552\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1328 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1366 - accuracy: 0.9310 - val_loss: 4.8994 - val_accuracy: 0.6552\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0664 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1223 - accuracy: 0.9483 - val_loss: 4.8059 - val_accuracy: 0.7241\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0949 - accuracy: 0.9569 - val_loss: 5.0501 - val_accuracy: 0.6552\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1313 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1156 - accuracy: 0.9483 - val_loss: 4.8806 - val_accuracy: 0.6552\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 1.00 - 0s 120us/sample - loss: 0.1068 - accuracy: 0.9655 - val_loss: 4.8420 - val_accuracy: 0.6552\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0812 - accuracy: 0.9828 - val_loss: 4.9358 - val_accuracy: 0.6552\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0976 - accuracy: 0.9655 - val_loss: 4.8714 - val_accuracy: 0.6552\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0435 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0742 - accuracy: 0.9655 - val_loss: 5.0566 - val_accuracy: 0.6207\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.90 - 0s 138us/sample - loss: 0.0841 - accuracy: 0.9569 - val_loss: 5.0402 - val_accuracy: 0.6552\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0668 - accuracy: 0.9741 - val_loss: 5.0947 - val_accuracy: 0.6897\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 1.00 - 0s 141us/sample - loss: 0.0689 - accuracy: 0.9741 - val_loss: 5.1742 - val_accuracy: 0.6207\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0615 - accuracy: 0.9828 - val_loss: 5.0282 - val_accuracy: 0.6552\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0979 - accuracy: 0.9569 - val_loss: 5.2717 - val_accuracy: 0.5862\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0800 - accuracy: 0.9655 - val_loss: 5.3483 - val_accuracy: 0.6552\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0441 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0745 - accuracy: 0.9741 - val_loss: 5.3983 - val_accuracy: 0.6552\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0652 - accuracy: 0.9655 - val_loss: 5.4632 - val_accuracy: 0.6897\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0627 - accuracy: 0.9741 - val_loss: 5.3040 - val_accuracy: 0.6207\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0738 - accuracy: 0.9655 - val_loss: 5.5414 - val_accuracy: 0.6552\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0828 - accuracy: 0.9741 - val_loss: 5.4180 - val_accuracy: 0.6207\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1448 - accuracy: 0.9397 - val_loss: 5.6275 - val_accuracy: 0.6207\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0398 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0871 - accuracy: 0.9741 - val_loss: 5.7053 - val_accuracy: 0.6207\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0627 - accuracy: 0.9741 - val_loss: 5.5719 - val_accuracy: 0.6207\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0706 - accuracy: 0.9741 - val_loss: 5.7532 - val_accuracy: 0.6552\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0685 - accuracy: 0.96 - 0s 301us/sample - loss: 0.0693 - accuracy: 0.9741 - val_loss: 5.6617 - val_accuracy: 0.6552\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 1.00 - 0s 482us/sample - loss: 0.0527 - accuracy: 0.9741 - val_loss: 5.5969 - val_accuracy: 0.6552\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.96 - 0s 499us/sample - loss: 0.0550 - accuracy: 0.9741 - val_loss: 5.7223 - val_accuracy: 0.6552\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 1.00 - 0s 464us/sample - loss: 0.0748 - accuracy: 0.9655 - val_loss: 5.8025 - val_accuracy: 0.6552\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 1.00 - 0s 481us/sample - loss: 0.1114 - accuracy: 0.9655 - val_loss: 5.5456 - val_accuracy: 0.6552\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 1.00 - 0s 524us/sample - loss: 0.0820 - accuracy: 0.9569 - val_loss: 5.6880 - val_accuracy: 0.5862\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 1.00 - 0s 464us/sample - loss: 0.0710 - accuracy: 0.9828 - val_loss: 5.5826 - val_accuracy: 0.6552\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.96 - 0s 447us/sample - loss: 0.0755 - accuracy: 0.9741 - val_loss: 5.6086 - val_accuracy: 0.6552\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.96 - 0s 490us/sample - loss: 0.0641 - accuracy: 0.9741 - val_loss: 5.5936 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.96 - 0s 464us/sample - loss: 0.0592 - accuracy: 0.9655 - val_loss: 5.3863 - val_accuracy: 0.6207\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 1.00 - 0s 499us/sample - loss: 0.0667 - accuracy: 0.9741 - val_loss: 5.6048 - val_accuracy: 0.6552\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.90 - 0s 498us/sample - loss: 0.0874 - accuracy: 0.9483 - val_loss: 5.8614 - val_accuracy: 0.6207\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.96 - 0s 473us/sample - loss: 0.0568 - accuracy: 0.9828 - val_loss: 5.7413 - val_accuracy: 0.6207\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 1.00 - 0s 456us/sample - loss: 0.0633 - accuracy: 0.9741 - val_loss: 5.8408 - val_accuracy: 0.6207\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0721 - accuracy: 0.96 - 0s 258us/sample - loss: 0.0464 - accuracy: 0.9741 - val_loss: 6.0093 - val_accuracy: 0.6207\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 1.00 - 0s 141us/sample - loss: 0.0874 - accuracy: 0.9569 - val_loss: 6.0865 - val_accuracy: 0.6207\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0623 - accuracy: 0.9655 - val_loss: 5.7721 - val_accuracy: 0.6552\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1506 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1534 - accuracy: 0.9310 - val_loss: 5.8583 - val_accuracy: 0.6207\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0452 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2081 - accuracy: 0.9052 - val_loss: 4.9597 - val_accuracy: 0.6207\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6018 - accuracy: 0.87 - 0s 138us/sample - loss: 0.4453 - accuracy: 0.9052 - val_loss: 5.6458 - val_accuracy: 0.6207\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3360 - accuracy: 0.90 - 0s 131us/sample - loss: 0.3199 - accuracy: 0.9224 - val_loss: 6.2637 - val_accuracy: 0.6552\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1496 - accuracy: 0.9138 - val_loss: 5.7972 - val_accuracy: 0.6552\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1200 - accuracy: 0.9483 - val_loss: 5.6804 - val_accuracy: 0.5862\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0937 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1240 - accuracy: 0.9569 - val_loss: 5.5702 - val_accuracy: 0.5862\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1235 - accuracy: 0.9397 - val_loss: 5.9002 - val_accuracy: 0.6552\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1390 - accuracy: 0.9483 - val_loss: 5.8405 - val_accuracy: 0.5862\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1506 - accuracy: 0.9138 - val_loss: 6.6186 - val_accuracy: 0.6552\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2340 - accuracy: 0.9483 - val_loss: 5.1328 - val_accuracy: 0.6552\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 1.00 - 0s 137us/sample - loss: 0.3601 - accuracy: 0.9224 - val_loss: 4.1921 - val_accuracy: 0.7586\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1818 - accuracy: 0.9224 - val_loss: 4.1809 - val_accuracy: 0.7586\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2672 - accuracy: 0.93 - 0s 142us/sample - loss: 0.2721 - accuracy: 0.9052 - val_loss: 3.9971 - val_accuracy: 0.7586\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1588 - accuracy: 0.9310 - val_loss: 4.0269 - val_accuracy: 0.7586\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1557 - accuracy: 0.90 - 0s 181us/sample - loss: 0.1309 - accuracy: 0.9310 - val_loss: 3.7869 - val_accuracy: 0.6897\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1549 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1125 - accuracy: 0.9483 - val_loss: 3.8339 - val_accuracy: 0.6552\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1205 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0930 - accuracy: 0.9569 - val_loss: 3.9136 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 372362d0601f9b8ae3b14ed131469348</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8275861740112305</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 99</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 33</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_units: 44</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6996 - accuracy: 0.28 - 1s 5ms/sample - loss: 0.6743 - accuracy: 0.5345 - val_loss: 0.6320 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6134 - accuracy: 0.68 - 0s 335us/sample - loss: 0.6400 - accuracy: 0.6638 - val_loss: 0.6236 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6057 - accuracy: 0.68 - 0s 181us/sample - loss: 0.6244 - accuracy: 0.6638 - val_loss: 0.6352 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6080 - accuracy: 0.68 - 0s 163us/sample - loss: 0.6189 - accuracy: 0.6638 - val_loss: 0.6076 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6270 - accuracy: 0.65 - 0s 164us/sample - loss: 0.6177 - accuracy: 0.6638 - val_loss: 0.5995 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5389 - accuracy: 0.71 - 0s 164us/sample - loss: 0.5967 - accuracy: 0.6638 - val_loss: 0.6101 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5633 - accuracy: 0.81 - 0s 163us/sample - loss: 0.6044 - accuracy: 0.6638 - val_loss: 0.6094 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5483 - accuracy: 0.71 - 0s 1ms/sample - loss: 0.5974 - accuracy: 0.6638 - val_loss: 0.5830 - val_accuracy: 0.6897\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5029 - accuracy: 0.75 - 0s 215us/sample - loss: 0.5942 - accuracy: 0.6897 - val_loss: 0.5702 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6133 - accuracy: 0.75 - 0s 1ms/sample - loss: 0.5831 - accuracy: 0.7155 - val_loss: 0.5723 - val_accuracy: 0.7241\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5370 - accuracy: 0.84 - 0s 1ms/sample - loss: 0.5794 - accuracy: 0.7069 - val_loss: 0.5617 - val_accuracy: 0.7586\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5408 - accuracy: 0.81 - 0s 163us/sample - loss: 0.5701 - accuracy: 0.7328 - val_loss: 0.5517 - val_accuracy: 0.7586\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5001 - accuracy: 0.75 - 0s 146us/sample - loss: 0.5587 - accuracy: 0.7241 - val_loss: 0.5438 - val_accuracy: 0.7586\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5770 - accuracy: 0.71 - 0s 164us/sample - loss: 0.5455 - accuracy: 0.7500 - val_loss: 0.5498 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4665 - accuracy: 0.78 - 0s 1ms/sample - loss: 0.5420 - accuracy: 0.7414 - val_loss: 0.5342 - val_accuracy: 0.8276\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5954 - accuracy: 0.68 - 0s 146us/sample - loss: 0.5188 - accuracy: 0.7586 - val_loss: 0.5288 - val_accuracy: 0.7931\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5697 - accuracy: 0.75 - 0s 138us/sample - loss: 0.5145 - accuracy: 0.7500 - val_loss: 0.6579 - val_accuracy: 0.6897\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6178 - accuracy: 0.65 - 0s 163us/sample - loss: 0.5306 - accuracy: 0.7241 - val_loss: 0.5567 - val_accuracy: 0.7586\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5301 - accuracy: 0.75 - 0s 163us/sample - loss: 0.5169 - accuracy: 0.7328 - val_loss: 0.6713 - val_accuracy: 0.6552\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5877 - accuracy: 0.59 - 0s 155us/sample - loss: 0.5136 - accuracy: 0.7069 - val_loss: 0.5791 - val_accuracy: 0.8276\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7395 - accuracy: 0.59 - 0s 163us/sample - loss: 0.4835 - accuracy: 0.7586 - val_loss: 0.6411 - val_accuracy: 0.7586\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4001 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4798 - accuracy: 0.7931 - val_loss: 0.8050 - val_accuracy: 0.6552\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5706 - accuracy: 0.68 - 0s 138us/sample - loss: 0.4737 - accuracy: 0.7845 - val_loss: 0.6516 - val_accuracy: 0.7586\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4305 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4770 - accuracy: 0.7759 - val_loss: 0.6762 - val_accuracy: 0.7586\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3475 - accuracy: 0.84 - 0s 163us/sample - loss: 0.4447 - accuracy: 0.7845 - val_loss: 0.7544 - val_accuracy: 0.7586\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4764 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4451 - accuracy: 0.7845 - val_loss: 0.7518 - val_accuracy: 0.7586\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3595 - accuracy: 0.90 - 0s 129us/sample - loss: 0.4312 - accuracy: 0.7931 - val_loss: 0.7217 - val_accuracy: 0.8276\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4837 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4121 - accuracy: 0.7931 - val_loss: 0.8699 - val_accuracy: 0.7586\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.78 - 0s 155us/sample - loss: 0.4310 - accuracy: 0.8017 - val_loss: 0.8286 - val_accuracy: 0.7931\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4685 - accuracy: 0.75 - 0s 155us/sample - loss: 0.4179 - accuracy: 0.8190 - val_loss: 1.1027 - val_accuracy: 0.6552\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4159 - accuracy: 0.81 - 0s 181us/sample - loss: 0.4248 - accuracy: 0.7845 - val_loss: 0.9676 - val_accuracy: 0.7241\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3757 - accuracy: 0.87 - 0s 181us/sample - loss: 0.4143 - accuracy: 0.8103 - val_loss: 1.1220 - val_accuracy: 0.7241\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4227 - accuracy: 0.81 - 0s 189us/sample - loss: 0.3834 - accuracy: 0.8190 - val_loss: 1.4001 - val_accuracy: 0.6897\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3416 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3775 - accuracy: 0.8103 - val_loss: 1.2785 - val_accuracy: 0.7586\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.81 - 0s 164us/sample - loss: 0.3680 - accuracy: 0.8190 - val_loss: 1.3959 - val_accuracy: 0.7241\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.81 - 0s 181us/sample - loss: 0.3569 - accuracy: 0.8017 - val_loss: 1.5736 - val_accuracy: 0.7241\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3097 - accuracy: 0.93 - 0s 137us/sample - loss: 0.3487 - accuracy: 0.8448 - val_loss: 1.6601 - val_accuracy: 0.7241\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2752 - accuracy: 0.87 - 0s 180us/sample - loss: 0.3479 - accuracy: 0.8276 - val_loss: 1.5208 - val_accuracy: 0.7586\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4784 - accuracy: 0.78 - 0s 172us/sample - loss: 0.3504 - accuracy: 0.8276 - val_loss: 1.7076 - val_accuracy: 0.7241\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3083 - accuracy: 0.84 - 0s 163us/sample - loss: 0.3341 - accuracy: 0.8448 - val_loss: 1.8787 - val_accuracy: 0.7241\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.75 - 0s 146us/sample - loss: 0.3555 - accuracy: 0.8448 - val_loss: 1.6156 - val_accuracy: 0.7931\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2453 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3253 - accuracy: 0.8362 - val_loss: 1.7690 - val_accuracy: 0.7241\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3358 - accuracy: 0.78 - 0s 146us/sample - loss: 0.3267 - accuracy: 0.8276 - val_loss: 1.5639 - val_accuracy: 0.7931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2413 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3708 - accuracy: 0.8621 - val_loss: 1.8204 - val_accuracy: 0.6207\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4000 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3639 - accuracy: 0.8448 - val_loss: 1.6515 - val_accuracy: 0.7241\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2563 - accuracy: 0.87 - 0s 189us/sample - loss: 0.3956 - accuracy: 0.8103 - val_loss: 2.0224 - val_accuracy: 0.7241\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3756 - accuracy: 0.87 - 0s 181us/sample - loss: 0.3779 - accuracy: 0.8362 - val_loss: 1.6101 - val_accuracy: 0.7586\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3093 - accuracy: 0.87 - 0s 198us/sample - loss: 0.3819 - accuracy: 0.7931 - val_loss: 1.4733 - val_accuracy: 0.7586\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3515 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3662 - accuracy: 0.8103 - val_loss: 1.5138 - val_accuracy: 0.7241\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2806 - accuracy: 0.96 - 0s 146us/sample - loss: 0.3775 - accuracy: 0.8362 - val_loss: 1.3923 - val_accuracy: 0.7931\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2660 - accuracy: 0.87 - 0s 142us/sample - loss: 0.3361 - accuracy: 0.8017 - val_loss: 1.4313 - val_accuracy: 0.7931\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3284 - accuracy: 0.8103 - val_loss: 1.6070 - val_accuracy: 0.7931\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3836 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3207 - accuracy: 0.8534 - val_loss: 1.9489 - val_accuracy: 0.7241\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3691 - accuracy: 0.78 - 0s 155us/sample - loss: 0.2976 - accuracy: 0.8276 - val_loss: 1.7181 - val_accuracy: 0.7931\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2997 - accuracy: 0.8621 - val_loss: 1.7263 - val_accuracy: 0.6897\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2775 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3364 - accuracy: 0.8362 - val_loss: 1.8433 - val_accuracy: 0.7241\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2964 - accuracy: 0.84 - 0s 224us/sample - loss: 0.3393 - accuracy: 0.8362 - val_loss: 1.9212 - val_accuracy: 0.6897\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2586 - accuracy: 0.84 - 0s 163us/sample - loss: 0.3491 - accuracy: 0.8276 - val_loss: 1.7192 - val_accuracy: 0.6552\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.87 - 0s 172us/sample - loss: 0.3177 - accuracy: 0.8534 - val_loss: 1.4147 - val_accuracy: 0.7241\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.78 - 0s 172us/sample - loss: 0.3393 - accuracy: 0.7845 - val_loss: 1.6063 - val_accuracy: 0.7241\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2884 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3014 - accuracy: 0.8707 - val_loss: 1.7861 - val_accuracy: 0.6897\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3585 - accuracy: 0.78 - 0s 172us/sample - loss: 0.3171 - accuracy: 0.8362 - val_loss: 1.6704 - val_accuracy: 0.7241\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.90 - 0s 181us/sample - loss: 0.3208 - accuracy: 0.8448 - val_loss: 1.9596 - val_accuracy: 0.7241\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2243 - accuracy: 0.87 - 0s 163us/sample - loss: 0.2669 - accuracy: 0.8966 - val_loss: 2.4577 - val_accuracy: 0.6207\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2536 - accuracy: 0.87 - 0s 172us/sample - loss: 0.2728 - accuracy: 0.8793 - val_loss: 2.1748 - val_accuracy: 0.7586\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2872 - accuracy: 0.87 - 0s 164us/sample - loss: 0.2744 - accuracy: 0.8707 - val_loss: 2.1152 - val_accuracy: 0.7241\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2649 - accuracy: 0.84 - 0s 172us/sample - loss: 0.2810 - accuracy: 0.8621 - val_loss: 1.8640 - val_accuracy: 0.6897\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2950 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2518 - accuracy: 0.8707 - val_loss: 2.0083 - val_accuracy: 0.6897\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.84 - 0s 137us/sample - loss: 0.2291 - accuracy: 0.8879 - val_loss: 2.1327 - val_accuracy: 0.7241\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2306 - accuracy: 0.84 - 0s 155us/sample - loss: 0.2984 - accuracy: 0.8879 - val_loss: 2.2808 - val_accuracy: 0.6897\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3562 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2611 - accuracy: 0.8793 - val_loss: 2.3046 - val_accuracy: 0.6897\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3348 - accuracy: 0.75 - 0s 146us/sample - loss: 0.2996 - accuracy: 0.8276 - val_loss: 2.2114 - val_accuracy: 0.7241\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2702 - accuracy: 0.8966 - val_loss: 2.4750 - val_accuracy: 0.5862\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2594 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3274 - accuracy: 0.8362 - val_loss: 2.8420 - val_accuracy: 0.6897\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3357 - accuracy: 0.8534 - val_loss: 1.8468 - val_accuracy: 0.6897\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4365 - accuracy: 0.84 - 0s 138us/sample - loss: 0.5261 - accuracy: 0.8017 - val_loss: 1.4462 - val_accuracy: 0.6552\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6178 - accuracy: 0.90 - 0s 137us/sample - loss: 0.4232 - accuracy: 0.8793 - val_loss: 2.1130 - val_accuracy: 0.7586\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3463 - accuracy: 0.8879 - val_loss: 2.5642 - val_accuracy: 0.7586\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3281 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2952 - accuracy: 0.8621 - val_loss: 2.8323 - val_accuracy: 0.7241\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.68 - 0s 129us/sample - loss: 0.2840 - accuracy: 0.8448 - val_loss: 2.5216 - val_accuracy: 0.7586\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2585 - accuracy: 0.8879 - val_loss: 2.5598 - val_accuracy: 0.6897\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2986 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2359 - accuracy: 0.9052 - val_loss: 2.6772 - val_accuracy: 0.6552\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2303 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2360 - accuracy: 0.8793 - val_loss: 2.6067 - val_accuracy: 0.7241\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.90 - 0s 137us/sample - loss: 0.1954 - accuracy: 0.9310 - val_loss: 2.9854 - val_accuracy: 0.5862\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.75 - 0s 138us/sample - loss: 0.2848 - accuracy: 0.8534 - val_loss: 2.7261 - val_accuracy: 0.6552\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3310 - accuracy: 0.8621 - val_loss: 2.5812 - val_accuracy: 0.6207\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3117 - accuracy: 0.8534 - val_loss: 2.7174 - val_accuracy: 0.6552\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1994 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2483 - accuracy: 0.8879 - val_loss: 2.7979 - val_accuracy: 0.7241\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2705 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2715 - accuracy: 0.8534 - val_loss: 2.8667 - val_accuracy: 0.6897\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.93 - 0s 137us/sample - loss: 0.2263 - accuracy: 0.9052 - val_loss: 2.8641 - val_accuracy: 0.7241\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3604 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2194 - accuracy: 0.9052 - val_loss: 2.8949 - val_accuracy: 0.7241\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2028 - accuracy: 0.90 - 0s 133us/sample - loss: 0.1750 - accuracy: 0.9310 - val_loss: 3.1313 - val_accuracy: 0.6897\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2020 - accuracy: 0.9138 - val_loss: 3.1022 - val_accuracy: 0.6897\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2350 - accuracy: 0.87 - 0s 120us/sample - loss: 0.1867 - accuracy: 0.9310 - val_loss: 3.0476 - val_accuracy: 0.7241\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1559 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2109 - accuracy: 0.9138 - val_loss: 3.0377 - val_accuracy: 0.6552\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1612 - accuracy: 0.9310 - val_loss: 3.2276 - val_accuracy: 0.6552\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1613 - accuracy: 0.96 - 0s 142us/sample - loss: 0.1502 - accuracy: 0.9224 - val_loss: 3.5902 - val_accuracy: 0.6552\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0505 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1610 - accuracy: 0.9224 - val_loss: 3.8018 - val_accuracy: 0.6207\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1456 - accuracy: 0.9483 - val_loss: 3.4944 - val_accuracy: 0.6897\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1641 - accuracy: 0.9224 - val_loss: 3.5928 - val_accuracy: 0.6207\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0898 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1630 - accuracy: 0.9224 - val_loss: 3.7355 - val_accuracy: 0.6552\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1540 - accuracy: 0.9310 - val_loss: 3.7338 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1154 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1526 - accuracy: 0.9224 - val_loss: 3.6982 - val_accuracy: 0.6552\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1494 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1615 - accuracy: 0.9310 - val_loss: 3.4866 - val_accuracy: 0.5862\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.84 - 0s 129us/sample - loss: 0.1756 - accuracy: 0.9224 - val_loss: 3.2752 - val_accuracy: 0.6897\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1496 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1631 - accuracy: 0.9310 - val_loss: 3.2271 - val_accuracy: 0.6207\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1466 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2154 - accuracy: 0.8966 - val_loss: 3.4705 - val_accuracy: 0.6552\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2245 - accuracy: 0.9138 - val_loss: 3.4441 - val_accuracy: 0.6552\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1531 - accuracy: 0.9397 - val_loss: 3.4777 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1416 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1789 - accuracy: 0.9224 - val_loss: 3.3619 - val_accuracy: 0.6897\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1729 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1504 - accuracy: 0.9310 - val_loss: 3.5243 - val_accuracy: 0.6207\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1700 - accuracy: 0.9052 - val_loss: 3.4216 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1532 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2739 - accuracy: 0.8793 - val_loss: 3.1801 - val_accuracy: 0.6897\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1762 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2090 - accuracy: 0.8966 - val_loss: 3.0179 - val_accuracy: 0.7241\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1858 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2112 - accuracy: 0.8707 - val_loss: 2.8522 - val_accuracy: 0.5517\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3051 - accuracy: 0.81 - 0s 120us/sample - loss: 0.2498 - accuracy: 0.8362 - val_loss: 2.8558 - val_accuracy: 0.6552\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 1.00 - 0s 142us/sample - loss: 0.2068 - accuracy: 0.9310 - val_loss: 3.1394 - val_accuracy: 0.7241\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1991 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1938 - accuracy: 0.9224 - val_loss: 3.0995 - val_accuracy: 0.6207\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2006 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1816 - accuracy: 0.9052 - val_loss: 3.0963 - val_accuracy: 0.6207\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.84 - 0s 138us/sample - loss: 0.1979 - accuracy: 0.8966 - val_loss: 3.2266 - val_accuracy: 0.6552\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1791 - accuracy: 0.9397 - val_loss: 3.3093 - val_accuracy: 0.6897\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0956 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1811 - accuracy: 0.9397 - val_loss: 3.2721 - val_accuracy: 0.6552\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2095 - accuracy: 0.87 - 0s 146us/sample - loss: 0.1658 - accuracy: 0.9224 - val_loss: 3.4860 - val_accuracy: 0.5862\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1513 - accuracy: 0.9310 - val_loss: 3.7396 - val_accuracy: 0.6552\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1778 - accuracy: 0.9224 - val_loss: 3.7557 - val_accuracy: 0.5862\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1483 - accuracy: 0.9397 - val_loss: 3.7332 - val_accuracy: 0.6207\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0988 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1062 - accuracy: 0.9569 - val_loss: 3.8044 - val_accuracy: 0.6552\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0905 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1235 - accuracy: 0.9310 - val_loss: 3.8441 - val_accuracy: 0.5517\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1363 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1219 - accuracy: 0.9397 - val_loss: 3.8816 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0775 - accuracy: 0.96 - 0s 189us/sample - loss: 0.1576 - accuracy: 0.9224 - val_loss: 3.7262 - val_accuracy: 0.6552\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0875 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1666 - accuracy: 0.9310 - val_loss: 3.7281 - val_accuracy: 0.5517\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1712 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2457 - accuracy: 0.8879 - val_loss: 3.1872 - val_accuracy: 0.6552\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1982 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1841 - accuracy: 0.9224 - val_loss: 3.1937 - val_accuracy: 0.5862\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1942 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2550 - accuracy: 0.9138 - val_loss: 2.8125 - val_accuracy: 0.6897\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1555 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1902 - accuracy: 0.9310 - val_loss: 2.4660 - val_accuracy: 0.6207\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1877 - accuracy: 0.9310 - val_loss: 2.5295 - val_accuracy: 0.6552\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1578 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1271 - accuracy: 0.9397 - val_loss: 2.7902 - val_accuracy: 0.6552\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1826 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1287 - accuracy: 0.9397 - val_loss: 2.9416 - val_accuracy: 0.6552\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1044 - accuracy: 0.9483 - val_loss: 2.9929 - val_accuracy: 0.6897\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1003 - accuracy: 0.9483 - val_loss: 3.1534 - val_accuracy: 0.6897\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0869 - accuracy: 0.9569 - val_loss: 3.3911 - val_accuracy: 0.6552\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1089 - accuracy: 0.9397 - val_loss: 3.6204 - val_accuracy: 0.5517\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0864 - accuracy: 0.9655 - val_loss: 3.4053 - val_accuracy: 0.7241\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1190 - accuracy: 0.9569 - val_loss: 3.3794 - val_accuracy: 0.7241\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1107 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0851 - accuracy: 0.9569 - val_loss: 3.6197 - val_accuracy: 0.6207\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0986 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0981 - accuracy: 0.9569 - val_loss: 3.5314 - val_accuracy: 0.6897\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0731 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0981 - accuracy: 0.9569 - val_loss: 3.3856 - val_accuracy: 0.6897\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0719 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1252 - accuracy: 0.9569 - val_loss: 3.0955 - val_accuracy: 0.6897\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1938 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1859 - accuracy: 0.9397 - val_loss: 3.1993 - val_accuracy: 0.6552\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2448 - accuracy: 0.8707 - val_loss: 2.9468 - val_accuracy: 0.6897\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2423 - accuracy: 0.8966 - val_loss: 2.9353 - val_accuracy: 0.6552\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1775 - accuracy: 0.9138 - val_loss: 2.7770 - val_accuracy: 0.5517\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1706 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1991 - accuracy: 0.8879 - val_loss: 2.5476 - val_accuracy: 0.6552\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1514 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1666 - accuracy: 0.9052 - val_loss: 2.4151 - val_accuracy: 0.6552\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1455 - accuracy: 0.9569 - val_loss: 2.7031 - val_accuracy: 0.7241\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0976 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1247 - accuracy: 0.9310 - val_loss: 3.1115 - val_accuracy: 0.6552\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0899 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1096 - accuracy: 0.9483 - val_loss: 3.4543 - val_accuracy: 0.6552\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0805 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1061 - accuracy: 0.9569 - val_loss: 3.6936 - val_accuracy: 0.6552\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0647 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0771 - accuracy: 0.9741 - val_loss: 3.6312 - val_accuracy: 0.6897\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1076 - accuracy: 0.9397 - val_loss: 3.6552 - val_accuracy: 0.6897\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.87 - 0s 129us/sample - loss: 0.0710 - accuracy: 0.9569 - val_loss: 3.6166 - val_accuracy: 0.6897\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1054 - accuracy: 0.9655 - val_loss: 3.5890 - val_accuracy: 0.6897\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1519 - accuracy: 0.90 - 0s 198us/sample - loss: 0.1032 - accuracy: 0.9483 - val_loss: 3.5267 - val_accuracy: 0.6207\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0931 - accuracy: 0.9483 - val_loss: 3.6529 - val_accuracy: 0.6552\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0407 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1078 - accuracy: 0.9483 - val_loss: 3.8909 - val_accuracy: 0.6552\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0822 - accuracy: 0.9655 - val_loss: 3.6686 - val_accuracy: 0.7241\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0740 - accuracy: 0.9828 - val_loss: 3.6430 - val_accuracy: 0.7241\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0832 - accuracy: 0.9741 - val_loss: 3.7820 - val_accuracy: 0.7241\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.93 - 0s 137us/sample - loss: 0.0702 - accuracy: 0.9741 - val_loss: 3.7673 - val_accuracy: 0.7586\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0662 - accuracy: 0.9655 - val_loss: 4.5213 - val_accuracy: 0.6207\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2799 - accuracy: 0.87 - 0s 129us/sample - loss: 0.1536 - accuracy: 0.9397 - val_loss: 4.0326 - val_accuracy: 0.6897\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2898 - accuracy: 0.9052 - val_loss: 3.9676 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2062 - accuracy: 0.9052 - val_loss: 3.2876 - val_accuracy: 0.6552\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1474 - accuracy: 0.9483 - val_loss: 2.5465 - val_accuracy: 0.7241\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1225 - accuracy: 0.9655 - val_loss: 3.2794 - val_accuracy: 0.6897\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1028 - accuracy: 0.96 - 0s 129us/sample - loss: 0.3102 - accuracy: 0.9397 - val_loss: 3.1310 - val_accuracy: 0.6897\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0997 - accuracy: 0.9655 - val_loss: 1.9280 - val_accuracy: 0.7586\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2828 - accuracy: 0.9310 - val_loss: 1.7092 - val_accuracy: 0.7241\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1101 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1517 - accuracy: 0.9569 - val_loss: 1.8058 - val_accuracy: 0.6897\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1139 - accuracy: 0.9655 - val_loss: 1.9356 - val_accuracy: 0.6552\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0895 - accuracy: 0.9914 - val_loss: 2.1857 - val_accuracy: 0.6552\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0711 - accuracy: 0.9828 - val_loss: 2.5336 - val_accuracy: 0.6897\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0791 - accuracy: 0.9655 - val_loss: 2.8056 - val_accuracy: 0.6897\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0612 - accuracy: 0.9741 - val_loss: 2.8609 - val_accuracy: 0.7241\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0538 - accuracy: 0.9828 - val_loss: 3.2517 - val_accuracy: 0.6897\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0655 - accuracy: 0.9655 - val_loss: 3.3773 - val_accuracy: 0.6897\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0417 - accuracy: 0.9828 - val_loss: 3.3077 - val_accuracy: 0.6897\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0704 - accuracy: 0.9741 - val_loss: 3.3981 - val_accuracy: 0.6552\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0840 - accuracy: 0.9741 - val_loss: 3.5953 - val_accuracy: 0.6552\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0837 - accuracy: 0.9741 - val_loss: 3.4372 - val_accuracy: 0.6897\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0580 - accuracy: 0.9741 - val_loss: 3.4366 - val_accuracy: 0.6897\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0308 - accuracy: 0.9914 - val_loss: 3.3583 - val_accuracy: 0.6552\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0804 - accuracy: 0.9741 - val_loss: 3.7217 - val_accuracy: 0.6552\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1039 - accuracy: 0.9741 - val_loss: 3.5144 - val_accuracy: 0.6897\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3567 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1855 - accuracy: 0.9397 - val_loss: 3.2176 - val_accuracy: 0.6897\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0762 - accuracy: 0.96 - 0s 142us/sample - loss: 0.0931 - accuracy: 0.9741 - val_loss: 3.4248 - val_accuracy: 0.5517\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1510 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1110 - accuracy: 0.9569 - val_loss: 3.0450 - val_accuracy: 0.6897\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0869 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1281 - accuracy: 0.9397 - val_loss: 2.9946 - val_accuracy: 0.6897\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1170 - accuracy: 0.93 - 0s 120us/sample - loss: 0.0940 - accuracy: 0.9569 - val_loss: 3.1060 - val_accuracy: 0.5862\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1332 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1051 - accuracy: 0.9569 - val_loss: 3.0554 - val_accuracy: 0.6552\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6909 - accuracy: 0.50 - 0s 4ms/sample - loss: 0.6457 - accuracy: 0.6552 - val_loss: 0.6410 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6717 - accuracy: 0.62 - 0s 181us/sample - loss: 0.6391 - accuracy: 0.6638 - val_loss: 0.6422 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6576 - accuracy: 0.62 - 0s 164us/sample - loss: 0.6343 - accuracy: 0.6638 - val_loss: 0.6275 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6102 - accuracy: 0.68 - 0s 155us/sample - loss: 0.6185 - accuracy: 0.6638 - val_loss: 0.6210 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.62 - 0s 155us/sample - loss: 0.6148 - accuracy: 0.6638 - val_loss: 0.6127 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7222 - accuracy: 0.56 - 0s 172us/sample - loss: 0.6108 - accuracy: 0.6638 - val_loss: 0.6058 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5893 - accuracy: 0.68 - 0s 155us/sample - loss: 0.6072 - accuracy: 0.6638 - val_loss: 0.5998 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6475 - accuracy: 0.62 - 0s 172us/sample - loss: 0.6007 - accuracy: 0.6638 - val_loss: 0.5926 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6274 - accuracy: 0.59 - 0s 163us/sample - loss: 0.6002 - accuracy: 0.6552 - val_loss: 0.6086 - val_accuracy: 0.7586\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6014 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5999 - accuracy: 0.6983 - val_loss: 0.5833 - val_accuracy: 0.6897\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5753 - accuracy: 0.68 - 0s 155us/sample - loss: 0.5899 - accuracy: 0.7069 - val_loss: 0.5761 - val_accuracy: 0.7241\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5491 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5818 - accuracy: 0.7241 - val_loss: 0.5715 - val_accuracy: 0.6897\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5124 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5780 - accuracy: 0.7069 - val_loss: 0.5688 - val_accuracy: 0.7586\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5918 - accuracy: 0.68 - 0s 146us/sample - loss: 0.5816 - accuracy: 0.7155 - val_loss: 0.5663 - val_accuracy: 0.7931\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5091 - accuracy: 0.78 - 0s 129us/sample - loss: 0.5617 - accuracy: 0.7500 - val_loss: 0.5623 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5349 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5723 - accuracy: 0.7241 - val_loss: 0.5649 - val_accuracy: 0.6897\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5431 - accuracy: 0.75 - 0s 138us/sample - loss: 0.5597 - accuracy: 0.7155 - val_loss: 0.5572 - val_accuracy: 0.6897\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6636 - accuracy: 0.62 - 0s 138us/sample - loss: 0.5587 - accuracy: 0.7155 - val_loss: 0.5540 - val_accuracy: 0.7931\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6741 - accuracy: 0.59 - 0s 129us/sample - loss: 0.5248 - accuracy: 0.7759 - val_loss: 0.5720 - val_accuracy: 0.7241\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5343 - accuracy: 0.71 - 0s 138us/sample - loss: 0.5180 - accuracy: 0.7586 - val_loss: 0.6788 - val_accuracy: 0.6552\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4178 - accuracy: 0.87 - 0s 129us/sample - loss: 0.5210 - accuracy: 0.7845 - val_loss: 0.5909 - val_accuracy: 0.7586\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5193 - accuracy: 0.7155 - val_loss: 0.6308 - val_accuracy: 0.7241\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4466 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4925 - accuracy: 0.7672 - val_loss: 0.6634 - val_accuracy: 0.7241\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6430 - accuracy: 0.75 - 0s 138us/sample - loss: 0.5298 - accuracy: 0.7586 - val_loss: 0.6297 - val_accuracy: 0.6897\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4795 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5058 - accuracy: 0.7759 - val_loss: 0.6374 - val_accuracy: 0.7241\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5882 - accuracy: 0.71 - 0s 155us/sample - loss: 0.4823 - accuracy: 0.7845 - val_loss: 0.6493 - val_accuracy: 0.7931\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4062 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4979 - accuracy: 0.7500 - val_loss: 0.7071 - val_accuracy: 0.8276\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4417 - accuracy: 0.78 - 0s 129us/sample - loss: 0.4583 - accuracy: 0.7759 - val_loss: 0.8310 - val_accuracy: 0.7586\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5309 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4471 - accuracy: 0.7845 - val_loss: 0.8007 - val_accuracy: 0.7586\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4799 - accuracy: 0.78 - 0s 129us/sample - loss: 0.4694 - accuracy: 0.7759 - val_loss: 0.8902 - val_accuracy: 0.7931\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4095 - accuracy: 0.78 - 0s 129us/sample - loss: 0.4281 - accuracy: 0.8017 - val_loss: 0.8614 - val_accuracy: 0.8276\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.81 - 0s 129us/sample - loss: 0.4111 - accuracy: 0.8103 - val_loss: 0.8892 - val_accuracy: 0.7931\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4263 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4149 - accuracy: 0.8017 - val_loss: 1.0620 - val_accuracy: 0.7586\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3260 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3949 - accuracy: 0.8103 - val_loss: 1.2644 - val_accuracy: 0.7586\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4215 - accuracy: 0.78 - 0s 146us/sample - loss: 0.3706 - accuracy: 0.8448 - val_loss: 1.2051 - val_accuracy: 0.7241\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3568 - accuracy: 0.84 - 0s 137us/sample - loss: 0.4985 - accuracy: 0.7845 - val_loss: 1.3866 - val_accuracy: 0.7241\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5124 - accuracy: 0.71 - 0s 138us/sample - loss: 0.5096 - accuracy: 0.7241 - val_loss: 1.0725 - val_accuracy: 0.7931\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.90 - 0s 129us/sample - loss: 0.4573 - accuracy: 0.8103 - val_loss: 1.1076 - val_accuracy: 0.7241\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4417 - accuracy: 0.7931 - val_loss: 1.1043 - val_accuracy: 0.7586\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4988 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4639 - accuracy: 0.8448 - val_loss: 1.0982 - val_accuracy: 0.7241\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4142 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4369 - accuracy: 0.8017 - val_loss: 1.0833 - val_accuracy: 0.7931\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3050 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4151 - accuracy: 0.8017 - val_loss: 1.3179 - val_accuracy: 0.7241\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3879 - accuracy: 0.8362 - val_loss: 1.4885 - val_accuracy: 0.6897\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3606 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3784 - accuracy: 0.8621 - val_loss: 1.3929 - val_accuracy: 0.6897\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.84 - 0s 139us/sample - loss: 0.3740 - accuracy: 0.8190 - val_loss: 1.6112 - val_accuracy: 0.6897\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5585 - accuracy: 0.71 - 0s 146us/sample - loss: 0.4634 - accuracy: 0.7845 - val_loss: 1.1754 - val_accuracy: 0.7931\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2220 - accuracy: 0.93 - 0s 146us/sample - loss: 0.4111 - accuracy: 0.8103 - val_loss: 1.6454 - val_accuracy: 0.7586\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3520 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3936 - accuracy: 0.8276 - val_loss: 1.7052 - val_accuracy: 0.6897\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4819 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4044 - accuracy: 0.8017 - val_loss: 1.7408 - val_accuracy: 0.7241\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2555 - accuracy: 0.90 - 0s 131us/sample - loss: 0.3556 - accuracy: 0.8362 - val_loss: 2.3517 - val_accuracy: 0.6897\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5243 - accuracy: 0.68 - 0s 155us/sample - loss: 0.4081 - accuracy: 0.8103 - val_loss: 1.6923 - val_accuracy: 0.7931\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3913 - accuracy: 0.8103 - val_loss: 1.4642 - val_accuracy: 0.7586\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3887 - accuracy: 0.78 - 0s 155us/sample - loss: 0.3597 - accuracy: 0.8448 - val_loss: 1.7213 - val_accuracy: 0.7241\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5186 - accuracy: 0.75 - 0s 138us/sample - loss: 0.3910 - accuracy: 0.8190 - val_loss: 1.5907 - val_accuracy: 0.6897\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2560 - accuracy: 0.93 - 0s 172us/sample - loss: 0.3519 - accuracy: 0.8534 - val_loss: 1.8322 - val_accuracy: 0.7586\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4741 - accuracy: 0.78 - 0s 180us/sample - loss: 0.3592 - accuracy: 0.8190 - val_loss: 1.7670 - val_accuracy: 0.7586\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.87 - 0s 215us/sample - loss: 0.3736 - accuracy: 0.8448 - val_loss: 1.4829 - val_accuracy: 0.7586\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4229 - accuracy: 0.81 - 0s 243us/sample - loss: 0.3535 - accuracy: 0.8362 - val_loss: 1.4731 - val_accuracy: 0.7586\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3435 - accuracy: 0.87 - 0s 189us/sample - loss: 0.3671 - accuracy: 0.8362 - val_loss: 1.5566 - val_accuracy: 0.7586\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4945 - accuracy: 0.75 - 0s 146us/sample - loss: 0.3492 - accuracy: 0.8190 - val_loss: 1.6925 - val_accuracy: 0.7586\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2829 - accuracy: 0.84 - 0s 172us/sample - loss: 0.3289 - accuracy: 0.8448 - val_loss: 1.9566 - val_accuracy: 0.6897\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4312 - accuracy: 0.81 - 0s 157us/sample - loss: 0.3473 - accuracy: 0.8276 - val_loss: 2.0722 - val_accuracy: 0.6897\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3285 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3335 - accuracy: 0.8448 - val_loss: 2.0152 - val_accuracy: 0.6897\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1826 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2995 - accuracy: 0.8621 - val_loss: 2.1511 - val_accuracy: 0.7241\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3326 - accuracy: 0.8190 - val_loss: 1.9749 - val_accuracy: 0.7931\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2399 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3071 - accuracy: 0.8707 - val_loss: 2.0776 - val_accuracy: 0.7586\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3079 - accuracy: 0.8707 - val_loss: 2.2453 - val_accuracy: 0.7241\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2675 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2997 - accuracy: 0.8793 - val_loss: 2.1935 - val_accuracy: 0.7586\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3962 - accuracy: 0.84 - 0s 163us/sample - loss: 0.3133 - accuracy: 0.8534 - val_loss: 2.3133 - val_accuracy: 0.7241\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2508 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2674 - accuracy: 0.8879 - val_loss: 2.2986 - val_accuracy: 0.7931\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3006 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2804 - accuracy: 0.8793 - val_loss: 2.5064 - val_accuracy: 0.7586\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3027 - accuracy: 0.81 - 0s 138us/sample - loss: 0.2685 - accuracy: 0.8707 - val_loss: 2.7374 - val_accuracy: 0.6897\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2580 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2805 - accuracy: 0.8621 - val_loss: 2.8949 - val_accuracy: 0.7586\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1529 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2827 - accuracy: 0.8707 - val_loss: 2.6148 - val_accuracy: 0.7586\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.96 - 0s 155us/sample - loss: 0.3094 - accuracy: 0.8707 - val_loss: 2.3322 - val_accuracy: 0.6897\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2626 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2638 - accuracy: 0.9052 - val_loss: 2.2073 - val_accuracy: 0.7241\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2053 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2611 - accuracy: 0.8879 - val_loss: 2.4458 - val_accuracy: 0.7241\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2751 - accuracy: 0.8707 - val_loss: 2.4099 - val_accuracy: 0.7241\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1695 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2794 - accuracy: 0.8707 - val_loss: 2.3385 - val_accuracy: 0.7931\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3439 - accuracy: 0.8448 - val_loss: 2.5185 - val_accuracy: 0.7241\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.96 - 0s 146us/sample - loss: 0.3449 - accuracy: 0.8448 - val_loss: 2.2539 - val_accuracy: 0.7241\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3896 - accuracy: 0.78 - 0s 172us/sample - loss: 0.3171 - accuracy: 0.8103 - val_loss: 2.3154 - val_accuracy: 0.7586\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4474 - accuracy: 0.71 - 0s 172us/sample - loss: 0.3371 - accuracy: 0.8448 - val_loss: 2.2514 - val_accuracy: 0.7241\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.90 - 0s 215us/sample - loss: 0.2818 - accuracy: 0.8966 - val_loss: 2.3073 - val_accuracy: 0.6897\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3145 - accuracy: 0.8534 - val_loss: 2.4190 - val_accuracy: 0.6897\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3189 - accuracy: 0.8190 - val_loss: 2.5126 - val_accuracy: 0.7241\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2508 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3543 - accuracy: 0.8448 - val_loss: 2.1079 - val_accuracy: 0.7931\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6916 - accuracy: 0.71 - 0s 138us/sample - loss: 0.4437 - accuracy: 0.7931 - val_loss: 2.7270 - val_accuracy: 0.6207\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4467 - accuracy: 0.84 - 0s 129us/sample - loss: 0.4342 - accuracy: 0.8276 - val_loss: 2.2134 - val_accuracy: 0.7241\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3133 - accuracy: 0.84 - 0s 137us/sample - loss: 0.3702 - accuracy: 0.8534 - val_loss: 1.9539 - val_accuracy: 0.7241\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2350 - accuracy: 0.90 - 0s 137us/sample - loss: 0.4125 - accuracy: 0.8276 - val_loss: 1.7989 - val_accuracy: 0.6897\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3643 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3764 - accuracy: 0.8707 - val_loss: 1.8266 - val_accuracy: 0.6897\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3573 - accuracy: 0.84 - 0s 120us/sample - loss: 0.3382 - accuracy: 0.8966 - val_loss: 1.7538 - val_accuracy: 0.8276\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.93 - 0s 129us/sample - loss: 0.3541 - accuracy: 0.8448 - val_loss: 1.9033 - val_accuracy: 0.7931\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3218 - accuracy: 0.78 - 0s 112us/sample - loss: 0.3138 - accuracy: 0.8534 - val_loss: 2.2953 - val_accuracy: 0.6552\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2881 - accuracy: 0.9052 - val_loss: 2.4603 - val_accuracy: 0.7241\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3054 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2794 - accuracy: 0.8793 - val_loss: 2.5891 - val_accuracy: 0.7586\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2396 - accuracy: 0.9138 - val_loss: 2.8679 - val_accuracy: 0.6897\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2264 - accuracy: 0.9224 - val_loss: 2.9727 - val_accuracy: 0.7586\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4022 - accuracy: 0.81 - 0s 120us/sample - loss: 0.2229 - accuracy: 0.9138 - val_loss: 3.2327 - val_accuracy: 0.7241\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2135 - accuracy: 0.9224 - val_loss: 3.6937 - val_accuracy: 0.6897\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.3235 - accuracy: 0.84 - 0s 120us/sample - loss: 0.2688 - accuracy: 0.8793 - val_loss: 3.4345 - val_accuracy: 0.7586\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3361 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2670 - accuracy: 0.8707 - val_loss: 3.2602 - val_accuracy: 0.6897\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.96 - 0s 120us/sample - loss: 0.2707 - accuracy: 0.8879 - val_loss: 3.1306 - val_accuracy: 0.7586\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.90 - 0s 120us/sample - loss: 0.2460 - accuracy: 0.8707 - val_loss: 3.2378 - val_accuracy: 0.7586\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2174 - accuracy: 0.9138 - val_loss: 3.3013 - val_accuracy: 0.7586\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2520 - accuracy: 0.84 - 0s 129us/sample - loss: 0.1888 - accuracy: 0.9052 - val_loss: 3.3419 - val_accuracy: 0.7586\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2148 - accuracy: 0.9224 - val_loss: 3.3436 - val_accuracy: 0.6897\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2122 - accuracy: 0.8966 - val_loss: 3.2529 - val_accuracy: 0.7586\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.93 - 0s 120us/sample - loss: 0.2962 - accuracy: 0.8621 - val_loss: 3.1447 - val_accuracy: 0.7586\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2745 - accuracy: 0.8534 - val_loss: 3.0163 - val_accuracy: 0.6897\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1122 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2047 - accuracy: 0.9224 - val_loss: 2.9717 - val_accuracy: 0.7241\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2193 - accuracy: 0.9052 - val_loss: 2.8799 - val_accuracy: 0.6897\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1929 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1782 - accuracy: 0.9310 - val_loss: 2.9094 - val_accuracy: 0.6552\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1472 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1947 - accuracy: 0.9310 - val_loss: 2.9324 - val_accuracy: 0.7241\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2251 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1763 - accuracy: 0.9224 - val_loss: 3.1204 - val_accuracy: 0.7586\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1666 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1658 - accuracy: 0.9310 - val_loss: 3.4387 - val_accuracy: 0.6207\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1333 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1468 - accuracy: 0.9397 - val_loss: 3.4059 - val_accuracy: 0.7931\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 0.96 - 0s 137us/sample - loss: 0.2290 - accuracy: 0.8707 - val_loss: 3.9967 - val_accuracy: 0.6207\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5277 - accuracy: 0.87 - 0s 120us/sample - loss: 0.3926 - accuracy: 0.8793 - val_loss: 2.5867 - val_accuracy: 0.7241\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4558 - accuracy: 0.84 - 0s 120us/sample - loss: 0.3398 - accuracy: 0.8621 - val_loss: 2.1318 - val_accuracy: 0.7586\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3524 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2904 - accuracy: 0.8879 - val_loss: 1.8852 - val_accuracy: 0.7586\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2927 - accuracy: 0.8707 - val_loss: 1.8284 - val_accuracy: 0.7586\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2865 - accuracy: 0.8793 - val_loss: 1.8791 - val_accuracy: 0.7586\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2597 - accuracy: 0.87 - 0s 120us/sample - loss: 0.2544 - accuracy: 0.9052 - val_loss: 1.9398 - val_accuracy: 0.7241\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2833 - accuracy: 0.87 - 0s 120us/sample - loss: 0.2449 - accuracy: 0.8879 - val_loss: 2.0778 - val_accuracy: 0.7586\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2156 - accuracy: 0.9138 - val_loss: 2.2120 - val_accuracy: 0.7931\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2000 - accuracy: 0.9138 - val_loss: 2.3163 - val_accuracy: 0.7586\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2391 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2054 - accuracy: 0.9138 - val_loss: 2.4774 - val_accuracy: 0.8276\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2001 - accuracy: 0.9138 - val_loss: 2.7105 - val_accuracy: 0.7241\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1426 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1770 - accuracy: 0.9310 - val_loss: 2.8403 - val_accuracy: 0.7586\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2468 - accuracy: 0.84 - 0s 163us/sample - loss: 0.1736 - accuracy: 0.9052 - val_loss: 2.8513 - val_accuracy: 0.7241\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1980 - accuracy: 0.9138 - val_loss: 3.2058 - val_accuracy: 0.6897\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1577 - accuracy: 0.9397 - val_loss: 3.3682 - val_accuracy: 0.7586\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 1.00 - 0s 164us/sample - loss: 0.2399 - accuracy: 0.8879 - val_loss: 3.2110 - val_accuracy: 0.7241\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 1.00 - 0s 120us/sample - loss: 0.2433 - accuracy: 0.8879 - val_loss: 3.0966 - val_accuracy: 0.6552\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2318 - accuracy: 0.9138 - val_loss: 2.8647 - val_accuracy: 0.7241\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1476 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1849 - accuracy: 0.9310 - val_loss: 3.0199 - val_accuracy: 0.6897\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1739 - accuracy: 0.9397 - val_loss: 2.7779 - val_accuracy: 0.7241\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2747 - accuracy: 0.87 - 0s 140us/sample - loss: 0.2117 - accuracy: 0.9138 - val_loss: 2.9555 - val_accuracy: 0.6552\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0715 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1614 - accuracy: 0.9569 - val_loss: 3.2869 - val_accuracy: 0.6552\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2253 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1596 - accuracy: 0.9483 - val_loss: 3.2725 - val_accuracy: 0.7241\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1547 - accuracy: 0.9310 - val_loss: 3.4122 - val_accuracy: 0.6897\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1235 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1370 - accuracy: 0.9569 - val_loss: 3.3878 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0769 - accuracy: 1.00 - 0s 133us/sample - loss: 0.1508 - accuracy: 0.9052 - val_loss: 3.4701 - val_accuracy: 0.7241\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1256 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1912 - accuracy: 0.9224 - val_loss: 3.5361 - val_accuracy: 0.7931\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1941 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1860 - accuracy: 0.8879 - val_loss: 3.6319 - val_accuracy: 0.6552\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 1.00 - 0s 120us/sample - loss: 0.1454 - accuracy: 0.9310 - val_loss: 3.1712 - val_accuracy: 0.7931\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1258 - accuracy: 0.9310 - val_loss: 3.4103 - val_accuracy: 0.7241\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1492 - accuracy: 0.9397 - val_loss: 3.2436 - val_accuracy: 0.7586\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1739 - accuracy: 0.9224 - val_loss: 3.6522 - val_accuracy: 0.5862\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0780 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1319 - accuracy: 0.9569 - val_loss: 3.8175 - val_accuracy: 0.6552\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0760 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1560 - accuracy: 0.9397 - val_loss: 3.1372 - val_accuracy: 0.7241\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 1.00 - 0s 138us/sample - loss: 0.2491 - accuracy: 0.9052 - val_loss: 4.0688 - val_accuracy: 0.5517\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.8181 - accuracy: 0.65 - 0s 137us/sample - loss: 0.4131 - accuracy: 0.8362 - val_loss: 3.1627 - val_accuracy: 0.7586\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3023 - accuracy: 0.8879 - val_loss: 2.8685 - val_accuracy: 0.6897\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2206 - accuracy: 0.9052 - val_loss: 2.4828 - val_accuracy: 0.7931\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1917 - accuracy: 0.9138 - val_loss: 2.4504 - val_accuracy: 0.8276\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1772 - accuracy: 0.9310 - val_loss: 2.6062 - val_accuracy: 0.6897\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1337 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1560 - accuracy: 0.9483 - val_loss: 2.5121 - val_accuracy: 0.7586\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1649 - accuracy: 0.9483 - val_loss: 2.8509 - val_accuracy: 0.6897\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1294 - accuracy: 0.9655 - val_loss: 3.0707 - val_accuracy: 0.6897\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 1.00 - 0s 137us/sample - loss: 0.1262 - accuracy: 0.9741 - val_loss: 3.2790 - val_accuracy: 0.7586\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1182 - accuracy: 0.9655 - val_loss: 3.5488 - val_accuracy: 0.7241\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 1.00 - 0s 120us/sample - loss: 0.1055 - accuracy: 0.9655 - val_loss: 3.7201 - val_accuracy: 0.7241\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0980 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0917 - accuracy: 0.9741 - val_loss: 4.0828 - val_accuracy: 0.6897\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1025 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0940 - accuracy: 0.9569 - val_loss: 4.3278 - val_accuracy: 0.7241\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0884 - accuracy: 0.9569 - val_loss: 4.6596 - val_accuracy: 0.7241\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0877 - accuracy: 0.9655 - val_loss: 4.7685 - val_accuracy: 0.7241\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0844 - accuracy: 0.9397 - val_loss: 5.0987 - val_accuracy: 0.6897\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0703 - accuracy: 0.9741 - val_loss: 5.1748 - val_accuracy: 0.7586\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.96 - 0s 137us/sample - loss: 0.1130 - accuracy: 0.9655 - val_loss: 5.0820 - val_accuracy: 0.7241\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1901 - accuracy: 0.9224 - val_loss: 5.4843 - val_accuracy: 0.5862\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2049 - accuracy: 0.9052 - val_loss: 5.7880 - val_accuracy: 0.7241\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2557 - accuracy: 0.84 - 0s 155us/sample - loss: 0.1601 - accuracy: 0.9052 - val_loss: 4.6362 - val_accuracy: 0.6552\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1210 - accuracy: 0.9741 - val_loss: 3.2573 - val_accuracy: 0.7241\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2705 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1161 - accuracy: 0.9569 - val_loss: 2.7367 - val_accuracy: 0.6897\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1113 - accuracy: 0.9741 - val_loss: 2.4165 - val_accuracy: 0.7931\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1576 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1285 - accuracy: 0.9483 - val_loss: 2.9119 - val_accuracy: 0.6552\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1443 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1195 - accuracy: 0.9310 - val_loss: 2.8769 - val_accuracy: 0.7241\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0763 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1197 - accuracy: 0.9569 - val_loss: 3.1596 - val_accuracy: 0.6207\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0347 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1643 - accuracy: 0.9310 - val_loss: 2.7746 - val_accuracy: 0.7931\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2069 - accuracy: 0.9224 - val_loss: 3.2699 - val_accuracy: 0.5862\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.81 - 0s 155us/sample - loss: 0.2857 - accuracy: 0.8966 - val_loss: 2.6770 - val_accuracy: 0.7241\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1405 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1691 - accuracy: 0.9052 - val_loss: 2.4997 - val_accuracy: 0.6897\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.90 - 0s 120us/sample - loss: 0.1484 - accuracy: 0.9483 - val_loss: 2.5317 - val_accuracy: 0.6552\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1120 - accuracy: 0.9569 - val_loss: 2.5591 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0947 - accuracy: 0.9741 - val_loss: 2.7094 - val_accuracy: 0.6207\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0903 - accuracy: 0.9655 - val_loss: 2.7404 - val_accuracy: 0.6552\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0751 - accuracy: 0.9741 - val_loss: 2.8849 - val_accuracy: 0.6552\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 1.00 - 0s 198us/sample - loss: 0.0668 - accuracy: 0.9828 - val_loss: 2.9687 - val_accuracy: 0.6552\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 1.00 - 0s 181us/sample - loss: 0.0589 - accuracy: 0.9914 - val_loss: 3.0609 - val_accuracy: 0.6897\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0493 - accuracy: 0.9914 - val_loss: 3.2963 - val_accuracy: 0.6552\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0528 - accuracy: 1.00 - 0s 215us/sample - loss: 0.0632 - accuracy: 0.9741 - val_loss: 3.4558 - val_accuracy: 0.7241\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.96 - 0s 172us/sample - loss: 0.0868 - accuracy: 0.9655 - val_loss: 3.7661 - val_accuracy: 0.6552\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0636 - accuracy: 0.9828 - val_loss: 3.6541 - val_accuracy: 0.6897\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0844 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0496 - accuracy: 0.9828 - val_loss: 3.7980 - val_accuracy: 0.6552\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0513 - accuracy: 0.9655 - val_loss: 3.7695 - val_accuracy: 0.7241\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0450 - accuracy: 0.9914 - val_loss: 3.7858 - val_accuracy: 0.6552\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1095 - accuracy: 0.9655 - val_loss: 3.9199 - val_accuracy: 0.6552\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6748 - accuracy: 0.75 - 0s 3ms/sample - loss: 0.6743 - accuracy: 0.6638 - val_loss: 0.6318 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6388 - accuracy: 0.65 - 0s 155us/sample - loss: 0.6330 - accuracy: 0.6638 - val_loss: 0.6277 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5980 - accuracy: 0.71 - 0s 138us/sample - loss: 0.6267 - accuracy: 0.6638 - val_loss: 0.6124 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.71 - 0s 146us/sample - loss: 0.6128 - accuracy: 0.6638 - val_loss: 0.6069 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5709 - accuracy: 0.71 - 0s 146us/sample - loss: 0.6068 - accuracy: 0.6638 - val_loss: 0.5986 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5253 - accuracy: 0.75 - 0s 146us/sample - loss: 0.6031 - accuracy: 0.6638 - val_loss: 0.5903 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7273 - accuracy: 0.59 - 0s 146us/sample - loss: 0.5990 - accuracy: 0.6638 - val_loss: 0.5840 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6250 - accuracy: 0.59 - 0s 146us/sample - loss: 0.5870 - accuracy: 0.6638 - val_loss: 0.5781 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4855 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5887 - accuracy: 0.6638 - val_loss: 0.5783 - val_accuracy: 0.7241\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6458 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5778 - accuracy: 0.7241 - val_loss: 0.5616 - val_accuracy: 0.6897\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5821 - accuracy: 0.68 - 0s 146us/sample - loss: 0.5798 - accuracy: 0.7069 - val_loss: 0.5580 - val_accuracy: 0.7241\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5664 - accuracy: 0.75 - 0s 146us/sample - loss: 0.5709 - accuracy: 0.7155 - val_loss: 0.5627 - val_accuracy: 0.6897\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5769 - accuracy: 0.68 - 0s 146us/sample - loss: 0.5728 - accuracy: 0.7328 - val_loss: 0.5548 - val_accuracy: 0.6897\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6339 - accuracy: 0.62 - 0s 146us/sample - loss: 0.5645 - accuracy: 0.7414 - val_loss: 0.5702 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5399 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5646 - accuracy: 0.7328 - val_loss: 0.5582 - val_accuracy: 0.7241\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5411 - accuracy: 0.75 - 0s 138us/sample - loss: 0.5586 - accuracy: 0.7414 - val_loss: 0.5435 - val_accuracy: 0.7241\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4985 - accuracy: 0.81 - 0s 137us/sample - loss: 0.5493 - accuracy: 0.7328 - val_loss: 0.5511 - val_accuracy: 0.6552\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5291 - accuracy: 0.68 - 0s 146us/sample - loss: 0.5361 - accuracy: 0.7328 - val_loss: 0.5451 - val_accuracy: 0.6897\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5444 - accuracy: 0.75 - 0s 138us/sample - loss: 0.5376 - accuracy: 0.7328 - val_loss: 0.5420 - val_accuracy: 0.7241\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4611 - accuracy: 0.84 - 0s 155us/sample - loss: 0.5158 - accuracy: 0.7845 - val_loss: 0.5277 - val_accuracy: 0.7241\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3433 - accuracy: 0.90 - 0s 146us/sample - loss: 0.4881 - accuracy: 0.7845 - val_loss: 0.6270 - val_accuracy: 0.5862\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5491 - accuracy: 0.65 - 0s 138us/sample - loss: 0.5241 - accuracy: 0.7328 - val_loss: 0.5528 - val_accuracy: 0.7241\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6067 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4717 - accuracy: 0.7759 - val_loss: 0.5907 - val_accuracy: 0.7241\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4567 - accuracy: 0.7931 - val_loss: 0.5993 - val_accuracy: 0.7586\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4788 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4579 - accuracy: 0.7931 - val_loss: 0.6083 - val_accuracy: 0.6897\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2900 - accuracy: 0.90 - 0s 146us/sample - loss: 0.4996 - accuracy: 0.7414 - val_loss: 0.7351 - val_accuracy: 0.7241\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5613 - accuracy: 0.65 - 0s 146us/sample - loss: 0.4725 - accuracy: 0.7500 - val_loss: 0.5792 - val_accuracy: 0.6897\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5109 - accuracy: 0.78 - 0s 129us/sample - loss: 0.4536 - accuracy: 0.8103 - val_loss: 0.6407 - val_accuracy: 0.6552\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4790 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4303 - accuracy: 0.8190 - val_loss: 0.6590 - val_accuracy: 0.6552\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4937 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4006 - accuracy: 0.8362 - val_loss: 0.7970 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4386 - accuracy: 0.81 - 0s 151us/sample - loss: 0.4160 - accuracy: 0.8190 - val_loss: 0.8296 - val_accuracy: 0.6897\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3968 - accuracy: 0.8534 - val_loss: 0.7193 - val_accuracy: 0.6897\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3165 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3850 - accuracy: 0.8362 - val_loss: 0.7703 - val_accuracy: 0.7241\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3011 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3911 - accuracy: 0.8362 - val_loss: 0.8524 - val_accuracy: 0.6897\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4019 - accuracy: 0.87 - 0s 137us/sample - loss: 0.3708 - accuracy: 0.8707 - val_loss: 0.9619 - val_accuracy: 0.6897\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2168 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3504 - accuracy: 0.8707 - val_loss: 0.9046 - val_accuracy: 0.6552\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3612 - accuracy: 0.8362 - val_loss: 1.0097 - val_accuracy: 0.7241\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4505 - accuracy: 0.75 - 0s 146us/sample - loss: 0.3629 - accuracy: 0.8448 - val_loss: 0.8213 - val_accuracy: 0.6897\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2891 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3356 - accuracy: 0.8621 - val_loss: 0.8807 - val_accuracy: 0.7241\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4222 - accuracy: 0.81 - 0s 144us/sample - loss: 0.3216 - accuracy: 0.8793 - val_loss: 1.0691 - val_accuracy: 0.7586\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3347 - accuracy: 0.8793 - val_loss: 1.1677 - val_accuracy: 0.7241\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3254 - accuracy: 0.84 - 0s 137us/sample - loss: 0.3326 - accuracy: 0.8534 - val_loss: 1.1604 - val_accuracy: 0.7241\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.93 - 0s 146us/sample - loss: 0.3253 - accuracy: 0.8793 - val_loss: 1.1890 - val_accuracy: 0.7931\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2764 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3269 - accuracy: 0.8707 - val_loss: 1.1525 - val_accuracy: 0.7241\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2051 - accuracy: 0.96 - 0s 172us/sample - loss: 0.4004 - accuracy: 0.8448 - val_loss: 0.9760 - val_accuracy: 0.7586\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.90 - 0s 163us/sample - loss: 0.3873 - accuracy: 0.8362 - val_loss: 1.0848 - val_accuracy: 0.7241\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3668 - accuracy: 0.84 - 0s 163us/sample - loss: 0.3848 - accuracy: 0.8276 - val_loss: 1.2074 - val_accuracy: 0.7241\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3379 - accuracy: 0.87 - 0s 146us/sample - loss: 0.4004 - accuracy: 0.8276 - val_loss: 1.3556 - val_accuracy: 0.6897\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4194 - accuracy: 0.8190 - val_loss: 1.1332 - val_accuracy: 0.7241\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3717 - accuracy: 0.84 - 0s 129us/sample - loss: 0.4357 - accuracy: 0.8103 - val_loss: 1.5019 - val_accuracy: 0.6897\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5576 - accuracy: 0.71 - 0s 120us/sample - loss: 0.4478 - accuracy: 0.8017 - val_loss: 0.6834 - val_accuracy: 0.7241\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.90 - 0s 120us/sample - loss: 0.4451 - accuracy: 0.8017 - val_loss: 0.4539 - val_accuracy: 0.8276\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2811 - accuracy: 0.87 - 0s 129us/sample - loss: 0.4202 - accuracy: 0.8103 - val_loss: 1.4672 - val_accuracy: 0.6897\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.84 - 0s 120us/sample - loss: 0.4195 - accuracy: 0.8103 - val_loss: 0.7141 - val_accuracy: 0.6897\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.87 - 0s 134us/sample - loss: 0.4378 - accuracy: 0.7931 - val_loss: 0.6027 - val_accuracy: 0.7241\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3674 - accuracy: 0.81 - 0s 129us/sample - loss: 0.4012 - accuracy: 0.8276 - val_loss: 0.8346 - val_accuracy: 0.6897\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4650 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4341 - accuracy: 0.8017 - val_loss: 0.6510 - val_accuracy: 0.7241\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3996 - accuracy: 0.84 - 0s 120us/sample - loss: 0.3962 - accuracy: 0.8103 - val_loss: 0.7510 - val_accuracy: 0.6897\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3596 - accuracy: 0.8534 - val_loss: 0.9754 - val_accuracy: 0.7241\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3816 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3852 - accuracy: 0.8448 - val_loss: 0.8128 - val_accuracy: 0.6897\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3667 - accuracy: 0.84 - 0s 120us/sample - loss: 0.3527 - accuracy: 0.8362 - val_loss: 0.9599 - val_accuracy: 0.7241\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3290 - accuracy: 0.8534 - val_loss: 1.2461 - val_accuracy: 0.7241\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3311 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3250 - accuracy: 0.8448 - val_loss: 1.2253 - val_accuracy: 0.6897\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3121 - accuracy: 0.8707 - val_loss: 1.3212 - val_accuracy: 0.7241\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2949 - accuracy: 0.8707 - val_loss: 1.4545 - val_accuracy: 0.7586\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3013 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2882 - accuracy: 0.8707 - val_loss: 1.2966 - val_accuracy: 0.6897\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4140 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3842 - accuracy: 0.8190 - val_loss: 1.0959 - val_accuracy: 0.7241\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3243 - accuracy: 0.8621 - val_loss: 0.9631 - val_accuracy: 0.7586\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3262 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3420 - accuracy: 0.8448 - val_loss: 1.3018 - val_accuracy: 0.7586\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3602 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3497 - accuracy: 0.8534 - val_loss: 0.6891 - val_accuracy: 0.7586\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5921 - accuracy: 0.71 - 0s 138us/sample - loss: 0.3865 - accuracy: 0.8534 - val_loss: 0.8447 - val_accuracy: 0.6897\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1850 - accuracy: 0.96 - 0s 146us/sample - loss: 0.3639 - accuracy: 0.8448 - val_loss: 0.9353 - val_accuracy: 0.6897\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3215 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3701 - accuracy: 0.8448 - val_loss: 0.9956 - val_accuracy: 0.7241\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3405 - accuracy: 0.87 - 0s 120us/sample - loss: 0.3477 - accuracy: 0.8448 - val_loss: 1.2106 - val_accuracy: 0.7241\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3058 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3439 - accuracy: 0.8534 - val_loss: 1.3836 - val_accuracy: 0.7241\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4595 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3414 - accuracy: 0.8448 - val_loss: 1.3267 - val_accuracy: 0.7241\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3326 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3289 - accuracy: 0.8621 - val_loss: 1.2912 - val_accuracy: 0.6207\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.93 - 0s 129us/sample - loss: 0.3390 - accuracy: 0.8534 - val_loss: 1.1912 - val_accuracy: 0.7241\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4078 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3437 - accuracy: 0.8448 - val_loss: 1.4335 - val_accuracy: 0.7241\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3486 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3331 - accuracy: 0.8621 - val_loss: 1.5747 - val_accuracy: 0.6897\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3057 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2984 - accuracy: 0.8621 - val_loss: 1.5300 - val_accuracy: 0.7241\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2314 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3209 - accuracy: 0.8534 - val_loss: 1.7331 - val_accuracy: 0.7241\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1680 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3030 - accuracy: 0.8621 - val_loss: 1.7032 - val_accuracy: 0.7586\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1360 - accuracy: 1.00 - 0s 163us/sample - loss: 0.3003 - accuracy: 0.8793 - val_loss: 1.6750 - val_accuracy: 0.7586\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2780 - accuracy: 0.8793 - val_loss: 1.6811 - val_accuracy: 0.7586\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2776 - accuracy: 0.87 - 0s 189us/sample - loss: 0.2754 - accuracy: 0.8793 - val_loss: 1.6657 - val_accuracy: 0.7586\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.90 - 0s 258us/sample - loss: 0.3077 - accuracy: 0.8793 - val_loss: 1.9640 - val_accuracy: 0.7931\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1856 - accuracy: 0.96 - 0s 163us/sample - loss: 0.2404 - accuracy: 0.9224 - val_loss: 2.1859 - val_accuracy: 0.7241\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2405 - accuracy: 0.9052 - val_loss: 2.3240 - val_accuracy: 0.7586\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2347 - accuracy: 0.87 - 0s 120us/sample - loss: 0.2374 - accuracy: 0.9052 - val_loss: 2.0888 - val_accuracy: 0.6897\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2105 - accuracy: 0.9224 - val_loss: 2.2777 - val_accuracy: 0.6207\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1807 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2517 - accuracy: 0.9138 - val_loss: 1.8546 - val_accuracy: 0.6897\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2558 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2438 - accuracy: 0.9052 - val_loss: 1.9470 - val_accuracy: 0.7241\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1879 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2683 - accuracy: 0.8966 - val_loss: 1.9413 - val_accuracy: 0.7241\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2330 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2613 - accuracy: 0.8707 - val_loss: 2.0338 - val_accuracy: 0.6897\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1417 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2769 - accuracy: 0.8879 - val_loss: 1.6555 - val_accuracy: 0.7241\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3725 - accuracy: 0.81 - 0s 138us/sample - loss: 0.2582 - accuracy: 0.8879 - val_loss: 1.5048 - val_accuracy: 0.7241\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1515 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2862 - accuracy: 0.8707 - val_loss: 1.5583 - val_accuracy: 0.7586\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3320 - accuracy: 0.8448 - val_loss: 2.2523 - val_accuracy: 0.7931\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3016 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2647 - accuracy: 0.8966 - val_loss: 1.5926 - val_accuracy: 0.7241\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.84 - 0s 120us/sample - loss: 0.2803 - accuracy: 0.8879 - val_loss: 1.8203 - val_accuracy: 0.7586\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2826 - accuracy: 0.8966 - val_loss: 1.5144 - val_accuracy: 0.7586\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1835 - accuracy: 0.93 - 0s 120us/sample - loss: 0.2771 - accuracy: 0.8793 - val_loss: 0.8034 - val_accuracy: 0.7241\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2350 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2657 - accuracy: 0.8707 - val_loss: 1.5799 - val_accuracy: 0.6552\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3429 - accuracy: 0.81 - 0s 151us/sample - loss: 0.2696 - accuracy: 0.8707 - val_loss: 1.8197 - val_accuracy: 0.6552\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2472 - accuracy: 0.8966 - val_loss: 1.6805 - val_accuracy: 0.7241\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.96 - 0s 137us/sample - loss: 0.2765 - accuracy: 0.9052 - val_loss: 1.8243 - val_accuracy: 0.7241\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.96 - 0s 120us/sample - loss: 0.2392 - accuracy: 0.9052 - val_loss: 1.9796 - val_accuracy: 0.7241\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2690 - accuracy: 0.8879 - val_loss: 1.9403 - val_accuracy: 0.7241\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3428 - accuracy: 0.81 - 0s 125us/sample - loss: 0.2799 - accuracy: 0.8707 - val_loss: 1.4246 - val_accuracy: 0.7241\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2291 - accuracy: 0.90 - 0s 120us/sample - loss: 0.2926 - accuracy: 0.8707 - val_loss: 1.2464 - val_accuracy: 0.6552\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3432 - accuracy: 0.81 - 0s 120us/sample - loss: 0.2693 - accuracy: 0.8534 - val_loss: 1.0341 - val_accuracy: 0.7586\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.90 - 0s 120us/sample - loss: 0.3147 - accuracy: 0.8534 - val_loss: 1.1575 - val_accuracy: 0.6897\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2420 - accuracy: 0.90 - 0s 120us/sample - loss: 0.2935 - accuracy: 0.8707 - val_loss: 1.3854 - val_accuracy: 0.7586\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1562 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2821 - accuracy: 0.8707 - val_loss: 1.7052 - val_accuracy: 0.7241\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1925 - accuracy: 0.90 - 0s 120us/sample - loss: 0.2721 - accuracy: 0.8621 - val_loss: 1.3888 - val_accuracy: 0.7241\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.1826 - accuracy: 0.90 - 0s 120us/sample - loss: 0.2549 - accuracy: 0.8879 - val_loss: 1.4105 - val_accuracy: 0.7586\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1734 - accuracy: 0.87 - 0s 120us/sample - loss: 0.2458 - accuracy: 0.8879 - val_loss: 1.8770 - val_accuracy: 0.7931\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2249 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2117 - accuracy: 0.9052 - val_loss: 2.0293 - val_accuracy: 0.7931\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2265 - accuracy: 0.96 - 0s 137us/sample - loss: 0.2005 - accuracy: 0.9224 - val_loss: 1.9948 - val_accuracy: 0.7586\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2831 - accuracy: 0.8879 - val_loss: 1.8784 - val_accuracy: 0.7931\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.81 - 0s 138us/sample - loss: 0.2184 - accuracy: 0.9052 - val_loss: 3.0352 - val_accuracy: 0.7241\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1257 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2937 - accuracy: 0.9138 - val_loss: 2.9984 - val_accuracy: 0.7586\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6543 - accuracy: 0.87 - 0s 146us/sample - loss: 0.4225 - accuracy: 0.8621 - val_loss: 1.6175 - val_accuracy: 0.6897\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.87 - 0s 137us/sample - loss: 0.3474 - accuracy: 0.8448 - val_loss: 2.1032 - val_accuracy: 0.6897\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1862 - accuracy: 0.93 - 0s 129us/sample - loss: 0.3243 - accuracy: 0.8879 - val_loss: 1.2111 - val_accuracy: 0.7241\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3179 - accuracy: 0.8793 - val_loss: 1.0648 - val_accuracy: 0.6897\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2850 - accuracy: 0.90 - 0s 137us/sample - loss: 0.2584 - accuracy: 0.9138 - val_loss: 1.1787 - val_accuracy: 0.6552\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1551 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2226 - accuracy: 0.9138 - val_loss: 1.2759 - val_accuracy: 0.7241\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2498 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2138 - accuracy: 0.9310 - val_loss: 1.3954 - val_accuracy: 0.7241\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1929 - accuracy: 0.9483 - val_loss: 1.5584 - val_accuracy: 0.6207\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1875 - accuracy: 0.9397 - val_loss: 1.6683 - val_accuracy: 0.6897\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3332 - accuracy: 0.87 - 0s 146us/sample - loss: 0.1791 - accuracy: 0.9397 - val_loss: 1.8521 - val_accuracy: 0.6552\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2499 - accuracy: 0.8966 - val_loss: 1.8701 - val_accuracy: 0.6897\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5200 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3284 - accuracy: 0.8793 - val_loss: 1.7129 - val_accuracy: 0.6897\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3369 - accuracy: 0.87 - 0s 140us/sample - loss: 0.2728 - accuracy: 0.8966 - val_loss: 1.6777 - val_accuracy: 0.6552\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2164 - accuracy: 0.9310 - val_loss: 1.4830 - val_accuracy: 0.7241\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1894 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2455 - accuracy: 0.8966 - val_loss: 1.7021 - val_accuracy: 0.6552\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2594 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1792 - accuracy: 0.9483 - val_loss: 1.9295 - val_accuracy: 0.6897\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2646 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2030 - accuracy: 0.9310 - val_loss: 1.8103 - val_accuracy: 0.6897\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.93 - 0s 142us/sample - loss: 0.2104 - accuracy: 0.9224 - val_loss: 2.1116 - val_accuracy: 0.6897\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2005 - accuracy: 0.9224 - val_loss: 2.4128 - val_accuracy: 0.6207\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1546 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1698 - accuracy: 0.9310 - val_loss: 2.3043 - val_accuracy: 0.6897\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 0.87 - 0s 129us/sample - loss: 0.1725 - accuracy: 0.9310 - val_loss: 2.3580 - val_accuracy: 0.7241\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1541 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1558 - accuracy: 0.9483 - val_loss: 2.4760 - val_accuracy: 0.7241\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1853 - accuracy: 0.9397 - val_loss: 2.1193 - val_accuracy: 0.7241\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1457 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1561 - accuracy: 0.9483 - val_loss: 2.6606 - val_accuracy: 0.6897\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2470 - accuracy: 0.9310 - val_loss: 2.2031 - val_accuracy: 0.7241\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1770 - accuracy: 0.9397 - val_loss: 1.6516 - val_accuracy: 0.6552\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.90 - 0s 142us/sample - loss: 0.2946 - accuracy: 0.8879 - val_loss: 1.4344 - val_accuracy: 0.7241\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0687 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2645 - accuracy: 0.8966 - val_loss: 1.4069 - val_accuracy: 0.7241\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2586 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2343 - accuracy: 0.8966 - val_loss: 1.4731 - val_accuracy: 0.6552\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2673 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2500 - accuracy: 0.9052 - val_loss: 1.4571 - val_accuracy: 0.6897\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2187 - accuracy: 0.8879 - val_loss: 1.6575 - val_accuracy: 0.7241\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2027 - accuracy: 0.9310 - val_loss: 1.9060 - val_accuracy: 0.6207\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.81 - 0s 146us/sample - loss: 0.1619 - accuracy: 0.9483 - val_loss: 2.1602 - val_accuracy: 0.6552\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1778 - accuracy: 0.9310 - val_loss: 2.6165 - val_accuracy: 0.6207\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1620 - accuracy: 0.9310 - val_loss: 2.9742 - val_accuracy: 0.6897\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1697 - accuracy: 0.9310 - val_loss: 2.8544 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1708 - accuracy: 0.9224 - val_loss: 2.8186 - val_accuracy: 0.6552\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2791 - accuracy: 0.9052 - val_loss: 3.1113 - val_accuracy: 0.5517\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3536 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2616 - accuracy: 0.8879 - val_loss: 2.2273 - val_accuracy: 0.7241\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2952 - accuracy: 0.8793 - val_loss: 2.3158 - val_accuracy: 0.6552\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2711 - accuracy: 0.9052 - val_loss: 1.7330 - val_accuracy: 0.6897\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2475 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2429 - accuracy: 0.9052 - val_loss: 1.5358 - val_accuracy: 0.6552\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2276 - accuracy: 0.8966 - val_loss: 1.6840 - val_accuracy: 0.6552\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1848 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1758 - accuracy: 0.9397 - val_loss: 1.8499 - val_accuracy: 0.6897\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1891 - accuracy: 0.9138 - val_loss: 2.2192 - val_accuracy: 0.6897\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1548 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1583 - accuracy: 0.9397 - val_loss: 2.6863 - val_accuracy: 0.6897\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.87 - 0s 120us/sample - loss: 0.1509 - accuracy: 0.9310 - val_loss: 2.4957 - val_accuracy: 0.6552\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2859 - accuracy: 0.9224 - val_loss: 2.3600 - val_accuracy: 0.6207\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1861 - accuracy: 0.9397 - val_loss: 2.2335 - val_accuracy: 0.6897\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1336 - accuracy: 0.9655 - val_loss: 2.3527 - val_accuracy: 0.6897\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1513 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1261 - accuracy: 0.9655 - val_loss: 2.7934 - val_accuracy: 0.5862\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1203 - accuracy: 0.9569 - val_loss: 2.6160 - val_accuracy: 0.6897\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1256 - accuracy: 0.9569 - val_loss: 2.6577 - val_accuracy: 0.6552\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1015 - accuracy: 0.9741 - val_loss: 2.9949 - val_accuracy: 0.6207\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1190 - accuracy: 0.9569 - val_loss: 2.9151 - val_accuracy: 0.6552\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1364 - accuracy: 0.9483 - val_loss: 2.9612 - val_accuracy: 0.6552\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1411 - accuracy: 0.9483 - val_loss: 3.1720 - val_accuracy: 0.6897\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1634 - accuracy: 0.9310 - val_loss: 2.8528 - val_accuracy: 0.7241\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1057 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1235 - accuracy: 0.9483 - val_loss: 2.7247 - val_accuracy: 0.6552\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1354 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1337 - accuracy: 0.9397 - val_loss: 2.5390 - val_accuracy: 0.7241\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1245 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1296 - accuracy: 0.9397 - val_loss: 2.7238 - val_accuracy: 0.6897\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1106 - accuracy: 0.9483 - val_loss: 2.8433 - val_accuracy: 0.6552\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.93 - 0s 137us/sample - loss: 0.1337 - accuracy: 0.9397 - val_loss: 2.9411 - val_accuracy: 0.6552\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1088 - accuracy: 0.9655 - val_loss: 3.1612 - val_accuracy: 0.6552\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0996 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1077 - accuracy: 0.9569 - val_loss: 2.7246 - val_accuracy: 0.6897\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1217 - accuracy: 0.9483 - val_loss: 2.6868 - val_accuracy: 0.6897\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1389 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1000 - accuracy: 0.9655 - val_loss: 2.5492 - val_accuracy: 0.6897\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2101 - accuracy: 0.9224 - val_loss: 2.6047 - val_accuracy: 0.6207\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3599 - accuracy: 0.8621 - val_loss: 2.4534 - val_accuracy: 0.6552\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0740 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2509 - accuracy: 0.9138 - val_loss: 2.7389 - val_accuracy: 0.6207\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4978 - accuracy: 0.84 - 0s 137us/sample - loss: 0.3032 - accuracy: 0.8793 - val_loss: 1.3171 - val_accuracy: 0.7241\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3378 - accuracy: 0.81 - 0s 129us/sample - loss: 0.2811 - accuracy: 0.8621 - val_loss: 1.0011 - val_accuracy: 0.6897\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2582 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2418 - accuracy: 0.8966 - val_loss: 1.0307 - val_accuracy: 0.6552\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1926 - accuracy: 0.9310 - val_loss: 1.0971 - val_accuracy: 0.6897\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1465 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1898 - accuracy: 0.9052 - val_loss: 1.1331 - val_accuracy: 0.7241\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1832 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1345 - accuracy: 0.9569 - val_loss: 1.2233 - val_accuracy: 0.6552\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1503 - accuracy: 0.9483 - val_loss: 1.3796 - val_accuracy: 0.6552\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6898 - accuracy: 0.62 - 0s 3ms/sample - loss: 0.6694 - accuracy: 0.6638 - val_loss: 0.6319 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6612 - accuracy: 0.62 - 0s 155us/sample - loss: 0.6324 - accuracy: 0.6638 - val_loss: 0.6223 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6162 - accuracy: 0.65 - 0s 155us/sample - loss: 0.6249 - accuracy: 0.6638 - val_loss: 0.6092 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6336 - accuracy: 0.62 - 0s 146us/sample - loss: 0.6229 - accuracy: 0.6379 - val_loss: 0.6324 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5884 - accuracy: 0.71 - 0s 149us/sample - loss: 0.6106 - accuracy: 0.6638 - val_loss: 0.5932 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7455 - accuracy: 0.56 - 0s 146us/sample - loss: 0.6120 - accuracy: 0.6638 - val_loss: 0.5969 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5436 - accuracy: 0.78 - 0s 146us/sample - loss: 0.6069 - accuracy: 0.6638 - val_loss: 0.5869 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6494 - accuracy: 0.59 - 0s 146us/sample - loss: 0.5987 - accuracy: 0.6638 - val_loss: 0.6032 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5590 - accuracy: 0.65 - 0s 138us/sample - loss: 0.5983 - accuracy: 0.6724 - val_loss: 0.5849 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5944 - accuracy: 0.68 - 0s 142us/sample - loss: 0.5900 - accuracy: 0.6983 - val_loss: 0.5799 - val_accuracy: 0.6897\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5811 - accuracy: 0.68 - 0s 146us/sample - loss: 0.5839 - accuracy: 0.6983 - val_loss: 0.5684 - val_accuracy: 0.6897\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6406 - accuracy: 0.68 - 0s 129us/sample - loss: 0.5835 - accuracy: 0.7069 - val_loss: 0.5709 - val_accuracy: 0.7586\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6231 - accuracy: 0.71 - 0s 129us/sample - loss: 0.5628 - accuracy: 0.7241 - val_loss: 0.5670 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6385 - accuracy: 0.65 - 0s 172us/sample - loss: 0.5629 - accuracy: 0.7069 - val_loss: 0.5838 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6513 - accuracy: 0.68 - 0s 198us/sample - loss: 0.5715 - accuracy: 0.7155 - val_loss: 0.5776 - val_accuracy: 0.7241\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.68 - 0s 206us/sample - loss: 0.5506 - accuracy: 0.7241 - val_loss: 0.5928 - val_accuracy: 0.6897\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5179 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5308 - accuracy: 0.7069 - val_loss: 0.7303 - val_accuracy: 0.6207\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4827 - accuracy: 0.75 - 0s 146us/sample - loss: 0.5458 - accuracy: 0.7155 - val_loss: 0.7036 - val_accuracy: 0.5862\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5577 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5315 - accuracy: 0.7241 - val_loss: 0.7577 - val_accuracy: 0.5862\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4989 - accuracy: 0.78 - 0s 138us/sample - loss: 0.5361 - accuracy: 0.6897 - val_loss: 0.8257 - val_accuracy: 0.6552\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4571 - accuracy: 0.78 - 0s 129us/sample - loss: 0.5164 - accuracy: 0.7241 - val_loss: 0.8486 - val_accuracy: 0.6552\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5685 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5177 - accuracy: 0.7241 - val_loss: 0.9021 - val_accuracy: 0.6897\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5102 - accuracy: 0.71 - 0s 163us/sample - loss: 0.4983 - accuracy: 0.7328 - val_loss: 0.9824 - val_accuracy: 0.7586\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6286 - accuracy: 0.56 - 0s 138us/sample - loss: 0.5286 - accuracy: 0.7586 - val_loss: 1.0495 - val_accuracy: 0.6897\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5197 - accuracy: 0.71 - 0s 129us/sample - loss: 0.4980 - accuracy: 0.7414 - val_loss: 1.0469 - val_accuracy: 0.6897\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.65 - 0s 129us/sample - loss: 0.4908 - accuracy: 0.7328 - val_loss: 1.1959 - val_accuracy: 0.7931\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4486 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4701 - accuracy: 0.7672 - val_loss: 1.3738 - val_accuracy: 0.7931\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3401 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4723 - accuracy: 0.7759 - val_loss: 1.6329 - val_accuracy: 0.7931\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4570 - accuracy: 0.81 - 0s 172us/sample - loss: 0.4561 - accuracy: 0.7759 - val_loss: 1.8138 - val_accuracy: 0.6897\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3696 - accuracy: 0.84 - 0s 249us/sample - loss: 0.4329 - accuracy: 0.7845 - val_loss: 1.7117 - val_accuracy: 0.7586\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4320 - accuracy: 0.78 - 0s 163us/sample - loss: 0.4249 - accuracy: 0.7845 - val_loss: 1.8816 - val_accuracy: 0.7241\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5611 - accuracy: 0.71 - 0s 146us/sample - loss: 0.4236 - accuracy: 0.8017 - val_loss: 2.0966 - val_accuracy: 0.7586\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4024 - accuracy: 0.78 - 0s 232us/sample - loss: 0.4125 - accuracy: 0.7931 - val_loss: 2.3765 - val_accuracy: 0.7586\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3287 - accuracy: 0.81 - 0s 163us/sample - loss: 0.4662 - accuracy: 0.7759 - val_loss: 1.9491 - val_accuracy: 0.8276\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.84 - 0s 163us/sample - loss: 0.4857 - accuracy: 0.7500 - val_loss: 1.6765 - val_accuracy: 0.8276\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4706 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4324 - accuracy: 0.8276 - val_loss: 1.7555 - val_accuracy: 0.7931\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3824 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4226 - accuracy: 0.8103 - val_loss: 1.8804 - val_accuracy: 0.8276\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4359 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4212 - accuracy: 0.8190 - val_loss: 2.0643 - val_accuracy: 0.7931\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4282 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3931 - accuracy: 0.8103 - val_loss: 2.2592 - val_accuracy: 0.6552\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4408 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4876 - accuracy: 0.7759 - val_loss: 1.9728 - val_accuracy: 0.7931\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3744 - accuracy: 0.87 - 0s 146us/sample - loss: 0.4203 - accuracy: 0.7931 - val_loss: 2.0783 - val_accuracy: 0.7241\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4017 - accuracy: 0.8362 - val_loss: 1.7879 - val_accuracy: 0.7931\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.90 - 0s 146us/sample - loss: 0.4088 - accuracy: 0.8103 - val_loss: 1.8569 - val_accuracy: 0.7931\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3143 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3781 - accuracy: 0.8190 - val_loss: 2.2285 - val_accuracy: 0.6897\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3842 - accuracy: 0.78 - 0s 129us/sample - loss: 0.3693 - accuracy: 0.8103 - val_loss: 2.2289 - val_accuracy: 0.7241\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.84 - 0s 120us/sample - loss: 0.3710 - accuracy: 0.8276 - val_loss: 2.3201 - val_accuracy: 0.6897\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.93 - 0s 120us/sample - loss: 0.3551 - accuracy: 0.8362 - val_loss: 2.2860 - val_accuracy: 0.8276\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3677 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3725 - accuracy: 0.8276 - val_loss: 2.4118 - val_accuracy: 0.7586\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2498 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3299 - accuracy: 0.8448 - val_loss: 2.5999 - val_accuracy: 0.6897\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2642 - accuracy: 0.90 - 0s 120us/sample - loss: 0.3489 - accuracy: 0.8621 - val_loss: 2.7424 - val_accuracy: 0.7241\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4323 - accuracy: 0.81 - 0s 116us/sample - loss: 0.3539 - accuracy: 0.8448 - val_loss: 2.6847 - val_accuracy: 0.7586\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2045 - accuracy: 0.90 - 0s 120us/sample - loss: 0.3432 - accuracy: 0.8362 - val_loss: 2.8954 - val_accuracy: 0.6897\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2269 - accuracy: 0.90 - 0s 120us/sample - loss: 0.3406 - accuracy: 0.8190 - val_loss: 2.7128 - val_accuracy: 0.7586\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3566 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3339 - accuracy: 0.8362 - val_loss: 2.8620 - val_accuracy: 0.7586\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.75 - 0s 129us/sample - loss: 0.3625 - accuracy: 0.8190 - val_loss: 2.9895 - val_accuracy: 0.7586\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2858 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3147 - accuracy: 0.8534 - val_loss: 3.1660 - val_accuracy: 0.7241\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3718 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3051 - accuracy: 0.8534 - val_loss: 3.2218 - val_accuracy: 0.7586\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3676 - accuracy: 0.78 - 0s 129us/sample - loss: 0.3080 - accuracy: 0.8362 - val_loss: 3.4997 - val_accuracy: 0.7586\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.90 - 0s 137us/sample - loss: 0.3418 - accuracy: 0.8448 - val_loss: 2.9391 - val_accuracy: 0.7931\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6569 - accuracy: 0.78 - 0s 138us/sample - loss: 0.5919 - accuracy: 0.7672 - val_loss: 2.9046 - val_accuracy: 0.7241\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6222 - accuracy: 0.68 - 0s 131us/sample - loss: 0.5619 - accuracy: 0.7500 - val_loss: 2.6534 - val_accuracy: 0.6552\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4705 - accuracy: 0.78 - 0s 129us/sample - loss: 0.4442 - accuracy: 0.8103 - val_loss: 1.5261 - val_accuracy: 0.6897\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4400 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4479 - accuracy: 0.7931 - val_loss: 1.0266 - val_accuracy: 0.7586\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 0.81 - 0s 129us/sample - loss: 0.4129 - accuracy: 0.8103 - val_loss: 0.8300 - val_accuracy: 0.7931\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3066 - accuracy: 0.84 - 0s 129us/sample - loss: 0.4016 - accuracy: 0.8017 - val_loss: 0.8597 - val_accuracy: 0.6897\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3866 - accuracy: 0.8103 - val_loss: 0.9076 - val_accuracy: 0.7586\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3596 - accuracy: 0.8448 - val_loss: 1.2308 - val_accuracy: 0.6897\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3951 - accuracy: 0.78 - 0s 129us/sample - loss: 0.3539 - accuracy: 0.8448 - val_loss: 1.2267 - val_accuracy: 0.7241\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2925 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3433 - accuracy: 0.8362 - val_loss: 1.3077 - val_accuracy: 0.7586\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2728 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3184 - accuracy: 0.8534 - val_loss: 1.6884 - val_accuracy: 0.6897\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1934 - accuracy: 0.96 - 0s 146us/sample - loss: 0.3229 - accuracy: 0.8621 - val_loss: 1.3570 - val_accuracy: 0.7241\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3333 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3393 - accuracy: 0.8448 - val_loss: 1.4918 - val_accuracy: 0.7241\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3670 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3487 - accuracy: 0.8276 - val_loss: 1.5156 - val_accuracy: 0.7241\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3153 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3135 - accuracy: 0.8793 - val_loss: 2.0071 - val_accuracy: 0.6897\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2824 - accuracy: 0.8879 - val_loss: 1.9532 - val_accuracy: 0.7241\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3154 - accuracy: 0.84 - 0s 133us/sample - loss: 0.2730 - accuracy: 0.8793 - val_loss: 2.0675 - val_accuracy: 0.7241\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2088 - accuracy: 0.90 - 0s 137us/sample - loss: 0.2561 - accuracy: 0.8879 - val_loss: 2.3867 - val_accuracy: 0.7241\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3133 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3104 - accuracy: 0.8707 - val_loss: 1.8363 - val_accuracy: 0.7586\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4098 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3140 - accuracy: 0.8621 - val_loss: 2.6174 - val_accuracy: 0.6897\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3251 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2868 - accuracy: 0.8534 - val_loss: 1.7600 - val_accuracy: 0.7586\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3155 - accuracy: 0.8534 - val_loss: 2.3190 - val_accuracy: 0.7241\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2400 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3205 - accuracy: 0.8362 - val_loss: 1.7107 - val_accuracy: 0.7586\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2345 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3209 - accuracy: 0.8534 - val_loss: 1.4683 - val_accuracy: 0.7586\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3023 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3261 - accuracy: 0.8362 - val_loss: 1.5873 - val_accuracy: 0.7586\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.93 - 0s 129us/sample - loss: 0.3062 - accuracy: 0.8621 - val_loss: 1.5712 - val_accuracy: 0.7586\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.96 - 0s 137us/sample - loss: 0.3166 - accuracy: 0.8707 - val_loss: 1.5796 - val_accuracy: 0.7586\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2721 - accuracy: 0.8793 - val_loss: 1.9720 - val_accuracy: 0.6897\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3102 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2876 - accuracy: 0.8621 - val_loss: 2.0083 - val_accuracy: 0.7241\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 1.00 - 0s 146us/sample - loss: 0.2688 - accuracy: 0.8879 - val_loss: 2.0129 - val_accuracy: 0.7241\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1979 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2800 - accuracy: 0.8966 - val_loss: 1.9645 - val_accuracy: 0.7241\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3095 - accuracy: 0.8448 - val_loss: 2.3123 - val_accuracy: 0.7241\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2874 - accuracy: 0.87 - 0s 137us/sample - loss: 0.2782 - accuracy: 0.8879 - val_loss: 1.7692 - val_accuracy: 0.6897\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3434 - accuracy: 0.87 - 0s 137us/sample - loss: 0.2773 - accuracy: 0.9224 - val_loss: 2.3512 - val_accuracy: 0.7931\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2727 - accuracy: 0.9138 - val_loss: 2.7629 - val_accuracy: 0.6897\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2747 - accuracy: 0.8879 - val_loss: 2.8483 - val_accuracy: 0.6897\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2960 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2533 - accuracy: 0.8966 - val_loss: 3.2614 - val_accuracy: 0.6897\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2839 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2540 - accuracy: 0.8879 - val_loss: 2.9566 - val_accuracy: 0.6897\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2292 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2457 - accuracy: 0.8966 - val_loss: 3.2512 - val_accuracy: 0.7241\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2158 - accuracy: 0.8966 - val_loss: 3.4070 - val_accuracy: 0.7241\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2152 - accuracy: 0.9138 - val_loss: 3.9371 - val_accuracy: 0.7241\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1608 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2383 - accuracy: 0.9138 - val_loss: 3.1186 - val_accuracy: 0.7586\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2504 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2593 - accuracy: 0.8879 - val_loss: 3.7080 - val_accuracy: 0.6552\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2406 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3128 - accuracy: 0.8534 - val_loss: 1.5307 - val_accuracy: 0.7241\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5837 - accuracy: 0.71 - 0s 129us/sample - loss: 0.3572 - accuracy: 0.8362 - val_loss: 1.2972 - val_accuracy: 0.7241\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2496 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3069 - accuracy: 0.8534 - val_loss: 1.9455 - val_accuracy: 0.7241\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3163 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3140 - accuracy: 0.8448 - val_loss: 1.9354 - val_accuracy: 0.6897\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2541 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2920 - accuracy: 0.8621 - val_loss: 1.8487 - val_accuracy: 0.7241\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2702 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2900 - accuracy: 0.8707 - val_loss: 1.9009 - val_accuracy: 0.7241\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3286 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2899 - accuracy: 0.8707 - val_loss: 1.6688 - val_accuracy: 0.7586\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2480 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2631 - accuracy: 0.8707 - val_loss: 1.5692 - val_accuracy: 0.7241\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2555 - accuracy: 0.8879 - val_loss: 1.4839 - val_accuracy: 0.7586\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2882 - accuracy: 0.84 - 0s 163us/sample - loss: 0.2485 - accuracy: 0.8793 - val_loss: 1.6962 - val_accuracy: 0.6897\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3978 - accuracy: 0.78 - 0s 189us/sample - loss: 0.2695 - accuracy: 0.8707 - val_loss: 1.2482 - val_accuracy: 0.7586\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2220 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2778 - accuracy: 0.8621 - val_loss: 1.8484 - val_accuracy: 0.7241\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2908 - accuracy: 0.84 - 0s 224us/sample - loss: 0.2457 - accuracy: 0.8707 - val_loss: 2.3863 - val_accuracy: 0.6552\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2410 - accuracy: 0.8707 - val_loss: 2.6284 - val_accuracy: 0.6897\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2407 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2314 - accuracy: 0.8793 - val_loss: 2.5636 - val_accuracy: 0.7241\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2297 - accuracy: 0.8879 - val_loss: 2.6586 - val_accuracy: 0.6897\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1932 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2355 - accuracy: 0.8793 - val_loss: 2.7196 - val_accuracy: 0.6897\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 1.00 - 0s 129us/sample - loss: 0.2237 - accuracy: 0.8966 - val_loss: 2.8635 - val_accuracy: 0.6897\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2384 - accuracy: 0.8707 - val_loss: 2.5521 - val_accuracy: 0.6897\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2251 - accuracy: 0.8879 - val_loss: 2.7332 - val_accuracy: 0.6897\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2372 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2514 - accuracy: 0.8879 - val_loss: 2.0664 - val_accuracy: 0.6897\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.90 - 0s 120us/sample - loss: 0.2460 - accuracy: 0.8879 - val_loss: 1.9179 - val_accuracy: 0.7241\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2453 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2867 - accuracy: 0.8793 - val_loss: 1.8908 - val_accuracy: 0.6897\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2058 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2815 - accuracy: 0.8707 - val_loss: 1.9879 - val_accuracy: 0.7241\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3904 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2524 - accuracy: 0.8879 - val_loss: 2.4434 - val_accuracy: 0.7241\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.81 - 0s 129us/sample - loss: 0.2643 - accuracy: 0.8707 - val_loss: 1.6047 - val_accuracy: 0.6897\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1240 - accuracy: 0.93 - 0s 127us/sample - loss: 0.2507 - accuracy: 0.8879 - val_loss: 1.6761 - val_accuracy: 0.6552\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1910 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2215 - accuracy: 0.8793 - val_loss: 1.8782 - val_accuracy: 0.6897\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.93 - 0s 120us/sample - loss: 0.2214 - accuracy: 0.8793 - val_loss: 1.8342 - val_accuracy: 0.6552\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2529 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2110 - accuracy: 0.8966 - val_loss: 1.7464 - val_accuracy: 0.6207\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 1.00 - 0s 137us/sample - loss: 0.2160 - accuracy: 0.8966 - val_loss: 1.7573 - val_accuracy: 0.6552\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1929 - accuracy: 0.90 - 0s 120us/sample - loss: 0.2097 - accuracy: 0.8966 - val_loss: 1.8501 - val_accuracy: 0.6552\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2388 - accuracy: 0.87 - 0s 120us/sample - loss: 0.2040 - accuracy: 0.8966 - val_loss: 1.6659 - val_accuracy: 0.6552\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2868 - accuracy: 0.81 - 0s 146us/sample - loss: 0.1983 - accuracy: 0.9052 - val_loss: 1.5988 - val_accuracy: 0.7241\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2476 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1958 - accuracy: 0.9052 - val_loss: 1.8503 - val_accuracy: 0.6552\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1680 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2167 - accuracy: 0.8879 - val_loss: 1.8135 - val_accuracy: 0.6897\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2288 - accuracy: 0.87 - 0s 134us/sample - loss: 0.2155 - accuracy: 0.8879 - val_loss: 1.5972 - val_accuracy: 0.7241\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2284 - accuracy: 0.8966 - val_loss: 1.8037 - val_accuracy: 0.7241\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2744 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2575 - accuracy: 0.8707 - val_loss: 1.2363 - val_accuracy: 0.6897\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2573 - accuracy: 0.8621 - val_loss: 1.6740 - val_accuracy: 0.6207\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5242 - accuracy: 0.78 - 0s 129us/sample - loss: 0.3622 - accuracy: 0.8621 - val_loss: 1.1505 - val_accuracy: 0.7586\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5421 - accuracy: 0.87 - 0s 131us/sample - loss: 0.3599 - accuracy: 0.8793 - val_loss: 0.9377 - val_accuracy: 0.6897\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2073 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2442 - accuracy: 0.8707 - val_loss: 2.6109 - val_accuracy: 0.6897\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1825 - accuracy: 0.93 - 0s 129us/sample - loss: 0.3380 - accuracy: 0.8362 - val_loss: 1.6696 - val_accuracy: 0.7241\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2207 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2601 - accuracy: 0.8793 - val_loss: 1.0714 - val_accuracy: 0.6552\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1414 - accuracy: 0.96 - 0s 137us/sample - loss: 0.2411 - accuracy: 0.8793 - val_loss: 0.8899 - val_accuracy: 0.6552\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2564 - accuracy: 0.84 - 0s 133us/sample - loss: 0.2397 - accuracy: 0.8793 - val_loss: 1.2103 - val_accuracy: 0.6897\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2232 - accuracy: 0.8966 - val_loss: 1.6496 - val_accuracy: 0.7241\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2839 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2083 - accuracy: 0.9138 - val_loss: 2.2228 - val_accuracy: 0.7241\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2052 - accuracy: 0.9138 - val_loss: 2.5777 - val_accuracy: 0.7241\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1832 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1977 - accuracy: 0.9052 - val_loss: 2.6477 - val_accuracy: 0.7241\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1838 - accuracy: 0.9138 - val_loss: 2.2893 - val_accuracy: 0.7241\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1838 - accuracy: 0.9138 - val_loss: 2.2560 - val_accuracy: 0.7241\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1198 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1802 - accuracy: 0.9052 - val_loss: 2.5039 - val_accuracy: 0.7241\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1725 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1617 - accuracy: 0.9310 - val_loss: 2.6417 - val_accuracy: 0.7241\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1750 - accuracy: 0.9224 - val_loss: 2.5317 - val_accuracy: 0.6897\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1592 - accuracy: 0.9224 - val_loss: 2.4637 - val_accuracy: 0.6552\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0827 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1598 - accuracy: 0.9138 - val_loss: 2.6217 - val_accuracy: 0.6552\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1491 - accuracy: 0.9224 - val_loss: 2.7055 - val_accuracy: 0.6897\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1473 - accuracy: 0.9310 - val_loss: 3.0067 - val_accuracy: 0.6897\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0948 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1482 - accuracy: 0.9310 - val_loss: 3.0348 - val_accuracy: 0.6552\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1100 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1670 - accuracy: 0.9138 - val_loss: 2.3935 - val_accuracy: 0.6552\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2404 - accuracy: 0.9310 - val_loss: 3.2517 - val_accuracy: 0.6207\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2513 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3166 - accuracy: 0.8879 - val_loss: 2.7054 - val_accuracy: 0.6552\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2314 - accuracy: 0.8879 - val_loss: 2.2083 - val_accuracy: 0.6552\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2040 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2379 - accuracy: 0.8534 - val_loss: 2.2959 - val_accuracy: 0.6897\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1716 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2404 - accuracy: 0.8534 - val_loss: 2.4578 - val_accuracy: 0.7586\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2809 - accuracy: 0.78 - 0s 138us/sample - loss: 0.2334 - accuracy: 0.8534 - val_loss: 3.0471 - val_accuracy: 0.7586\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1780 - accuracy: 0.93 - 0s 189us/sample - loss: 0.2295 - accuracy: 0.8793 - val_loss: 3.2480 - val_accuracy: 0.7241\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1348 - accuracy: 0.96 - 0s 163us/sample - loss: 0.2158 - accuracy: 0.8879 - val_loss: 2.9385 - val_accuracy: 0.7586\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1950 - accuracy: 0.87 - 0s 189us/sample - loss: 0.2067 - accuracy: 0.8793 - val_loss: 2.6418 - val_accuracy: 0.6552\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2024 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2091 - accuracy: 0.9052 - val_loss: 2.4351 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1581 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1974 - accuracy: 0.9052 - val_loss: 2.2782 - val_accuracy: 0.6552\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.90 - 0s 181us/sample - loss: 0.1868 - accuracy: 0.8966 - val_loss: 2.3579 - val_accuracy: 0.6207\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2656 - accuracy: 0.84 - 0s 163us/sample - loss: 0.2061 - accuracy: 0.8879 - val_loss: 2.3148 - val_accuracy: 0.6897\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3701 - accuracy: 0.81 - 0s 163us/sample - loss: 0.2303 - accuracy: 0.8966 - val_loss: 2.4866 - val_accuracy: 0.6552\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2686 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3911 - accuracy: 0.8793 - val_loss: 3.5434 - val_accuracy: 0.7241\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.81 - 0s 163us/sample - loss: 0.2299 - accuracy: 0.8879 - val_loss: 5.8227 - val_accuracy: 0.6897\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.87 - 0s 164us/sample - loss: 0.7840 - accuracy: 0.8276 - val_loss: 1.8851 - val_accuracy: 0.6552\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.84 - 0s 181us/sample - loss: 0.3775 - accuracy: 0.8103 - val_loss: 0.7771 - val_accuracy: 0.6552\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2987 - accuracy: 0.81 - 0s 189us/sample - loss: 0.3396 - accuracy: 0.8621 - val_loss: 0.6806 - val_accuracy: 0.7241\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2995 - accuracy: 0.81 - 0s 172us/sample - loss: 0.3400 - accuracy: 0.8103 - val_loss: 0.6040 - val_accuracy: 0.6897\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4638 - accuracy: 0.75 - 0s 155us/sample - loss: 0.3256 - accuracy: 0.8362 - val_loss: 0.5724 - val_accuracy: 0.6552\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2906 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2609 - accuracy: 0.8793 - val_loss: 0.5978 - val_accuracy: 0.6897\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2456 - accuracy: 0.8879 - val_loss: 0.6482 - val_accuracy: 0.6897\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2363 - accuracy: 0.8793 - val_loss: 0.6511 - val_accuracy: 0.7241\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1890 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1964 - accuracy: 0.9052 - val_loss: 0.7578 - val_accuracy: 0.6552\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2036 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1920 - accuracy: 0.9138 - val_loss: 0.9011 - val_accuracy: 0.6552\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2916 - accuracy: 0.84 - 0s 120us/sample - loss: 0.1590 - accuracy: 0.9397 - val_loss: 0.9340 - val_accuracy: 0.7241\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1564 - accuracy: 0.93 - 0s 112us/sample - loss: 0.1747 - accuracy: 0.9138 - val_loss: 0.9375 - val_accuracy: 0.6897\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.90 - 0s 112us/sample - loss: 0.1597 - accuracy: 0.9224 - val_loss: 1.1428 - val_accuracy: 0.6897\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0969 - accuracy: 0.96 - 0s 103us/sample - loss: 0.1437 - accuracy: 0.9310 - val_loss: 1.1285 - val_accuracy: 0.7241\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.87 - 0s 112us/sample - loss: 0.1776 - accuracy: 0.9138 - val_loss: 1.0733 - val_accuracy: 0.6552\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1358 - accuracy: 0.96 - 0s 112us/sample - loss: 0.1923 - accuracy: 0.9138 - val_loss: 1.1949 - val_accuracy: 0.6552\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1458 - accuracy: 0.93 - 0s 119us/sample - loss: 0.1454 - accuracy: 0.9224 - val_loss: 1.1866 - val_accuracy: 0.6897\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1520 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1406 - accuracy: 0.9310 - val_loss: 1.2581 - val_accuracy: 0.7241\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1607 - accuracy: 0.9138 - val_loss: 1.1714 - val_accuracy: 0.6897\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1256 - accuracy: 0.9397 - val_loss: 1.2066 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d3a15f814946abd65d9d5f6492c5dcdc</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8275862336158752</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 44</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 77</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_3_units: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_units: 66</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 1s - loss: 0.6920 - accuracy: 0.56 - 1s 5ms/sample - loss: 0.6700 - accuracy: 0.6293 - val_loss: 0.6234 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7010 - accuracy: 0.56 - 0s 275us/sample - loss: 0.6513 - accuracy: 0.6638 - val_loss: 0.6312 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5613 - accuracy: 0.78 - 0s 155us/sample - loss: 0.6282 - accuracy: 0.6638 - val_loss: 0.6156 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5954 - accuracy: 0.71 - 0s 146us/sample - loss: 0.6155 - accuracy: 0.6638 - val_loss: 0.6059 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5845 - accuracy: 0.71 - 0s 146us/sample - loss: 0.6144 - accuracy: 0.6638 - val_loss: 0.6194 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5835 - accuracy: 0.68 - 0s 1ms/sample - loss: 0.6051 - accuracy: 0.6724 - val_loss: 0.5891 - val_accuracy: 0.6897\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.68 - 0s 163us/sample - loss: 0.6033 - accuracy: 0.6724 - val_loss: 0.5781 - val_accuracy: 0.6897\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5008 - accuracy: 0.84 - 0s 146us/sample - loss: 0.5804 - accuracy: 0.7328 - val_loss: 0.5961 - val_accuracy: 0.6897\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.81 - 0s 138us/sample - loss: 0.5805 - accuracy: 0.7241 - val_loss: 0.5960 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5736 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5469 - accuracy: 0.7241 - val_loss: 0.5888 - val_accuracy: 0.6897\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6816 - accuracy: 0.62 - 0s 1ms/sample - loss: 0.5494 - accuracy: 0.7328 - val_loss: 0.5732 - val_accuracy: 0.7241\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3760 - accuracy: 0.87 - 0s 146us/sample - loss: 0.5300 - accuracy: 0.7586 - val_loss: 0.6354 - val_accuracy: 0.5862\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4445 - accuracy: 0.81 - 0s 138us/sample - loss: 0.5421 - accuracy: 0.7241 - val_loss: 0.5658 - val_accuracy: 0.7241\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6022 - accuracy: 0.68 - 0s 172us/sample - loss: 0.5524 - accuracy: 0.7328 - val_loss: 0.5864 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4690 - accuracy: 0.81 - 0s 163us/sample - loss: 0.5462 - accuracy: 0.7241 - val_loss: 0.6179 - val_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.81 - 0s 155us/sample - loss: 0.5473 - accuracy: 0.7328 - val_loss: 0.5380 - val_accuracy: 0.7241\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.68 - 0s 1ms/sample - loss: 0.5181 - accuracy: 0.7414 - val_loss: 0.5526 - val_accuracy: 0.7586\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3451 - accuracy: 0.87 - 0s 284us/sample - loss: 0.5317 - accuracy: 0.7328 - val_loss: 0.5658 - val_accuracy: 0.7241\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5814 - accuracy: 0.62 - 0s 163us/sample - loss: 0.5413 - accuracy: 0.7414 - val_loss: 0.5611 - val_accuracy: 0.7241\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6042 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5004 - accuracy: 0.7586 - val_loss: 0.6129 - val_accuracy: 0.6897\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5663 - accuracy: 0.68 - 0s 232us/sample - loss: 0.5016 - accuracy: 0.7500 - val_loss: 0.5123 - val_accuracy: 0.7586\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.75 - 0s 198us/sample - loss: 0.4994 - accuracy: 0.7672 - val_loss: 0.5141 - val_accuracy: 0.7586\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5618 - accuracy: 0.65 - 0s 138us/sample - loss: 0.4914 - accuracy: 0.7586 - val_loss: 0.5086 - val_accuracy: 0.7586\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5700 - accuracy: 0.68 - 0s 189us/sample - loss: 0.4938 - accuracy: 0.7414 - val_loss: 0.5452 - val_accuracy: 0.7241\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5306 - accuracy: 0.75 - 0s 189us/sample - loss: 0.4993 - accuracy: 0.7500 - val_loss: 0.5484 - val_accuracy: 0.7241\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5566 - accuracy: 0.65 - 0s 163us/sample - loss: 0.4923 - accuracy: 0.7672 - val_loss: 0.5675 - val_accuracy: 0.7241\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.84 - 0s 172us/sample - loss: 0.4922 - accuracy: 0.7586 - val_loss: 0.5823 - val_accuracy: 0.7241\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5164 - accuracy: 0.71 - 0s 155us/sample - loss: 0.4944 - accuracy: 0.7586 - val_loss: 0.6359 - val_accuracy: 0.7241\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4701 - accuracy: 0.78 - 0s 172us/sample - loss: 0.4310 - accuracy: 0.8103 - val_loss: 0.7805 - val_accuracy: 0.7241\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6070 - accuracy: 0.68 - 0s 155us/sample - loss: 0.4915 - accuracy: 0.7586 - val_loss: 0.6476 - val_accuracy: 0.6897\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5778 - accuracy: 0.68 - 0s 159us/sample - loss: 0.4428 - accuracy: 0.8017 - val_loss: 0.6157 - val_accuracy: 0.7586\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4156 - accuracy: 0.78 - 0s 163us/sample - loss: 0.4483 - accuracy: 0.7845 - val_loss: 0.6385 - val_accuracy: 0.6897\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3685 - accuracy: 0.81 - 0s 163us/sample - loss: 0.4378 - accuracy: 0.7759 - val_loss: 0.7491 - val_accuracy: 0.7241\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3925 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4219 - accuracy: 0.8190 - val_loss: 0.7549 - val_accuracy: 0.6897\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3755 - accuracy: 0.87 - 0s 138us/sample - loss: 0.4031 - accuracy: 0.8276 - val_loss: 0.8991 - val_accuracy: 0.7241\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4151 - accuracy: 0.87 - 0s 129us/sample - loss: 0.4113 - accuracy: 0.8103 - val_loss: 1.0155 - val_accuracy: 0.6897\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3607 - accuracy: 0.84 - 0s 120us/sample - loss: 0.4038 - accuracy: 0.8017 - val_loss: 0.9359 - val_accuracy: 0.6897\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4836 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4036 - accuracy: 0.7931 - val_loss: 0.9990 - val_accuracy: 0.6552\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3726 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3894 - accuracy: 0.8448 - val_loss: 1.1682 - val_accuracy: 0.6897\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3962 - accuracy: 0.8276 - val_loss: 1.2112 - val_accuracy: 0.6552\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4747 - accuracy: 0.75 - 0s 129us/sample - loss: 0.4365 - accuracy: 0.7586 - val_loss: 0.9262 - val_accuracy: 0.6897\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5273 - accuracy: 0.78 - 0s 129us/sample - loss: 0.4401 - accuracy: 0.7931 - val_loss: 1.0646 - val_accuracy: 0.6897\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4623 - accuracy: 0.78 - 0s 129us/sample - loss: 0.4809 - accuracy: 0.7759 - val_loss: 0.8088 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4655 - accuracy: 0.8017 - val_loss: 0.6417 - val_accuracy: 0.6897\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4643 - accuracy: 0.75 - 0s 129us/sample - loss: 0.4511 - accuracy: 0.8017 - val_loss: 0.5357 - val_accuracy: 0.7241\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5119 - accuracy: 0.75 - 0s 120us/sample - loss: 0.4383 - accuracy: 0.8103 - val_loss: 0.5214 - val_accuracy: 0.7241\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5385 - accuracy: 0.78 - 0s 120us/sample - loss: 0.4660 - accuracy: 0.8103 - val_loss: 0.5552 - val_accuracy: 0.7241\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.75 - 0s 129us/sample - loss: 0.4034 - accuracy: 0.8017 - val_loss: 0.5129 - val_accuracy: 0.7241\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3884 - accuracy: 0.78 - 0s 120us/sample - loss: 0.4056 - accuracy: 0.8103 - val_loss: 0.5540 - val_accuracy: 0.7586\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3543 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3991 - accuracy: 0.8276 - val_loss: 0.6366 - val_accuracy: 0.7241\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4155 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3975 - accuracy: 0.8190 - val_loss: 0.6171 - val_accuracy: 0.6207\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3834 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3792 - accuracy: 0.8103 - val_loss: 0.6104 - val_accuracy: 0.6897\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3638 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3501 - accuracy: 0.8707 - val_loss: 0.6768 - val_accuracy: 0.7241\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3312 - accuracy: 0.8793 - val_loss: 0.7151 - val_accuracy: 0.7586\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2419 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3191 - accuracy: 0.8448 - val_loss: 0.7913 - val_accuracy: 0.7586\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2356 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2944 - accuracy: 0.8879 - val_loss: 0.9805 - val_accuracy: 0.7241\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4354 - accuracy: 0.81 - 0s 138us/sample - loss: 0.2819 - accuracy: 0.8707 - val_loss: 1.2410 - val_accuracy: 0.6897\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3004 - accuracy: 0.8534 - val_loss: 1.1605 - val_accuracy: 0.7241\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2341 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3418 - accuracy: 0.8534 - val_loss: 1.2820 - val_accuracy: 0.6897\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2750 - accuracy: 0.9052 - val_loss: 1.1363 - val_accuracy: 0.6897\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3839 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3061 - accuracy: 0.8534 - val_loss: 1.3662 - val_accuracy: 0.6552\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2771 - accuracy: 0.8707 - val_loss: 1.5550 - val_accuracy: 0.7241\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2825 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2604 - accuracy: 0.8879 - val_loss: 1.5581 - val_accuracy: 0.7241\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2443 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2546 - accuracy: 0.8879 - val_loss: 1.6532 - val_accuracy: 0.6897\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2935 - accuracy: 0.78 - 0s 155us/sample - loss: 0.2786 - accuracy: 0.8534 - val_loss: 2.0351 - val_accuracy: 0.6552\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2434 - accuracy: 0.8879 - val_loss: 1.9664 - val_accuracy: 0.6897\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1637 - accuracy: 0.93 - 0s 129us/sample - loss: 0.3236 - accuracy: 0.8534 - val_loss: 2.0165 - val_accuracy: 0.6897\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1703 - accuracy: 0.93 - 0s 146us/sample - loss: 0.3486 - accuracy: 0.8276 - val_loss: 2.0223 - val_accuracy: 0.6897\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2023 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2761 - accuracy: 0.8707 - val_loss: 1.8088 - val_accuracy: 0.7586\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2853 - accuracy: 0.8621 - val_loss: 1.7236 - val_accuracy: 0.7586\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2853 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2447 - accuracy: 0.9052 - val_loss: 1.9638 - val_accuracy: 0.6897\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2591 - accuracy: 0.8793 - val_loss: 2.2497 - val_accuracy: 0.7241\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2931 - accuracy: 0.8707 - val_loss: 2.3147 - val_accuracy: 0.7241\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2018 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2379 - accuracy: 0.9052 - val_loss: 2.3159 - val_accuracy: 0.6552\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3886 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2578 - accuracy: 0.8793 - val_loss: 2.1350 - val_accuracy: 0.6897\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2951 - accuracy: 0.8534 - val_loss: 1.9870 - val_accuracy: 0.7241\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1883 - accuracy: 0.90 - 0s 163us/sample - loss: 0.3137 - accuracy: 0.8793 - val_loss: 2.2452 - val_accuracy: 0.7241\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.90 - 0s 163us/sample - loss: 0.4754 - accuracy: 0.8621 - val_loss: 1.6428 - val_accuracy: 0.7586\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.87 - 0s 172us/sample - loss: 0.4088 - accuracy: 0.8190 - val_loss: 1.2020 - val_accuracy: 0.7241\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4362 - accuracy: 0.78 - 0s 172us/sample - loss: 0.5345 - accuracy: 0.8793 - val_loss: 0.7237 - val_accuracy: 0.7241\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4536 - accuracy: 0.87 - 0s 129us/sample - loss: 0.4468 - accuracy: 0.8448 - val_loss: 0.7027 - val_accuracy: 0.7241\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4096 - accuracy: 0.90 - 0s 138us/sample - loss: 0.4026 - accuracy: 0.8793 - val_loss: 0.6793 - val_accuracy: 0.6897\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4362 - accuracy: 0.78 - 0s 146us/sample - loss: 0.3412 - accuracy: 0.8534 - val_loss: 0.8780 - val_accuracy: 0.6897\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3559 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2590 - accuracy: 0.9138 - val_loss: 1.2854 - val_accuracy: 0.6897\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2760 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2764 - accuracy: 0.8793 - val_loss: 1.3613 - val_accuracy: 0.7241\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2850 - accuracy: 0.8879 - val_loss: 1.2253 - val_accuracy: 0.6897\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1008 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2808 - accuracy: 0.8879 - val_loss: 1.2760 - val_accuracy: 0.7241\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2069 - accuracy: 0.96 - 0s 137us/sample - loss: 0.2893 - accuracy: 0.8534 - val_loss: 1.3525 - val_accuracy: 0.6897\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2676 - accuracy: 0.8879 - val_loss: 1.2081 - val_accuracy: 0.6897\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3551 - accuracy: 0.81 - 0s 138us/sample - loss: 0.2307 - accuracy: 0.9052 - val_loss: 1.4795 - val_accuracy: 0.6897\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2412 - accuracy: 0.8966 - val_loss: 1.4935 - val_accuracy: 0.6897\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1293 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2769 - accuracy: 0.8966 - val_loss: 1.6860 - val_accuracy: 0.6552\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4006 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2802 - accuracy: 0.8879 - val_loss: 1.5222 - val_accuracy: 0.7241\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2883 - accuracy: 0.8707 - val_loss: 1.5581 - val_accuracy: 0.7241\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2029 - accuracy: 0.93 - 0s 144us/sample - loss: 0.2430 - accuracy: 0.8879 - val_loss: 1.6521 - val_accuracy: 0.6552\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3015 - accuracy: 0.81 - 0s 137us/sample - loss: 0.2368 - accuracy: 0.8966 - val_loss: 1.3329 - val_accuracy: 0.7241\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.90 - 0s 120us/sample - loss: 0.2387 - accuracy: 0.9052 - val_loss: 1.5933 - val_accuracy: 0.7241\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 0.93 - 0s 120us/sample - loss: 0.2022 - accuracy: 0.9138 - val_loss: 1.7714 - val_accuracy: 0.7241\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1958 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1821 - accuracy: 0.9138 - val_loss: 1.9648 - val_accuracy: 0.7241\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1758 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1679 - accuracy: 0.9224 - val_loss: 2.1458 - val_accuracy: 0.7241\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1978 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1691 - accuracy: 0.9224 - val_loss: 2.1524 - val_accuracy: 0.6897\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2063 - accuracy: 0.9138 - val_loss: 2.3666 - val_accuracy: 0.7241\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1019 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2634 - accuracy: 0.9138 - val_loss: 2.0496 - val_accuracy: 0.7241\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1750 - accuracy: 0.9310 - val_loss: 1.8456 - val_accuracy: 0.7241\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2859 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2976 - accuracy: 0.8879 - val_loss: 1.7647 - val_accuracy: 0.7241\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1532 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2579 - accuracy: 0.8966 - val_loss: 1.7658 - val_accuracy: 0.7241\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1758 - accuracy: 0.93 - 0s 172us/sample - loss: 0.2335 - accuracy: 0.8966 - val_loss: 1.6849 - val_accuracy: 0.6897\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3061 - accuracy: 0.87 - 0s 163us/sample - loss: 0.2494 - accuracy: 0.9052 - val_loss: 1.6556 - val_accuracy: 0.6552\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1924 - accuracy: 0.90 - 0s 198us/sample - loss: 0.2453 - accuracy: 0.8793 - val_loss: 1.3369 - val_accuracy: 0.6552\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.90 - 0s 224us/sample - loss: 0.2048 - accuracy: 0.9138 - val_loss: 1.4514 - val_accuracy: 0.6897\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.90 - 0s 181us/sample - loss: 0.1909 - accuracy: 0.9397 - val_loss: 1.3590 - val_accuracy: 0.7241\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1841 - accuracy: 0.9224 - val_loss: 1.6665 - val_accuracy: 0.6897\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1824 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2072 - accuracy: 0.9052 - val_loss: 1.9106 - val_accuracy: 0.7241\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0925 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1867 - accuracy: 0.9397 - val_loss: 2.0088 - val_accuracy: 0.7241\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2347 - accuracy: 0.9052 - val_loss: 1.8382 - val_accuracy: 0.7241\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1247 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2042 - accuracy: 0.8966 - val_loss: 1.9471 - val_accuracy: 0.7241\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1737 - accuracy: 0.9224 - val_loss: 1.8460 - val_accuracy: 0.6897\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0724 - accuracy: 1.00 - 0s 137us/sample - loss: 0.1530 - accuracy: 0.9483 - val_loss: 1.9308 - val_accuracy: 0.6552\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1433 - accuracy: 0.9397 - val_loss: 1.8085 - val_accuracy: 0.6552\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1517 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1497 - accuracy: 0.9397 - val_loss: 2.1208 - val_accuracy: 0.5172\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1951 - accuracy: 0.9310 - val_loss: 1.6351 - val_accuracy: 0.7241\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1861 - accuracy: 0.9397 - val_loss: 1.9183 - val_accuracy: 0.6552\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1679 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2091 - accuracy: 0.9138 - val_loss: 2.2038 - val_accuracy: 0.7241\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1705 - accuracy: 0.9397 - val_loss: 2.1692 - val_accuracy: 0.7241\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1646 - accuracy: 0.9310 - val_loss: 2.3908 - val_accuracy: 0.6552\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.90 - 0s 163us/sample - loss: 0.1863 - accuracy: 0.9224 - val_loss: 2.2989 - val_accuracy: 0.7241\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1942 - accuracy: 0.9224 - val_loss: 1.9413 - val_accuracy: 0.7241\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3323 - accuracy: 0.84 - 0s 129us/sample - loss: 0.1823 - accuracy: 0.9310 - val_loss: 2.3197 - val_accuracy: 0.6897\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2170 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1996 - accuracy: 0.9052 - val_loss: 2.2643 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 1.00 - 0s 241us/sample - loss: 0.1975 - accuracy: 0.9310 - val_loss: 2.0824 - val_accuracy: 0.7241\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1569 - accuracy: 0.9397 - val_loss: 2.4298 - val_accuracy: 0.6207\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1581 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1904 - accuracy: 0.9310 - val_loss: 2.4517 - val_accuracy: 0.6897\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1096 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1494 - accuracy: 0.9397 - val_loss: 2.5774 - val_accuracy: 0.6897\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.93 - 0s 172us/sample - loss: 0.1283 - accuracy: 0.9483 - val_loss: 2.7238 - val_accuracy: 0.7241\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2463 - accuracy: 0.90 - 0s 172us/sample - loss: 0.1789 - accuracy: 0.9310 - val_loss: 2.7320 - val_accuracy: 0.7241\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.90 - 0s 163us/sample - loss: 0.1350 - accuracy: 0.9397 - val_loss: 2.6221 - val_accuracy: 0.7241\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1024 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1395 - accuracy: 0.9483 - val_loss: 2.7151 - val_accuracy: 0.6552\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1286 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1492 - accuracy: 0.9483 - val_loss: 2.8376 - val_accuracy: 0.7241\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0957 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1158 - accuracy: 0.9569 - val_loss: 2.7972 - val_accuracy: 0.7241\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1614 - accuracy: 0.9483 - val_loss: 3.2245 - val_accuracy: 0.5862\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3089 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1640 - accuracy: 0.9397 - val_loss: 3.0416 - val_accuracy: 0.7241\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0669 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1598 - accuracy: 0.9310 - val_loss: 2.8473 - val_accuracy: 0.7241\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.93 - 0s 172us/sample - loss: 0.1943 - accuracy: 0.9397 - val_loss: 2.4576 - val_accuracy: 0.6897\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2245 - accuracy: 0.9052 - val_loss: 2.3415 - val_accuracy: 0.6897\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3054 - accuracy: 0.84 - 0s 137us/sample - loss: 0.1955 - accuracy: 0.9052 - val_loss: 2.0015 - val_accuracy: 0.6207\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2147 - accuracy: 0.8966 - val_loss: 1.6874 - val_accuracy: 0.6897\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1561 - accuracy: 0.9483 - val_loss: 1.9365 - val_accuracy: 0.7241\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1002 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1587 - accuracy: 0.9397 - val_loss: 2.2872 - val_accuracy: 0.6897\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1310 - accuracy: 0.9655 - val_loss: 2.7222 - val_accuracy: 0.6897\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0818 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1249 - accuracy: 0.9569 - val_loss: 2.9951 - val_accuracy: 0.6552\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1884 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1315 - accuracy: 0.9483 - val_loss: 3.1402 - val_accuracy: 0.7586\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1830 - accuracy: 0.9052 - val_loss: 2.8588 - val_accuracy: 0.6552\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2282 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1835 - accuracy: 0.9310 - val_loss: 2.8068 - val_accuracy: 0.7241\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0585 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1346 - accuracy: 0.9397 - val_loss: 2.7895 - val_accuracy: 0.6897\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0522 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1585 - accuracy: 0.9397 - val_loss: 2.9754 - val_accuracy: 0.6897\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1241 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1457 - accuracy: 0.9310 - val_loss: 3.1125 - val_accuracy: 0.7586\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1197 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1787 - accuracy: 0.9224 - val_loss: 3.5508 - val_accuracy: 0.6552\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3091 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2383 - accuracy: 0.8793 - val_loss: 3.2419 - val_accuracy: 0.6897\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1544 - accuracy: 0.9224 - val_loss: 3.4170 - val_accuracy: 0.7241\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1966 - accuracy: 0.9052 - val_loss: 3.6149 - val_accuracy: 0.6552\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1009 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1827 - accuracy: 0.9052 - val_loss: 4.0112 - val_accuracy: 0.6552\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2460 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2011 - accuracy: 0.9052 - val_loss: 3.9788 - val_accuracy: 0.7241\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2240 - accuracy: 0.90 - 0s 137us/sample - loss: 0.1871 - accuracy: 0.9138 - val_loss: 3.8679 - val_accuracy: 0.6897\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1881 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1533 - accuracy: 0.9397 - val_loss: 3.6597 - val_accuracy: 0.7241\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1396 - accuracy: 0.9310 - val_loss: 4.4373 - val_accuracy: 0.6552\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1416 - accuracy: 0.9310 - val_loss: 4.0903 - val_accuracy: 0.6897\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.90 - 0s 164us/sample - loss: 0.3291 - accuracy: 0.9052 - val_loss: 4.3202 - val_accuracy: 0.6552\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4886 - accuracy: 0.87 - 0s 148us/sample - loss: 0.3018 - accuracy: 0.8966 - val_loss: 2.1032 - val_accuracy: 0.6897\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.81 - 0s 138us/sample - loss: 0.2723 - accuracy: 0.8793 - val_loss: 1.7777 - val_accuracy: 0.6552\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2803 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2456 - accuracy: 0.9310 - val_loss: 1.8736 - val_accuracy: 0.6897\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1719 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2153 - accuracy: 0.9310 - val_loss: 2.0914 - val_accuracy: 0.7241\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.90 - 0s 165us/sample - loss: 0.2067 - accuracy: 0.8879 - val_loss: 2.2089 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2439 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1801 - accuracy: 0.9224 - val_loss: 2.6671 - val_accuracy: 0.6897\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1736 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1821 - accuracy: 0.9052 - val_loss: 2.5575 - val_accuracy: 0.6897\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1822 - accuracy: 0.9397 - val_loss: 2.6325 - val_accuracy: 0.6897\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1509 - accuracy: 0.9397 - val_loss: 2.8677 - val_accuracy: 0.7241\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1658 - accuracy: 0.9224 - val_loss: 3.2311 - val_accuracy: 0.7241\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1189 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1406 - accuracy: 0.9397 - val_loss: 3.3407 - val_accuracy: 0.7241\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 1.00 - 0s 241us/sample - loss: 0.1407 - accuracy: 0.9397 - val_loss: 3.4594 - val_accuracy: 0.7241\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1456 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1168 - accuracy: 0.9569 - val_loss: 3.7094 - val_accuracy: 0.6897\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1631 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1280 - accuracy: 0.9483 - val_loss: 3.6621 - val_accuracy: 0.7241\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1931 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1531 - accuracy: 0.9397 - val_loss: 3.9817 - val_accuracy: 0.6897\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1123 - accuracy: 0.9655 - val_loss: 4.2881 - val_accuracy: 0.6897\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0987 - accuracy: 0.9569 - val_loss: 4.5669 - val_accuracy: 0.6897\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1078 - accuracy: 0.9569 - val_loss: 4.8740 - val_accuracy: 0.7241\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0942 - accuracy: 0.9655 - val_loss: 5.0263 - val_accuracy: 0.7241\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0940 - accuracy: 0.9655 - val_loss: 5.1473 - val_accuracy: 0.7241\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0815 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1022 - accuracy: 0.9483 - val_loss: 5.3376 - val_accuracy: 0.7241\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1213 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1464 - accuracy: 0.9397 - val_loss: 5.0400 - val_accuracy: 0.7241\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0923 - accuracy: 0.9569 - val_loss: 4.8579 - val_accuracy: 0.6207\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1141 - accuracy: 0.9569 - val_loss: 4.6444 - val_accuracy: 0.6552\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0641 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1427 - accuracy: 0.9224 - val_loss: 4.6299 - val_accuracy: 0.6552\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1427 - accuracy: 0.9138 - val_loss: 4.6936 - val_accuracy: 0.6897\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1154 - accuracy: 0.9483 - val_loss: 4.7763 - val_accuracy: 0.7241\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1171 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1093 - accuracy: 0.9569 - val_loss: 4.8264 - val_accuracy: 0.6897\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1043 - accuracy: 0.9397 - val_loss: 5.1776 - val_accuracy: 0.6552\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0554 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0915 - accuracy: 0.9483 - val_loss: 5.3703 - val_accuracy: 0.6207\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0990 - accuracy: 0.9483 - val_loss: 5.6487 - val_accuracy: 0.6207\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0698 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0930 - accuracy: 0.9569 - val_loss: 5.4701 - val_accuracy: 0.7241\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.90 - 0s 146us/sample - loss: 0.0873 - accuracy: 0.9483 - val_loss: 5.6332 - val_accuracy: 0.7241\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6863 - accuracy: 0.62 - 0s 4ms/sample - loss: 0.6411 - accuracy: 0.6638 - val_loss: 0.6273 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4968 - accuracy: 0.81 - 0s 163us/sample - loss: 0.6888 - accuracy: 0.6638 - val_loss: 0.6404 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6196 - accuracy: 0.71 - 0s 181us/sample - loss: 0.6605 - accuracy: 0.6724 - val_loss: 0.6831 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6858 - accuracy: 0.59 - 0s 172us/sample - loss: 0.6779 - accuracy: 0.6638 - val_loss: 0.6713 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6662 - accuracy: 0.68 - 0s 172us/sample - loss: 0.6637 - accuracy: 0.6638 - val_loss: 0.6508 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6496 - accuracy: 0.65 - 0s 168us/sample - loss: 0.6413 - accuracy: 0.6638 - val_loss: 0.6349 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7167 - accuracy: 0.53 - 0s 181us/sample - loss: 0.6280 - accuracy: 0.6638 - val_loss: 0.6241 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6626 - accuracy: 0.59 - 0s 163us/sample - loss: 0.6211 - accuracy: 0.6638 - val_loss: 0.6057 - val_accuracy: 0.6897\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7268 - accuracy: 0.59 - 0s 163us/sample - loss: 0.6111 - accuracy: 0.6724 - val_loss: 0.5945 - val_accuracy: 0.6552\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5949 - accuracy: 0.68 - 0s 168us/sample - loss: 0.6190 - accuracy: 0.6983 - val_loss: 0.6010 - val_accuracy: 0.6552\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5453 - accuracy: 0.78 - 0s 155us/sample - loss: 0.5776 - accuracy: 0.7328 - val_loss: 0.6291 - val_accuracy: 0.6207\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5720 - accuracy: 0.78 - 0s 172us/sample - loss: 0.5736 - accuracy: 0.7241 - val_loss: 0.6182 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5733 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5596 - accuracy: 0.7241 - val_loss: 0.6489 - val_accuracy: 0.7241\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5302 - accuracy: 0.75 - 0s 151us/sample - loss: 0.5855 - accuracy: 0.6983 - val_loss: 0.6260 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5487 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5698 - accuracy: 0.6983 - val_loss: 0.6962 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.71 - 0s 181us/sample - loss: 0.5635 - accuracy: 0.7586 - val_loss: 0.6091 - val_accuracy: 0.6552\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5211 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5532 - accuracy: 0.7155 - val_loss: 0.6050 - val_accuracy: 0.6897\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6164 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5447 - accuracy: 0.7328 - val_loss: 0.6707 - val_accuracy: 0.7586\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5743 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5228 - accuracy: 0.7672 - val_loss: 0.7621 - val_accuracy: 0.7586\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4746 - accuracy: 0.78 - 0s 155us/sample - loss: 0.5015 - accuracy: 0.7586 - val_loss: 0.8935 - val_accuracy: 0.7586\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4964 - accuracy: 0.75 - 0s 224us/sample - loss: 0.4890 - accuracy: 0.7586 - val_loss: 0.8288 - val_accuracy: 0.7241\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4251 - accuracy: 0.84 - 0s 206us/sample - loss: 0.4745 - accuracy: 0.7931 - val_loss: 0.9378 - val_accuracy: 0.7586\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3935 - accuracy: 0.81 - 0s 180us/sample - loss: 0.4555 - accuracy: 0.8103 - val_loss: 1.0980 - val_accuracy: 0.7586\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3954 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4590 - accuracy: 0.7931 - val_loss: 1.0958 - val_accuracy: 0.7586\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.71 - 0s 224us/sample - loss: 0.4947 - accuracy: 0.7414 - val_loss: 1.0916 - val_accuracy: 0.7241\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.75 - 0s 198us/sample - loss: 0.4986 - accuracy: 0.7672 - val_loss: 0.8579 - val_accuracy: 0.7586\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.71 - 0s 163us/sample - loss: 0.4842 - accuracy: 0.7586 - val_loss: 0.9193 - val_accuracy: 0.7241\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4954 - accuracy: 0.75 - 0s 163us/sample - loss: 0.4384 - accuracy: 0.8017 - val_loss: 1.1965 - val_accuracy: 0.6897\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4411 - accuracy: 0.81 - 0s 163us/sample - loss: 0.4159 - accuracy: 0.8190 - val_loss: 1.4634 - val_accuracy: 0.7241\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5023 - accuracy: 0.75 - 0s 163us/sample - loss: 0.3946 - accuracy: 0.8103 - val_loss: 1.5789 - val_accuracy: 0.6897\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5178 - accuracy: 0.75 - 0s 163us/sample - loss: 0.3806 - accuracy: 0.8190 - val_loss: 1.5564 - val_accuracy: 0.7586\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3092 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3948 - accuracy: 0.8190 - val_loss: 1.5636 - val_accuracy: 0.7586\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.71 - 0s 163us/sample - loss: 0.4204 - accuracy: 0.8017 - val_loss: 1.6137 - val_accuracy: 0.6897\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.84 - 0s 163us/sample - loss: 0.4301 - accuracy: 0.8190 - val_loss: 1.4507 - val_accuracy: 0.7586\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3026 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3799 - accuracy: 0.7845 - val_loss: 1.1680 - val_accuracy: 0.7586\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4692 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4404 - accuracy: 0.8017 - val_loss: 1.1053 - val_accuracy: 0.7586\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4035 - accuracy: 0.7845 - val_loss: 1.1678 - val_accuracy: 0.7586\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5610 - accuracy: 0.68 - 0s 146us/sample - loss: 0.4236 - accuracy: 0.7931 - val_loss: 1.4815 - val_accuracy: 0.7241\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.90 - 0s 2ms/sample - loss: 0.3994 - accuracy: 0.8448 - val_loss: 1.6708 - val_accuracy: 0.7931\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3652 - accuracy: 0.84 - 0s 318us/sample - loss: 0.3476 - accuracy: 0.8362 - val_loss: 1.8622 - val_accuracy: 0.7931\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3575 - accuracy: 0.78 - 0s 172us/sample - loss: 0.3646 - accuracy: 0.8276 - val_loss: 2.0618 - val_accuracy: 0.7931\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3138 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3426 - accuracy: 0.8534 - val_loss: 2.1681 - val_accuracy: 0.7586\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.96 - 0s 163us/sample - loss: 0.3422 - accuracy: 0.8621 - val_loss: 2.3855 - val_accuracy: 0.7586\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2263 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3279 - accuracy: 0.8362 - val_loss: 2.1935 - val_accuracy: 0.7241\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3206 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3398 - accuracy: 0.8276 - val_loss: 2.3168 - val_accuracy: 0.7241\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3685 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2962 - accuracy: 0.8966 - val_loss: 2.8565 - val_accuracy: 0.7931\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2742 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3153 - accuracy: 0.8707 - val_loss: 2.6204 - val_accuracy: 0.7586\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.90 - 0s 164us/sample - loss: 0.3753 - accuracy: 0.8707 - val_loss: 1.9884 - val_accuracy: 0.7586\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3535 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3198 - accuracy: 0.8534 - val_loss: 1.7429 - val_accuracy: 0.7586\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3567 - accuracy: 0.90 - 0s 163us/sample - loss: 0.3460 - accuracy: 0.8362 - val_loss: 2.2872 - val_accuracy: 0.7241\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3359 - accuracy: 0.84 - 0s 163us/sample - loss: 0.3434 - accuracy: 0.8362 - val_loss: 1.9083 - val_accuracy: 0.7931\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3716 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3128 - accuracy: 0.8448 - val_loss: 1.9711 - val_accuracy: 0.7931\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3491 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3740 - accuracy: 0.8190 - val_loss: 2.0184 - val_accuracy: 0.6552\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4611 - accuracy: 0.71 - 0s 146us/sample - loss: 0.3313 - accuracy: 0.8621 - val_loss: 2.0193 - val_accuracy: 0.7241\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2988 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2805 - accuracy: 0.8966 - val_loss: 1.9876 - val_accuracy: 0.7931\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1879 - accuracy: 0.96 - 0s 172us/sample - loss: 0.2986 - accuracy: 0.8879 - val_loss: 2.4850 - val_accuracy: 0.7586\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.84 - 0s 163us/sample - loss: 0.2887 - accuracy: 0.8707 - val_loss: 2.3957 - val_accuracy: 0.6897\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4688 - accuracy: 0.78 - 0s 181us/sample - loss: 0.2904 - accuracy: 0.8879 - val_loss: 2.5060 - val_accuracy: 0.7586\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1878 - accuracy: 0.93 - 0s 172us/sample - loss: 0.2430 - accuracy: 0.8966 - val_loss: 3.1242 - val_accuracy: 0.7931\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2483 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2745 - accuracy: 0.8707 - val_loss: 2.8172 - val_accuracy: 0.7241\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4865 - accuracy: 0.75 - 0s 155us/sample - loss: 0.3076 - accuracy: 0.8621 - val_loss: 3.3606 - val_accuracy: 0.7241\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1780 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2449 - accuracy: 0.9138 - val_loss: 3.7202 - val_accuracy: 0.7241\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2522 - accuracy: 0.8966 - val_loss: 4.4376 - val_accuracy: 0.7586\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2714 - accuracy: 0.8966 - val_loss: 3.9890 - val_accuracy: 0.7931\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2997 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2537 - accuracy: 0.9052 - val_loss: 4.2065 - val_accuracy: 0.7586\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3175 - accuracy: 0.84 - 0s 151us/sample - loss: 0.2744 - accuracy: 0.8793 - val_loss: 3.9001 - val_accuracy: 0.7931\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1984 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2489 - accuracy: 0.8793 - val_loss: 4.7179 - val_accuracy: 0.7586\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1984 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3028 - accuracy: 0.8879 - val_loss: 4.1413 - val_accuracy: 0.6552\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7891 - accuracy: 0.81 - 0s 137us/sample - loss: 0.5978 - accuracy: 0.8190 - val_loss: 1.8303 - val_accuracy: 0.7241\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3122 - accuracy: 0.90 - 0s 138us/sample - loss: 0.5168 - accuracy: 0.7931 - val_loss: 2.4341 - val_accuracy: 0.6552\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4004 - accuracy: 0.87 - 0s 133us/sample - loss: 0.7938 - accuracy: 0.7759 - val_loss: 1.4146 - val_accuracy: 0.7586\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5219 - accuracy: 0.84 - 0s 146us/sample - loss: 0.5083 - accuracy: 0.8190 - val_loss: 0.8039 - val_accuracy: 0.7586\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4967 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5309 - accuracy: 0.7155 - val_loss: 0.7117 - val_accuracy: 0.6897\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5381 - accuracy: 0.68 - 0s 163us/sample - loss: 0.5346 - accuracy: 0.6983 - val_loss: 0.6726 - val_accuracy: 0.6897\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5041 - accuracy: 0.7241 - val_loss: 0.6287 - val_accuracy: 0.7241\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5020 - accuracy: 0.75 - 0s 219us/sample - loss: 0.4445 - accuracy: 0.7931 - val_loss: 0.6373 - val_accuracy: 0.6897\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3929 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4077 - accuracy: 0.8103 - val_loss: 0.8110 - val_accuracy: 0.6552\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4475 - accuracy: 0.75 - 0s 172us/sample - loss: 0.3587 - accuracy: 0.8276 - val_loss: 0.8817 - val_accuracy: 0.6897\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3064 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3124 - accuracy: 0.8707 - val_loss: 0.9468 - val_accuracy: 0.6897\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3045 - accuracy: 0.8534 - val_loss: 1.0464 - val_accuracy: 0.6552\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2880 - accuracy: 0.8966 - val_loss: 1.2592 - val_accuracy: 0.6897\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3271 - accuracy: 0.84 - 0s 155us/sample - loss: 0.2872 - accuracy: 0.8793 - val_loss: 1.3107 - val_accuracy: 0.5862\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3112 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3387 - accuracy: 0.8534 - val_loss: 1.2010 - val_accuracy: 0.6897\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2965 - accuracy: 0.8707 - val_loss: 1.3510 - val_accuracy: 0.5862\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3910 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4355 - accuracy: 0.7845 - val_loss: 0.9832 - val_accuracy: 0.7586\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2422 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3708 - accuracy: 0.8448 - val_loss: 0.8519 - val_accuracy: 0.7241\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1923 - accuracy: 0.96 - 0s 146us/sample - loss: 0.3093 - accuracy: 0.8707 - val_loss: 1.0419 - val_accuracy: 0.5862\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4275 - accuracy: 0.71 - 0s 146us/sample - loss: 0.3712 - accuracy: 0.7759 - val_loss: 1.0660 - val_accuracy: 0.6897\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4361 - accuracy: 0.71 - 0s 163us/sample - loss: 0.2655 - accuracy: 0.8879 - val_loss: 1.3769 - val_accuracy: 0.6897\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3628 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2632 - accuracy: 0.9138 - val_loss: 1.7746 - val_accuracy: 0.7241\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1955 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2111 - accuracy: 0.9224 - val_loss: 1.8863 - val_accuracy: 0.6897\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2961 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2601 - accuracy: 0.8966 - val_loss: 2.1046 - val_accuracy: 0.6897\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2679 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2303 - accuracy: 0.8793 - val_loss: 1.8082 - val_accuracy: 0.6552\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2180 - accuracy: 0.9224 - val_loss: 1.7918 - val_accuracy: 0.7241\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2350 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2478 - accuracy: 0.9138 - val_loss: 1.7849 - val_accuracy: 0.7241\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.93 - 0s 172us/sample - loss: 0.2396 - accuracy: 0.8966 - val_loss: 2.3650 - val_accuracy: 0.5517\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1273 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2383 - accuracy: 0.9052 - val_loss: 2.1421 - val_accuracy: 0.6897\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2637 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3276 - accuracy: 0.8707 - val_loss: 2.1311 - val_accuracy: 0.6897\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2556 - accuracy: 0.8793 - val_loss: 1.8988 - val_accuracy: 0.7241\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2636 - accuracy: 0.9052 - val_loss: 1.7824 - val_accuracy: 0.6897\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2170 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2637 - accuracy: 0.8793 - val_loss: 1.8517 - val_accuracy: 0.7586\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.1900 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2489 - accuracy: 0.8966 - val_loss: 2.0542 - val_accuracy: 0.6552\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1203 - accuracy: 1.00 - 0s 155us/sample - loss: 0.2287 - accuracy: 0.9310 - val_loss: 2.1627 - val_accuracy: 0.6897\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2026 - accuracy: 0.9052 - val_loss: 2.6307 - val_accuracy: 0.6897\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.87 - 0s 137us/sample - loss: 0.1912 - accuracy: 0.9138 - val_loss: 2.6189 - val_accuracy: 0.6897\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2503 - accuracy: 0.90 - 0s 172us/sample - loss: 0.1810 - accuracy: 0.9310 - val_loss: 2.8800 - val_accuracy: 0.6552\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1676 - accuracy: 0.9224 - val_loss: 2.9489 - val_accuracy: 0.7241\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1706 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1498 - accuracy: 0.9483 - val_loss: 3.2529 - val_accuracy: 0.6207\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1135 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2068 - accuracy: 0.9052 - val_loss: 3.3499 - val_accuracy: 0.6897\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2385 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1898 - accuracy: 0.9224 - val_loss: 3.9503 - val_accuracy: 0.4828\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2126 - accuracy: 0.96 - 0s 129us/sample - loss: 0.3958 - accuracy: 0.8793 - val_loss: 2.5161 - val_accuracy: 0.6897\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6696 - accuracy: 0.81 - 0s 138us/sample - loss: 0.5011 - accuracy: 0.8362 - val_loss: 2.0014 - val_accuracy: 0.6897\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3121 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3098 - accuracy: 0.8879 - val_loss: 1.8767 - val_accuracy: 0.6897\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3202 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3130 - accuracy: 0.8793 - val_loss: 1.6250 - val_accuracy: 0.7586\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2931 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2870 - accuracy: 0.8966 - val_loss: 1.6902 - val_accuracy: 0.7586\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2457 - accuracy: 0.8879 - val_loss: 2.1103 - val_accuracy: 0.7241\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.96 - 0s 142us/sample - loss: 0.2392 - accuracy: 0.8966 - val_loss: 2.4774 - val_accuracy: 0.6897\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2432 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2300 - accuracy: 0.8793 - val_loss: 2.5212 - val_accuracy: 0.6897\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2016 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1991 - accuracy: 0.9224 - val_loss: 2.4611 - val_accuracy: 0.7241\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2160 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1865 - accuracy: 0.9224 - val_loss: 2.5915 - val_accuracy: 0.6552\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1605 - accuracy: 0.9397 - val_loss: 2.8007 - val_accuracy: 0.7241\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.96 - 0s 142us/sample - loss: 0.1661 - accuracy: 0.9310 - val_loss: 3.2574 - val_accuracy: 0.6552\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1827 - accuracy: 0.9138 - val_loss: 3.3272 - val_accuracy: 0.7241\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2160 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2332 - accuracy: 0.8966 - val_loss: 3.0264 - val_accuracy: 0.7586\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1129 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2611 - accuracy: 0.8966 - val_loss: 3.0593 - val_accuracy: 0.6207\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2626 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2818 - accuracy: 0.8966 - val_loss: 2.7969 - val_accuracy: 0.6552\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2742 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2446 - accuracy: 0.8966 - val_loss: 2.5929 - val_accuracy: 0.6207\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2538 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2540 - accuracy: 0.8879 - val_loss: 2.2520 - val_accuracy: 0.7241\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2120 - accuracy: 0.9052 - val_loss: 2.3503 - val_accuracy: 0.6897\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1698 - accuracy: 0.9397 - val_loss: 2.7401 - val_accuracy: 0.6897\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1886 - accuracy: 0.9224 - val_loss: 2.9502 - val_accuracy: 0.6897\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1556 - accuracy: 0.9310 - val_loss: 3.0756 - val_accuracy: 0.6552\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1410 - accuracy: 0.9310 - val_loss: 3.5789 - val_accuracy: 0.5517\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1516 - accuracy: 0.9310 - val_loss: 3.7942 - val_accuracy: 0.5862\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1119 - accuracy: 0.9569 - val_loss: 4.0635 - val_accuracy: 0.6207\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1897 - accuracy: 0.90 - 0s 167us/sample - loss: 0.1425 - accuracy: 0.9224 - val_loss: 4.2589 - val_accuracy: 0.5862\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1190 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1075 - accuracy: 0.9655 - val_loss: 4.7960 - val_accuracy: 0.5517\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1273 - accuracy: 0.9397 - val_loss: 5.4690 - val_accuracy: 0.4483\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2354 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1899 - accuracy: 0.9052 - val_loss: 4.1544 - val_accuracy: 0.6897\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.87 - 0s 140us/sample - loss: 0.1826 - accuracy: 0.9052 - val_loss: 4.1117 - val_accuracy: 0.5862\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2457 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1182 - accuracy: 0.9741 - val_loss: 4.0146 - val_accuracy: 0.6897\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2502 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1489 - accuracy: 0.9397 - val_loss: 4.3643 - val_accuracy: 0.5172\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1254 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1257 - accuracy: 0.9569 - val_loss: 4.3325 - val_accuracy: 0.5862\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0884 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1426 - accuracy: 0.9310 - val_loss: 4.6737 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1583 - accuracy: 0.90 - 0s 131us/sample - loss: 0.1183 - accuracy: 0.9483 - val_loss: 4.6921 - val_accuracy: 0.6552\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1211 - accuracy: 0.9483 - val_loss: 4.7534 - val_accuracy: 0.6207\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1117 - accuracy: 0.9569 - val_loss: 4.6752 - val_accuracy: 0.6207\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.90 - 0s 172us/sample - loss: 0.1597 - accuracy: 0.9310 - val_loss: 5.0861 - val_accuracy: 0.5172\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 1.00 - 0s 186us/sample - loss: 0.1230 - accuracy: 0.9569 - val_loss: 4.8522 - val_accuracy: 0.6207\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.93 - 0s 189us/sample - loss: 0.1592 - accuracy: 0.9224 - val_loss: 5.2178 - val_accuracy: 0.5862\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0591 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1628 - accuracy: 0.9397 - val_loss: 4.6960 - val_accuracy: 0.6207\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1562 - accuracy: 0.9310 - val_loss: 5.0041 - val_accuracy: 0.5517\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1368 - accuracy: 0.9397 - val_loss: 4.8604 - val_accuracy: 0.4828\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1207 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1548 - accuracy: 0.9483 - val_loss: 4.7519 - val_accuracy: 0.6552\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1149 - accuracy: 0.9569 - val_loss: 5.5985 - val_accuracy: 0.5517\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0877 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1365 - accuracy: 0.9483 - val_loss: 4.6005 - val_accuracy: 0.6552\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1343 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2648 - accuracy: 0.9052 - val_loss: 5.2334 - val_accuracy: 0.5172\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3583 - accuracy: 0.81 - 0s 138us/sample - loss: 0.1959 - accuracy: 0.9138 - val_loss: 4.3743 - val_accuracy: 0.6207\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.96 - 0s 163us/sample - loss: 0.2993 - accuracy: 0.8879 - val_loss: 4.6657 - val_accuracy: 0.6207\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2047 - accuracy: 0.93 - 0s 163us/sample - loss: 0.3078 - accuracy: 0.8621 - val_loss: 2.8742 - val_accuracy: 0.6897\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2037 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2152 - accuracy: 0.9138 - val_loss: 2.0319 - val_accuracy: 0.6552\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.87 - 0s 151us/sample - loss: 0.2227 - accuracy: 0.9310 - val_loss: 1.8768 - val_accuracy: 0.5862\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3380 - accuracy: 0.81 - 0s 172us/sample - loss: 0.2134 - accuracy: 0.9138 - val_loss: 2.0824 - val_accuracy: 0.5862\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.87 - 0s 163us/sample - loss: 0.1795 - accuracy: 0.9224 - val_loss: 2.6900 - val_accuracy: 0.6552\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1040 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1542 - accuracy: 0.9310 - val_loss: 3.4822 - val_accuracy: 0.6552\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1598 - accuracy: 0.93 - 0s 172us/sample - loss: 0.1407 - accuracy: 0.9224 - val_loss: 3.9386 - val_accuracy: 0.6552\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1092 - accuracy: 0.9310 - val_loss: 4.2507 - val_accuracy: 0.5862\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0988 - accuracy: 0.9655 - val_loss: 4.7148 - val_accuracy: 0.5172\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0742 - accuracy: 0.9741 - val_loss: 5.2417 - val_accuracy: 0.5517\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0743 - accuracy: 0.9655 - val_loss: 6.1136 - val_accuracy: 0.5517\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.96 - 0s 158us/sample - loss: 0.0941 - accuracy: 0.9741 - val_loss: 5.7213 - val_accuracy: 0.5172\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1602 - accuracy: 0.9483 - val_loss: 6.2184 - val_accuracy: 0.5517\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3209 - accuracy: 0.87 - 0s 163us/sample - loss: 0.1789 - accuracy: 0.9310 - val_loss: 5.7418 - val_accuracy: 0.5172\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1996 - accuracy: 0.9310 - val_loss: 4.0795 - val_accuracy: 0.6552\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2166 - accuracy: 0.9397 - val_loss: 3.7125 - val_accuracy: 0.5172\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2738 - accuracy: 0.8879 - val_loss: 2.9518 - val_accuracy: 0.6207\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.87 - 0s 215us/sample - loss: 0.2372 - accuracy: 0.8879 - val_loss: 3.1886 - val_accuracy: 0.6552\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1437 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1911 - accuracy: 0.9397 - val_loss: 3.4009 - val_accuracy: 0.5517\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1831 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1886 - accuracy: 0.9310 - val_loss: 3.3218 - val_accuracy: 0.6552\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0807 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1593 - accuracy: 0.9397 - val_loss: 3.5152 - val_accuracy: 0.6552\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1402 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1600 - accuracy: 0.9310 - val_loss: 4.2493 - val_accuracy: 0.6207\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1272 - accuracy: 0.9655 - val_loss: 5.0857 - val_accuracy: 0.6207\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1116 - accuracy: 0.9569 - val_loss: 6.4179 - val_accuracy: 0.5517\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0946 - accuracy: 0.9569 - val_loss: 6.4036 - val_accuracy: 0.6207\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.90 - 0s 138us/sample - loss: 0.0866 - accuracy: 0.9655 - val_loss: 7.1525 - val_accuracy: 0.5517\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0315 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0874 - accuracy: 0.9569 - val_loss: 9.7860 - val_accuracy: 0.5172\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1774 - accuracy: 0.9138 - val_loss: 7.7750 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1849 - accuracy: 0.9224 - val_loss: 6.9179 - val_accuracy: 0.6552\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.93 - 0s 163us/sample - loss: 0.8273 - accuracy: 0.8190 - val_loss: 5.6136 - val_accuracy: 0.6897\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4866 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4635 - accuracy: 0.8362 - val_loss: 3.9889 - val_accuracy: 0.6552\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3238 - accuracy: 0.8793 - val_loss: 2.2537 - val_accuracy: 0.7241\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3717 - accuracy: 0.90 - 0s 137us/sample - loss: 0.3397 - accuracy: 0.8966 - val_loss: 1.6190 - val_accuracy: 0.6897\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.96 - 0s 155us/sample - loss: 0.3105 - accuracy: 0.8966 - val_loss: 1.8997 - val_accuracy: 0.6897\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2641 - accuracy: 0.8966 - val_loss: 2.8512 - val_accuracy: 0.6897\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2555 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2337 - accuracy: 0.8793 - val_loss: 3.4406 - val_accuracy: 0.6897\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2540 - accuracy: 0.9138 - val_loss: 3.6935 - val_accuracy: 0.7241\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2277 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2170 - accuracy: 0.8966 - val_loss: 3.8840 - val_accuracy: 0.6897\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2603 - accuracy: 0.84 - 0s 146us/sample - loss: 0.1735 - accuracy: 0.9224 - val_loss: 3.4721 - val_accuracy: 0.7241\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1845 - accuracy: 0.9138 - val_loss: 3.5889 - val_accuracy: 0.7241\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1299 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1570 - accuracy: 0.9224 - val_loss: 4.0015 - val_accuracy: 0.6207\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 1s - loss: 0.6952 - accuracy: 0.50 - 1s 7ms/sample - loss: 0.6389 - accuracy: 0.6552 - val_loss: 0.8217 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.8255 - accuracy: 0.65 - 0s 155us/sample - loss: 0.7265 - accuracy: 0.6638 - val_loss: 0.6524 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6573 - accuracy: 0.65 - 0s 155us/sample - loss: 0.6551 - accuracy: 0.6638 - val_loss: 0.6559 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6409 - accuracy: 0.71 - 0s 163us/sample - loss: 0.6484 - accuracy: 0.6638 - val_loss: 0.6388 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6307 - accuracy: 0.68 - 0s 155us/sample - loss: 0.6384 - accuracy: 0.6638 - val_loss: 0.6172 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5604 - accuracy: 0.71 - 0s 155us/sample - loss: 0.6189 - accuracy: 0.6638 - val_loss: 0.6047 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6050 - accuracy: 0.68 - 0s 155us/sample - loss: 0.6066 - accuracy: 0.6638 - val_loss: 0.5923 - val_accuracy: 0.7241\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5912 - accuracy: 0.7155 - val_loss: 0.5749 - val_accuracy: 0.6897\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5973 - accuracy: 0.68 - 0s 181us/sample - loss: 0.5943 - accuracy: 0.6983 - val_loss: 0.5609 - val_accuracy: 0.7241\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.75 - 0s 172us/sample - loss: 0.5809 - accuracy: 0.7069 - val_loss: 0.5577 - val_accuracy: 0.7586\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5183 - accuracy: 0.78 - 0s 181us/sample - loss: 0.5618 - accuracy: 0.7328 - val_loss: 0.5605 - val_accuracy: 0.6897\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4965 - accuracy: 0.75 - 0s 163us/sample - loss: 0.5507 - accuracy: 0.7414 - val_loss: 0.5625 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5706 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5296 - accuracy: 0.7672 - val_loss: 0.5700 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5401 - accuracy: 0.7069 - val_loss: 0.5819 - val_accuracy: 0.7241\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4361 - accuracy: 0.78 - 0s 155us/sample - loss: 0.5295 - accuracy: 0.7414 - val_loss: 0.5815 - val_accuracy: 0.7586\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.75 - 0s 163us/sample - loss: 0.5775 - accuracy: 0.6552 - val_loss: 0.6014 - val_accuracy: 0.6897\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5739 - accuracy: 0.65 - 0s 155us/sample - loss: 0.4846 - accuracy: 0.7500 - val_loss: 0.5906 - val_accuracy: 0.7241\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4084 - accuracy: 0.78 - 0s 163us/sample - loss: 0.5137 - accuracy: 0.7414 - val_loss: 0.6837 - val_accuracy: 0.7241\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4702 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4845 - accuracy: 0.7845 - val_loss: 0.6160 - val_accuracy: 0.7931\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4948 - accuracy: 0.75 - 0s 155us/sample - loss: 0.4667 - accuracy: 0.7759 - val_loss: 0.7793 - val_accuracy: 0.7241\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4350 - accuracy: 0.81 - 0s 163us/sample - loss: 0.4367 - accuracy: 0.7931 - val_loss: 0.7730 - val_accuracy: 0.7931\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4886 - accuracy: 0.7414 - val_loss: 1.5167 - val_accuracy: 0.5862\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4638 - accuracy: 0.84 - 0s 163us/sample - loss: 0.4579 - accuracy: 0.7759 - val_loss: 0.8244 - val_accuracy: 0.7586\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5624 - accuracy: 0.68 - 0s 155us/sample - loss: 0.5306 - accuracy: 0.7328 - val_loss: 0.7507 - val_accuracy: 0.6897\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4297 - accuracy: 0.81 - 0s 163us/sample - loss: 0.4959 - accuracy: 0.7586 - val_loss: 1.0484 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5273 - accuracy: 0.81 - 0s 155us/sample - loss: 0.5402 - accuracy: 0.7500 - val_loss: 0.9416 - val_accuracy: 0.6897\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4918 - accuracy: 0.81 - 0s 155us/sample - loss: 0.5114 - accuracy: 0.7500 - val_loss: 0.5903 - val_accuracy: 0.7241\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6135 - accuracy: 0.65 - 0s 146us/sample - loss: 0.5253 - accuracy: 0.7241 - val_loss: 0.5629 - val_accuracy: 0.7586\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5756 - accuracy: 0.68 - 0s 163us/sample - loss: 0.5442 - accuracy: 0.7414 - val_loss: 0.5747 - val_accuracy: 0.6897\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4564 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4994 - accuracy: 0.7759 - val_loss: 0.5390 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4352 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4940 - accuracy: 0.7672 - val_loss: 0.5755 - val_accuracy: 0.7586\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4959 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4772 - accuracy: 0.8017 - val_loss: 0.7265 - val_accuracy: 0.6897\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4312 - accuracy: 0.87 - 0s 138us/sample - loss: 0.4640 - accuracy: 0.8017 - val_loss: 0.6726 - val_accuracy: 0.7241\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3575 - accuracy: 0.87 - 0s 146us/sample - loss: 0.4389 - accuracy: 0.7931 - val_loss: 1.0305 - val_accuracy: 0.7586\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3052 - accuracy: 0.84 - 0s 129us/sample - loss: 0.5330 - accuracy: 0.7069 - val_loss: 0.5617 - val_accuracy: 0.7586\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5792 - accuracy: 0.71 - 0s 206us/sample - loss: 0.5073 - accuracy: 0.7241 - val_loss: 0.5496 - val_accuracy: 0.7241\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6070 - accuracy: 0.68 - 0s 163us/sample - loss: 0.5175 - accuracy: 0.7931 - val_loss: 0.6081 - val_accuracy: 0.6552\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.68 - 0s 163us/sample - loss: 0.5119 - accuracy: 0.7759 - val_loss: 0.5792 - val_accuracy: 0.6897\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5397 - accuracy: 0.68 - 0s 155us/sample - loss: 0.4620 - accuracy: 0.7845 - val_loss: 0.6252 - val_accuracy: 0.6897\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.87 - 0s 138us/sample - loss: 0.4430 - accuracy: 0.8017 - val_loss: 1.1098 - val_accuracy: 0.6897\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5335 - accuracy: 0.71 - 0s 138us/sample - loss: 0.4399 - accuracy: 0.8190 - val_loss: 1.2267 - val_accuracy: 0.6897\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5077 - accuracy: 0.75 - 0s 151us/sample - loss: 0.4084 - accuracy: 0.8190 - val_loss: 1.0960 - val_accuracy: 0.6897\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3351 - accuracy: 0.87 - 0s 138us/sample - loss: 0.4569 - accuracy: 0.8017 - val_loss: 1.3676 - val_accuracy: 0.6897\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3223 - accuracy: 0.93 - 0s 146us/sample - loss: 0.4092 - accuracy: 0.8534 - val_loss: 1.0879 - val_accuracy: 0.7241\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4135 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4131 - accuracy: 0.8190 - val_loss: 0.7021 - val_accuracy: 0.6552\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3782 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3887 - accuracy: 0.8362 - val_loss: 0.7281 - val_accuracy: 0.6897\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.78 - 0s 146us/sample - loss: 0.3826 - accuracy: 0.8534 - val_loss: 0.7740 - val_accuracy: 0.7241\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4651 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3693 - accuracy: 0.8534 - val_loss: 1.0495 - val_accuracy: 0.6897\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3465 - accuracy: 0.8707 - val_loss: 1.3655 - val_accuracy: 0.7241\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2608 - accuracy: 0.90 - 0s 155us/sample - loss: 0.4107 - accuracy: 0.8017 - val_loss: 1.1271 - val_accuracy: 0.7241\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3017 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4445 - accuracy: 0.7759 - val_loss: 1.0432 - val_accuracy: 0.7586\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.90 - 0s 146us/sample - loss: 0.4118 - accuracy: 0.8017 - val_loss: 0.8582 - val_accuracy: 0.6897\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3097 - accuracy: 0.90 - 0s 146us/sample - loss: 0.4069 - accuracy: 0.8190 - val_loss: 0.7679 - val_accuracy: 0.6552\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3313 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3930 - accuracy: 0.8103 - val_loss: 0.9885 - val_accuracy: 0.7586\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3387 - accuracy: 0.78 - 0s 129us/sample - loss: 0.3519 - accuracy: 0.8276 - val_loss: 1.2827 - val_accuracy: 0.7241\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3330 - accuracy: 0.8534 - val_loss: 1.6742 - val_accuracy: 0.6897\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3747 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3528 - accuracy: 0.8448 - val_loss: 1.6460 - val_accuracy: 0.6897\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2219 - accuracy: 0.93 - 0s 129us/sample - loss: 0.3202 - accuracy: 0.8707 - val_loss: 2.0345 - val_accuracy: 0.7241\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3368 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3605 - accuracy: 0.8103 - val_loss: 1.6875 - val_accuracy: 0.6897\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3191 - accuracy: 0.8621 - val_loss: 1.8590 - val_accuracy: 0.6897\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3621 - accuracy: 0.84 - 0s 148us/sample - loss: 0.3089 - accuracy: 0.8534 - val_loss: 1.7595 - val_accuracy: 0.6897\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3015 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3569 - accuracy: 0.8448 - val_loss: 2.6763 - val_accuracy: 0.5862\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4625 - accuracy: 0.78 - 0s 155us/sample - loss: 0.3511 - accuracy: 0.8362 - val_loss: 1.7282 - val_accuracy: 0.7241\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4815 - accuracy: 0.78 - 0s 146us/sample - loss: 0.3946 - accuracy: 0.8190 - val_loss: 2.0779 - val_accuracy: 0.7241\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3609 - accuracy: 0.8190 - val_loss: 1.5346 - val_accuracy: 0.6207\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1990 - accuracy: 0.93 - 0s 151us/sample - loss: 0.3559 - accuracy: 0.8534 - val_loss: 1.3348 - val_accuracy: 0.5862\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3436 - accuracy: 0.8448 - val_loss: 1.6268 - val_accuracy: 0.6897\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3788 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3324 - accuracy: 0.8621 - val_loss: 1.8215 - val_accuracy: 0.6552\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.78 - 0s 155us/sample - loss: 0.3146 - accuracy: 0.8534 - val_loss: 2.2652 - val_accuracy: 0.6897\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2448 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2861 - accuracy: 0.8621 - val_loss: 2.5137 - val_accuracy: 0.6552\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3181 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3229 - accuracy: 0.8621 - val_loss: 3.0190 - val_accuracy: 0.6897\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3093 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2869 - accuracy: 0.8707 - val_loss: 3.3342 - val_accuracy: 0.6897\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2064 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3168 - accuracy: 0.8448 - val_loss: 3.1337 - val_accuracy: 0.6552\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2800 - accuracy: 0.8793 - val_loss: 3.6163 - val_accuracy: 0.5862\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4287 - accuracy: 0.71 - 0s 146us/sample - loss: 0.2945 - accuracy: 0.8448 - val_loss: 2.2443 - val_accuracy: 0.6207\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3758 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3684 - accuracy: 0.8276 - val_loss: 1.8798 - val_accuracy: 0.5862\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2588 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3334 - accuracy: 0.8276 - val_loss: 1.6903 - val_accuracy: 0.5862\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3699 - accuracy: 0.90 - 0s 155us/sample - loss: 0.4313 - accuracy: 0.8362 - val_loss: 1.3713 - val_accuracy: 0.6207\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4771 - accuracy: 0.71 - 0s 146us/sample - loss: 0.4590 - accuracy: 0.7845 - val_loss: 1.8278 - val_accuracy: 0.6207\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4303 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4977 - accuracy: 0.7672 - val_loss: 0.8254 - val_accuracy: 0.6897\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5733 - accuracy: 0.65 - 0s 138us/sample - loss: 0.4533 - accuracy: 0.7414 - val_loss: 0.7017 - val_accuracy: 0.6897\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6457 - accuracy: 0.68 - 0s 138us/sample - loss: 0.5258 - accuracy: 0.7328 - val_loss: 0.6570 - val_accuracy: 0.7241\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4647 - accuracy: 0.7414 - val_loss: 0.6328 - val_accuracy: 0.7241\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4819 - accuracy: 0.68 - 0s 155us/sample - loss: 0.4401 - accuracy: 0.7759 - val_loss: 0.5688 - val_accuracy: 0.6897\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4011 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4244 - accuracy: 0.7759 - val_loss: 0.5916 - val_accuracy: 0.6552\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4279 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4349 - accuracy: 0.7759 - val_loss: 0.7467 - val_accuracy: 0.6897\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4663 - accuracy: 0.81 - 0s 129us/sample - loss: 0.4033 - accuracy: 0.8276 - val_loss: 1.0895 - val_accuracy: 0.6552\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3361 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3920 - accuracy: 0.8103 - val_loss: 1.5047 - val_accuracy: 0.6552\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3549 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3819 - accuracy: 0.8103 - val_loss: 1.7845 - val_accuracy: 0.6552\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3682 - accuracy: 0.8448 - val_loss: 2.4153 - val_accuracy: 0.7241\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3072 - accuracy: 0.90 - 0s 129us/sample - loss: 0.3695 - accuracy: 0.8448 - val_loss: 2.9979 - val_accuracy: 0.6552\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3014 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3934 - accuracy: 0.8362 - val_loss: 2.7514 - val_accuracy: 0.6552\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3886 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4382 - accuracy: 0.7759 - val_loss: 2.5645 - val_accuracy: 0.6897\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3283 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4131 - accuracy: 0.7845 - val_loss: 2.4140 - val_accuracy: 0.6897\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.71 - 0s 129us/sample - loss: 0.4131 - accuracy: 0.8017 - val_loss: 1.9289 - val_accuracy: 0.6897\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4281 - accuracy: 0.78 - 0s 146us/sample - loss: 0.3847 - accuracy: 0.8276 - val_loss: 2.2248 - val_accuracy: 0.6552\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3479 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3531 - accuracy: 0.8534 - val_loss: 2.4113 - val_accuracy: 0.6897\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4117 - accuracy: 0.78 - 0s 129us/sample - loss: 0.3512 - accuracy: 0.8276 - val_loss: 2.3348 - val_accuracy: 0.7241\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3080 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3891 - accuracy: 0.8362 - val_loss: 2.5964 - val_accuracy: 0.6552\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2631 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3862 - accuracy: 0.8103 - val_loss: 2.3183 - val_accuracy: 0.6552\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3795 - accuracy: 0.8190 - val_loss: 2.3712 - val_accuracy: 0.6552\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3605 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3218 - accuracy: 0.8707 - val_loss: 2.7495 - val_accuracy: 0.7241\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3061 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3438 - accuracy: 0.8621 - val_loss: 2.6255 - val_accuracy: 0.7241\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3863 - accuracy: 0.78 - 0s 146us/sample - loss: 0.3838 - accuracy: 0.8103 - val_loss: 2.7160 - val_accuracy: 0.6897\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2764 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3610 - accuracy: 0.8534 - val_loss: 3.2113 - val_accuracy: 0.5862\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3246 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3446 - accuracy: 0.8190 - val_loss: 2.6991 - val_accuracy: 0.6552\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3161 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3785 - accuracy: 0.8017 - val_loss: 4.4962 - val_accuracy: 0.7586\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.93 - 0s 137us/sample - loss: 0.3664 - accuracy: 0.8448 - val_loss: 0.9631 - val_accuracy: 0.7241\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2708 - accuracy: 0.90 - 0s 155us/sample - loss: 0.4243 - accuracy: 0.8362 - val_loss: 0.7005 - val_accuracy: 0.7586\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3213 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3488 - accuracy: 0.8448 - val_loss: 1.4835 - val_accuracy: 0.7586\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3412 - accuracy: 0.8707 - val_loss: 2.5122 - val_accuracy: 0.6897\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3112 - accuracy: 0.8621 - val_loss: 4.8524 - val_accuracy: 0.7586\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2978 - accuracy: 0.90 - 0s 2ms/sample - loss: 0.3097 - accuracy: 0.8707 - val_loss: 2.0013 - val_accuracy: 0.8276\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.84 - 0s 164us/sample - loss: 0.3481 - accuracy: 0.8448 - val_loss: 1.7543 - val_accuracy: 0.7931\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1569 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2865 - accuracy: 0.8534 - val_loss: 1.8900 - val_accuracy: 0.7586\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4068 - accuracy: 0.78 - 0s 155us/sample - loss: 0.3525 - accuracy: 0.8448 - val_loss: 2.5650 - val_accuracy: 0.7241\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.5183 - accuracy: 0.68 - 0s 155us/sample - loss: 0.3565 - accuracy: 0.8362 - val_loss: 2.9873 - val_accuracy: 0.7241\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2481 - accuracy: 0.93 - 0s 155us/sample - loss: 0.3087 - accuracy: 0.8621 - val_loss: 2.5388 - val_accuracy: 0.7586\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3062 - accuracy: 0.8707 - val_loss: 3.3888 - val_accuracy: 0.7586\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.87 - 0s 164us/sample - loss: 0.3114 - accuracy: 0.8707 - val_loss: 3.3798 - val_accuracy: 0.7241\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3182 - accuracy: 0.8448 - val_loss: 3.8860 - val_accuracy: 0.6897\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3575 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2876 - accuracy: 0.8793 - val_loss: 3.3863 - val_accuracy: 0.7586\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3006 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2724 - accuracy: 0.8879 - val_loss: 3.2179 - val_accuracy: 0.7931\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4653 - accuracy: 0.75 - 0s 155us/sample - loss: 0.2770 - accuracy: 0.8793 - val_loss: 3.2829 - val_accuracy: 0.8276\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1840 - accuracy: 0.90 - 0s 164us/sample - loss: 0.2622 - accuracy: 0.8879 - val_loss: 3.2241 - val_accuracy: 0.7586\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3494 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2513 - accuracy: 0.8879 - val_loss: 3.0587 - val_accuracy: 0.7931\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1763 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2198 - accuracy: 0.9052 - val_loss: 3.4307 - val_accuracy: 0.7586\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2822 - accuracy: 0.8793 - val_loss: 3.5788 - val_accuracy: 0.7586\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2157 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2665 - accuracy: 0.8879 - val_loss: 3.7752 - val_accuracy: 0.6207\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.93 - 0s 284us/sample - loss: 0.2721 - accuracy: 0.8879 - val_loss: 3.2692 - val_accuracy: 0.7586\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4168 - accuracy: 0.81 - 0s 163us/sample - loss: 0.4457 - accuracy: 0.8534 - val_loss: 3.0266 - val_accuracy: 0.7241\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4122 - accuracy: 0.78 - 0s 146us/sample - loss: 0.3660 - accuracy: 0.8276 - val_loss: 3.0071 - val_accuracy: 0.6897\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4163 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3225 - accuracy: 0.8707 - val_loss: 2.6734 - val_accuracy: 0.7931\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2335 - accuracy: 0.93 - 0s 149us/sample - loss: 0.3530 - accuracy: 0.8448 - val_loss: 2.7913 - val_accuracy: 0.7931\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2998 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3091 - accuracy: 0.8621 - val_loss: 3.2923 - val_accuracy: 0.7241\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4213 - accuracy: 0.81 - 0s 258us/sample - loss: 0.3394 - accuracy: 0.8707 - val_loss: 3.1320 - val_accuracy: 0.7241\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2801 - accuracy: 0.8793 - val_loss: 2.7078 - val_accuracy: 0.7241\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3973 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3427 - accuracy: 0.8448 - val_loss: 2.9057 - val_accuracy: 0.7241\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2908 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3015 - accuracy: 0.8707 - val_loss: 2.9299 - val_accuracy: 0.7241\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3354 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2790 - accuracy: 0.8966 - val_loss: 2.7659 - val_accuracy: 0.7586\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3090 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2841 - accuracy: 0.8621 - val_loss: 2.8958 - val_accuracy: 0.7586\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2781 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2562 - accuracy: 0.9052 - val_loss: 3.0989 - val_accuracy: 0.5862\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1751 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2850 - accuracy: 0.9052 - val_loss: 3.2889 - val_accuracy: 0.7586\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2614 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2300 - accuracy: 0.9138 - val_loss: 3.9341 - val_accuracy: 0.6207\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2758 - accuracy: 0.8966 - val_loss: 3.5007 - val_accuracy: 0.7241\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1240 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2105 - accuracy: 0.9224 - val_loss: 3.9428 - val_accuracy: 0.6207\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2793 - accuracy: 0.8793 - val_loss: 3.5800 - val_accuracy: 0.7586\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1642 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2500 - accuracy: 0.9052 - val_loss: 3.6191 - val_accuracy: 0.6897\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2360 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2429 - accuracy: 0.9052 - val_loss: 3.4327 - val_accuracy: 0.7241\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1180 - accuracy: 0.96 - 0s 163us/sample - loss: 0.2676 - accuracy: 0.8966 - val_loss: 3.4575 - val_accuracy: 0.7241\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2096 - accuracy: 0.9138 - val_loss: 4.1022 - val_accuracy: 0.6207\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.96 - 0s 163us/sample - loss: 0.2064 - accuracy: 0.9224 - val_loss: 3.6073 - val_accuracy: 0.7241\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2214 - accuracy: 0.8966 - val_loss: 3.9651 - val_accuracy: 0.6897\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1613 - accuracy: 0.93 - 0s 206us/sample - loss: 0.2023 - accuracy: 0.9052 - val_loss: 4.0450 - val_accuracy: 0.7241\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0547 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2346 - accuracy: 0.8966 - val_loss: 4.0806 - val_accuracy: 0.7241\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1642 - accuracy: 0.90 - 0s 163us/sample - loss: 0.1939 - accuracy: 0.8966 - val_loss: 3.9926 - val_accuracy: 0.7586\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2584 - accuracy: 0.87 - 0s 146us/sample - loss: 0.1819 - accuracy: 0.9224 - val_loss: 3.7702 - val_accuracy: 0.7586\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2038 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1904 - accuracy: 0.9138 - val_loss: 3.8134 - val_accuracy: 0.6897\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2951 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2229 - accuracy: 0.9138 - val_loss: 3.8225 - val_accuracy: 0.7586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1795 - accuracy: 0.9224 - val_loss: 3.8158 - val_accuracy: 0.7241\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.84 - 0s 146us/sample - loss: 0.1696 - accuracy: 0.9224 - val_loss: 4.3086 - val_accuracy: 0.6552\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1539 - accuracy: 0.9397 - val_loss: 4.7571 - val_accuracy: 0.7241\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1357 - accuracy: 0.9310 - val_loss: 5.2279 - val_accuracy: 0.6897\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1389 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1364 - accuracy: 0.9397 - val_loss: 5.9860 - val_accuracy: 0.6552\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1719 - accuracy: 0.9483 - val_loss: 5.5452 - val_accuracy: 0.7586\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.93 - 0s 146us/sample - loss: 0.3949 - accuracy: 0.8793 - val_loss: 8.1974 - val_accuracy: 0.5517\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7162 - accuracy: 0.84 - 0s 138us/sample - loss: 0.9829 - accuracy: 0.7845 - val_loss: 2.2174 - val_accuracy: 0.7586\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.9287 - accuracy: 0.68 - 0s 146us/sample - loss: 0.7719 - accuracy: 0.7759 - val_loss: 0.8946 - val_accuracy: 0.6897\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4709 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5496 - accuracy: 0.7414 - val_loss: 0.6576 - val_accuracy: 0.6897\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4637 - accuracy: 0.81 - 0s 155us/sample - loss: 0.5771 - accuracy: 0.6983 - val_loss: 0.6681 - val_accuracy: 0.6897\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5956 - accuracy: 0.65 - 0s 163us/sample - loss: 0.5683 - accuracy: 0.6983 - val_loss: 0.6318 - val_accuracy: 0.6897\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6065 - accuracy: 0.56 - 0s 146us/sample - loss: 0.5568 - accuracy: 0.6983 - val_loss: 0.6465 - val_accuracy: 0.6897\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6253 - accuracy: 0.71 - 0s 146us/sample - loss: 0.5363 - accuracy: 0.6983 - val_loss: 0.6112 - val_accuracy: 0.6897\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.65 - 0s 146us/sample - loss: 0.5202 - accuracy: 0.7069 - val_loss: 0.5768 - val_accuracy: 0.6897\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5239 - accuracy: 0.71 - 0s 138us/sample - loss: 0.4953 - accuracy: 0.7328 - val_loss: 0.5720 - val_accuracy: 0.6897\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3759 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4900 - accuracy: 0.7328 - val_loss: 0.5144 - val_accuracy: 0.7241\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5279 - accuracy: 0.81 - 0s 163us/sample - loss: 0.4555 - accuracy: 0.8190 - val_loss: 0.4989 - val_accuracy: 0.6897\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3444 - accuracy: 0.93 - 0s 163us/sample - loss: 0.4359 - accuracy: 0.7845 - val_loss: 0.4586 - val_accuracy: 0.7241\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4202 - accuracy: 0.78 - 0s 155us/sample - loss: 0.4062 - accuracy: 0.7931 - val_loss: 0.4000 - val_accuracy: 0.7931\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3803 - accuracy: 0.81 - 0s 172us/sample - loss: 0.3945 - accuracy: 0.8103 - val_loss: 0.4079 - val_accuracy: 0.7931\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4002 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4103 - accuracy: 0.8017 - val_loss: 0.3765 - val_accuracy: 0.8276\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3865 - accuracy: 0.78 - 0s 146us/sample - loss: 0.3978 - accuracy: 0.8017 - val_loss: 0.4464 - val_accuracy: 0.7931\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3973 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3797 - accuracy: 0.8276 - val_loss: 0.4486 - val_accuracy: 0.7931\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3597 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3488 - accuracy: 0.8103 - val_loss: 0.4261 - val_accuracy: 0.8276\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2972 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3212 - accuracy: 0.8362 - val_loss: 0.5536 - val_accuracy: 0.7931\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2245 - accuracy: 0.93 - 0s 146us/sample - loss: 0.3185 - accuracy: 0.8707 - val_loss: 0.7492 - val_accuracy: 0.7241\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.90 - 0s 163us/sample - loss: 0.3419 - accuracy: 0.8362 - val_loss: 0.9378 - val_accuracy: 0.7931\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3291 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3582 - accuracy: 0.8621 - val_loss: 1.0416 - val_accuracy: 0.7586\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3233 - accuracy: 0.90 - 0s 154us/sample - loss: 0.3688 - accuracy: 0.8103 - val_loss: 1.1005 - val_accuracy: 0.7586\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5320 - accuracy: 0.65 - 0s 155us/sample - loss: 0.3723 - accuracy: 0.8103 - val_loss: 1.2981 - val_accuracy: 0.6897\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3142 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3215 - accuracy: 0.8966 - val_loss: 1.5676 - val_accuracy: 0.6897\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2410 - accuracy: 0.96 - 0s 183us/sample - loss: 0.2773 - accuracy: 0.8966 - val_loss: 1.8180 - val_accuracy: 0.7241\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.90 - 0s 181us/sample - loss: 0.2733 - accuracy: 0.8793 - val_loss: 1.7836 - val_accuracy: 0.6897\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3011 - accuracy: 0.84 - 0s 198us/sample - loss: 0.2629 - accuracy: 0.8879 - val_loss: 1.7301 - val_accuracy: 0.7241\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3906 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2645 - accuracy: 0.8879 - val_loss: 1.7447 - val_accuracy: 0.7241\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.96 - 0s 146us/sample - loss: 0.3278 - accuracy: 0.8621 - val_loss: 1.6823 - val_accuracy: 0.7586\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1499 - accuracy: 0.96 - 0s 172us/sample - loss: 0.2264 - accuracy: 0.8966 - val_loss: 2.1642 - val_accuracy: 0.6897\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2806 - accuracy: 0.84 - 0s 163us/sample - loss: 0.3254 - accuracy: 0.8362 - val_loss: 1.3326 - val_accuracy: 0.7241\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.96 - 0s 155us/sample - loss: 0.3480 - accuracy: 0.8707 - val_loss: 1.6435 - val_accuracy: 0.7241\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1872 - accuracy: 0.96 - 0s 176us/sample - loss: 0.3441 - accuracy: 0.8966 - val_loss: 1.0466 - val_accuracy: 0.7586\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 1s - loss: 0.6924 - accuracy: 0.59 - 1s 4ms/sample - loss: 0.6502 - accuracy: 0.6552 - val_loss: 0.6350 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6623 - accuracy: 0.62 - 0s 181us/sample - loss: 0.6260 - accuracy: 0.6638 - val_loss: 0.6168 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6942 - accuracy: 0.56 - 0s 172us/sample - loss: 0.6384 - accuracy: 0.6638 - val_loss: 0.6210 - val_accuracy: 0.6207\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6201 - accuracy: 0.62 - 0s 189us/sample - loss: 0.6080 - accuracy: 0.6810 - val_loss: 0.6073 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7194 - accuracy: 0.62 - 0s 181us/sample - loss: 0.6097 - accuracy: 0.6724 - val_loss: 0.5948 - val_accuracy: 0.7241\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6298 - accuracy: 0.65 - 0s 172us/sample - loss: 0.5919 - accuracy: 0.7155 - val_loss: 0.5926 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6873 - accuracy: 0.62 - 0s 181us/sample - loss: 0.5767 - accuracy: 0.7069 - val_loss: 0.5864 - val_accuracy: 0.6897\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5447 - accuracy: 0.75 - 0s 181us/sample - loss: 0.5850 - accuracy: 0.7155 - val_loss: 0.6008 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7603 - accuracy: 0.56 - 0s 172us/sample - loss: 0.5932 - accuracy: 0.6897 - val_loss: 0.5885 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4918 - accuracy: 0.78 - 0s 155us/sample - loss: 0.5766 - accuracy: 0.6983 - val_loss: 0.6078 - val_accuracy: 0.6552\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6040 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5872 - accuracy: 0.6983 - val_loss: 0.6077 - val_accuracy: 0.6207\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5275 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5644 - accuracy: 0.7069 - val_loss: 0.5968 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6382 - accuracy: 0.65 - 0s 163us/sample - loss: 0.5565 - accuracy: 0.7500 - val_loss: 0.6386 - val_accuracy: 0.7586\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5483 - accuracy: 0.65 - 0s 215us/sample - loss: 0.5288 - accuracy: 0.7155 - val_loss: 0.6401 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6171 - accuracy: 0.71 - 0s 146us/sample - loss: 0.5447 - accuracy: 0.7414 - val_loss: 0.6446 - val_accuracy: 0.7586\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5392 - accuracy: 0.71 - 0s 125us/sample - loss: 0.5329 - accuracy: 0.7069 - val_loss: 0.6904 - val_accuracy: 0.7931\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4533 - accuracy: 0.78 - 0s 129us/sample - loss: 0.4964 - accuracy: 0.7414 - val_loss: 0.8329 - val_accuracy: 0.7931\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4682 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4773 - accuracy: 0.7586 - val_loss: 0.9458 - val_accuracy: 0.7931\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4731 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4787 - accuracy: 0.7500 - val_loss: 0.9102 - val_accuracy: 0.7931\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4127 - accuracy: 0.84 - 0s 129us/sample - loss: 0.4853 - accuracy: 0.7414 - val_loss: 0.9893 - val_accuracy: 0.7931\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5115 - accuracy: 0.65 - 0s 129us/sample - loss: 0.4777 - accuracy: 0.7586 - val_loss: 1.1375 - val_accuracy: 0.8276\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5558 - accuracy: 0.65 - 0s 129us/sample - loss: 0.4459 - accuracy: 0.7414 - val_loss: 1.1455 - val_accuracy: 0.7931\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4839 - accuracy: 0.81 - 0s 129us/sample - loss: 0.4476 - accuracy: 0.7672 - val_loss: 3.3359 - val_accuracy: 0.5862\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5715 - accuracy: 0.68 - 0s 129us/sample - loss: 0.8557 - accuracy: 0.6983 - val_loss: 0.8688 - val_accuracy: 0.6552\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.65 - 0s 138us/sample - loss: 0.5208 - accuracy: 0.7155 - val_loss: 0.5638 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5434 - accuracy: 0.71 - 0s 134us/sample - loss: 0.5482 - accuracy: 0.7155 - val_loss: 0.5280 - val_accuracy: 0.6897\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5128 - accuracy: 0.78 - 0s 138us/sample - loss: 0.5504 - accuracy: 0.7069 - val_loss: 0.4956 - val_accuracy: 0.7586\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5281 - accuracy: 0.71 - 0s 2ms/sample - loss: 0.5433 - accuracy: 0.7328 - val_loss: 0.5073 - val_accuracy: 0.8621\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5780 - accuracy: 0.68 - 0s 273us/sample - loss: 0.5408 - accuracy: 0.7500 - val_loss: 0.5361 - val_accuracy: 0.7931\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5413 - accuracy: 0.68 - 0s 155us/sample - loss: 0.4995 - accuracy: 0.7328 - val_loss: 0.5131 - val_accuracy: 0.7586\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5336 - accuracy: 0.71 - 0s 146us/sample - loss: 0.5299 - accuracy: 0.7328 - val_loss: 0.6933 - val_accuracy: 0.7931\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6063 - accuracy: 0.59 - 0s 155us/sample - loss: 0.5098 - accuracy: 0.7414 - val_loss: 0.6452 - val_accuracy: 0.8276\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4994 - accuracy: 0.65 - 0s 163us/sample - loss: 0.4775 - accuracy: 0.7241 - val_loss: 0.5466 - val_accuracy: 0.7931\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5084 - accuracy: 0.68 - 0s 155us/sample - loss: 0.4853 - accuracy: 0.7328 - val_loss: 0.6523 - val_accuracy: 0.8276\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4671 - accuracy: 0.71 - 0s 155us/sample - loss: 0.4721 - accuracy: 0.7500 - val_loss: 0.6398 - val_accuracy: 0.7586\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4277 - accuracy: 0.78 - 0s 155us/sample - loss: 0.4509 - accuracy: 0.7586 - val_loss: 0.8257 - val_accuracy: 0.8621\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4934 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4678 - accuracy: 0.7845 - val_loss: 0.9413 - val_accuracy: 0.7931\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4099 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4545 - accuracy: 0.7586 - val_loss: 0.9679 - val_accuracy: 0.7586\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2664 - accuracy: 0.84 - 0s 129us/sample - loss: 0.4529 - accuracy: 0.7500 - val_loss: 1.0197 - val_accuracy: 0.7241\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4730 - accuracy: 0.65 - 0s 146us/sample - loss: 0.4379 - accuracy: 0.7500 - val_loss: 0.8601 - val_accuracy: 0.7931\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5776 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4446 - accuracy: 0.7845 - val_loss: 0.8966 - val_accuracy: 0.7931\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3892 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4196 - accuracy: 0.7845 - val_loss: 0.9162 - val_accuracy: 0.7586\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4127 - accuracy: 0.81 - 0s 129us/sample - loss: 0.4259 - accuracy: 0.7845 - val_loss: 0.9604 - val_accuracy: 0.7241\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4046 - accuracy: 0.78 - 0s 146us/sample - loss: 0.4377 - accuracy: 0.7672 - val_loss: 0.9332 - val_accuracy: 0.7931\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.87 - 0s 146us/sample - loss: 0.4139 - accuracy: 0.7845 - val_loss: 1.0218 - val_accuracy: 0.7931\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3365 - accuracy: 0.87 - 0s 146us/sample - loss: 0.4068 - accuracy: 0.7931 - val_loss: 1.0343 - val_accuracy: 0.7931\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3408 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4111 - accuracy: 0.7845 - val_loss: 1.0362 - val_accuracy: 0.7931\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4340 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4000 - accuracy: 0.8103 - val_loss: 1.1939 - val_accuracy: 0.7586\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4016 - accuracy: 0.8017 - val_loss: 1.3825 - val_accuracy: 0.7241\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3012 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3891 - accuracy: 0.8017 - val_loss: 1.4374 - val_accuracy: 0.7586\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4175 - accuracy: 0.78 - 0s 146us/sample - loss: 0.3785 - accuracy: 0.8362 - val_loss: 1.4916 - val_accuracy: 0.7931\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3760 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3937 - accuracy: 0.7931 - val_loss: 1.5045 - val_accuracy: 0.8276\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4125 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3992 - accuracy: 0.8276 - val_loss: 1.2666 - val_accuracy: 0.8621\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3916 - accuracy: 0.8017 - val_loss: 1.3306 - val_accuracy: 0.7586\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3514 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3857 - accuracy: 0.8017 - val_loss: 1.3529 - val_accuracy: 0.8276\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3024 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3693 - accuracy: 0.8362 - val_loss: 1.5698 - val_accuracy: 0.6897\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.87 - 0s 146us/sample - loss: 0.4095 - accuracy: 0.7931 - val_loss: 1.5817 - val_accuracy: 0.8276\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2805 - accuracy: 0.90 - 0s 155us/sample - loss: 0.4045 - accuracy: 0.8103 - val_loss: 2.1143 - val_accuracy: 0.7931\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5493 - accuracy: 0.68 - 0s 146us/sample - loss: 0.4409 - accuracy: 0.7931 - val_loss: 1.2178 - val_accuracy: 0.7586\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4935 - accuracy: 0.75 - 0s 129us/sample - loss: 0.5088 - accuracy: 0.7155 - val_loss: 1.4197 - val_accuracy: 0.7241\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3997 - accuracy: 0.71 - 0s 129us/sample - loss: 0.4816 - accuracy: 0.7586 - val_loss: 1.0056 - val_accuracy: 0.7586\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4841 - accuracy: 0.68 - 0s 138us/sample - loss: 0.4505 - accuracy: 0.7586 - val_loss: 0.8985 - val_accuracy: 0.6552\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.71 - 0s 138us/sample - loss: 0.4780 - accuracy: 0.7414 - val_loss: 0.7921 - val_accuracy: 0.7241\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4464 - accuracy: 0.81 - 0s 129us/sample - loss: 0.4452 - accuracy: 0.7500 - val_loss: 0.8321 - val_accuracy: 0.7586\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4143 - accuracy: 0.78 - 0s 129us/sample - loss: 0.4232 - accuracy: 0.7759 - val_loss: 0.9178 - val_accuracy: 0.7931\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4395 - accuracy: 0.78 - 0s 120us/sample - loss: 0.4273 - accuracy: 0.7845 - val_loss: 1.0925 - val_accuracy: 0.8276\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3316 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4284 - accuracy: 0.8017 - val_loss: 1.2038 - val_accuracy: 0.7241\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3858 - accuracy: 0.7845 - val_loss: 1.2509 - val_accuracy: 0.7931\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4063 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4237 - accuracy: 0.7672 - val_loss: 1.3877 - val_accuracy: 0.7931\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.84 - 0s 198us/sample - loss: 0.4126 - accuracy: 0.7845 - val_loss: 1.4082 - val_accuracy: 0.8276\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2832 - accuracy: 0.87 - 0s 172us/sample - loss: 0.4052 - accuracy: 0.7845 - val_loss: 1.5050 - val_accuracy: 0.6897\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3908 - accuracy: 0.75 - 0s 181us/sample - loss: 0.3651 - accuracy: 0.7931 - val_loss: 1.4703 - val_accuracy: 0.7931\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3999 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3941 - accuracy: 0.7672 - val_loss: 1.5783 - val_accuracy: 0.7241\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4976 - accuracy: 0.71 - 0s 163us/sample - loss: 0.3859 - accuracy: 0.8017 - val_loss: 1.5899 - val_accuracy: 0.7586\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.71 - 0s 198us/sample - loss: 0.4067 - accuracy: 0.7759 - val_loss: 1.6693 - val_accuracy: 0.6552\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3730 - accuracy: 0.81 - 0s 168us/sample - loss: 0.3645 - accuracy: 0.8276 - val_loss: 1.8286 - val_accuracy: 0.7931\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3946 - accuracy: 0.78 - 0s 163us/sample - loss: 0.3764 - accuracy: 0.8190 - val_loss: 1.4827 - val_accuracy: 0.7586\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3238 - accuracy: 0.84 - 0s 163us/sample - loss: 0.4454 - accuracy: 0.7586 - val_loss: 1.1645 - val_accuracy: 0.7241\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4658 - accuracy: 0.84 - 0s 163us/sample - loss: 0.4141 - accuracy: 0.8276 - val_loss: 1.0931 - val_accuracy: 0.7586\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4251 - accuracy: 0.75 - 0s 163us/sample - loss: 0.3901 - accuracy: 0.7931 - val_loss: 1.1339 - val_accuracy: 0.7931\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3848 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3708 - accuracy: 0.8190 - val_loss: 1.2444 - val_accuracy: 0.7586\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3408 - accuracy: 0.8276 - val_loss: 1.3417 - val_accuracy: 0.7931\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4561 - accuracy: 0.71 - 0s 155us/sample - loss: 0.3211 - accuracy: 0.8362 - val_loss: 1.4992 - val_accuracy: 0.7931\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3364 - accuracy: 0.78 - 0s 172us/sample - loss: 0.3268 - accuracy: 0.8017 - val_loss: 1.6153 - val_accuracy: 0.8276\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2578 - accuracy: 0.90 - 0s 163us/sample - loss: 0.3072 - accuracy: 0.8362 - val_loss: 1.5914 - val_accuracy: 0.8276\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3062 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3394 - accuracy: 0.8103 - val_loss: 1.6505 - val_accuracy: 0.6552\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4379 - accuracy: 0.7414 - val_loss: 1.4057 - val_accuracy: 0.7586\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.81 - 0s 198us/sample - loss: 0.3920 - accuracy: 0.7931 - val_loss: 1.3353 - val_accuracy: 0.7586\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.3015 - accuracy: 0.78 - 0s 129us/sample - loss: 0.3333 - accuracy: 0.8362 - val_loss: 1.4095 - val_accuracy: 0.7586\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3193 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3215 - accuracy: 0.8362 - val_loss: 1.5241 - val_accuracy: 0.7931\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2971 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3492 - accuracy: 0.7845 - val_loss: 1.4909 - val_accuracy: 0.6207\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3374 - accuracy: 0.8017 - val_loss: 0.9873 - val_accuracy: 0.7241\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3496 - accuracy: 0.78 - 0s 129us/sample - loss: 0.3908 - accuracy: 0.8276 - val_loss: 0.9655 - val_accuracy: 0.7931\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4935 - accuracy: 0.75 - 0s 138us/sample - loss: 0.3871 - accuracy: 0.8103 - val_loss: 1.3484 - val_accuracy: 0.8276\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4105 - accuracy: 0.75 - 0s 129us/sample - loss: 0.4181 - accuracy: 0.7672 - val_loss: 1.3890 - val_accuracy: 0.8621\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4667 - accuracy: 0.78 - 0s 129us/sample - loss: 0.3888 - accuracy: 0.8448 - val_loss: 1.4347 - val_accuracy: 0.7931\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4009 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3662 - accuracy: 0.8017 - val_loss: 1.3877 - val_accuracy: 0.7586\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3571 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3311 - accuracy: 0.8103 - val_loss: 1.5797 - val_accuracy: 0.7931\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3104 - accuracy: 0.84 - 0s 129us/sample - loss: 0.3160 - accuracy: 0.8707 - val_loss: 1.5232 - val_accuracy: 0.8621\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4143 - accuracy: 0.71 - 0s 138us/sample - loss: 0.3030 - accuracy: 0.8362 - val_loss: 1.6630 - val_accuracy: 0.8621\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2507 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2936 - accuracy: 0.8362 - val_loss: 1.7213 - val_accuracy: 0.8276\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3702 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3023 - accuracy: 0.8362 - val_loss: 1.5430 - val_accuracy: 0.7241\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2619 - accuracy: 0.8362 - val_loss: 1.9989 - val_accuracy: 0.7241\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2932 - accuracy: 0.84 - 0s 125us/sample - loss: 0.2724 - accuracy: 0.8621 - val_loss: 1.8484 - val_accuracy: 0.7931\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2882 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2643 - accuracy: 0.8879 - val_loss: 1.9492 - val_accuracy: 0.7586\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2875 - accuracy: 0.8534 - val_loss: 1.4932 - val_accuracy: 0.8276\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4283 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3631 - accuracy: 0.8362 - val_loss: 1.1516 - val_accuracy: 0.7931\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2872 - accuracy: 0.93 - 0s 129us/sample - loss: 0.3185 - accuracy: 0.8621 - val_loss: 1.1258 - val_accuracy: 0.7931\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4641 - accuracy: 0.68 - 0s 120us/sample - loss: 0.3176 - accuracy: 0.8276 - val_loss: 1.1421 - val_accuracy: 0.7931\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2965 - accuracy: 0.84 - 0s 163us/sample - loss: 0.2874 - accuracy: 0.8621 - val_loss: 1.2180 - val_accuracy: 0.7931\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2769 - accuracy: 0.8707 - val_loss: 1.3260 - val_accuracy: 0.7241\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1775 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2587 - accuracy: 0.8879 - val_loss: 1.5255 - val_accuracy: 0.7241\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2824 - accuracy: 0.8793 - val_loss: 1.6107 - val_accuracy: 0.6897\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2921 - accuracy: 0.8621 - val_loss: 1.3380 - val_accuracy: 0.7931\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2043 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3327 - accuracy: 0.8017 - val_loss: 1.1948 - val_accuracy: 0.7241\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.84 - 0s 129us/sample - loss: 0.4214 - accuracy: 0.7586 - val_loss: 1.1612 - val_accuracy: 0.7241\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3894 - accuracy: 0.78 - 0s 120us/sample - loss: 0.3557 - accuracy: 0.8190 - val_loss: 1.1013 - val_accuracy: 0.6552\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3620 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3176 - accuracy: 0.8534 - val_loss: 1.0734 - val_accuracy: 0.7241\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.81 - 0s 120us/sample - loss: 0.3268 - accuracy: 0.8190 - val_loss: 1.0560 - val_accuracy: 0.7586\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3051 - accuracy: 0.81 - 0s 120us/sample - loss: 0.3171 - accuracy: 0.8448 - val_loss: 1.1546 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3364 - accuracy: 0.8276 - val_loss: 1.2533 - val_accuracy: 0.7931\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2940 - accuracy: 0.84 - 0s 120us/sample - loss: 0.2993 - accuracy: 0.8276 - val_loss: 1.4958 - val_accuracy: 0.7241\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2442 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2585 - accuracy: 0.8793 - val_loss: 1.5984 - val_accuracy: 0.7586\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1493 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2599 - accuracy: 0.8707 - val_loss: 1.5946 - val_accuracy: 0.7931\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2328 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2440 - accuracy: 0.8621 - val_loss: 1.7617 - val_accuracy: 0.7241\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3065 - accuracy: 0.81 - 0s 129us/sample - loss: 0.2363 - accuracy: 0.8966 - val_loss: 1.6608 - val_accuracy: 0.7586\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1731 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2508 - accuracy: 0.8707 - val_loss: 1.7949 - val_accuracy: 0.7586\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2423 - accuracy: 0.8793 - val_loss: 2.1151 - val_accuracy: 0.7241\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2298 - accuracy: 0.8879 - val_loss: 2.1424 - val_accuracy: 0.6897\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3310 - accuracy: 0.81 - 0s 138us/sample - loss: 0.2490 - accuracy: 0.8793 - val_loss: 2.2139 - val_accuracy: 0.6897\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2329 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2425 - accuracy: 0.8879 - val_loss: 2.1215 - val_accuracy: 0.7586\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2586 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2420 - accuracy: 0.8793 - val_loss: 2.1821 - val_accuracy: 0.6207\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2340 - accuracy: 0.93 - 0s 172us/sample - loss: 0.2071 - accuracy: 0.9224 - val_loss: 2.2600 - val_accuracy: 0.7241\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1729 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1809 - accuracy: 0.9224 - val_loss: 2.4528 - val_accuracy: 0.7586\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3517 - accuracy: 0.78 - 0s 198us/sample - loss: 0.2093 - accuracy: 0.8879 - val_loss: 2.2666 - val_accuracy: 0.7931\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1577 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1784 - accuracy: 0.8879 - val_loss: 2.6003 - val_accuracy: 0.6897\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1842 - accuracy: 0.93 - 0s 172us/sample - loss: 0.2302 - accuracy: 0.8621 - val_loss: 2.5402 - val_accuracy: 0.7931\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1500 - accuracy: 0.90 - 0s 198us/sample - loss: 0.2463 - accuracy: 0.8707 - val_loss: 2.4170 - val_accuracy: 0.6897\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3657 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3623 - accuracy: 0.7931 - val_loss: 1.6348 - val_accuracy: 0.7241\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2935 - accuracy: 0.8621 - val_loss: 1.5965 - val_accuracy: 0.7931\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2104 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2523 - accuracy: 0.8879 - val_loss: 1.8057 - val_accuracy: 0.7586\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3460 - accuracy: 0.81 - 0s 155us/sample - loss: 0.2574 - accuracy: 0.9052 - val_loss: 2.0342 - val_accuracy: 0.7931\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1715 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2409 - accuracy: 0.8966 - val_loss: 2.1548 - val_accuracy: 0.7931\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2378 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2077 - accuracy: 0.8707 - val_loss: 2.1075 - val_accuracy: 0.7586\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2270 - accuracy: 0.8707 - val_loss: 2.2141 - val_accuracy: 0.7586\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1996 - accuracy: 0.8793 - val_loss: 2.4029 - val_accuracy: 0.7586\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1947 - accuracy: 0.93 - 0s 133us/sample - loss: 0.1723 - accuracy: 0.9052 - val_loss: 2.3100 - val_accuracy: 0.7586\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1658 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2874 - accuracy: 0.8707 - val_loss: 2.6667 - val_accuracy: 0.6207\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1551 - accuracy: 0.90 - 0s 120us/sample - loss: 0.2629 - accuracy: 0.8448 - val_loss: 3.3627 - val_accuracy: 0.7586\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1439 - accuracy: 0.96 - 0s 129us/sample - loss: 0.4015 - accuracy: 0.8621 - val_loss: 3.0994 - val_accuracy: 0.7586\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2951 - accuracy: 0.81 - 0s 129us/sample - loss: 0.2912 - accuracy: 0.8534 - val_loss: 3.0226 - val_accuracy: 0.6552\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.78 - 0s 133us/sample - loss: 0.3355 - accuracy: 0.8534 - val_loss: 2.7536 - val_accuracy: 0.7586\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3075 - accuracy: 0.8621 - val_loss: 2.8256 - val_accuracy: 0.7931\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.65 - 0s 129us/sample - loss: 0.2671 - accuracy: 0.8190 - val_loss: 2.8351 - val_accuracy: 0.7586\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2664 - accuracy: 0.78 - 0s 129us/sample - loss: 0.2497 - accuracy: 0.8362 - val_loss: 2.9520 - val_accuracy: 0.7586\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2321 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2201 - accuracy: 0.8793 - val_loss: 3.1772 - val_accuracy: 0.7241\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2020 - accuracy: 0.8879 - val_loss: 3.4533 - val_accuracy: 0.7586\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1590 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1985 - accuracy: 0.8879 - val_loss: 3.7956 - val_accuracy: 0.7586\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1715 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1893 - accuracy: 0.9138 - val_loss: 3.8848 - val_accuracy: 0.7241\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1379 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1738 - accuracy: 0.9138 - val_loss: 4.1051 - val_accuracy: 0.7931\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1493 - accuracy: 0.9310 - val_loss: 4.7249 - val_accuracy: 0.6552\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1953 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1724 - accuracy: 0.9052 - val_loss: 4.6160 - val_accuracy: 0.7241\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1227 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1693 - accuracy: 0.9138 - val_loss: 4.5744 - val_accuracy: 0.5862\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1860 - accuracy: 0.9138 - val_loss: 4.5317 - val_accuracy: 0.7931\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2532 - accuracy: 0.87 - 0s 146us/sample - loss: 0.1907 - accuracy: 0.9052 - val_loss: 5.2682 - val_accuracy: 0.5517\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0834 - accuracy: 1.00 - 0s 120us/sample - loss: 0.2613 - accuracy: 0.8707 - val_loss: 6.7102 - val_accuracy: 0.7931\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2457 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3846 - accuracy: 0.8448 - val_loss: 6.2065 - val_accuracy: 0.8621\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2708 - accuracy: 0.8707 - val_loss: 5.4738 - val_accuracy: 0.7931\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3562 - accuracy: 0.81 - 0s 138us/sample - loss: 0.2890 - accuracy: 0.8621 - val_loss: 4.4192 - val_accuracy: 0.8276\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2705 - accuracy: 0.8621 - val_loss: 4.0427 - val_accuracy: 0.8276\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3920 - accuracy: 0.75 - 0s 129us/sample - loss: 0.2690 - accuracy: 0.8879 - val_loss: 4.2674 - val_accuracy: 0.7931\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2877 - accuracy: 0.8966 - val_loss: 4.3964 - val_accuracy: 0.7931\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2868 - accuracy: 0.8103 - val_loss: 4.1969 - val_accuracy: 0.7931\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3445 - accuracy: 0.78 - 0s 138us/sample - loss: 0.2539 - accuracy: 0.8448 - val_loss: 4.4290 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2669 - accuracy: 0.8793 - val_loss: 4.3613 - val_accuracy: 0.7586\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1994 - accuracy: 0.9052 - val_loss: 4.3134 - val_accuracy: 0.7586\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2113 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1657 - accuracy: 0.9224 - val_loss: 4.6272 - val_accuracy: 0.7241\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1480 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1542 - accuracy: 0.9052 - val_loss: 4.7410 - val_accuracy: 0.7931\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1383 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1672 - accuracy: 0.8966 - val_loss: 4.7996 - val_accuracy: 0.7586\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1380 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1550 - accuracy: 0.9224 - val_loss: 4.9820 - val_accuracy: 0.6897\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.84 - 0s 138us/sample - loss: 0.1512 - accuracy: 0.9138 - val_loss: 4.6498 - val_accuracy: 0.7241\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1131 - accuracy: 0.96 - 0s 133us/sample - loss: 0.1659 - accuracy: 0.9569 - val_loss: 4.7779 - val_accuracy: 0.7241\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1183 - accuracy: 0.9397 - val_loss: 5.2535 - val_accuracy: 0.7586\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0858 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1587 - accuracy: 0.9397 - val_loss: 5.8972 - val_accuracy: 0.7931\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3998 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2165 - accuracy: 0.8879 - val_loss: 6.9139 - val_accuracy: 0.6552\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1651 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2145 - accuracy: 0.9138 - val_loss: 5.8138 - val_accuracy: 0.7586\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.8509 - accuracy: 0.75 - 0s 140us/sample - loss: 0.3510 - accuracy: 0.8707 - val_loss: 4.9147 - val_accuracy: 0.7241\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2635 - accuracy: 0.84 - 0s 155us/sample - loss: 0.2256 - accuracy: 0.8966 - val_loss: 4.3788 - val_accuracy: 0.6552\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2033 - accuracy: 0.96 - 0s 120us/sample - loss: 0.2054 - accuracy: 0.9052 - val_loss: 4.2007 - val_accuracy: 0.7586\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.84 - 0s 129us/sample - loss: 0.1724 - accuracy: 0.8879 - val_loss: 5.0691 - val_accuracy: 0.7586\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.90 - 0s 120us/sample - loss: 0.1672 - accuracy: 0.9052 - val_loss: 5.7128 - val_accuracy: 0.7586\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.93 - 0s 134us/sample - loss: 0.1521 - accuracy: 0.9224 - val_loss: 5.5996 - val_accuracy: 0.7586\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.84 - 0s 138us/sample - loss: 0.1642 - accuracy: 0.9138 - val_loss: 5.7987 - val_accuracy: 0.7586\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1182 - accuracy: 0.9224 - val_loss: 6.2138 - val_accuracy: 0.6897\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1074 - accuracy: 0.9483 - val_loss: 6.5526 - val_accuracy: 0.7241\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1384 - accuracy: 0.90 - 0s 138us/sample - loss: 0.0820 - accuracy: 0.9483 - val_loss: 6.9102 - val_accuracy: 0.7241\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0813 - accuracy: 0.96 - 0s 122us/sample - loss: 0.0823 - accuracy: 0.9569 - val_loss: 7.4525 - val_accuracy: 0.6552\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1254 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0813 - accuracy: 0.9655 - val_loss: 7.6362 - val_accuracy: 0.7586\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1388 - accuracy: 0.9138 - val_loss: 7.9971 - val_accuracy: 0.6207\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0727 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1882 - accuracy: 0.9138 - val_loss: 7.5780 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: c2cf3ce2254ee43421073dae802aaf7b</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8103448152542114</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 99</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 110</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 44</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_3_units: 99</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_units: 33</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LOG_DIR=f\"second_year\\{int(time.time())}\"\n",
    "\n",
    "tuner2= RandomSearch(\n",
    "    build_model_2,\n",
    "    objective=kt.Objective(\"val_accuracy\",direction='max'),\n",
    "    max_trials=4,\n",
    "    executions_per_trial=4,\n",
    "    directory=LOG_DIR\n",
    ")\n",
    "\n",
    "earlyStopping =EarlyStopping(monitor='loss', patience=50, verbose=0, mode='min')\n",
    "#mcp_save = ModelCheckpoint('mp.hdf5', save_best_only=True, monitor='loss', mode='min')\n",
    "#reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=7, verbose=1,min_delta=0.01, mode='min')\n",
    "\n",
    "tuner2.search(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_test,y_test),\n",
    "    epochs=200,\n",
    "    callbacks=[earlyStopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_units': 66, 'n_layers': 4, 'dense_0_units': 44, 'dense_1_units': 77, 'dense_2_units': 11, 'dense_3_units': 11}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Results in second_year\\1584346365\\untitled_project</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Objective(name='val_accuracy', direction='max')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: d3a15f814946abd65d9d5f6492c5dcdc</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8275862336158752</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 44</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 77</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_3_units: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_units: 66</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 372362d0601f9b8ae3b14ed131469348</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8275861740112305</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 99</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 33</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_units: 44</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: c2cf3ce2254ee43421073dae802aaf7b</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8103448152542114</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 99</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 110</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 44</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_3_units: 99</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_units: 33</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 2986b97d0d7a3d208988c06d3a630eb4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7931034564971924</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 11</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-input_units: 99</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tuner2.get_best_hyperparameters()[0].values)\n",
    "\n",
    "print(tuner2.results_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7973684210526315  Accuracy: 0.8275862068965517\n"
     ]
    }
   ],
   "source": [
    "best_model2=tuner2.get_best_models()[0]\n",
    "\n",
    "y_pred=best_model2.predict(X_test)\n",
    "y_pred[y_pred<0.5]=0\n",
    "y_pred[y_pred>0.5]=1\n",
    "auc_nn2=metrics.roc_auc_score(y_test,y_pred)\n",
    "acc_nn2=metrics.accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(\"AUC:\",auc_nn2,\" Accuracy:\",acc_nn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset \"last year\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset is comprised of 145 rows and 38 columns. We have 49 bankrupted companies and 96 companies that still operate.\n"
     ]
    }
   ],
   "source": [
    "df_last=pd.read_csv(\"last year.csv\")\n",
    "df_last['final'][df_last['final']=='Bankrupted']=0\n",
    "df_last['final'][df_last['final']=='Non-Bankrupted']=1\n",
    "df_last.head()\n",
    "\n",
    "bankruptcies=df_last['final'][df_last['final']==0].count()\n",
    "rows=df_last.shape[0]\n",
    "columns=df_last.shape[1]\n",
    "print(f'Our dataset is comprised of {rows} rows and {columns} columns. We have {bankruptcies} bankrupted companies and {rows-bankruptcies} companies that still operate.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(333)\n",
    "\n",
    "X=df_last.iloc[:,0:-1].values\n",
    "Y=df_last.iloc[:,-1]\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=43) \n",
    "X_train=preprocessing.normalize(X_train)\n",
    "X_test=preprocessing.normalize(X_test)\n",
    "y_train=y_train.astype(int)\n",
    "y_test=y_test.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_last(hp):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hp.Int(\"input_units\",min_value=37,max_value=167,step=13),input_shape=(37,),activation='relu'))\n",
    "    \n",
    "    for i in range(hp.Int(\"n_layers\",1,4)):\n",
    "    \n",
    "        model.add(Dense(hp.Int(f\"dense_{i}_units\",min_value=24,max_value=120,step=12),activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    model.compile(Adam(lr=0.01),loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do NOT run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0316 10:20:33.108121 13836 util.py:144] Unresolved object in checkpoint: (root).optimizer.iter\n",
      "W0316 10:20:33.110089 13836 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "W0316 10:20:33.112084 13836 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "W0316 10:20:33.114077 13836 util.py:144] Unresolved object in checkpoint: (root).optimizer.decay\n",
      "W0316 10:20:33.115076 13836 util.py:144] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "W0316 10:20:33.118065 13836 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6870 - accuracy: 0.62 - 1s 6ms/sample - loss: 0.6795 - accuracy: 0.6552 - val_loss: 0.6466 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.62 - 0s 301us/sample - loss: 0.6660 - accuracy: 0.6638 - val_loss: 0.6542 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.75 - 0s 180us/sample - loss: 0.6324 - accuracy: 0.6638 - val_loss: 0.6323 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6068 - accuracy: 0.68 - 0s 189us/sample - loss: 0.6202 - accuracy: 0.6638 - val_loss: 0.6379 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.71 - 0s 189us/sample - loss: 0.6131 - accuracy: 0.6638 - val_loss: 0.6222 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6294 - accuracy: 0.62 - 0s 172us/sample - loss: 0.5960 - accuracy: 0.6638 - val_loss: 0.6184 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4637 - accuracy: 0.81 - 0s 172us/sample - loss: 0.5928 - accuracy: 0.6638 - val_loss: 0.6183 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5150 - accuracy: 0.71 - 0s 146us/sample - loss: 0.5773 - accuracy: 0.6638 - val_loss: 0.6169 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5899 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5586 - accuracy: 0.6724 - val_loss: 0.6284 - val_accuracy: 0.6552\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4539 - accuracy: 0.75 - 0s 172us/sample - loss: 0.5469 - accuracy: 0.7328 - val_loss: 0.6132 - val_accuracy: 0.6552\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5368 - accuracy: 0.78 - 0s 189us/sample - loss: 0.5337 - accuracy: 0.7672 - val_loss: 0.6237 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3372 - accuracy: 0.84 - 0s 189us/sample - loss: 0.5134 - accuracy: 0.7414 - val_loss: 0.6216 - val_accuracy: 0.5862\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5272 - accuracy: 0.84 - 0s 2ms/sample - loss: 0.4943 - accuracy: 0.8448 - val_loss: 0.6596 - val_accuracy: 0.6897\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5604 - accuracy: 0.71 - 0s 155us/sample - loss: 0.4724 - accuracy: 0.7672 - val_loss: 0.6769 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6343 - accuracy: 0.71 - 0s 146us/sample - loss: 0.4570 - accuracy: 0.8190 - val_loss: 0.7706 - val_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3598 - accuracy: 0.81 - 0s 163us/sample - loss: 0.4443 - accuracy: 0.7931 - val_loss: 0.7942 - val_accuracy: 0.6207\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.87 - 0s 215us/sample - loss: 0.4418 - accuracy: 0.7759 - val_loss: 0.8895 - val_accuracy: 0.6897\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3115 - accuracy: 0.84 - 0s 172us/sample - loss: 0.4925 - accuracy: 0.7931 - val_loss: 0.8204 - val_accuracy: 0.6552\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4758 - accuracy: 0.81 - 0s 172us/sample - loss: 0.4503 - accuracy: 0.8103 - val_loss: 0.8348 - val_accuracy: 0.5172\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4442 - accuracy: 0.87 - 0s 181us/sample - loss: 0.3596 - accuracy: 0.8621 - val_loss: 0.9102 - val_accuracy: 0.6207\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3000 - accuracy: 0.84 - 0s 163us/sample - loss: 0.4194 - accuracy: 0.7931 - val_loss: 0.8513 - val_accuracy: 0.5862\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3560 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3573 - accuracy: 0.8534 - val_loss: 0.9519 - val_accuracy: 0.5172\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4573 - accuracy: 0.78 - 0s 172us/sample - loss: 0.3103 - accuracy: 0.8621 - val_loss: 1.0834 - val_accuracy: 0.6897\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.96 - 0s 172us/sample - loss: 0.2899 - accuracy: 0.8879 - val_loss: 1.2444 - val_accuracy: 0.5517\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3732 - accuracy: 0.78 - 0s 189us/sample - loss: 0.3290 - accuracy: 0.8362 - val_loss: 1.1289 - val_accuracy: 0.6897\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2786 - accuracy: 0.90 - 0s 181us/sample - loss: 0.2751 - accuracy: 0.8966 - val_loss: 1.3570 - val_accuracy: 0.5172\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.87 - 0s 189us/sample - loss: 0.2624 - accuracy: 0.8793 - val_loss: 1.1725 - val_accuracy: 0.6552\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3054 - accuracy: 0.90 - 0s 172us/sample - loss: 0.2523 - accuracy: 0.9224 - val_loss: 1.2937 - val_accuracy: 0.5517\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2255 - accuracy: 0.90 - 0s 181us/sample - loss: 0.2282 - accuracy: 0.9310 - val_loss: 1.2318 - val_accuracy: 0.6207\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2644 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2034 - accuracy: 0.9310 - val_loss: 1.4472 - val_accuracy: 0.5517\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2162 - accuracy: 0.9052 - val_loss: 1.4398 - val_accuracy: 0.6552\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2413 - accuracy: 0.9052 - val_loss: 1.7262 - val_accuracy: 0.5172\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1986 - accuracy: 0.93 - 0s 172us/sample - loss: 0.2827 - accuracy: 0.8707 - val_loss: 1.4512 - val_accuracy: 0.6552\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2366 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2763 - accuracy: 0.8793 - val_loss: 1.3955 - val_accuracy: 0.6207\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2763 - accuracy: 0.87 - 0s 172us/sample - loss: 0.2474 - accuracy: 0.9052 - val_loss: 1.7486 - val_accuracy: 0.6552\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2054 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2976 - accuracy: 0.9052 - val_loss: 1.6259 - val_accuracy: 0.6552\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1514 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2351 - accuracy: 0.9138 - val_loss: 1.4881 - val_accuracy: 0.6897\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2337 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1756 - accuracy: 0.9569 - val_loss: 1.9340 - val_accuracy: 0.5172\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1550 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1820 - accuracy: 0.9224 - val_loss: 1.7430 - val_accuracy: 0.6897\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1568 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1767 - accuracy: 0.9397 - val_loss: 1.8588 - val_accuracy: 0.6207\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1385 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1428 - accuracy: 0.9483 - val_loss: 2.1506 - val_accuracy: 0.5862\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1617 - accuracy: 0.9310 - val_loss: 2.1267 - val_accuracy: 0.5862\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1487 - accuracy: 0.9483 - val_loss: 2.3713 - val_accuracy: 0.5172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1653 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1417 - accuracy: 0.9483 - val_loss: 2.0581 - val_accuracy: 0.6207\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1273 - accuracy: 0.9569 - val_loss: 2.4837 - val_accuracy: 0.5172\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0618 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1057 - accuracy: 0.9828 - val_loss: 2.7799 - val_accuracy: 0.5862\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0947 - accuracy: 0.9655 - val_loss: 3.0006 - val_accuracy: 0.5862\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0504 - accuracy: 1.00 - 0s 189us/sample - loss: 0.0876 - accuracy: 0.9741 - val_loss: 2.9424 - val_accuracy: 0.6207\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.00 - 0s 181us/sample - loss: 0.0879 - accuracy: 0.9741 - val_loss: 3.3985 - val_accuracy: 0.5172\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0335 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0950 - accuracy: 0.9655 - val_loss: 3.0365 - val_accuracy: 0.5862\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1047 - accuracy: 0.9483 - val_loss: 3.0113 - val_accuracy: 0.5862\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0372 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1150 - accuracy: 0.9655 - val_loss: 3.3488 - val_accuracy: 0.5862\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0790 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2810 - accuracy: 0.9138 - val_loss: 2.8120 - val_accuracy: 0.5517\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1718 - accuracy: 0.9310 - val_loss: 2.6211 - val_accuracy: 0.5517\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1119 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1182 - accuracy: 0.9569 - val_loss: 2.4698 - val_accuracy: 0.6207\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1551 - accuracy: 0.9397 - val_loss: 2.9489 - val_accuracy: 0.5172\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.96 - 0s 151us/sample - loss: 0.1387 - accuracy: 0.9483 - val_loss: 2.7973 - val_accuracy: 0.5517\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0985 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1119 - accuracy: 0.9569 - val_loss: 2.6508 - val_accuracy: 0.5862\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1356 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1015 - accuracy: 0.9569 - val_loss: 2.6173 - val_accuracy: 0.5862\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0999 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0879 - accuracy: 0.9655 - val_loss: 2.9222 - val_accuracy: 0.5517\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0736 - accuracy: 0.9655 - val_loss: 3.1481 - val_accuracy: 0.5172\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0565 - accuracy: 0.9741 - val_loss: 3.0617 - val_accuracy: 0.6207\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0465 - accuracy: 0.9914 - val_loss: 3.0358 - val_accuracy: 0.6552\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0484 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0427 - accuracy: 0.9828 - val_loss: 3.8177 - val_accuracy: 0.6207\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1504 - accuracy: 0.9741 - val_loss: 4.0499 - val_accuracy: 0.6207\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0846 - accuracy: 0.9569 - val_loss: 3.8086 - val_accuracy: 0.6207\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0380 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0656 - accuracy: 0.9914 - val_loss: 4.3646 - val_accuracy: 0.6552\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0489 - accuracy: 0.9828 - val_loss: 4.4345 - val_accuracy: 0.6897\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1220 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1382 - accuracy: 0.9483 - val_loss: 4.8413 - val_accuracy: 0.5172\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.93 - 0s 120us/sample - loss: 0.1089 - accuracy: 0.9397 - val_loss: 4.2020 - val_accuracy: 0.5862\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1806 - accuracy: 0.9483 - val_loss: 3.7247 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0593 - accuracy: 0.9828 - val_loss: 3.7115 - val_accuracy: 0.5517\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0436 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0522 - accuracy: 0.9914 - val_loss: 4.2075 - val_accuracy: 0.5862\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0351 - accuracy: 0.9828 - val_loss: 4.5562 - val_accuracy: 0.5862\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0273 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0411 - accuracy: 0.9914 - val_loss: 4.5659 - val_accuracy: 0.5517\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0150 - accuracy: 1.0000 - val_loss: 4.3305 - val_accuracy: 0.5862\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0611 - accuracy: 0.9741 - val_loss: 6.0752 - val_accuracy: 0.4828\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0507 - accuracy: 0.9741 - val_loss: 5.5255 - val_accuracy: 0.5517\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0795 - accuracy: 0.9741 - val_loss: 4.5586 - val_accuracy: 0.5517\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1543 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0987 - accuracy: 0.9741 - val_loss: 4.6349 - val_accuracy: 0.5862\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1274 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0439 - accuracy: 0.9914 - val_loss: 5.2242 - val_accuracy: 0.5862\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1287 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0615 - accuracy: 0.9828 - val_loss: 5.7244 - val_accuracy: 0.4828\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0849 - accuracy: 0.9828 - val_loss: 5.1514 - val_accuracy: 0.5517\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0406 - accuracy: 0.9914 - val_loss: 4.6207 - val_accuracy: 0.5862\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0548 - accuracy: 0.9828 - val_loss: 4.7374 - val_accuracy: 0.5862\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0699 - accuracy: 0.9741 - val_loss: 5.0627 - val_accuracy: 0.5862\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0314 - accuracy: 0.9914 - val_loss: 5.6006 - val_accuracy: 0.5172\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 5.7659 - val_accuracy: 0.5862\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0182 - accuracy: 0.9914 - val_loss: 5.9578 - val_accuracy: 0.5862\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 5.9422 - val_accuracy: 0.5862\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 6.0440 - val_accuracy: 0.5862\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 6.1694 - val_accuracy: 0.5862\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 6.3070 - val_accuracy: 0.5862\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 6.4501 - val_accuracy: 0.5862\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7634e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.5700 - val_accuracy: 0.5862\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 6.6739 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1023e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.7710 - val_accuracy: 0.5862\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 138us/sample - loss: 8.4507e-04 - accuracy: 1.0000 - val_loss: 6.8642 - val_accuracy: 0.5862\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1817e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 7.1232e-04 - accuracy: 1.0000 - val_loss: 6.9513 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4855e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.1731e-04 - accuracy: 1.0000 - val_loss: 7.0220 - val_accuracy: 0.5862\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.2616e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.2277e-04 - accuracy: 1.0000 - val_loss: 7.0837 - val_accuracy: 0.5862\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2399e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 4.7152e-04 - accuracy: 1.0000 - val_loss: 7.1389 - val_accuracy: 0.5862\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4582e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.3253e-04 - accuracy: 1.0000 - val_loss: 7.1867 - val_accuracy: 0.5862\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8902e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.0774e-04 - accuracy: 1.0000 - val_loss: 7.2290 - val_accuracy: 0.5862\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3145e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.7449e-04 - accuracy: 1.0000 - val_loss: 7.2678 - val_accuracy: 0.5862\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1040e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.4520e-04 - accuracy: 1.0000 - val_loss: 7.3044 - val_accuracy: 0.5862\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0629e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.2399e-04 - accuracy: 1.0000 - val_loss: 7.3292 - val_accuracy: 0.5862\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1731e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.0882e-04 - accuracy: 1.0000 - val_loss: 7.3520 - val_accuracy: 0.5862\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2367e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.9093e-04 - accuracy: 1.0000 - val_loss: 7.3756 - val_accuracy: 0.5862\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2502e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.7487e-04 - accuracy: 1.0000 - val_loss: 7.3967 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3710e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.6520e-04 - accuracy: 1.0000 - val_loss: 7.4168 - val_accuracy: 0.5862\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5966e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.5499e-04 - accuracy: 1.0000 - val_loss: 7.4384 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1232e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.4594e-04 - accuracy: 1.0000 - val_loss: 7.4555 - val_accuracy: 0.5862\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7730e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.3388e-04 - accuracy: 1.0000 - val_loss: 7.4726 - val_accuracy: 0.5862\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4788e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.2627e-04 - accuracy: 1.0000 - val_loss: 7.4862 - val_accuracy: 0.5862\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5745e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.2004e-04 - accuracy: 1.0000 - val_loss: 7.4979 - val_accuracy: 0.5862\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3027e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.1048e-04 - accuracy: 1.0000 - val_loss: 7.5057 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9296e-04 - accuracy: 1.00 - 0s 148us/sample - loss: 2.0723e-04 - accuracy: 1.0000 - val_loss: 7.5120 - val_accuracy: 0.5862\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3426e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.9907e-04 - accuracy: 1.0000 - val_loss: 7.5215 - val_accuracy: 0.5862\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6352e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.9448e-04 - accuracy: 1.0000 - val_loss: 7.5322 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0414e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.8601e-04 - accuracy: 1.0000 - val_loss: 7.5390 - val_accuracy: 0.5862\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3538e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8099e-04 - accuracy: 1.0000 - val_loss: 7.5463 - val_accuracy: 0.5862\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7385e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 1.7831e-04 - accuracy: 1.0000 - val_loss: 7.5577 - val_accuracy: 0.5862\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4009e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7257e-04 - accuracy: 1.0000 - val_loss: 7.5708 - val_accuracy: 0.5517\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8633e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.6972e-04 - accuracy: 1.0000 - val_loss: 7.5824 - val_accuracy: 0.5517\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1102e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.6094e-04 - accuracy: 1.0000 - val_loss: 7.5900 - val_accuracy: 0.5517\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5361e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.5492e-04 - accuracy: 1.0000 - val_loss: 7.6010 - val_accuracy: 0.5517\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3471e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5164e-04 - accuracy: 1.0000 - val_loss: 7.6012 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4809e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4796e-04 - accuracy: 1.0000 - val_loss: 7.6093 - val_accuracy: 0.5862\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4624e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4402e-04 - accuracy: 1.0000 - val_loss: 7.6187 - val_accuracy: 0.5517\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1375e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.4168e-04 - accuracy: 1.0000 - val_loss: 7.6260 - val_accuracy: 0.5517\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6166e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3637e-04 - accuracy: 1.0000 - val_loss: 7.6313 - val_accuracy: 0.5517\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4136e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3286e-04 - accuracy: 1.0000 - val_loss: 7.6339 - val_accuracy: 0.5517\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1439e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3040e-04 - accuracy: 1.0000 - val_loss: 7.6380 - val_accuracy: 0.5517\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5302e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.2872e-04 - accuracy: 1.0000 - val_loss: 7.6443 - val_accuracy: 0.5517\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2881e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2386e-04 - accuracy: 1.0000 - val_loss: 7.6508 - val_accuracy: 0.5517\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.8064e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2179e-04 - accuracy: 1.0000 - val_loss: 7.6536 - val_accuracy: 0.5862\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0902e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1869e-04 - accuracy: 1.0000 - val_loss: 7.6632 - val_accuracy: 0.5517\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7554e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1636e-04 - accuracy: 1.0000 - val_loss: 7.6733 - val_accuracy: 0.5517\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9261e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1408e-04 - accuracy: 1.0000 - val_loss: 7.6792 - val_accuracy: 0.5517\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1566e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1194e-04 - accuracy: 1.0000 - val_loss: 7.6861 - val_accuracy: 0.5517\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4590e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1043e-04 - accuracy: 1.0000 - val_loss: 7.6928 - val_accuracy: 0.5517\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0991e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.0813e-04 - accuracy: 1.0000 - val_loss: 7.6976 - val_accuracy: 0.5517\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0965e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0495e-04 - accuracy: 1.0000 - val_loss: 7.7018 - val_accuracy: 0.5517\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5703e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0341e-04 - accuracy: 1.0000 - val_loss: 7.7082 - val_accuracy: 0.5517\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3078e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0168e-04 - accuracy: 1.0000 - val_loss: 7.7142 - val_accuracy: 0.5517\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0431e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 9.9115e-05 - accuracy: 1.0000 - val_loss: 7.7195 - val_accuracy: 0.5517\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7246e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 9.7147e-05 - accuracy: 1.0000 - val_loss: 7.7281 - val_accuracy: 0.5517\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4463e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 9.5534e-05 - accuracy: 1.0000 - val_loss: 7.7340 - val_accuracy: 0.5517\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4497e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 9.3335e-05 - accuracy: 1.0000 - val_loss: 7.7405 - val_accuracy: 0.5517\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4731e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.2747e-05 - accuracy: 1.0000 - val_loss: 7.7456 - val_accuracy: 0.5517\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5755e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 9.0054e-05 - accuracy: 1.0000 - val_loss: 7.7514 - val_accuracy: 0.5517\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3769e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.8407e-05 - accuracy: 1.0000 - val_loss: 7.7566 - val_accuracy: 0.5517\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7025e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.6806e-05 - accuracy: 1.0000 - val_loss: 7.7626 - val_accuracy: 0.5517\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6435e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.5397e-05 - accuracy: 1.0000 - val_loss: 7.7696 - val_accuracy: 0.5517\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3829e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 8.4381e-05 - accuracy: 1.0000 - val_loss: 7.7763 - val_accuracy: 0.5517\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3434e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.3146e-05 - accuracy: 1.0000 - val_loss: 7.7828 - val_accuracy: 0.5517\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7015e-05 - accuracy: 1.00 - 0s 181us/sample - loss: 8.1174e-05 - accuracy: 1.0000 - val_loss: 7.7880 - val_accuracy: 0.5517\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7169e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.9991e-05 - accuracy: 1.0000 - val_loss: 7.7936 - val_accuracy: 0.5517\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2415e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 7.8743e-05 - accuracy: 1.0000 - val_loss: 7.7993 - val_accuracy: 0.5517\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9824e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.7676e-05 - accuracy: 1.0000 - val_loss: 7.8042 - val_accuracy: 0.5517\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.8933e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.7464e-05 - accuracy: 1.0000 - val_loss: 7.8129 - val_accuracy: 0.5517\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4671e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.5219e-05 - accuracy: 1.0000 - val_loss: 7.8166 - val_accuracy: 0.5517\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.5745e-05 - accuracy: 1.00 - 0s 142us/sample - loss: 7.3728e-05 - accuracy: 1.0000 - val_loss: 7.8204 - val_accuracy: 0.5517\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6864e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.3231e-05 - accuracy: 1.0000 - val_loss: 7.8236 - val_accuracy: 0.5862\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2754e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.1857e-05 - accuracy: 1.0000 - val_loss: 7.8291 - val_accuracy: 0.5862\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2009e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 7.0836e-05 - accuracy: 1.0000 - val_loss: 7.8371 - val_accuracy: 0.5517\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7683e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.9351e-05 - accuracy: 1.0000 - val_loss: 7.8430 - val_accuracy: 0.5517\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2752e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.8004e-05 - accuracy: 1.0000 - val_loss: 7.8491 - val_accuracy: 0.5517\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5378e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.7716e-05 - accuracy: 1.0000 - val_loss: 7.8537 - val_accuracy: 0.5517\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0132e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.6341e-05 - accuracy: 1.0000 - val_loss: 7.8572 - val_accuracy: 0.5517\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9661e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.5314e-05 - accuracy: 1.0000 - val_loss: 7.8610 - val_accuracy: 0.5517\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1034e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 6.4282e-05 - accuracy: 1.0000 - val_loss: 7.8650 - val_accuracy: 0.5517\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8058e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.3246e-05 - accuracy: 1.0000 - val_loss: 7.8715 - val_accuracy: 0.5517\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0155e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 6.2587e-05 - accuracy: 1.0000 - val_loss: 7.8765 - val_accuracy: 0.5517\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2620e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 6.1970e-05 - accuracy: 1.0000 - val_loss: 7.8802 - val_accuracy: 0.5862\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0250e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 6.0455e-05 - accuracy: 1.0000 - val_loss: 7.8875 - val_accuracy: 0.5517\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6588e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.9801e-05 - accuracy: 1.0000 - val_loss: 7.8959 - val_accuracy: 0.5517\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6581e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.9467e-05 - accuracy: 1.0000 - val_loss: 7.8997 - val_accuracy: 0.5517\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4524e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.8049e-05 - accuracy: 1.0000 - val_loss: 7.9064 - val_accuracy: 0.5517\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8373e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.7421e-05 - accuracy: 1.0000 - val_loss: 7.9117 - val_accuracy: 0.5517\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1898e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.6340e-05 - accuracy: 1.0000 - val_loss: 7.9172 - val_accuracy: 0.5517\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6584e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.5719e-05 - accuracy: 1.0000 - val_loss: 7.9216 - val_accuracy: 0.5517\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1506e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.5758e-05 - accuracy: 1.0000 - val_loss: 7.9272 - val_accuracy: 0.5517\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6554e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.4182e-05 - accuracy: 1.0000 - val_loss: 7.9312 - val_accuracy: 0.5517\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9429e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.3234e-05 - accuracy: 1.0000 - val_loss: 7.9343 - val_accuracy: 0.5517\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4341e-05 - accuracy: 1.00 - 0s 142us/sample - loss: 5.3638e-05 - accuracy: 1.0000 - val_loss: 7.9371 - val_accuracy: 0.5517\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4795e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.1893e-05 - accuracy: 1.0000 - val_loss: 7.9424 - val_accuracy: 0.5517\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5974e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 5.1308e-05 - accuracy: 1.0000 - val_loss: 7.9499 - val_accuracy: 0.5517\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5007e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.0725e-05 - accuracy: 1.0000 - val_loss: 7.9559 - val_accuracy: 0.5517\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6674e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.0150e-05 - accuracy: 1.0000 - val_loss: 7.9589 - val_accuracy: 0.5517\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5080e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.9270e-05 - accuracy: 1.0000 - val_loss: 7.9614 - val_accuracy: 0.5517\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3549e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.8644e-05 - accuracy: 1.0000 - val_loss: 7.9647 - val_accuracy: 0.5517\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3399e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.7855e-05 - accuracy: 1.0000 - val_loss: 7.9697 - val_accuracy: 0.5517\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6936e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 4.7460e-05 - accuracy: 1.0000 - val_loss: 7.9733 - val_accuracy: 0.5517\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0499e-05 - accuracy: 1.00 - 0s 176us/sample - loss: 4.6696e-05 - accuracy: 1.0000 - val_loss: 7.9774 - val_accuracy: 0.5517\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8309e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 4.6347e-05 - accuracy: 1.0000 - val_loss: 7.9834 - val_accuracy: 0.5517\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8975e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.5478e-05 - accuracy: 1.0000 - val_loss: 7.9876 - val_accuracy: 0.5517\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4545e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.5728e-05 - accuracy: 1.0000 - val_loss: 7.9887 - val_accuracy: 0.5517\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7919e-05 - accuracy: 1.00 - 0s 156us/sample - loss: 4.4601e-05 - accuracy: 1.0000 - val_loss: 7.9934 - val_accuracy: 0.5517\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.62 - 0s 3ms/sample - loss: 0.6647 - accuracy: 0.6379 - val_loss: 0.6320 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5729 - accuracy: 0.71 - 0s 172us/sample - loss: 0.6390 - accuracy: 0.6638 - val_loss: 0.6328 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6140 - accuracy: 0.68 - 0s 163us/sample - loss: 0.6157 - accuracy: 0.6638 - val_loss: 0.6364 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6415 - accuracy: 0.59 - 0s 164us/sample - loss: 0.5965 - accuracy: 0.6638 - val_loss: 0.6305 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5929 - accuracy: 0.65 - 0s 172us/sample - loss: 0.5900 - accuracy: 0.6810 - val_loss: 0.6154 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.71 - 0s 198us/sample - loss: 0.5707 - accuracy: 0.7069 - val_loss: 0.6078 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.78 - 0s 215us/sample - loss: 0.5617 - accuracy: 0.7241 - val_loss: 0.6104 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5979 - accuracy: 0.71 - 0s 180us/sample - loss: 0.5645 - accuracy: 0.7241 - val_loss: 0.6222 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5240 - accuracy: 0.75 - 0s 180us/sample - loss: 0.5078 - accuracy: 0.7500 - val_loss: 0.6615 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6146 - accuracy: 0.68 - 0s 172us/sample - loss: 0.5042 - accuracy: 0.7759 - val_loss: 0.6337 - val_accuracy: 0.6207\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4768 - accuracy: 0.75 - 0s 155us/sample - loss: 0.4771 - accuracy: 0.7845 - val_loss: 0.6556 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3626 - accuracy: 0.84 - 0s 172us/sample - loss: 0.4594 - accuracy: 0.7759 - val_loss: 0.7120 - val_accuracy: 0.6207\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.81 - 0s 181us/sample - loss: 0.4037 - accuracy: 0.8534 - val_loss: 0.7430 - val_accuracy: 0.6207\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4076 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3952 - accuracy: 0.8448 - val_loss: 0.8663 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3152 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3921 - accuracy: 0.8621 - val_loss: 0.8724 - val_accuracy: 0.5517\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3448 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4035 - accuracy: 0.8103 - val_loss: 0.8555 - val_accuracy: 0.6897\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3866 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4410 - accuracy: 0.7845 - val_loss: 0.8209 - val_accuracy: 0.5862\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3423 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3845 - accuracy: 0.8448 - val_loss: 0.7912 - val_accuracy: 0.5172\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4272 - accuracy: 0.81 - 0s 172us/sample - loss: 0.3372 - accuracy: 0.8793 - val_loss: 0.8337 - val_accuracy: 0.6207\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.87 - 0s 172us/sample - loss: 0.3563 - accuracy: 0.8276 - val_loss: 0.9352 - val_accuracy: 0.5517\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.96 - 0s 155us/sample - loss: 0.3608 - accuracy: 0.8534 - val_loss: 1.0114 - val_accuracy: 0.5862\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2608 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3118 - accuracy: 0.8879 - val_loss: 1.0318 - val_accuracy: 0.5517\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2702 - accuracy: 0.8966 - val_loss: 1.0807 - val_accuracy: 0.5862\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1971 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2575 - accuracy: 0.9052 - val_loss: 1.1790 - val_accuracy: 0.5862\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1085 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2264 - accuracy: 0.9224 - val_loss: 1.2051 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1969 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2941 - accuracy: 0.8879 - val_loss: 1.1536 - val_accuracy: 0.5517\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1185 - accuracy: 1.00 - 0s 155us/sample - loss: 0.2435 - accuracy: 0.9052 - val_loss: 1.0714 - val_accuracy: 0.5862\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1427 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2038 - accuracy: 0.9397 - val_loss: 1.0489 - val_accuracy: 0.6897\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2547 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2011 - accuracy: 0.9397 - val_loss: 1.3387 - val_accuracy: 0.5517\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2547 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1785 - accuracy: 0.9310 - val_loss: 1.3982 - val_accuracy: 0.5862\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.93 - 0s 135us/sample - loss: 0.1861 - accuracy: 0.9310 - val_loss: 1.4164 - val_accuracy: 0.5862\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1432 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1511 - accuracy: 0.9569 - val_loss: 1.8535 - val_accuracy: 0.5172\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2347 - accuracy: 0.8793 - val_loss: 1.8177 - val_accuracy: 0.6207\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3003 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2215 - accuracy: 0.9052 - val_loss: 1.7153 - val_accuracy: 0.5862\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.96 - 0s 204us/sample - loss: 0.2105 - accuracy: 0.9483 - val_loss: 1.7528 - val_accuracy: 0.4828\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1873 - accuracy: 0.93 - 0s 138us/sample - loss: 0.2184 - accuracy: 0.9052 - val_loss: 1.6389 - val_accuracy: 0.5172\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3048 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2105 - accuracy: 0.9310 - val_loss: 1.5182 - val_accuracy: 0.4828\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2210 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1565 - accuracy: 0.9397 - val_loss: 1.7248 - val_accuracy: 0.5172\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0702 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1486 - accuracy: 0.9397 - val_loss: 1.7973 - val_accuracy: 0.5172\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1444 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1954 - accuracy: 0.9310 - val_loss: 1.9838 - val_accuracy: 0.5862\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1791 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1503 - accuracy: 0.9569 - val_loss: 1.9016 - val_accuracy: 0.5172\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1980 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1440 - accuracy: 0.9310 - val_loss: 1.9821 - val_accuracy: 0.6207\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1401 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1492 - accuracy: 0.9483 - val_loss: 2.0304 - val_accuracy: 0.5862\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1132 - accuracy: 0.9569 - val_loss: 2.1542 - val_accuracy: 0.5862\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0326 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1051 - accuracy: 0.9569 - val_loss: 2.2193 - val_accuracy: 0.5862\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0756 - accuracy: 0.9828 - val_loss: 2.4551 - val_accuracy: 0.5862\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.96 - 0s 137us/sample - loss: 0.0692 - accuracy: 0.9741 - val_loss: 2.5359 - val_accuracy: 0.6207\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0603 - accuracy: 0.9828 - val_loss: 2.9438 - val_accuracy: 0.6207\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0639 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0480 - accuracy: 0.9828 - val_loss: 3.3949 - val_accuracy: 0.4828\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0558 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0396 - accuracy: 0.9828 - val_loss: 3.9332 - val_accuracy: 0.4828\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0388 - accuracy: 0.9914 - val_loss: 3.9601 - val_accuracy: 0.6552\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1950 - accuracy: 0.9224 - val_loss: 3.9663 - val_accuracy: 0.5517\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0423 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1559 - accuracy: 0.9483 - val_loss: 5.5290 - val_accuracy: 0.5862\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.8917 - accuracy: 0.78 - 0s 163us/sample - loss: 0.3672 - accuracy: 0.8966 - val_loss: 2.7125 - val_accuracy: 0.6897\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1168 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2652 - accuracy: 0.8966 - val_loss: 1.9869 - val_accuracy: 0.6897\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3578 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2716 - accuracy: 0.8879 - val_loss: 2.3396 - val_accuracy: 0.6207\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2245 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2259 - accuracy: 0.9310 - val_loss: 2.6808 - val_accuracy: 0.6552\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1871 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2156 - accuracy: 0.9224 - val_loss: 2.6779 - val_accuracy: 0.4828\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2190 - accuracy: 0.90 - 0s 172us/sample - loss: 0.1716 - accuracy: 0.9397 - val_loss: 3.1726 - val_accuracy: 0.5862\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.87 - 0s 146us/sample - loss: 0.1783 - accuracy: 0.9224 - val_loss: 3.1647 - val_accuracy: 0.4138\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1550 - accuracy: 0.9310 - val_loss: 3.4127 - val_accuracy: 0.4483\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1201 - accuracy: 0.9569 - val_loss: 3.6181 - val_accuracy: 0.4828\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1088 - accuracy: 0.9483 - val_loss: 3.8414 - val_accuracy: 0.4828\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0185 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0760 - accuracy: 0.9828 - val_loss: 4.1197 - val_accuracy: 0.4828\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0754 - accuracy: 0.9741 - val_loss: 4.4765 - val_accuracy: 0.4828\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0630 - accuracy: 0.9828 - val_loss: 4.9897 - val_accuracy: 0.5172\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0429 - accuracy: 0.9914 - val_loss: 5.5030 - val_accuracy: 0.4138\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1278 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0949 - accuracy: 0.9483 - val_loss: 5.6298 - val_accuracy: 0.4483\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1412 - accuracy: 0.9483 - val_loss: 5.7309 - val_accuracy: 0.5862\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 1.00 - 0s 146us/sample - loss: 0.3228 - accuracy: 0.9138 - val_loss: 5.0230 - val_accuracy: 0.5172\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0859 - accuracy: 0.9828 - val_loss: 4.1165 - val_accuracy: 0.4828\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0809 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1122 - accuracy: 0.9483 - val_loss: 3.3631 - val_accuracy: 0.5517\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1398 - accuracy: 0.90 - 0s 138us/sample - loss: 0.0960 - accuracy: 0.9741 - val_loss: 2.9883 - val_accuracy: 0.5517\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1224 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0639 - accuracy: 1.0000 - val_loss: 3.3305 - val_accuracy: 0.5172\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0750 - accuracy: 0.9655 - val_loss: 3.4892 - val_accuracy: 0.4828\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0790 - accuracy: 0.9828 - val_loss: 3.6258 - val_accuracy: 0.4483\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0441 - accuracy: 0.9914 - val_loss: 4.3126 - val_accuracy: 0.6207\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1144 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0744 - accuracy: 0.9655 - val_loss: 3.6462 - val_accuracy: 0.5517\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0657 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0877 - accuracy: 0.9655 - val_loss: 4.1498 - val_accuracy: 0.5862\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0876 - accuracy: 0.9569 - val_loss: 3.8579 - val_accuracy: 0.4483\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0557 - accuracy: 0.9741 - val_loss: 4.1455 - val_accuracy: 0.4483\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0278 - accuracy: 0.9914 - val_loss: 4.5346 - val_accuracy: 0.4483\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0281 - accuracy: 1.0000 - val_loss: 4.4895 - val_accuracy: 0.4138\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0136 - accuracy: 1.0000 - val_loss: 4.6412 - val_accuracy: 0.4138\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0091 - accuracy: 1.0000 - val_loss: 4.8016 - val_accuracy: 0.4138\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 5.0129 - val_accuracy: 0.4138\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 5.3698 - val_accuracy: 0.4138\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 5.6295 - val_accuracy: 0.4138\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.7754 - val_accuracy: 0.4138\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1431e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 5.8242 - val_accuracy: 0.4138\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7439e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 5.8266 - val_accuracy: 0.4138\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.9464 - val_accuracy: 0.4138\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5577e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 9.6644e-04 - accuracy: 1.0000 - val_loss: 6.1322 - val_accuracy: 0.4138\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 155us/sample - loss: 8.7035e-04 - accuracy: 1.0000 - val_loss: 6.2496 - val_accuracy: 0.4138\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7139e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 7.3494e-04 - accuracy: 1.0000 - val_loss: 6.3174 - val_accuracy: 0.4138\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 142us/sample - loss: 6.5551e-04 - accuracy: 1.0000 - val_loss: 6.3581 - val_accuracy: 0.4138\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8004e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.6832e-04 - accuracy: 1.0000 - val_loss: 6.4079 - val_accuracy: 0.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8939e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.3295e-04 - accuracy: 1.0000 - val_loss: 6.4696 - val_accuracy: 0.4138\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5265e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.8133e-04 - accuracy: 1.0000 - val_loss: 6.5453 - val_accuracy: 0.4138\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5259e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.3448e-04 - accuracy: 1.0000 - val_loss: 6.6072 - val_accuracy: 0.4138\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9496e-04 - accuracy: 1.00 - 0s 148us/sample - loss: 4.1402e-04 - accuracy: 1.0000 - val_loss: 6.6555 - val_accuracy: 0.4138\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7673e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.8970e-04 - accuracy: 1.0000 - val_loss: 6.6773 - val_accuracy: 0.4138\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4624e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.6068e-04 - accuracy: 1.0000 - val_loss: 6.6818 - val_accuracy: 0.4483\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0952e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.3871e-04 - accuracy: 1.0000 - val_loss: 6.7030 - val_accuracy: 0.4483\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5245e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.2159e-04 - accuracy: 1.0000 - val_loss: 6.7368 - val_accuracy: 0.4138\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0431e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.0175e-04 - accuracy: 1.0000 - val_loss: 6.7649 - val_accuracy: 0.4138\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1231e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.8937e-04 - accuracy: 1.0000 - val_loss: 6.7920 - val_accuracy: 0.4138\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9516e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.7579e-04 - accuracy: 1.0000 - val_loss: 6.8222 - val_accuracy: 0.4138\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6441e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.6638e-04 - accuracy: 1.0000 - val_loss: 6.8571 - val_accuracy: 0.4138\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4290e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.5450e-04 - accuracy: 1.0000 - val_loss: 6.8794 - val_accuracy: 0.4138\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1050e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.4450e-04 - accuracy: 1.0000 - val_loss: 6.9096 - val_accuracy: 0.4138\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6499e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.3500e-04 - accuracy: 1.0000 - val_loss: 6.9320 - val_accuracy: 0.4138\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5939e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.2504e-04 - accuracy: 1.0000 - val_loss: 6.9434 - val_accuracy: 0.4483\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1601e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.1712e-04 - accuracy: 1.0000 - val_loss: 6.9651 - val_accuracy: 0.4483\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6411e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.1078e-04 - accuracy: 1.0000 - val_loss: 6.9836 - val_accuracy: 0.4483\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5737e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.0672e-04 - accuracy: 1.0000 - val_loss: 7.0117 - val_accuracy: 0.4483\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9234e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.9854e-04 - accuracy: 1.0000 - val_loss: 7.0397 - val_accuracy: 0.4483\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7157e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.9010e-04 - accuracy: 1.0000 - val_loss: 7.0775 - val_accuracy: 0.4483\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3224e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.8408e-04 - accuracy: 1.0000 - val_loss: 7.1148 - val_accuracy: 0.4483\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6094e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7977e-04 - accuracy: 1.0000 - val_loss: 7.1383 - val_accuracy: 0.4138\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1422e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7488e-04 - accuracy: 1.0000 - val_loss: 7.1557 - val_accuracy: 0.4483\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1066e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.6821e-04 - accuracy: 1.0000 - val_loss: 7.1712 - val_accuracy: 0.4483\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0002e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6451e-04 - accuracy: 1.0000 - val_loss: 7.1775 - val_accuracy: 0.4483\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9472e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.5941e-04 - accuracy: 1.0000 - val_loss: 7.2002 - val_accuracy: 0.4483\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1908e-04 - accuracy: 1.00 - 0s 168us/sample - loss: 1.5573e-04 - accuracy: 1.0000 - val_loss: 7.2275 - val_accuracy: 0.4483\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2421e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5176e-04 - accuracy: 1.0000 - val_loss: 7.2440 - val_accuracy: 0.4483\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5255e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 1.4567e-04 - accuracy: 1.0000 - val_loss: 7.2711 - val_accuracy: 0.4483\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5562e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.4335e-04 - accuracy: 1.0000 - val_loss: 7.2988 - val_accuracy: 0.4483\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7042e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 1.3860e-04 - accuracy: 1.0000 - val_loss: 7.3207 - val_accuracy: 0.4483\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6412e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3541e-04 - accuracy: 1.0000 - val_loss: 7.3380 - val_accuracy: 0.4483\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0839e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3214e-04 - accuracy: 1.0000 - val_loss: 7.3517 - val_accuracy: 0.4483\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1193e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.2846e-04 - accuracy: 1.0000 - val_loss: 7.3705 - val_accuracy: 0.4483\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6204e-04 - accuracy: 1.00 - 0s 176us/sample - loss: 1.2581e-04 - accuracy: 1.0000 - val_loss: 7.3914 - val_accuracy: 0.4483\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4768e-04 - accuracy: 1.00 - 0s 181us/sample - loss: 1.2236e-04 - accuracy: 1.0000 - val_loss: 7.4076 - val_accuracy: 0.4483\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3293e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.1978e-04 - accuracy: 1.0000 - val_loss: 7.4268 - val_accuracy: 0.4483\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7712e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.1733e-04 - accuracy: 1.0000 - val_loss: 7.4404 - val_accuracy: 0.4483\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1302e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1473e-04 - accuracy: 1.0000 - val_loss: 7.4637 - val_accuracy: 0.4483\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3331e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1192e-04 - accuracy: 1.0000 - val_loss: 7.4778 - val_accuracy: 0.4483\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5337e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.0948e-04 - accuracy: 1.0000 - val_loss: 7.4926 - val_accuracy: 0.4483\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1324e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0624e-04 - accuracy: 1.0000 - val_loss: 7.5124 - val_accuracy: 0.4483\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1644e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0418e-04 - accuracy: 1.0000 - val_loss: 7.5332 - val_accuracy: 0.4483\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.8550e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0153e-04 - accuracy: 1.0000 - val_loss: 7.5511 - val_accuracy: 0.4483\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.4796e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 9.9332e-05 - accuracy: 1.0000 - val_loss: 7.5615 - val_accuracy: 0.4483\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0967e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.6999e-05 - accuracy: 1.0000 - val_loss: 7.5770 - val_accuracy: 0.4483\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0373e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 9.4888e-05 - accuracy: 1.0000 - val_loss: 7.5937 - val_accuracy: 0.4483\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8213e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 9.3116e-05 - accuracy: 1.0000 - val_loss: 7.6128 - val_accuracy: 0.4483\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4491e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 9.1432e-05 - accuracy: 1.0000 - val_loss: 7.6338 - val_accuracy: 0.4483\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8800e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.9156e-05 - accuracy: 1.0000 - val_loss: 7.6504 - val_accuracy: 0.4483\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8194e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.7168e-05 - accuracy: 1.0000 - val_loss: 7.6670 - val_accuracy: 0.4483\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2400e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.5941e-05 - accuracy: 1.0000 - val_loss: 7.6806 - val_accuracy: 0.4483\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0732e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.3509e-05 - accuracy: 1.0000 - val_loss: 7.6991 - val_accuracy: 0.4483\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6012e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.1862e-05 - accuracy: 1.0000 - val_loss: 7.7161 - val_accuracy: 0.4483\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1101e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.0671e-05 - accuracy: 1.0000 - val_loss: 7.7354 - val_accuracy: 0.4483\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3749e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.9031e-05 - accuracy: 1.0000 - val_loss: 7.7483 - val_accuracy: 0.4483\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0653e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.7396e-05 - accuracy: 1.0000 - val_loss: 7.7592 - val_accuracy: 0.4483\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2162e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 7.6147e-05 - accuracy: 1.0000 - val_loss: 7.7694 - val_accuracy: 0.4483\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0354e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.4728e-05 - accuracy: 1.0000 - val_loss: 7.7830 - val_accuracy: 0.4483\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1008e-05 - accuracy: 1.00 - 0s 164us/sample - loss: 7.3105e-05 - accuracy: 1.0000 - val_loss: 7.7981 - val_accuracy: 0.4483\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.1925e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.1979e-05 - accuracy: 1.0000 - val_loss: 7.8158 - val_accuracy: 0.4483\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.2316e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.0662e-05 - accuracy: 1.0000 - val_loss: 7.8344 - val_accuracy: 0.4483\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7486e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.9449e-05 - accuracy: 1.0000 - val_loss: 7.8495 - val_accuracy: 0.4483\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8456e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.8113e-05 - accuracy: 1.0000 - val_loss: 7.8627 - val_accuracy: 0.4483\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2834e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.6787e-05 - accuracy: 1.0000 - val_loss: 7.8747 - val_accuracy: 0.4483\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.1038e-05 - accuracy: 1.00 - 0s 181us/sample - loss: 6.5662e-05 - accuracy: 1.0000 - val_loss: 7.8941 - val_accuracy: 0.4483\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3778e-06 - accuracy: 1.00 - 0s 189us/sample - loss: 6.4179e-05 - accuracy: 1.0000 - val_loss: 7.9098 - val_accuracy: 0.4483\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6830e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.3623e-05 - accuracy: 1.0000 - val_loss: 7.9300 - val_accuracy: 0.4483\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.5240e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.2365e-05 - accuracy: 1.0000 - val_loss: 7.9407 - val_accuracy: 0.4483\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3193e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 6.1158e-05 - accuracy: 1.0000 - val_loss: 7.9551 - val_accuracy: 0.4483\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4655e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.9781e-05 - accuracy: 1.0000 - val_loss: 7.9672 - val_accuracy: 0.4483\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0028e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.9430e-05 - accuracy: 1.0000 - val_loss: 7.9790 - val_accuracy: 0.4483\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.1924e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.7988e-05 - accuracy: 1.0000 - val_loss: 7.9982 - val_accuracy: 0.4483\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5361e-05 - accuracy: 1.00 - 0s 137us/sample - loss: 5.6905e-05 - accuracy: 1.0000 - val_loss: 8.0208 - val_accuracy: 0.4483\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2998e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.5674e-05 - accuracy: 1.0000 - val_loss: 8.0410 - val_accuracy: 0.4483\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8864e-05 - accuracy: 1.00 - 0s 159us/sample - loss: 5.4847e-05 - accuracy: 1.0000 - val_loss: 8.0598 - val_accuracy: 0.4483\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1313e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.3945e-05 - accuracy: 1.0000 - val_loss: 8.0727 - val_accuracy: 0.4483\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2658e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.3270e-05 - accuracy: 1.0000 - val_loss: 8.0853 - val_accuracy: 0.4483\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8344e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.1955e-05 - accuracy: 1.0000 - val_loss: 8.1009 - val_accuracy: 0.4483\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4762e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.1133e-05 - accuracy: 1.0000 - val_loss: 8.1172 - val_accuracy: 0.4483\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9257e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.0505e-05 - accuracy: 1.0000 - val_loss: 8.1329 - val_accuracy: 0.4483\n",
      "Epoch 180/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 7.9609e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.9604e-05 - accuracy: 1.0000 - val_loss: 8.1476 - val_accuracy: 0.4483\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7776e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.8688e-05 - accuracy: 1.0000 - val_loss: 8.1597 - val_accuracy: 0.4483\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8197e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.7827e-05 - accuracy: 1.0000 - val_loss: 8.1713 - val_accuracy: 0.4483\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0354e-05 - accuracy: 1.00 - 0s 148us/sample - loss: 4.7152e-05 - accuracy: 1.0000 - val_loss: 8.1829 - val_accuracy: 0.4483\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1769e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.6559e-05 - accuracy: 1.0000 - val_loss: 8.1923 - val_accuracy: 0.4483\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4976e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.5728e-05 - accuracy: 1.0000 - val_loss: 8.2049 - val_accuracy: 0.4483\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5192e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.4999e-05 - accuracy: 1.0000 - val_loss: 8.2237 - val_accuracy: 0.4483\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.2219e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.4304e-05 - accuracy: 1.0000 - val_loss: 8.2417 - val_accuracy: 0.4483\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9833e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.3861e-05 - accuracy: 1.0000 - val_loss: 8.2582 - val_accuracy: 0.4483\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7250e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.3073e-05 - accuracy: 1.0000 - val_loss: 8.2678 - val_accuracy: 0.4483\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3109e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 4.2176e-05 - accuracy: 1.0000 - val_loss: 8.2789 - val_accuracy: 0.4483\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5781e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.1584e-05 - accuracy: 1.0000 - val_loss: 8.2908 - val_accuracy: 0.4483\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2591e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 4.1079e-05 - accuracy: 1.0000 - val_loss: 8.3020 - val_accuracy: 0.4483\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8404e-05 - accuracy: 1.00 - 0s 134us/sample - loss: 4.0348e-05 - accuracy: 1.0000 - val_loss: 8.3199 - val_accuracy: 0.4483\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5295e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.9535e-05 - accuracy: 1.0000 - val_loss: 8.3394 - val_accuracy: 0.4483\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0278e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.9008e-05 - accuracy: 1.0000 - val_loss: 8.3587 - val_accuracy: 0.4483\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9611e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.8528e-05 - accuracy: 1.0000 - val_loss: 8.3759 - val_accuracy: 0.4483\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1579e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.8209e-05 - accuracy: 1.0000 - val_loss: 8.3954 - val_accuracy: 0.4483\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1902e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.7497e-05 - accuracy: 1.0000 - val_loss: 8.4093 - val_accuracy: 0.4483\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1118e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.7328e-05 - accuracy: 1.0000 - val_loss: 8.4184 - val_accuracy: 0.4483\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8944e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 3.6188e-05 - accuracy: 1.0000 - val_loss: 8.4343 - val_accuracy: 0.4483\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6823 - accuracy: 0.65 - 0s 3ms/sample - loss: 0.6632 - accuracy: 0.6638 - val_loss: 0.6489 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6175 - accuracy: 0.68 - 0s 172us/sample - loss: 0.6380 - accuracy: 0.6638 - val_loss: 0.6478 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6101 - accuracy: 0.78 - 0s 172us/sample - loss: 0.6329 - accuracy: 0.6638 - val_loss: 0.6247 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5883 - accuracy: 0.68 - 0s 163us/sample - loss: 0.6078 - accuracy: 0.6638 - val_loss: 0.6167 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5224 - accuracy: 0.75 - 0s 163us/sample - loss: 0.5925 - accuracy: 0.6638 - val_loss: 0.6036 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6229 - accuracy: 0.62 - 0s 172us/sample - loss: 0.5955 - accuracy: 0.6638 - val_loss: 0.6087 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5958 - accuracy: 0.68 - 0s 163us/sample - loss: 0.5673 - accuracy: 0.6638 - val_loss: 0.6065 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5846 - accuracy: 0.68 - 0s 2ms/sample - loss: 0.5558 - accuracy: 0.6810 - val_loss: 0.5813 - val_accuracy: 0.7586\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4338 - accuracy: 0.93 - 0s 327us/sample - loss: 0.5428 - accuracy: 0.7500 - val_loss: 0.5713 - val_accuracy: 0.7241\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4676 - accuracy: 0.81 - 0s 181us/sample - loss: 0.5215 - accuracy: 0.7328 - val_loss: 0.5673 - val_accuracy: 0.7241\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3870 - accuracy: 0.81 - 0s 172us/sample - loss: 0.4887 - accuracy: 0.7586 - val_loss: 0.5692 - val_accuracy: 0.6207\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5337 - accuracy: 0.71 - 0s 181us/sample - loss: 0.4430 - accuracy: 0.8190 - val_loss: 0.6955 - val_accuracy: 0.7241\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4550 - accuracy: 0.75 - 0s 164us/sample - loss: 0.5264 - accuracy: 0.7328 - val_loss: 0.6421 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3915 - accuracy: 0.87 - 0s 155us/sample - loss: 0.5323 - accuracy: 0.7759 - val_loss: 0.5713 - val_accuracy: 0.7241\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4005 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4269 - accuracy: 0.8190 - val_loss: 0.6316 - val_accuracy: 0.7241\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7200 - accuracy: 0.56 - 0s 163us/sample - loss: 0.4668 - accuracy: 0.7500 - val_loss: 0.5753 - val_accuracy: 0.6897\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4057 - accuracy: 0.8103 - val_loss: 0.5978 - val_accuracy: 0.6897\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3686 - accuracy: 0.8276 - val_loss: 0.6990 - val_accuracy: 0.6207\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3992 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3469 - accuracy: 0.8621 - val_loss: 0.8442 - val_accuracy: 0.5862\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.90 - 0s 142us/sample - loss: 0.3319 - accuracy: 0.8879 - val_loss: 0.8265 - val_accuracy: 0.7241\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5017 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3142 - accuracy: 0.8879 - val_loss: 0.7567 - val_accuracy: 0.6897\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4353 - accuracy: 0.81 - 0s 146us/sample - loss: 0.2809 - accuracy: 0.8879 - val_loss: 0.8820 - val_accuracy: 0.6552\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3579 - accuracy: 0.84 - 0s 155us/sample - loss: 0.2837 - accuracy: 0.8879 - val_loss: 0.9484 - val_accuracy: 0.6207\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3071 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2518 - accuracy: 0.9052 - val_loss: 0.8899 - val_accuracy: 0.5862\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1636 - accuracy: 0.93 - 0s 137us/sample - loss: 0.2690 - accuracy: 0.8621 - val_loss: 0.9011 - val_accuracy: 0.7241\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1908 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2701 - accuracy: 0.8966 - val_loss: 1.0976 - val_accuracy: 0.4483\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2847 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2474 - accuracy: 0.8879 - val_loss: 0.7817 - val_accuracy: 0.7586\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2661 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2515 - accuracy: 0.8707 - val_loss: 0.9059 - val_accuracy: 0.6552\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2054 - accuracy: 0.8966 - val_loss: 1.0080 - val_accuracy: 0.7586\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3438 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2923 - accuracy: 0.8879 - val_loss: 1.4046 - val_accuracy: 0.5862\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2910 - accuracy: 0.87 - 0s 163us/sample - loss: 0.2070 - accuracy: 0.9310 - val_loss: 0.9427 - val_accuracy: 0.7241\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2714 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1839 - accuracy: 0.9310 - val_loss: 1.0138 - val_accuracy: 0.6207\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1253 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1671 - accuracy: 0.9397 - val_loss: 1.0624 - val_accuracy: 0.6552\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1648 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1446 - accuracy: 0.9397 - val_loss: 1.2338 - val_accuracy: 0.6207\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1294 - accuracy: 0.9483 - val_loss: 1.5570 - val_accuracy: 0.5862\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1703 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1740 - accuracy: 0.8966 - val_loss: 1.0025 - val_accuracy: 0.7241\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1949 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1503 - accuracy: 0.9310 - val_loss: 1.9268 - val_accuracy: 0.5517\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3007 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2401 - accuracy: 0.9138 - val_loss: 1.2930 - val_accuracy: 0.7586\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1671 - accuracy: 0.9224 - val_loss: 1.8737 - val_accuracy: 0.6207\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2830 - accuracy: 0.84 - 0s 155us/sample - loss: 0.1893 - accuracy: 0.9138 - val_loss: 1.7355 - val_accuracy: 0.7241\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2215 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1742 - accuracy: 0.9138 - val_loss: 2.3455 - val_accuracy: 0.4828\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4569 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1977 - accuracy: 0.9483 - val_loss: 1.4051 - val_accuracy: 0.6552\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2415 - accuracy: 0.8966 - val_loss: 2.0558 - val_accuracy: 0.4483\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.96 - 0s 133us/sample - loss: 0.1850 - accuracy: 0.9224 - val_loss: 1.9086 - val_accuracy: 0.6552\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1985 - accuracy: 0.90 - 0s 138us/sample - loss: 0.4920 - accuracy: 0.8534 - val_loss: 1.6652 - val_accuracy: 0.5862\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0887 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2132 - accuracy: 0.9397 - val_loss: 1.2942 - val_accuracy: 0.7241\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3207 - accuracy: 0.84 - 0s 120us/sample - loss: 0.2848 - accuracy: 0.9052 - val_loss: 1.2897 - val_accuracy: 0.6897\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2381 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1950 - accuracy: 0.9224 - val_loss: 1.9030 - val_accuracy: 0.5517\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1679 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1763 - accuracy: 0.9310 - val_loss: 1.9920 - val_accuracy: 0.5862\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1844 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1379 - accuracy: 0.9483 - val_loss: 1.8267 - val_accuracy: 0.6207\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0855 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1243 - accuracy: 0.9483 - val_loss: 1.6516 - val_accuracy: 0.6552\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1252 - accuracy: 0.9397 - val_loss: 1.5499 - val_accuracy: 0.6207\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0990 - accuracy: 0.9483 - val_loss: 2.0090 - val_accuracy: 0.6207\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0942 - accuracy: 0.9828 - val_loss: 2.2739 - val_accuracy: 0.5517\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0989 - accuracy: 0.9483 - val_loss: 2.1852 - val_accuracy: 0.6207\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0229 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0590 - accuracy: 0.9828 - val_loss: 2.0192 - val_accuracy: 0.6207\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0785 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0470 - accuracy: 0.9828 - val_loss: 2.1068 - val_accuracy: 0.6207\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0319 - accuracy: 0.9914 - val_loss: 2.3252 - val_accuracy: 0.5862\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0551 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0265 - accuracy: 0.9914 - val_loss: 2.5777 - val_accuracy: 0.5517\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.6579 - val_accuracy: 0.5517\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0205 - accuracy: 0.9914 - val_loss: 2.9008 - val_accuracy: 0.5172\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0120 - accuracy: 0.9914 - val_loss: 2.9612 - val_accuracy: 0.5517\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.7008 - val_accuracy: 0.5172\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9502e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0144 - accuracy: 1.0000 - val_loss: 2.6577 - val_accuracy: 0.5862\n",
      "Epoch 65/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.7622 - val_accuracy: 0.5517\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.7684 - val_accuracy: 0.6552\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.7903 - val_accuracy: 0.6552\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.8326 - val_accuracy: 0.6207\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.9557 - val_accuracy: 0.5862\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.0881 - val_accuracy: 0.5862\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8335e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.2103 - val_accuracy: 0.5862\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.1197e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.3308 - val_accuracy: 0.5862\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8973e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.4600 - val_accuracy: 0.5862\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.5784 - val_accuracy: 0.5862\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5166e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.3855e-04 - accuracy: 1.0000 - val_loss: 3.6385 - val_accuracy: 0.5862\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 138us/sample - loss: 5.6173e-04 - accuracy: 1.0000 - val_loss: 3.6662 - val_accuracy: 0.5862\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4882e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.0972e-04 - accuracy: 1.0000 - val_loss: 3.6781 - val_accuracy: 0.5862\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8446e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.0373e-04 - accuracy: 1.0000 - val_loss: 3.6936 - val_accuracy: 0.5862\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1758e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.7356e-04 - accuracy: 1.0000 - val_loss: 3.7045 - val_accuracy: 0.5862\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2107e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.1470e-04 - accuracy: 1.0000 - val_loss: 3.7176 - val_accuracy: 0.5862\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5886e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.8191e-04 - accuracy: 1.0000 - val_loss: 3.7223 - val_accuracy: 0.5862\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2550e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.7323e-04 - accuracy: 1.0000 - val_loss: 3.7262 - val_accuracy: 0.5862\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7389e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.6091e-04 - accuracy: 1.0000 - val_loss: 3.7225 - val_accuracy: 0.5862\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7265e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.3995e-04 - accuracy: 1.0000 - val_loss: 3.7376 - val_accuracy: 0.5862\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9983e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.2057e-04 - accuracy: 1.0000 - val_loss: 3.7631 - val_accuracy: 0.5862\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9122e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.0542e-04 - accuracy: 1.0000 - val_loss: 3.7911 - val_accuracy: 0.5862\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7046e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.8857e-04 - accuracy: 1.0000 - val_loss: 3.8208 - val_accuracy: 0.5862\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1931e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.7445e-04 - accuracy: 1.0000 - val_loss: 3.8537 - val_accuracy: 0.5862\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5302e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.6202e-04 - accuracy: 1.0000 - val_loss: 3.8885 - val_accuracy: 0.5862\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3396e-04 - accuracy: 1.00 - 0s 189us/sample - loss: 1.5090e-04 - accuracy: 1.0000 - val_loss: 3.9249 - val_accuracy: 0.6207\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6207e-04 - accuracy: 1.00 - 0s 181us/sample - loss: 1.3755e-04 - accuracy: 1.0000 - val_loss: 3.9617 - val_accuracy: 0.6207\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1121e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.2552e-04 - accuracy: 1.0000 - val_loss: 4.0025 - val_accuracy: 0.6207\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2677e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.1455e-04 - accuracy: 1.0000 - val_loss: 4.0419 - val_accuracy: 0.6207\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7830e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0587e-04 - accuracy: 1.0000 - val_loss: 4.0886 - val_accuracy: 0.6552\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1456e-04 - accuracy: 1.00 - 0s 152us/sample - loss: 9.5109e-05 - accuracy: 1.0000 - val_loss: 4.1194 - val_accuracy: 0.6207\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5287e-04 - accuracy: 1.00 - 0s 189us/sample - loss: 8.6518e-05 - accuracy: 1.0000 - val_loss: 4.1540 - val_accuracy: 0.6207\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3682e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 7.8237e-05 - accuracy: 1.0000 - val_loss: 4.1996 - val_accuracy: 0.6207\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.2156e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.1176e-05 - accuracy: 1.0000 - val_loss: 4.2193 - val_accuracy: 0.6207\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3917e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.4111e-05 - accuracy: 1.0000 - val_loss: 4.2279 - val_accuracy: 0.6207\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3428e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.8597e-05 - accuracy: 1.0000 - val_loss: 4.2665 - val_accuracy: 0.6207\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6336e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.3726e-05 - accuracy: 1.0000 - val_loss: 4.2928 - val_accuracy: 0.6207\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8717e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.9772e-05 - accuracy: 1.0000 - val_loss: 4.3187 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0604e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.5583e-05 - accuracy: 1.0000 - val_loss: 4.3521 - val_accuracy: 0.6207\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0816e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.1724e-05 - accuracy: 1.0000 - val_loss: 4.3803 - val_accuracy: 0.6207\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1990e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.9189e-05 - accuracy: 1.0000 - val_loss: 4.4152 - val_accuracy: 0.6207\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5752e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.6070e-05 - accuracy: 1.0000 - val_loss: 4.4535 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6752e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.3600e-05 - accuracy: 1.0000 - val_loss: 4.4917 - val_accuracy: 0.6207\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3153e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.1171e-05 - accuracy: 1.0000 - val_loss: 4.5324 - val_accuracy: 0.6207\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2943e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 2.9027e-05 - accuracy: 1.0000 - val_loss: 4.5686 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7674e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.7202e-05 - accuracy: 1.0000 - val_loss: 4.6060 - val_accuracy: 0.6207\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5742e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.5416e-05 - accuracy: 1.0000 - val_loss: 4.6517 - val_accuracy: 0.6207\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8900e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.4122e-05 - accuracy: 1.0000 - val_loss: 4.6864 - val_accuracy: 0.6207\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1494e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 2.2547e-05 - accuracy: 1.0000 - val_loss: 4.7116 - val_accuracy: 0.6207\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9067e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 2.1266e-05 - accuracy: 1.0000 - val_loss: 4.7357 - val_accuracy: 0.6207\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5725e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 2.0172e-05 - accuracy: 1.0000 - val_loss: 4.7572 - val_accuracy: 0.6207\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1697e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.9188e-05 - accuracy: 1.0000 - val_loss: 4.7819 - val_accuracy: 0.6207\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0393e-05 - accuracy: 1.00 - 0s 137us/sample - loss: 1.8215e-05 - accuracy: 1.0000 - val_loss: 4.8091 - val_accuracy: 0.6207\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5136e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.7427e-05 - accuracy: 1.0000 - val_loss: 4.8350 - val_accuracy: 0.6207\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8831e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.6732e-05 - accuracy: 1.0000 - val_loss: 4.8582 - val_accuracy: 0.6207\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8634e-06 - accuracy: 1.00 - 0s 129us/sample - loss: 1.5880e-05 - accuracy: 1.0000 - val_loss: 4.8788 - val_accuracy: 0.6207\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.2707e-06 - accuracy: 1.00 - 0s 155us/sample - loss: 1.5273e-05 - accuracy: 1.0000 - val_loss: 4.8987 - val_accuracy: 0.6207\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1210e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.4705e-05 - accuracy: 1.0000 - val_loss: 4.9191 - val_accuracy: 0.6207\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3873e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4169e-05 - accuracy: 1.0000 - val_loss: 4.9395 - val_accuracy: 0.6207\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2055e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.3652e-05 - accuracy: 1.0000 - val_loss: 4.9574 - val_accuracy: 0.6207\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9934e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 1.3186e-05 - accuracy: 1.0000 - val_loss: 4.9737 - val_accuracy: 0.6207\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4740e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2653e-05 - accuracy: 1.0000 - val_loss: 4.9886 - val_accuracy: 0.6207\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2113e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.2205e-05 - accuracy: 1.0000 - val_loss: 5.0035 - val_accuracy: 0.6207\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8650e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1801e-05 - accuracy: 1.0000 - val_loss: 5.0196 - val_accuracy: 0.6207\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6277e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1350e-05 - accuracy: 1.0000 - val_loss: 5.0367 - val_accuracy: 0.6207\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2918e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0975e-05 - accuracy: 1.0000 - val_loss: 5.0547 - val_accuracy: 0.6207\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7650e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0569e-05 - accuracy: 1.0000 - val_loss: 5.0707 - val_accuracy: 0.6207\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4648e-05 - accuracy: 1.00 - 0s 215us/sample - loss: 1.0228e-05 - accuracy: 1.0000 - val_loss: 5.0878 - val_accuracy: 0.6207\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2308e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 9.9460e-06 - accuracy: 1.0000 - val_loss: 5.1040 - val_accuracy: 0.6207\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4768e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 9.6479e-06 - accuracy: 1.0000 - val_loss: 5.1190 - val_accuracy: 0.6207\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4280e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 9.3567e-06 - accuracy: 1.0000 - val_loss: 5.1326 - val_accuracy: 0.6207\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1846e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 9.0562e-06 - accuracy: 1.0000 - val_loss: 5.1459 - val_accuracy: 0.6207\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0312e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.8308e-06 - accuracy: 1.0000 - val_loss: 5.1587 - val_accuracy: 0.6207\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4626e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 8.5570e-06 - accuracy: 1.0000 - val_loss: 5.1719 - val_accuracy: 0.6207\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5008e-06 - accuracy: 1.00 - 0s 155us/sample - loss: 8.3188e-06 - accuracy: 1.0000 - val_loss: 5.1847 - val_accuracy: 0.6207\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1059e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 8.1254e-06 - accuracy: 1.0000 - val_loss: 5.1985 - val_accuracy: 0.6207\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6145e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 7.8746e-06 - accuracy: 1.0000 - val_loss: 5.2119 - val_accuracy: 0.6207\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3582e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 7.6907e-06 - accuracy: 1.0000 - val_loss: 5.2251 - val_accuracy: 0.6207\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0320e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.4728e-06 - accuracy: 1.0000 - val_loss: 5.2389 - val_accuracy: 0.6207\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2400e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 7.2463e-06 - accuracy: 1.0000 - val_loss: 5.2523 - val_accuracy: 0.6207\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9793e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 7.0758e-06 - accuracy: 1.0000 - val_loss: 5.2657 - val_accuracy: 0.6207\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6014e-07 - accuracy: 1.00 - 0s 155us/sample - loss: 6.8835e-06 - accuracy: 1.0000 - val_loss: 5.2798 - val_accuracy: 0.6207\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1721e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 6.7294e-06 - accuracy: 1.0000 - val_loss: 5.2932 - val_accuracy: 0.6207\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4755e-06 - accuracy: 1.00 - 0s 155us/sample - loss: 6.5676e-06 - accuracy: 1.0000 - val_loss: 5.3056 - val_accuracy: 0.6207\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7994e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 6.4216e-06 - accuracy: 1.0000 - val_loss: 5.3171 - val_accuracy: 0.6207\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3482e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.2875e-06 - accuracy: 1.0000 - val_loss: 5.3287 - val_accuracy: 0.6207\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2959e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 6.1316e-06 - accuracy: 1.0000 - val_loss: 5.3397 - val_accuracy: 0.6207\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0740e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.9778e-06 - accuracy: 1.0000 - val_loss: 5.3506 - val_accuracy: 0.6207\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1002e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 5.8282e-06 - accuracy: 1.0000 - val_loss: 5.3620 - val_accuracy: 0.6207\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8085e-06 - accuracy: 1.00 - 0s 129us/sample - loss: 5.7217e-06 - accuracy: 1.0000 - val_loss: 5.3739 - val_accuracy: 0.6207\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9189e-06 - accuracy: 1.00 - 0s 155us/sample - loss: 5.5996e-06 - accuracy: 1.0000 - val_loss: 5.3853 - val_accuracy: 0.6207\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0804e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.4913e-06 - accuracy: 1.0000 - val_loss: 5.3962 - val_accuracy: 0.6207\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7146e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 5.3583e-06 - accuracy: 1.0000 - val_loss: 5.4065 - val_accuracy: 0.6207\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3267e-06 - accuracy: 1.00 - 0s 155us/sample - loss: 5.2515e-06 - accuracy: 1.0000 - val_loss: 5.4170 - val_accuracy: 0.6207\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.1748e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 5.1729e-06 - accuracy: 1.0000 - val_loss: 5.4277 - val_accuracy: 0.6207\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3493e-06 - accuracy: 1.00 - 0s 141us/sample - loss: 5.0528e-06 - accuracy: 1.0000 - val_loss: 5.4381 - val_accuracy: 0.6207\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3151e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 4.9569e-06 - accuracy: 1.0000 - val_loss: 5.4486 - val_accuracy: 0.6207\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0868e-06 - accuracy: 1.00 - 0s 129us/sample - loss: 4.8496e-06 - accuracy: 1.0000 - val_loss: 5.4588 - val_accuracy: 0.6207\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7697e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 4.7722e-06 - accuracy: 1.0000 - val_loss: 5.4705 - val_accuracy: 0.6207\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8724e-07 - accuracy: 1.00 - 0s 163us/sample - loss: 4.6710e-06 - accuracy: 1.0000 - val_loss: 5.4852 - val_accuracy: 0.6207\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3958e-07 - accuracy: 1.00 - 0s 146us/sample - loss: 4.5953e-06 - accuracy: 1.0000 - val_loss: 5.4988 - val_accuracy: 0.6207\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9106e-06 - accuracy: 1.00 - 0s 155us/sample - loss: 4.5318e-06 - accuracy: 1.0000 - val_loss: 5.5112 - val_accuracy: 0.6207\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4164e-06 - accuracy: 1.00 - 0s 163us/sample - loss: 4.4278e-06 - accuracy: 1.0000 - val_loss: 5.5216 - val_accuracy: 0.6207\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9712e-06 - accuracy: 1.00 - 0s 155us/sample - loss: 4.3466e-06 - accuracy: 1.0000 - val_loss: 5.5312 - val_accuracy: 0.6207\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7092e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 4.2539e-06 - accuracy: 1.0000 - val_loss: 5.5403 - val_accuracy: 0.6207\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5197e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 4.1695e-06 - accuracy: 1.0000 - val_loss: 5.5490 - val_accuracy: 0.6207\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1730e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 4.0950e-06 - accuracy: 1.0000 - val_loss: 5.5578 - val_accuracy: 0.6207\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0530e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 4.0006e-06 - accuracy: 1.0000 - val_loss: 5.5660 - val_accuracy: 0.6207\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0413e-06 - accuracy: 1.00 - 0s 129us/sample - loss: 3.9439e-06 - accuracy: 1.0000 - val_loss: 5.5753 - val_accuracy: 0.6207\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8924e-06 - accuracy: 1.00 - 0s 155us/sample - loss: 3.8675e-06 - accuracy: 1.0000 - val_loss: 5.5842 - val_accuracy: 0.6207\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2994e-06 - accuracy: 1.00 - 0s 163us/sample - loss: 3.7945e-06 - accuracy: 1.0000 - val_loss: 5.5929 - val_accuracy: 0.6207\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6475e-07 - accuracy: 1.00 - 0s 138us/sample - loss: 3.7304e-06 - accuracy: 1.0000 - val_loss: 5.6011 - val_accuracy: 0.6207\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0336e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 3.6728e-06 - accuracy: 1.0000 - val_loss: 5.6095 - val_accuracy: 0.6207\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4415e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 3.6112e-06 - accuracy: 1.0000 - val_loss: 5.6184 - val_accuracy: 0.6207\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5632e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 3.5389e-06 - accuracy: 1.0000 - val_loss: 5.6274 - val_accuracy: 0.6207\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3983e-06 - accuracy: 1.00 - 0s 155us/sample - loss: 3.4872e-06 - accuracy: 1.0000 - val_loss: 5.6365 - val_accuracy: 0.6207\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0150e-06 - accuracy: 1.00 - 0s 155us/sample - loss: 3.4391e-06 - accuracy: 1.0000 - val_loss: 5.6455 - val_accuracy: 0.6207\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9521e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 3.3757e-06 - accuracy: 1.0000 - val_loss: 5.6539 - val_accuracy: 0.6207\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3247e-07 - accuracy: 1.00 - 0s 155us/sample - loss: 3.3116e-06 - accuracy: 1.0000 - val_loss: 5.6614 - val_accuracy: 0.6207\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5386e-06 - accuracy: 1.00 - 0s 155us/sample - loss: 3.2653e-06 - accuracy: 1.0000 - val_loss: 5.6703 - val_accuracy: 0.6207\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5389e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 3.2114e-06 - accuracy: 1.0000 - val_loss: 5.6804 - val_accuracy: 0.6207\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9607e-06 - accuracy: 1.00 - 0s 155us/sample - loss: 3.1722e-06 - accuracy: 1.0000 - val_loss: 5.6899 - val_accuracy: 0.6207\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8317e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 3.1170e-06 - accuracy: 1.0000 - val_loss: 5.6983 - val_accuracy: 0.6207\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3743e-06 - accuracy: 1.00 - 0s 151us/sample - loss: 3.0639e-06 - accuracy: 1.0000 - val_loss: 5.7061 - val_accuracy: 0.6207\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 7.7018e-07 - accuracy: 1.00 - 0s 155us/sample - loss: 3.0174e-06 - accuracy: 1.0000 - val_loss: 5.7137 - val_accuracy: 0.6207\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3767e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 2.9830e-06 - accuracy: 1.0000 - val_loss: 5.7214 - val_accuracy: 0.6207\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6318e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 2.9347e-06 - accuracy: 1.0000 - val_loss: 5.7287 - val_accuracy: 0.6207\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7850e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 2.8885e-06 - accuracy: 1.0000 - val_loss: 5.7359 - val_accuracy: 0.6207\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1750e-06 - accuracy: 1.00 - 0s 167us/sample - loss: 2.8456e-06 - accuracy: 1.0000 - val_loss: 5.7430 - val_accuracy: 0.6207\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6826e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 2.8059e-06 - accuracy: 1.0000 - val_loss: 5.7505 - val_accuracy: 0.6207\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7420e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 2.7609e-06 - accuracy: 1.0000 - val_loss: 5.7586 - val_accuracy: 0.6207\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0989e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 2.7200e-06 - accuracy: 1.0000 - val_loss: 5.7658 - val_accuracy: 0.6207\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2379e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 2.6826e-06 - accuracy: 1.0000 - val_loss: 5.7746 - val_accuracy: 0.6207\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7486e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 2.6533e-06 - accuracy: 1.0000 - val_loss: 5.7829 - val_accuracy: 0.6207\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9294e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 2.6083e-06 - accuracy: 1.0000 - val_loss: 5.7910 - val_accuracy: 0.6207\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9976e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 2.5793e-06 - accuracy: 1.0000 - val_loss: 5.7989 - val_accuracy: 0.6207\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.46 - 0s 3ms/sample - loss: 0.6577 - accuracy: 0.5948 - val_loss: 0.6386 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4984 - accuracy: 0.78 - 0s 163us/sample - loss: 0.6659 - accuracy: 0.6638 - val_loss: 0.6396 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6458 - accuracy: 0.65 - 0s 155us/sample - loss: 0.6394 - accuracy: 0.7069 - val_loss: 0.6308 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6174 - accuracy: 0.68 - 0s 172us/sample - loss: 0.6076 - accuracy: 0.6638 - val_loss: 0.6186 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6591 - accuracy: 0.59 - 0s 155us/sample - loss: 0.6007 - accuracy: 0.6638 - val_loss: 0.6183 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6781 - accuracy: 0.56 - 0s 163us/sample - loss: 0.5873 - accuracy: 0.6638 - val_loss: 0.5901 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6073 - accuracy: 0.68 - 0s 160us/sample - loss: 0.5643 - accuracy: 0.7328 - val_loss: 0.5830 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.68 - 0s 155us/sample - loss: 0.5398 - accuracy: 0.7414 - val_loss: 0.5737 - val_accuracy: 0.6897\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4391 - accuracy: 0.87 - 0s 155us/sample - loss: 0.5191 - accuracy: 0.7586 - val_loss: 0.6022 - val_accuracy: 0.6552\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5297 - accuracy: 0.75 - 0s 146us/sample - loss: 0.5162 - accuracy: 0.7414 - val_loss: 0.5923 - val_accuracy: 0.6897\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4576 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4587 - accuracy: 0.7845 - val_loss: 0.6257 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4717 - accuracy: 0.71 - 0s 163us/sample - loss: 0.4528 - accuracy: 0.7845 - val_loss: 0.6703 - val_accuracy: 0.6897\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4712 - accuracy: 0.75 - 0s 155us/sample - loss: 0.4189 - accuracy: 0.8017 - val_loss: 0.6887 - val_accuracy: 0.6207\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4496 - accuracy: 0.84 - 0s 163us/sample - loss: 0.3962 - accuracy: 0.8448 - val_loss: 0.7225 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4383 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3609 - accuracy: 0.8534 - val_loss: 0.6991 - val_accuracy: 0.7241\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2621 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3478 - accuracy: 0.8621 - val_loss: 0.7519 - val_accuracy: 0.6552\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2458 - accuracy: 0.93 - 0s 997us/sample - loss: 0.3104 - accuracy: 0.8966 - val_loss: 0.8037 - val_accuracy: 0.7931\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3118 - accuracy: 0.8621 - val_loss: 0.7373 - val_accuracy: 0.6552\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2655 - accuracy: 0.90 - 0s 147us/sample - loss: 0.2811 - accuracy: 0.8793 - val_loss: 0.7158 - val_accuracy: 0.6897\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2843 - accuracy: 0.8879 - val_loss: 0.7562 - val_accuracy: 0.7586\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2606 - accuracy: 0.9052 - val_loss: 0.8141 - val_accuracy: 0.6552\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1104 - accuracy: 0.96 - 0s 155us/sample - loss: 0.3367 - accuracy: 0.8448 - val_loss: 0.7070 - val_accuracy: 0.7241\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1888 - accuracy: 0.93 - 0s 163us/sample - loss: 0.3187 - accuracy: 0.8534 - val_loss: 0.6840 - val_accuracy: 0.7586\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2885 - accuracy: 0.87 - 0s 172us/sample - loss: 0.3038 - accuracy: 0.8707 - val_loss: 0.8426 - val_accuracy: 0.7241\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1813 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2835 - accuracy: 0.8707 - val_loss: 0.9666 - val_accuracy: 0.5862\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3901 - accuracy: 0.78 - 0s 164us/sample - loss: 0.3238 - accuracy: 0.8448 - val_loss: 0.7828 - val_accuracy: 0.7241\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2354 - accuracy: 0.9138 - val_loss: 0.7849 - val_accuracy: 0.7241\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2321 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2188 - accuracy: 0.9310 - val_loss: 0.9647 - val_accuracy: 0.6897\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1454 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1912 - accuracy: 0.9310 - val_loss: 0.9884 - val_accuracy: 0.7241\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2988 - accuracy: 0.90 - 0s 158us/sample - loss: 0.1651 - accuracy: 0.9569 - val_loss: 1.1088 - val_accuracy: 0.6552\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0908 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1476 - accuracy: 0.9569 - val_loss: 1.1624 - val_accuracy: 0.7241\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.96 - 0s 164us/sample - loss: 0.1378 - accuracy: 0.9483 - val_loss: 1.3540 - val_accuracy: 0.6552\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0606 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1188 - accuracy: 0.9569 - val_loss: 1.4494 - val_accuracy: 0.7241\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1335 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1362 - accuracy: 0.9569 - val_loss: 1.5465 - val_accuracy: 0.6552\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1246 - accuracy: 0.9569 - val_loss: 1.7013 - val_accuracy: 0.6897\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0992 - accuracy: 0.9741 - val_loss: 1.7279 - val_accuracy: 0.6207\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1716 - accuracy: 0.9397 - val_loss: 1.7581 - val_accuracy: 0.6552\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1101 - accuracy: 0.9569 - val_loss: 1.7750 - val_accuracy: 0.6897\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1351 - accuracy: 0.9310 - val_loss: 1.8812 - val_accuracy: 0.7241\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5711 - accuracy: 0.78 - 0s 138us/sample - loss: 0.2775 - accuracy: 0.8966 - val_loss: 1.8886 - val_accuracy: 0.5517\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1464 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2060 - accuracy: 0.9052 - val_loss: 1.1911 - val_accuracy: 0.6897\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1789 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1642 - accuracy: 0.9224 - val_loss: 1.9184 - val_accuracy: 0.6897\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1029 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1844 - accuracy: 0.9224 - val_loss: 1.1817 - val_accuracy: 0.7241\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1976 - accuracy: 0.9138 - val_loss: 1.0537 - val_accuracy: 0.7241\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1885 - accuracy: 0.8966 - val_loss: 1.0706 - val_accuracy: 0.7241\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0857 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2040 - accuracy: 0.8966 - val_loss: 1.1693 - val_accuracy: 0.7586\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1428 - accuracy: 0.9397 - val_loss: 1.5232 - val_accuracy: 0.6207\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1375 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1417 - accuracy: 0.9569 - val_loss: 1.3494 - val_accuracy: 0.7241\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1437 - accuracy: 0.9397 - val_loss: 1.3994 - val_accuracy: 0.7586\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0794 - accuracy: 0.9655 - val_loss: 1.7287 - val_accuracy: 0.5862\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0718 - accuracy: 0.9741 - val_loss: 1.5660 - val_accuracy: 0.7586\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1003 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0639 - accuracy: 0.9655 - val_loss: 1.6584 - val_accuracy: 0.6552\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0419 - accuracy: 0.9914 - val_loss: 1.9120 - val_accuracy: 0.7241\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0331 - accuracy: 0.9828 - val_loss: 2.1792 - val_accuracy: 0.7241\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0187 - accuracy: 1.0000 - val_loss: 2.4283 - val_accuracy: 0.5862\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.5760 - val_accuracy: 0.6207\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.6880 - val_accuracy: 0.5517\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.8904 - val_accuracy: 0.5862\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.2807 - val_accuracy: 0.5862\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.5043 - val_accuracy: 0.6552\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.6101 - val_accuracy: 0.6207\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.1780e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.6335 - val_accuracy: 0.5862\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4827e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.6293 - val_accuracy: 0.6897\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1862e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.6957 - val_accuracy: 0.5862\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2668e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.7980 - val_accuracy: 0.5862\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1613e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 8.7001e-04 - accuracy: 1.0000 - val_loss: 3.8674 - val_accuracy: 0.5862\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1587e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 6.8886e-04 - accuracy: 1.0000 - val_loss: 3.9431 - val_accuracy: 0.6897\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.5428e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.1415e-04 - accuracy: 1.0000 - val_loss: 3.9982 - val_accuracy: 0.6552\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0875e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.0932e-04 - accuracy: 1.0000 - val_loss: 4.0570 - val_accuracy: 0.5862\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3514e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.0310e-04 - accuracy: 1.0000 - val_loss: 4.1022 - val_accuracy: 0.5862\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1159e-04 - accuracy: 1.00 - 0s 151us/sample - loss: 4.8414e-04 - accuracy: 1.0000 - val_loss: 4.1249 - val_accuracy: 0.5862\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6522e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.1420e-04 - accuracy: 1.0000 - val_loss: 4.1473 - val_accuracy: 0.5862\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6337e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.9528e-04 - accuracy: 1.0000 - val_loss: 4.1738 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6329e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.6591e-04 - accuracy: 1.0000 - val_loss: 4.1933 - val_accuracy: 0.5862\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7541e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.5048e-04 - accuracy: 1.0000 - val_loss: 4.2119 - val_accuracy: 0.5862\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4549e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.3625e-04 - accuracy: 1.0000 - val_loss: 4.2261 - val_accuracy: 0.5862\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9878e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.2514e-04 - accuracy: 1.0000 - val_loss: 4.2397 - val_accuracy: 0.5862\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2068e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.1085e-04 - accuracy: 1.0000 - val_loss: 4.2617 - val_accuracy: 0.5862\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7634e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.0384e-04 - accuracy: 1.0000 - val_loss: 4.2793 - val_accuracy: 0.5862\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5944e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.9108e-04 - accuracy: 1.0000 - val_loss: 4.2911 - val_accuracy: 0.5862\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9781e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.7660e-04 - accuracy: 1.0000 - val_loss: 4.3028 - val_accuracy: 0.5862\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4703e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.6298e-04 - accuracy: 1.0000 - val_loss: 4.3203 - val_accuracy: 0.5862\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9944e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 2.5205e-04 - accuracy: 1.0000 - val_loss: 4.3399 - val_accuracy: 0.5862\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2720e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.5413e-04 - accuracy: 1.0000 - val_loss: 4.3580 - val_accuracy: 0.5862\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6584e-04 - accuracy: 1.00 - 0s 132us/sample - loss: 2.3972e-04 - accuracy: 1.0000 - val_loss: 4.3695 - val_accuracy: 0.5862\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1891e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.2952e-04 - accuracy: 1.0000 - val_loss: 4.3791 - val_accuracy: 0.5862\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9756e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.2507e-04 - accuracy: 1.0000 - val_loss: 4.3926 - val_accuracy: 0.5862\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3311e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.1996e-04 - accuracy: 1.0000 - val_loss: 4.4069 - val_accuracy: 0.5862\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0593e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.1004e-04 - accuracy: 1.0000 - val_loss: 4.4188 - val_accuracy: 0.5862\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2311e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.0909e-04 - accuracy: 1.0000 - val_loss: 4.4313 - val_accuracy: 0.5862\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4724e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.9797e-04 - accuracy: 1.0000 - val_loss: 4.4463 - val_accuracy: 0.5862\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7869e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 1.9159e-04 - accuracy: 1.0000 - val_loss: 4.4604 - val_accuracy: 0.5862\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1184e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.8770e-04 - accuracy: 1.0000 - val_loss: 4.4722 - val_accuracy: 0.5862\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8417e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.8104e-04 - accuracy: 1.0000 - val_loss: 4.4867 - val_accuracy: 0.5862\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8958e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7853e-04 - accuracy: 1.0000 - val_loss: 4.4944 - val_accuracy: 0.5862\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8164e-04 - accuracy: 1.00 - 0s 206us/sample - loss: 1.7024e-04 - accuracy: 1.0000 - val_loss: 4.5096 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4898e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.6712e-04 - accuracy: 1.0000 - val_loss: 4.5236 - val_accuracy: 0.5862\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6821e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6212e-04 - accuracy: 1.0000 - val_loss: 4.5340 - val_accuracy: 0.5862\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7704e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5925e-04 - accuracy: 1.0000 - val_loss: 4.5452 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3086e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.5284e-04 - accuracy: 1.0000 - val_loss: 4.5579 - val_accuracy: 0.5862\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0001e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4831e-04 - accuracy: 1.0000 - val_loss: 4.5709 - val_accuracy: 0.5862\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6263e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.4580e-04 - accuracy: 1.0000 - val_loss: 4.5815 - val_accuracy: 0.5862\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0214e-04 - accuracy: 1.00 - 0s 158us/sample - loss: 1.4066e-04 - accuracy: 1.0000 - val_loss: 4.5962 - val_accuracy: 0.5862\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3399e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3923e-04 - accuracy: 1.0000 - val_loss: 4.6094 - val_accuracy: 0.5862\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0233e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3547e-04 - accuracy: 1.0000 - val_loss: 4.6182 - val_accuracy: 0.5862\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4469e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3124e-04 - accuracy: 1.0000 - val_loss: 4.6276 - val_accuracy: 0.5862\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7936e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.2772e-04 - accuracy: 1.0000 - val_loss: 4.6377 - val_accuracy: 0.6207\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6388e-04 - accuracy: 1.00 - 0s 159us/sample - loss: 1.2566e-04 - accuracy: 1.0000 - val_loss: 4.6471 - val_accuracy: 0.6207\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0081e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2394e-04 - accuracy: 1.0000 - val_loss: 4.6584 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2723e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1980e-04 - accuracy: 1.0000 - val_loss: 4.6682 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2899e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.1927e-04 - accuracy: 1.0000 - val_loss: 4.6787 - val_accuracy: 0.5862\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6296e-05 - accuracy: 1.00 - 0s 151us/sample - loss: 1.1458e-04 - accuracy: 1.0000 - val_loss: 4.6849 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4374e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1183e-04 - accuracy: 1.0000 - val_loss: 4.6936 - val_accuracy: 0.6207\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1189e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1233e-04 - accuracy: 1.0000 - val_loss: 4.7009 - val_accuracy: 0.6207\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1220e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0724e-04 - accuracy: 1.0000 - val_loss: 4.7150 - val_accuracy: 0.6207\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4763e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0434e-04 - accuracy: 1.0000 - val_loss: 4.7298 - val_accuracy: 0.5862\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3804e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0344e-04 - accuracy: 1.0000 - val_loss: 4.7413 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9526e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0160e-04 - accuracy: 1.0000 - val_loss: 4.7501 - val_accuracy: 0.6207\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9181e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 9.9071e-05 - accuracy: 1.0000 - val_loss: 4.7561 - val_accuracy: 0.6207\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6248e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.7913e-05 - accuracy: 1.0000 - val_loss: 4.7613 - val_accuracy: 0.6207\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2265e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 9.5855e-05 - accuracy: 1.0000 - val_loss: 4.7694 - val_accuracy: 0.6207\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0368e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 9.4160e-05 - accuracy: 1.0000 - val_loss: 4.7803 - val_accuracy: 0.6207\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4586e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 9.1626e-05 - accuracy: 1.0000 - val_loss: 4.7900 - val_accuracy: 0.6207\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.1492e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 9.0839e-05 - accuracy: 1.0000 - val_loss: 4.7996 - val_accuracy: 0.6207\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2659e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.8780e-05 - accuracy: 1.0000 - val_loss: 4.8035 - val_accuracy: 0.6207\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3585e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.8003e-05 - accuracy: 1.0000 - val_loss: 4.8133 - val_accuracy: 0.6207\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4718e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.5123e-05 - accuracy: 1.0000 - val_loss: 4.8209 - val_accuracy: 0.6207\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0418e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 8.3495e-05 - accuracy: 1.0000 - val_loss: 4.8295 - val_accuracy: 0.6207\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1231e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 8.1803e-05 - accuracy: 1.0000 - val_loss: 4.8369 - val_accuracy: 0.6207\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1365e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.0786e-05 - accuracy: 1.0000 - val_loss: 4.8444 - val_accuracy: 0.6207\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2582e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.9353e-05 - accuracy: 1.0000 - val_loss: 4.8533 - val_accuracy: 0.6207\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3760e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.7251e-05 - accuracy: 1.0000 - val_loss: 4.8643 - val_accuracy: 0.6207\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2607e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 7.9298e-05 - accuracy: 1.0000 - val_loss: 4.8735 - val_accuracy: 0.6207\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8508e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.6462e-05 - accuracy: 1.0000 - val_loss: 4.8766 - val_accuracy: 0.6207\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1981e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.4002e-05 - accuracy: 1.0000 - val_loss: 4.8792 - val_accuracy: 0.6207\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5046e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.3190e-05 - accuracy: 1.0000 - val_loss: 4.8835 - val_accuracy: 0.6207\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.2749e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.2581e-05 - accuracy: 1.0000 - val_loss: 4.8902 - val_accuracy: 0.6207\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9402e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.0915e-05 - accuracy: 1.0000 - val_loss: 4.8981 - val_accuracy: 0.6207\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.2239e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 6.9156e-05 - accuracy: 1.0000 - val_loss: 4.9097 - val_accuracy: 0.6207\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0947e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 6.8349e-05 - accuracy: 1.0000 - val_loss: 4.9189 - val_accuracy: 0.6207\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3671e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.8489e-05 - accuracy: 1.0000 - val_loss: 4.9268 - val_accuracy: 0.6207\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0264e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.6330e-05 - accuracy: 1.0000 - val_loss: 4.9307 - val_accuracy: 0.6207\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5252e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.5434e-05 - accuracy: 1.0000 - val_loss: 4.9348 - val_accuracy: 0.6207\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6179e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.4418e-05 - accuracy: 1.0000 - val_loss: 4.9400 - val_accuracy: 0.6207\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6653e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.3954e-05 - accuracy: 1.0000 - val_loss: 4.9457 - val_accuracy: 0.6207\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4918e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 6.3224e-05 - accuracy: 1.0000 - val_loss: 4.9579 - val_accuracy: 0.6207\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.5550e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.1786e-05 - accuracy: 1.0000 - val_loss: 4.9671 - val_accuracy: 0.6207\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4103e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 6.0912e-05 - accuracy: 1.0000 - val_loss: 4.9740 - val_accuracy: 0.6207\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1310e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.9297e-05 - accuracy: 1.0000 - val_loss: 4.9787 - val_accuracy: 0.6207\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3923e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.9214e-05 - accuracy: 1.0000 - val_loss: 4.9817 - val_accuracy: 0.6207\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3650e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.7666e-05 - accuracy: 1.0000 - val_loss: 4.9872 - val_accuracy: 0.6207\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3550e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.7245e-05 - accuracy: 1.0000 - val_loss: 4.9919 - val_accuracy: 0.6207\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.5109e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.6077e-05 - accuracy: 1.0000 - val_loss: 4.9978 - val_accuracy: 0.6207\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3123e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.5090e-05 - accuracy: 1.0000 - val_loss: 5.0041 - val_accuracy: 0.6207\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1719e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.4033e-05 - accuracy: 1.0000 - val_loss: 5.0136 - val_accuracy: 0.6207\n",
      "Epoch 156/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 8.1543e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.3960e-05 - accuracy: 1.0000 - val_loss: 5.0223 - val_accuracy: 0.6207\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5209e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.3198e-05 - accuracy: 1.0000 - val_loss: 5.0280 - val_accuracy: 0.6207\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9057e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.2134e-05 - accuracy: 1.0000 - val_loss: 5.0340 - val_accuracy: 0.6207\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7283e-05 - accuracy: 1.00 - 0s 139us/sample - loss: 5.1309e-05 - accuracy: 1.0000 - val_loss: 5.0382 - val_accuracy: 0.6207\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5294e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.0864e-05 - accuracy: 1.0000 - val_loss: 5.0437 - val_accuracy: 0.6207\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7123e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.0182e-05 - accuracy: 1.0000 - val_loss: 5.0497 - val_accuracy: 0.6207\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3413e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.9479e-05 - accuracy: 1.0000 - val_loss: 5.0559 - val_accuracy: 0.6207\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8444e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.8525e-05 - accuracy: 1.0000 - val_loss: 5.0640 - val_accuracy: 0.6207\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9747e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.8213e-05 - accuracy: 1.0000 - val_loss: 5.0703 - val_accuracy: 0.6207\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.5085e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.7338e-05 - accuracy: 1.0000 - val_loss: 5.0740 - val_accuracy: 0.6207\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3009e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.6893e-05 - accuracy: 1.0000 - val_loss: 5.0765 - val_accuracy: 0.6207\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6903e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.6069e-05 - accuracy: 1.0000 - val_loss: 5.0837 - val_accuracy: 0.6207\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6131e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.6049e-05 - accuracy: 1.0000 - val_loss: 5.0909 - val_accuracy: 0.6207\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4999e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.4767e-05 - accuracy: 1.0000 - val_loss: 5.0954 - val_accuracy: 0.6207\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8029e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 4.4768e-05 - accuracy: 1.0000 - val_loss: 5.0992 - val_accuracy: 0.6207\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1897e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.4106e-05 - accuracy: 1.0000 - val_loss: 5.1056 - val_accuracy: 0.6207\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5339e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.3322e-05 - accuracy: 1.0000 - val_loss: 5.1119 - val_accuracy: 0.6207\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9814e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.2759e-05 - accuracy: 1.0000 - val_loss: 5.1185 - val_accuracy: 0.6207\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1927e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.2669e-05 - accuracy: 1.0000 - val_loss: 5.1283 - val_accuracy: 0.6207\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7669e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.1842e-05 - accuracy: 1.0000 - val_loss: 5.1335 - val_accuracy: 0.6207\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0759e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.1194e-05 - accuracy: 1.0000 - val_loss: 5.1371 - val_accuracy: 0.6207\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0925e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.0651e-05 - accuracy: 1.0000 - val_loss: 5.1421 - val_accuracy: 0.6207\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7383e-05 - accuracy: 1.00 - 0s 139us/sample - loss: 4.0139e-05 - accuracy: 1.0000 - val_loss: 5.1497 - val_accuracy: 0.6207\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7033e-05 - accuracy: 1.00 - 0s 181us/sample - loss: 3.9477e-05 - accuracy: 1.0000 - val_loss: 5.1545 - val_accuracy: 0.6207\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9999e-06 - accuracy: 1.00 - 0s 189us/sample - loss: 3.8862e-05 - accuracy: 1.0000 - val_loss: 5.1604 - val_accuracy: 0.6207\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6032e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 3.8504e-05 - accuracy: 1.0000 - val_loss: 5.1652 - val_accuracy: 0.6207\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3618e-05 - accuracy: 1.00 - 0s 142us/sample - loss: 3.8022e-05 - accuracy: 1.0000 - val_loss: 5.1695 - val_accuracy: 0.6207\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1097e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.7620e-05 - accuracy: 1.0000 - val_loss: 5.1741 - val_accuracy: 0.6207\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0188e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.7137e-05 - accuracy: 1.0000 - val_loss: 5.1786 - val_accuracy: 0.6207\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4261e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.6800e-05 - accuracy: 1.0000 - val_loss: 5.1850 - val_accuracy: 0.6207\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1283e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.6597e-05 - accuracy: 1.0000 - val_loss: 5.1900 - val_accuracy: 0.6207\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8013e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.6135e-05 - accuracy: 1.0000 - val_loss: 5.1975 - val_accuracy: 0.6207\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0291e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.5906e-05 - accuracy: 1.0000 - val_loss: 5.2042 - val_accuracy: 0.6207\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0553e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.5335e-05 - accuracy: 1.0000 - val_loss: 5.2075 - val_accuracy: 0.6207\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1187e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.4619e-05 - accuracy: 1.0000 - val_loss: 5.2116 - val_accuracy: 0.6207\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0160e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.4217e-05 - accuracy: 1.0000 - val_loss: 5.2156 - val_accuracy: 0.6207\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4130e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.4084e-05 - accuracy: 1.0000 - val_loss: 5.2199 - val_accuracy: 0.6207\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0805e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.3662e-05 - accuracy: 1.0000 - val_loss: 5.2265 - val_accuracy: 0.6207\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8589e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 3.3209e-05 - accuracy: 1.0000 - val_loss: 5.2307 - val_accuracy: 0.6207\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4320e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.2941e-05 - accuracy: 1.0000 - val_loss: 5.2345 - val_accuracy: 0.6207\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1669e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.2428e-05 - accuracy: 1.0000 - val_loss: 5.2401 - val_accuracy: 0.6207\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8990e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.2148e-05 - accuracy: 1.0000 - val_loss: 5.2451 - val_accuracy: 0.6207\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7395e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.1675e-05 - accuracy: 1.0000 - val_loss: 5.2515 - val_accuracy: 0.6207\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7762e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.1463e-05 - accuracy: 1.0000 - val_loss: 5.2575 - val_accuracy: 0.6207\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2618e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.1187e-05 - accuracy: 1.0000 - val_loss: 5.2626 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 54dc66a7b8cd993fa7e4f96d7b399349</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.732758641242981</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 60</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 24</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 24</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 115</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6847 - accuracy: 0.75 - 1s 5ms/sample - loss: 0.6799 - accuracy: 0.6638 - val_loss: 0.6401 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6204 - accuracy: 0.68 - 0s 340us/sample - loss: 0.6282 - accuracy: 0.6638 - val_loss: 0.6342 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5692 - accuracy: 0.71 - 0s 172us/sample - loss: 0.6090 - accuracy: 0.6638 - val_loss: 0.6254 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6281 - accuracy: 0.71 - 0s 1ms/sample - loss: 0.5859 - accuracy: 0.6897 - val_loss: 0.6181 - val_accuracy: 0.6897\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5942 - accuracy: 0.68 - 0s 250us/sample - loss: 0.5695 - accuracy: 0.7328 - val_loss: 0.6119 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4081 - accuracy: 0.81 - 0s 172us/sample - loss: 0.6040 - accuracy: 0.7155 - val_loss: 0.6022 - val_accuracy: 0.5862\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5203 - accuracy: 0.68 - 0s 172us/sample - loss: 0.5680 - accuracy: 0.7155 - val_loss: 0.6142 - val_accuracy: 0.5862\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5043 - accuracy: 0.78 - 0s 172us/sample - loss: 0.5233 - accuracy: 0.7586 - val_loss: 0.6096 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5916 - accuracy: 0.71 - 0s 181us/sample - loss: 0.5169 - accuracy: 0.7500 - val_loss: 0.5959 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4698 - accuracy: 0.78 - 0s 163us/sample - loss: 0.4968 - accuracy: 0.7672 - val_loss: 0.5885 - val_accuracy: 0.6897\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5600 - accuracy: 0.65 - 0s 1ms/sample - loss: 0.4517 - accuracy: 0.7931 - val_loss: 0.6055 - val_accuracy: 0.7241\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3184 - accuracy: 0.90 - 0s 146us/sample - loss: 0.4291 - accuracy: 0.8276 - val_loss: 0.6334 - val_accuracy: 0.7241\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4494 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4323 - accuracy: 0.8017 - val_loss: 0.7013 - val_accuracy: 0.6897\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4954 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4016 - accuracy: 0.8448 - val_loss: 0.6623 - val_accuracy: 0.7241\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4331 - accuracy: 0.81 - 0s 163us/sample - loss: 0.3816 - accuracy: 0.8707 - val_loss: 0.7470 - val_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3513 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3991 - accuracy: 0.8190 - val_loss: 0.7067 - val_accuracy: 0.5862\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2486 - accuracy: 0.93 - 0s 1ms/sample - loss: 0.4300 - accuracy: 0.8190 - val_loss: 0.6618 - val_accuracy: 0.7586\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3486 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4172 - accuracy: 0.7845 - val_loss: 0.6483 - val_accuracy: 0.7241\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3476 - accuracy: 0.8793 - val_loss: 0.7292 - val_accuracy: 0.6552\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3996 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3503 - accuracy: 0.8534 - val_loss: 0.7544 - val_accuracy: 0.6897\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3920 - accuracy: 0.84 - 0s 172us/sample - loss: 0.3046 - accuracy: 0.8793 - val_loss: 0.7573 - val_accuracy: 0.6552\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3006 - accuracy: 0.90 - 0s 1ms/sample - loss: 0.2694 - accuracy: 0.9052 - val_loss: 0.7700 - val_accuracy: 0.7931\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1451 - accuracy: 0.93 - 0s 181us/sample - loss: 0.2413 - accuracy: 0.9052 - val_loss: 1.0371 - val_accuracy: 0.6207\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3226 - accuracy: 0.81 - 0s 163us/sample - loss: 0.2583 - accuracy: 0.8879 - val_loss: 0.9913 - val_accuracy: 0.7241\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2062 - accuracy: 0.87 - 0s 224us/sample - loss: 0.3105 - accuracy: 0.8793 - val_loss: 0.8424 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2366 - accuracy: 0.9224 - val_loss: 0.7841 - val_accuracy: 0.7241\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0904 - accuracy: 0.96 - 0s 224us/sample - loss: 0.2527 - accuracy: 0.9138 - val_loss: 0.7906 - val_accuracy: 0.7241\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1949 - accuracy: 0.9483 - val_loss: 0.8831 - val_accuracy: 0.7241\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1686 - accuracy: 0.9655 - val_loss: 1.0056 - val_accuracy: 0.6897\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1426 - accuracy: 0.9741 - val_loss: 1.1029 - val_accuracy: 0.6897\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1208 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1176 - accuracy: 0.9741 - val_loss: 1.2090 - val_accuracy: 0.6897\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1343 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1103 - accuracy: 0.9741 - val_loss: 1.1031 - val_accuracy: 0.7241\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1104 - accuracy: 0.9655 - val_loss: 1.1579 - val_accuracy: 0.6897\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1063 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0878 - accuracy: 0.9655 - val_loss: 1.2902 - val_accuracy: 0.6897\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0859 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0783 - accuracy: 0.9741 - val_loss: 1.2120 - val_accuracy: 0.7241\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0581 - accuracy: 0.9828 - val_loss: 1.2829 - val_accuracy: 0.6897\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0607 - accuracy: 0.9914 - val_loss: 1.4883 - val_accuracy: 0.7241\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0936 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1058 - accuracy: 0.9483 - val_loss: 1.5477 - val_accuracy: 0.6897\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.90 - 0s 163us/sample - loss: 0.1909 - accuracy: 0.9138 - val_loss: 1.9052 - val_accuracy: 0.6897\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 1.00 - 0s 146us/sample - loss: 0.3326 - accuracy: 0.9397 - val_loss: 2.1260 - val_accuracy: 0.6552\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1866 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2727 - accuracy: 0.9138 - val_loss: 1.7893 - val_accuracy: 0.6897\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1864 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2565 - accuracy: 0.8879 - val_loss: 1.4700 - val_accuracy: 0.5862\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2016 - accuracy: 0.9052 - val_loss: 1.2536 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1698 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1981 - accuracy: 0.9138 - val_loss: 1.1963 - val_accuracy: 0.7241\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1448 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1783 - accuracy: 0.9052 - val_loss: 2.1229 - val_accuracy: 0.6552\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1834 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2312 - accuracy: 0.9224 - val_loss: 1.3312 - val_accuracy: 0.6897\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2004 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3928 - accuracy: 0.8793 - val_loss: 1.1963 - val_accuracy: 0.6552\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1629 - accuracy: 0.9397 - val_loss: 1.3171 - val_accuracy: 0.5862\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2202 - accuracy: 0.8879 - val_loss: 1.4622 - val_accuracy: 0.5862\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1607 - accuracy: 0.9310 - val_loss: 1.4088 - val_accuracy: 0.5862\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1047 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1382 - accuracy: 0.9483 - val_loss: 1.2578 - val_accuracy: 0.7241\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0799 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1144 - accuracy: 0.9483 - val_loss: 1.3962 - val_accuracy: 0.6552\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0936 - accuracy: 0.9483 - val_loss: 1.4530 - val_accuracy: 0.7586\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0532 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0843 - accuracy: 0.9741 - val_loss: 1.4644 - val_accuracy: 0.7241\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0578 - accuracy: 0.9914 - val_loss: 1.6195 - val_accuracy: 0.6552\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0932 - accuracy: 0.93 - 0s 163us/sample - loss: 0.0404 - accuracy: 0.9828 - val_loss: 1.7324 - val_accuracy: 0.6897\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0355 - accuracy: 0.9914 - val_loss: 1.7386 - val_accuracy: 0.7241\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0324 - accuracy: 1.0000 - val_loss: 1.8433 - val_accuracy: 0.6897\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.9200 - val_accuracy: 0.6897\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0109 - accuracy: 1.0000 - val_loss: 2.0465 - val_accuracy: 0.6897\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0071 - accuracy: 1.0000 - val_loss: 2.1881 - val_accuracy: 0.6897\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.2729 - val_accuracy: 0.6897\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.3255 - val_accuracy: 0.7241\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.4071 - val_accuracy: 0.6897\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.5815e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3864 - val_accuracy: 0.7241\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.3757 - val_accuracy: 0.7241\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.4504 - val_accuracy: 0.7241\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6265e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.5504 - val_accuracy: 0.6897\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.5628 - val_accuracy: 0.7241\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.5806 - val_accuracy: 0.7241\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7299e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.6241 - val_accuracy: 0.7241\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4254e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.0682e-04 - accuracy: 1.0000 - val_loss: 2.6738 - val_accuracy: 0.7241\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 146us/sample - loss: 7.9532e-04 - accuracy: 1.0000 - val_loss: 2.7106 - val_accuracy: 0.6897\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9456e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.3370e-04 - accuracy: 1.0000 - val_loss: 2.7372 - val_accuracy: 0.6897\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0759e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 6.4038e-04 - accuracy: 1.0000 - val_loss: 2.7569 - val_accuracy: 0.7241\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9320e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.0103e-04 - accuracy: 1.0000 - val_loss: 2.7798 - val_accuracy: 0.7241\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1393e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 5.5963e-04 - accuracy: 1.0000 - val_loss: 2.8101 - val_accuracy: 0.7241\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2610e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.0939e-04 - accuracy: 1.0000 - val_loss: 2.8438 - val_accuracy: 0.7241\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6398e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.6610e-04 - accuracy: 1.0000 - val_loss: 2.8744 - val_accuracy: 0.7241\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2117e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 4.2159e-04 - accuracy: 1.0000 - val_loss: 2.8981 - val_accuracy: 0.7241\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9978e-04 - accuracy: 1.00 - 0s 159us/sample - loss: 3.9009e-04 - accuracy: 1.0000 - val_loss: 2.9231 - val_accuracy: 0.7241\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7477e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.6118e-04 - accuracy: 1.0000 - val_loss: 2.9467 - val_accuracy: 0.7241\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4099e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.4185e-04 - accuracy: 1.0000 - val_loss: 2.9798 - val_accuracy: 0.7241\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2617e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.1401e-04 - accuracy: 1.0000 - val_loss: 3.0100 - val_accuracy: 0.7241\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8325e-04 - accuracy: 1.00 - 0s 147us/sample - loss: 2.9812e-04 - accuracy: 1.0000 - val_loss: 3.0335 - val_accuracy: 0.7241\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4160e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 2.7592e-04 - accuracy: 1.0000 - val_loss: 3.0481 - val_accuracy: 0.7241\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3197e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.6044e-04 - accuracy: 1.0000 - val_loss: 3.0692 - val_accuracy: 0.7241\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0782e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.4414e-04 - accuracy: 1.0000 - val_loss: 3.0954 - val_accuracy: 0.7241\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9513e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 2.2742e-04 - accuracy: 1.0000 - val_loss: 3.1250 - val_accuracy: 0.6897\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2639e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 2.1538e-04 - accuracy: 1.0000 - val_loss: 3.1500 - val_accuracy: 0.7241\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1811e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 2.0415e-04 - accuracy: 1.0000 - val_loss: 3.1741 - val_accuracy: 0.7241\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9619e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.9739e-04 - accuracy: 1.0000 - val_loss: 3.1932 - val_accuracy: 0.6897\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8260e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.8519e-04 - accuracy: 1.0000 - val_loss: 3.2157 - val_accuracy: 0.7241\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7458e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7542e-04 - accuracy: 1.0000 - val_loss: 3.2409 - val_accuracy: 0.7241\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8458e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.6613e-04 - accuracy: 1.0000 - val_loss: 3.2645 - val_accuracy: 0.6897\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5063e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5817e-04 - accuracy: 1.0000 - val_loss: 3.2833 - val_accuracy: 0.6897\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6750e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.5212e-04 - accuracy: 1.0000 - val_loss: 3.2997 - val_accuracy: 0.6897\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8936e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4611e-04 - accuracy: 1.0000 - val_loss: 3.3181 - val_accuracy: 0.6897\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4165e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3911e-04 - accuracy: 1.0000 - val_loss: 3.3352 - val_accuracy: 0.6897\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9876e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3434e-04 - accuracy: 1.0000 - val_loss: 3.3549 - val_accuracy: 0.6897\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7759e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.2734e-04 - accuracy: 1.0000 - val_loss: 3.3742 - val_accuracy: 0.6897\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3623e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2261e-04 - accuracy: 1.0000 - val_loss: 3.3927 - val_accuracy: 0.6897\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6421e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.1953e-04 - accuracy: 1.0000 - val_loss: 3.4097 - val_accuracy: 0.7241\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0920e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1365e-04 - accuracy: 1.0000 - val_loss: 3.4254 - val_accuracy: 0.6897\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6442e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0802e-04 - accuracy: 1.0000 - val_loss: 3.4419 - val_accuracy: 0.6897\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2236e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.0744e-04 - accuracy: 1.0000 - val_loss: 3.4612 - val_accuracy: 0.6897\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9968e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0067e-04 - accuracy: 1.0000 - val_loss: 3.4788 - val_accuracy: 0.6897\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6668e-05 - accuracy: 1.00 - 0s 165us/sample - loss: 9.6733e-05 - accuracy: 1.0000 - val_loss: 3.4961 - val_accuracy: 0.6897\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6252e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.3717e-05 - accuracy: 1.0000 - val_loss: 3.5129 - val_accuracy: 0.6897\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5614e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 9.1014e-05 - accuracy: 1.0000 - val_loss: 3.5299 - val_accuracy: 0.6897\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.6090e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.7854e-05 - accuracy: 1.0000 - val_loss: 3.5456 - val_accuracy: 0.6897\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5130e-05 - accuracy: 1.00 - 0s 159us/sample - loss: 8.4827e-05 - accuracy: 1.0000 - val_loss: 3.5609 - val_accuracy: 0.6897\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1687e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.3489e-05 - accuracy: 1.0000 - val_loss: 3.5761 - val_accuracy: 0.6897\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3702e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.1068e-05 - accuracy: 1.0000 - val_loss: 3.5904 - val_accuracy: 0.6897\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7256e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.6231e-05 - accuracy: 1.0000 - val_loss: 3.6065 - val_accuracy: 0.6897\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8317e-05 - accuracy: 1.00 - 0s 142us/sample - loss: 7.4211e-05 - accuracy: 1.0000 - val_loss: 3.6194 - val_accuracy: 0.6897\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1203e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.1197e-05 - accuracy: 1.0000 - val_loss: 3.6344 - val_accuracy: 0.6897\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2696e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 6.9063e-05 - accuracy: 1.0000 - val_loss: 3.6491 - val_accuracy: 0.6897\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5362e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.7788e-05 - accuracy: 1.0000 - val_loss: 3.6655 - val_accuracy: 0.6897\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1565e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.4278e-05 - accuracy: 1.0000 - val_loss: 3.6823 - val_accuracy: 0.6897\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3008e-05 - accuracy: 1.00 - 0s 168us/sample - loss: 6.4612e-05 - accuracy: 1.0000 - val_loss: 3.6994 - val_accuracy: 0.6897\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5866e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.1663e-05 - accuracy: 1.0000 - val_loss: 3.7120 - val_accuracy: 0.6897\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5373e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.9123e-05 - accuracy: 1.0000 - val_loss: 3.7234 - val_accuracy: 0.6897\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0911e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.7253e-05 - accuracy: 1.0000 - val_loss: 3.7372 - val_accuracy: 0.6897\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9034e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.6288e-05 - accuracy: 1.0000 - val_loss: 3.7499 - val_accuracy: 0.6897\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3134e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.4180e-05 - accuracy: 1.0000 - val_loss: 3.7625 - val_accuracy: 0.6897\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 2.0993e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.2780e-05 - accuracy: 1.0000 - val_loss: 3.7739 - val_accuracy: 0.6897\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2903e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.1598e-05 - accuracy: 1.0000 - val_loss: 3.7858 - val_accuracy: 0.6897\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6345e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.0370e-05 - accuracy: 1.0000 - val_loss: 3.7974 - val_accuracy: 0.6897\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.8608e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 4.8466e-05 - accuracy: 1.0000 - val_loss: 3.8104 - val_accuracy: 0.6897\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0078e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.7416e-05 - accuracy: 1.0000 - val_loss: 3.8206 - val_accuracy: 0.6897\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2207e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.5671e-05 - accuracy: 1.0000 - val_loss: 3.8330 - val_accuracy: 0.6897\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3206e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.4974e-05 - accuracy: 1.0000 - val_loss: 3.8418 - val_accuracy: 0.6897\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6615e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.3595e-05 - accuracy: 1.0000 - val_loss: 3.8542 - val_accuracy: 0.6897\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0842e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.2588e-05 - accuracy: 1.0000 - val_loss: 3.8663 - val_accuracy: 0.6897\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0542e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.1771e-05 - accuracy: 1.0000 - val_loss: 3.8773 - val_accuracy: 0.6897\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9313e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.0797e-05 - accuracy: 1.0000 - val_loss: 3.8888 - val_accuracy: 0.6897\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6725e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.9702e-05 - accuracy: 1.0000 - val_loss: 3.8964 - val_accuracy: 0.6897\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3459e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.8551e-05 - accuracy: 1.0000 - val_loss: 3.9057 - val_accuracy: 0.6897\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9592e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 3.7605e-05 - accuracy: 1.0000 - val_loss: 3.9171 - val_accuracy: 0.6897\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3239e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.6854e-05 - accuracy: 1.0000 - val_loss: 3.9272 - val_accuracy: 0.6897\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1093e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.6444e-05 - accuracy: 1.0000 - val_loss: 3.9388 - val_accuracy: 0.6897\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3364e-05 - accuracy: 1.00 - 0s 137us/sample - loss: 3.5483e-05 - accuracy: 1.0000 - val_loss: 3.9492 - val_accuracy: 0.6897\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9761e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.4426e-05 - accuracy: 1.0000 - val_loss: 3.9577 - val_accuracy: 0.6897\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8850e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.3737e-05 - accuracy: 1.0000 - val_loss: 3.9678 - val_accuracy: 0.6897\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4759e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 3.2873e-05 - accuracy: 1.0000 - val_loss: 3.9777 - val_accuracy: 0.6897\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5422e-05 - accuracy: 1.00 - 0s 189us/sample - loss: 3.2230e-05 - accuracy: 1.0000 - val_loss: 3.9882 - val_accuracy: 0.6897\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6729e-05 - accuracy: 1.00 - 0s 181us/sample - loss: 3.1441e-05 - accuracy: 1.0000 - val_loss: 3.9979 - val_accuracy: 0.6897\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8911e-05 - accuracy: 1.00 - 0s 137us/sample - loss: 3.0837e-05 - accuracy: 1.0000 - val_loss: 4.0070 - val_accuracy: 0.6897\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6530e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.9998e-05 - accuracy: 1.0000 - val_loss: 4.0170 - val_accuracy: 0.6897\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1257e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.9406e-05 - accuracy: 1.0000 - val_loss: 4.0279 - val_accuracy: 0.6897\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7970e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 2.8833e-05 - accuracy: 1.0000 - val_loss: 4.0379 - val_accuracy: 0.6897\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4572e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 2.8189e-05 - accuracy: 1.0000 - val_loss: 4.0455 - val_accuracy: 0.6897\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2382e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.7326e-05 - accuracy: 1.0000 - val_loss: 4.0546 - val_accuracy: 0.6897\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1583e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 2.6944e-05 - accuracy: 1.0000 - val_loss: 4.0660 - val_accuracy: 0.6897\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0163e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 2.6301e-05 - accuracy: 1.0000 - val_loss: 4.0767 - val_accuracy: 0.6897\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7896e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 2.5840e-05 - accuracy: 1.0000 - val_loss: 4.0856 - val_accuracy: 0.6897\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6254e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 2.5349e-05 - accuracy: 1.0000 - val_loss: 4.0964 - val_accuracy: 0.6897\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1035e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 2.4627e-05 - accuracy: 1.0000 - val_loss: 4.1064 - val_accuracy: 0.6897\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1091e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.4031e-05 - accuracy: 1.0000 - val_loss: 4.1130 - val_accuracy: 0.6897\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9998e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.3518e-05 - accuracy: 1.0000 - val_loss: 4.1210 - val_accuracy: 0.6897\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.4400e-06 - accuracy: 1.00 - 0s 151us/sample - loss: 2.2899e-05 - accuracy: 1.0000 - val_loss: 4.1292 - val_accuracy: 0.6897\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3019e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.2546e-05 - accuracy: 1.0000 - val_loss: 4.1361 - val_accuracy: 0.6897\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0990e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 2.2105e-05 - accuracy: 1.0000 - val_loss: 4.1450 - val_accuracy: 0.6897\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1595e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.1661e-05 - accuracy: 1.0000 - val_loss: 4.1532 - val_accuracy: 0.6897\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0371e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.1163e-05 - accuracy: 1.0000 - val_loss: 4.1611 - val_accuracy: 0.6897\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4564e-06 - accuracy: 1.00 - 0s 151us/sample - loss: 2.0715e-05 - accuracy: 1.0000 - val_loss: 4.1688 - val_accuracy: 0.6897\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5320e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.0373e-05 - accuracy: 1.0000 - val_loss: 4.1777 - val_accuracy: 0.6897\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0252e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.0019e-05 - accuracy: 1.0000 - val_loss: 4.1860 - val_accuracy: 0.6897\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7565e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 1.9856e-05 - accuracy: 1.0000 - val_loss: 4.1934 - val_accuracy: 0.6897\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3487e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 1.9342e-05 - accuracy: 1.0000 - val_loss: 4.2002 - val_accuracy: 0.6897\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5501e-05 - accuracy: 1.00 - 0s 181us/sample - loss: 1.8955e-05 - accuracy: 1.0000 - val_loss: 4.2076 - val_accuracy: 0.6897\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0015e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.8627e-05 - accuracy: 1.0000 - val_loss: 4.2157 - val_accuracy: 0.6897\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4960e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.8299e-05 - accuracy: 1.0000 - val_loss: 4.2226 - val_accuracy: 0.6897\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8915e-06 - accuracy: 1.00 - 0s 158us/sample - loss: 1.7994e-05 - accuracy: 1.0000 - val_loss: 4.2298 - val_accuracy: 0.6897\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1746e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.7681e-05 - accuracy: 1.0000 - val_loss: 4.2374 - val_accuracy: 0.6897\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6173e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7375e-05 - accuracy: 1.0000 - val_loss: 4.2434 - val_accuracy: 0.6897\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2046e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.7115e-05 - accuracy: 1.0000 - val_loss: 4.2506 - val_accuracy: 0.6897\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9522e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.6747e-05 - accuracy: 1.0000 - val_loss: 4.2583 - val_accuracy: 0.6897\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7276e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.6434e-05 - accuracy: 1.0000 - val_loss: 4.2654 - val_accuracy: 0.6897\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1395e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.6191e-05 - accuracy: 1.0000 - val_loss: 4.2725 - val_accuracy: 0.6897\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.8453e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5929e-05 - accuracy: 1.0000 - val_loss: 4.2792 - val_accuracy: 0.6897\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5079e-06 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5678e-05 - accuracy: 1.0000 - val_loss: 4.2846 - val_accuracy: 0.6897\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9286e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5586e-05 - accuracy: 1.0000 - val_loss: 4.2916 - val_accuracy: 0.6897\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3855e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5163e-05 - accuracy: 1.0000 - val_loss: 4.2974 - val_accuracy: 0.6897\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1488e-06 - accuracy: 1.00 - 0s 172us/sample - loss: 1.4891e-05 - accuracy: 1.0000 - val_loss: 4.3042 - val_accuracy: 0.6897\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3021e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.4673e-05 - accuracy: 1.0000 - val_loss: 4.3121 - val_accuracy: 0.6897\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0286e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.4410e-05 - accuracy: 1.0000 - val_loss: 4.3184 - val_accuracy: 0.6897\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1226e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4214e-05 - accuracy: 1.0000 - val_loss: 4.3239 - val_accuracy: 0.6897\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6690e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4011e-05 - accuracy: 1.0000 - val_loss: 4.3308 - val_accuracy: 0.6897\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1864e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.3776e-05 - accuracy: 1.0000 - val_loss: 4.3377 - val_accuracy: 0.6897\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3376e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.3547e-05 - accuracy: 1.0000 - val_loss: 4.3449 - val_accuracy: 0.6897\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1484e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3343e-05 - accuracy: 1.0000 - val_loss: 4.3515 - val_accuracy: 0.6897\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0364e-05 - accuracy: 1.00 - 0s 133us/sample - loss: 1.3146e-05 - accuracy: 1.0000 - val_loss: 4.3567 - val_accuracy: 0.6897\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0251e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2950e-05 - accuracy: 1.0000 - val_loss: 4.3624 - val_accuracy: 0.6897\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0213e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 1.2792e-05 - accuracy: 1.0000 - val_loss: 4.3678 - val_accuracy: 0.6897\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2200e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2596e-05 - accuracy: 1.0000 - val_loss: 4.3732 - val_accuracy: 0.6897\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6725e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.2442e-05 - accuracy: 1.0000 - val_loss: 4.3799 - val_accuracy: 0.6897\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3782e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.2335e-05 - accuracy: 1.0000 - val_loss: 4.3862 - val_accuracy: 0.6897\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2653e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2030e-05 - accuracy: 1.0000 - val_loss: 4.3922 - val_accuracy: 0.6897\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6940 - accuracy: 0.43 - 0s 4ms/sample - loss: 0.6522 - accuracy: 0.6293 - val_loss: 0.6609 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6863 - accuracy: 0.62 - 0s 164us/sample - loss: 0.6462 - accuracy: 0.6638 - val_loss: 0.6382 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5623 - accuracy: 0.84 - 0s 172us/sample - loss: 0.6257 - accuracy: 0.6810 - val_loss: 0.6251 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6586 - accuracy: 0.59 - 0s 180us/sample - loss: 0.5921 - accuracy: 0.7069 - val_loss: 0.6119 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6337 - accuracy: 0.65 - 0s 163us/sample - loss: 0.5617 - accuracy: 0.7500 - val_loss: 0.6182 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6322 - accuracy: 0.65 - 0s 163us/sample - loss: 0.5461 - accuracy: 0.7155 - val_loss: 0.6042 - val_accuracy: 0.5862\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.84 - 0s 155us/sample - loss: 0.5417 - accuracy: 0.7500 - val_loss: 0.6212 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3710 - accuracy: 0.84 - 0s 163us/sample - loss: 0.5138 - accuracy: 0.7500 - val_loss: 0.6239 - val_accuracy: 0.5862\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.5363 - accuracy: 0.68 - 0s 155us/sample - loss: 0.5134 - accuracy: 0.7414 - val_loss: 0.5717 - val_accuracy: 0.6552\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5002 - accuracy: 0.75 - 0s 172us/sample - loss: 0.4598 - accuracy: 0.7672 - val_loss: 0.5773 - val_accuracy: 0.7586\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3926 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4408 - accuracy: 0.7931 - val_loss: 0.5994 - val_accuracy: 0.7241\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5194 - accuracy: 0.75 - 0s 172us/sample - loss: 0.4433 - accuracy: 0.7759 - val_loss: 0.6371 - val_accuracy: 0.7241\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4400 - accuracy: 0.78 - 0s 137us/sample - loss: 0.4984 - accuracy: 0.7672 - val_loss: 0.6466 - val_accuracy: 0.7241\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4727 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4163 - accuracy: 0.8362 - val_loss: 0.6737 - val_accuracy: 0.5862\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.81 - 0s 138us/sample - loss: 0.3744 - accuracy: 0.8707 - val_loss: 0.6356 - val_accuracy: 0.7241\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2518 - accuracy: 0.93 - 0s 138us/sample - loss: 0.3348 - accuracy: 0.8707 - val_loss: 0.8084 - val_accuracy: 0.5862\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4083 - accuracy: 0.81 - 0s 155us/sample - loss: 0.3291 - accuracy: 0.8707 - val_loss: 0.7391 - val_accuracy: 0.7241\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2876 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2717 - accuracy: 0.9052 - val_loss: 0.7584 - val_accuracy: 0.7241\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2473 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2275 - accuracy: 0.9310 - val_loss: 0.7404 - val_accuracy: 0.7586\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2088 - accuracy: 0.96 - 0s 163us/sample - loss: 0.2322 - accuracy: 0.9310 - val_loss: 0.8431 - val_accuracy: 0.6552\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1209 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2377 - accuracy: 0.9138 - val_loss: 0.7667 - val_accuracy: 0.7586\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1167 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1948 - accuracy: 0.9397 - val_loss: 0.6691 - val_accuracy: 0.7586\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1230 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1916 - accuracy: 0.9483 - val_loss: 1.4971 - val_accuracy: 0.5172\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2546 - accuracy: 0.90 - 0s 129us/sample - loss: 0.1855 - accuracy: 0.9397 - val_loss: 0.9130 - val_accuracy: 0.7241\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1576 - accuracy: 0.9569 - val_loss: 1.0246 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1598 - accuracy: 0.9483 - val_loss: 1.5574 - val_accuracy: 0.5172\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.93 - 0s 141us/sample - loss: 0.1638 - accuracy: 0.9310 - val_loss: 1.1762 - val_accuracy: 0.6897\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1307 - accuracy: 0.9569 - val_loss: 2.0004 - val_accuracy: 0.5862\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1379 - accuracy: 0.9569 - val_loss: 1.4311 - val_accuracy: 0.7241\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1744 - accuracy: 0.9224 - val_loss: 1.9216 - val_accuracy: 0.5862\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0429 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1378 - accuracy: 0.9483 - val_loss: 1.5619 - val_accuracy: 0.6552\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1365 - accuracy: 0.9483 - val_loss: 1.6520 - val_accuracy: 0.6552\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1124 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1560 - accuracy: 0.9310 - val_loss: 2.7672 - val_accuracy: 0.5517\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3269 - accuracy: 0.78 - 0s 181us/sample - loss: 0.2238 - accuracy: 0.8879 - val_loss: 1.7637 - val_accuracy: 0.6552\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3854 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2982 - accuracy: 0.8793 - val_loss: 2.2219 - val_accuracy: 0.6897\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 1.00 - 0s 138us/sample - loss: 0.2723 - accuracy: 0.9052 - val_loss: 2.5503 - val_accuracy: 0.7241\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1583 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2119 - accuracy: 0.9052 - val_loss: 2.4257 - val_accuracy: 0.6552\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1557 - accuracy: 0.9483 - val_loss: 2.6664 - val_accuracy: 0.5862\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0944 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1290 - accuracy: 0.9655 - val_loss: 2.6329 - val_accuracy: 0.6207\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1231 - accuracy: 0.9655 - val_loss: 2.7733 - val_accuracy: 0.5862\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.93 - 0s 142us/sample - loss: 0.1225 - accuracy: 0.9569 - val_loss: 2.4488 - val_accuracy: 0.6897\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0804 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1042 - accuracy: 0.9655 - val_loss: 2.6484 - val_accuracy: 0.6207\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1533 - accuracy: 0.93 - 0s 163us/sample - loss: 0.0852 - accuracy: 0.9741 - val_loss: 2.5020 - val_accuracy: 0.6207\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0776 - accuracy: 0.9655 - val_loss: 2.9392 - val_accuracy: 0.5517\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.96 - 0s 162us/sample - loss: 0.0696 - accuracy: 0.9741 - val_loss: 2.9814 - val_accuracy: 0.6207\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0604 - accuracy: 0.9741 - val_loss: 3.0268 - val_accuracy: 0.6552\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1352 - accuracy: 0.90 - 0s 146us/sample - loss: 0.0678 - accuracy: 0.9655 - val_loss: 2.8411 - val_accuracy: 0.6552\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0861 - accuracy: 0.9655 - val_loss: 3.5543 - val_accuracy: 0.6207\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1608 - accuracy: 0.9397 - val_loss: 2.1858 - val_accuracy: 0.6552\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6072 - accuracy: 0.78 - 0s 151us/sample - loss: 0.3430 - accuracy: 0.8707 - val_loss: 3.7742 - val_accuracy: 0.5517\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5768 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3333 - accuracy: 0.8793 - val_loss: 2.9203 - val_accuracy: 0.6897\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3589 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2294 - accuracy: 0.9138 - val_loss: 3.1223 - val_accuracy: 0.5517\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1236 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1788 - accuracy: 0.9483 - val_loss: 2.8355 - val_accuracy: 0.5517\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1217 - accuracy: 0.9655 - val_loss: 2.5825 - val_accuracy: 0.6552\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0957 - accuracy: 0.9655 - val_loss: 2.4403 - val_accuracy: 0.6207\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0680 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0961 - accuracy: 0.9655 - val_loss: 1.8809 - val_accuracy: 0.6897\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1054 - accuracy: 0.9569 - val_loss: 2.3041 - val_accuracy: 0.6207\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0688 - accuracy: 0.96 - 0s 172us/sample - loss: 0.0961 - accuracy: 0.9569 - val_loss: 1.9528 - val_accuracy: 0.6897\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1127 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1324 - accuracy: 0.9397 - val_loss: 2.1223 - val_accuracy: 0.6552\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0952 - accuracy: 0.9483 - val_loss: 3.4992 - val_accuracy: 0.4483\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1532 - accuracy: 0.90 - 0s 138us/sample - loss: 0.0756 - accuracy: 0.9569 - val_loss: 1.9158 - val_accuracy: 0.7241\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2481 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1745 - accuracy: 0.9224 - val_loss: 2.2148 - val_accuracy: 0.6207\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0823 - accuracy: 0.9655 - val_loss: 3.3530 - val_accuracy: 0.4828\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0569 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0681 - accuracy: 0.9741 - val_loss: 3.3325 - val_accuracy: 0.5517\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0523 - accuracy: 0.9741 - val_loss: 3.0551 - val_accuracy: 0.5862\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0637 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0518 - accuracy: 0.9741 - val_loss: 3.0568 - val_accuracy: 0.5862\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0367 - accuracy: 0.9741 - val_loss: 3.2728 - val_accuracy: 0.5517\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0360 - accuracy: 0.9741 - val_loss: 3.3036 - val_accuracy: 0.5862\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0296 - accuracy: 0.9741 - val_loss: 3.1770 - val_accuracy: 0.5862\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0269 - accuracy: 0.9741 - val_loss: 3.1621 - val_accuracy: 0.5862\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0218 - accuracy: 0.9914 - val_loss: 3.2083 - val_accuracy: 0.5862\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0182 - accuracy: 1.0000 - val_loss: 3.2773 - val_accuracy: 0.5862\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0161 - accuracy: 1.0000 - val_loss: 3.3711 - val_accuracy: 0.5862\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3819e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0132 - accuracy: 1.0000 - val_loss: 3.5151 - val_accuracy: 0.5862\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0116 - accuracy: 1.0000 - val_loss: 3.5759 - val_accuracy: 0.5862\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 3.5440 - val_accuracy: 0.5862\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 3.4976 - val_accuracy: 0.5862\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.4815 - val_accuracy: 0.5862\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.5286 - val_accuracy: 0.5862\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.6280 - val_accuracy: 0.5862\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.6781 - val_accuracy: 0.5862\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.6981 - val_accuracy: 0.5862\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.7032 - val_accuracy: 0.5862\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.6906 - val_accuracy: 0.5862\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4237e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.7088 - val_accuracy: 0.5862\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3002e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.7563 - val_accuracy: 0.5862\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.8180 - val_accuracy: 0.5862\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.8333 - val_accuracy: 0.5862\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8943e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.8536 - val_accuracy: 0.5862\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.8740 - val_accuracy: 0.5862\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3370e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 9.1955e-04 - accuracy: 1.0000 - val_loss: 3.8916 - val_accuracy: 0.5862\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8735e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 8.1192e-04 - accuracy: 1.0000 - val_loss: 3.9232 - val_accuracy: 0.5862\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0226e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.4532e-04 - accuracy: 1.0000 - val_loss: 3.9454 - val_accuracy: 0.5862\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3902e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.0095e-04 - accuracy: 1.0000 - val_loss: 3.9639 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7418e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 6.3966e-04 - accuracy: 1.0000 - val_loss: 3.9900 - val_accuracy: 0.5862\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7119e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.9445e-04 - accuracy: 1.0000 - val_loss: 4.0101 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6472e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 5.5145e-04 - accuracy: 1.0000 - val_loss: 4.0283 - val_accuracy: 0.5862\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8650e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.2002e-04 - accuracy: 1.0000 - val_loss: 4.0449 - val_accuracy: 0.5862\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2854e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.9520e-04 - accuracy: 1.0000 - val_loss: 4.0676 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1433e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 4.6248e-04 - accuracy: 1.0000 - val_loss: 4.0798 - val_accuracy: 0.5862\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1631e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.2956e-04 - accuracy: 1.0000 - val_loss: 4.0995 - val_accuracy: 0.5862\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6789e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.0746e-04 - accuracy: 1.0000 - val_loss: 4.1126 - val_accuracy: 0.5862\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4726e-04 - accuracy: 1.00 - 0s 189us/sample - loss: 3.9202e-04 - accuracy: 1.0000 - val_loss: 4.1259 - val_accuracy: 0.5862\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9351e-04 - accuracy: 1.00 - 0s 181us/sample - loss: 3.6868e-04 - accuracy: 1.0000 - val_loss: 4.1445 - val_accuracy: 0.5862\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7414e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.5471e-04 - accuracy: 1.0000 - val_loss: 4.1553 - val_accuracy: 0.5862\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7092e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.4079e-04 - accuracy: 1.0000 - val_loss: 4.1830 - val_accuracy: 0.5862\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8099e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.2227e-04 - accuracy: 1.0000 - val_loss: 4.2000 - val_accuracy: 0.5862\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4855e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.1022e-04 - accuracy: 1.0000 - val_loss: 4.2143 - val_accuracy: 0.5862\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7390e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.9692e-04 - accuracy: 1.0000 - val_loss: 4.2300 - val_accuracy: 0.5862\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4975e-04 - accuracy: 1.00 - 0s 133us/sample - loss: 2.8574e-04 - accuracy: 1.0000 - val_loss: 4.2452 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4799e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 2.7623e-04 - accuracy: 1.0000 - val_loss: 4.2560 - val_accuracy: 0.5862\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4902e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.6387e-04 - accuracy: 1.0000 - val_loss: 4.2736 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2395e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.5595e-04 - accuracy: 1.0000 - val_loss: 4.2840 - val_accuracy: 0.5862\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2789e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.4409e-04 - accuracy: 1.0000 - val_loss: 4.3030 - val_accuracy: 0.5862\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3088e-04 - accuracy: 1.00 - 0s 148us/sample - loss: 2.3730e-04 - accuracy: 1.0000 - val_loss: 4.3163 - val_accuracy: 0.5862\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6449e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 2.2767e-04 - accuracy: 1.0000 - val_loss: 4.3303 - val_accuracy: 0.5862\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6443e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.2137e-04 - accuracy: 1.0000 - val_loss: 4.3434 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2129e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.1335e-04 - accuracy: 1.0000 - val_loss: 4.3602 - val_accuracy: 0.5862\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1503e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.0797e-04 - accuracy: 1.0000 - val_loss: 4.3732 - val_accuracy: 0.5862\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6166e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.0107e-04 - accuracy: 1.0000 - val_loss: 4.3771 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8896e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.9462e-04 - accuracy: 1.0000 - val_loss: 4.3817 - val_accuracy: 0.5862\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7432e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.8865e-04 - accuracy: 1.0000 - val_loss: 4.3984 - val_accuracy: 0.5862\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5179e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.8158e-04 - accuracy: 1.0000 - val_loss: 4.4100 - val_accuracy: 0.5862\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4414e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.7586e-04 - accuracy: 1.0000 - val_loss: 4.4201 - val_accuracy: 0.5862\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6726e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7147e-04 - accuracy: 1.0000 - val_loss: 4.4282 - val_accuracy: 0.5862\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7737e-05 - accuracy: 1.00 - 0s 198us/sample - loss: 1.6599e-04 - accuracy: 1.0000 - val_loss: 4.4327 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1975e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.6148e-04 - accuracy: 1.0000 - val_loss: 4.4408 - val_accuracy: 0.5862\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4623e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5758e-04 - accuracy: 1.0000 - val_loss: 4.4538 - val_accuracy: 0.5862\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5179e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.5178e-04 - accuracy: 1.0000 - val_loss: 4.4663 - val_accuracy: 0.5862\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2779e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.4895e-04 - accuracy: 1.0000 - val_loss: 4.4797 - val_accuracy: 0.5862\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4638e-05 - accuracy: 1.00 - 0s 137us/sample - loss: 1.4412e-04 - accuracy: 1.0000 - val_loss: 4.4927 - val_accuracy: 0.5862\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2916e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4021e-04 - accuracy: 1.0000 - val_loss: 4.5006 - val_accuracy: 0.5862\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2594e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3680e-04 - accuracy: 1.0000 - val_loss: 4.5075 - val_accuracy: 0.5862\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0596e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3315e-04 - accuracy: 1.0000 - val_loss: 4.5196 - val_accuracy: 0.5862\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5118e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3022e-04 - accuracy: 1.0000 - val_loss: 4.5272 - val_accuracy: 0.5862\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8040e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.2623e-04 - accuracy: 1.0000 - val_loss: 4.5397 - val_accuracy: 0.5862\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7804e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.2342e-04 - accuracy: 1.0000 - val_loss: 4.5495 - val_accuracy: 0.5862\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3653e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.2031e-04 - accuracy: 1.0000 - val_loss: 4.5675 - val_accuracy: 0.5862\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.5639e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1592e-04 - accuracy: 1.0000 - val_loss: 4.5769 - val_accuracy: 0.5862\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0290e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1319e-04 - accuracy: 1.0000 - val_loss: 4.5866 - val_accuracy: 0.5862\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1495e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1011e-04 - accuracy: 1.0000 - val_loss: 4.6003 - val_accuracy: 0.5862\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4957e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0769e-04 - accuracy: 1.0000 - val_loss: 4.6129 - val_accuracy: 0.5862\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5342e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0464e-04 - accuracy: 1.0000 - val_loss: 4.6232 - val_accuracy: 0.5862\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0747e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0229e-04 - accuracy: 1.0000 - val_loss: 4.6379 - val_accuracy: 0.5862\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1592e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0031e-04 - accuracy: 1.0000 - val_loss: 4.6526 - val_accuracy: 0.5862\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4928e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 9.8200e-05 - accuracy: 1.0000 - val_loss: 4.6677 - val_accuracy: 0.5862\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.9728e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 9.4777e-05 - accuracy: 1.0000 - val_loss: 4.6725 - val_accuracy: 0.5862\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0450e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 9.2557e-05 - accuracy: 1.0000 - val_loss: 4.6798 - val_accuracy: 0.5862\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6347e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 9.0833e-05 - accuracy: 1.0000 - val_loss: 4.6915 - val_accuracy: 0.5862\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.9624e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.8541e-05 - accuracy: 1.0000 - val_loss: 4.7031 - val_accuracy: 0.5862\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8582e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.6073e-05 - accuracy: 1.0000 - val_loss: 4.7125 - val_accuracy: 0.5862\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6114e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.4693e-05 - accuracy: 1.0000 - val_loss: 4.7233 - val_accuracy: 0.5862\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1227e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 8.2672e-05 - accuracy: 1.0000 - val_loss: 4.7443 - val_accuracy: 0.5862\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7381e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.1261e-05 - accuracy: 1.0000 - val_loss: 4.7576 - val_accuracy: 0.5862\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.5184e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.9462e-05 - accuracy: 1.0000 - val_loss: 4.7607 - val_accuracy: 0.5862\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0417e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.7693e-05 - accuracy: 1.0000 - val_loss: 4.7681 - val_accuracy: 0.5862\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1654e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 7.6985e-05 - accuracy: 1.0000 - val_loss: 4.7733 - val_accuracy: 0.5862\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3811e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.7151e-05 - accuracy: 1.0000 - val_loss: 4.7973 - val_accuracy: 0.5862\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6361e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.4403e-05 - accuracy: 1.0000 - val_loss: 4.8005 - val_accuracy: 0.5862\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5777e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.1836e-05 - accuracy: 1.0000 - val_loss: 4.8068 - val_accuracy: 0.5862\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2614e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 7.0044e-05 - accuracy: 1.0000 - val_loss: 4.8080 - val_accuracy: 0.5862\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0826e-04 - accuracy: 1.00 - 0s 130us/sample - loss: 6.9010e-05 - accuracy: 1.0000 - val_loss: 4.8073 - val_accuracy: 0.5862\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1208e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 6.8358e-05 - accuracy: 1.0000 - val_loss: 4.8152 - val_accuracy: 0.5862\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1163e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.6998e-05 - accuracy: 1.0000 - val_loss: 4.8284 - val_accuracy: 0.5862\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6423e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 6.5205e-05 - accuracy: 1.0000 - val_loss: 4.8424 - val_accuracy: 0.5862\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4202e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.4127e-05 - accuracy: 1.0000 - val_loss: 4.8594 - val_accuracy: 0.5862\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4407e-05 - accuracy: 1.00 - 0s 159us/sample - loss: 6.3133e-05 - accuracy: 1.0000 - val_loss: 4.8686 - val_accuracy: 0.5862\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6629e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.2027e-05 - accuracy: 1.0000 - val_loss: 4.8761 - val_accuracy: 0.5862\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9356e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.0852e-05 - accuracy: 1.0000 - val_loss: 4.8827 - val_accuracy: 0.5862\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.1715e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 6.0505e-05 - accuracy: 1.0000 - val_loss: 4.8824 - val_accuracy: 0.5862\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8087e-05 - accuracy: 1.00 - 0s 164us/sample - loss: 5.8858e-05 - accuracy: 1.0000 - val_loss: 4.8962 - val_accuracy: 0.5862\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1383e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.7574e-05 - accuracy: 1.0000 - val_loss: 4.9048 - val_accuracy: 0.5862\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3366e-05 - accuracy: 1.00 - 0s 137us/sample - loss: 5.6622e-05 - accuracy: 1.0000 - val_loss: 4.9166 - val_accuracy: 0.5862\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0175e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.5708e-05 - accuracy: 1.0000 - val_loss: 4.9302 - val_accuracy: 0.5862\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9915e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.5105e-05 - accuracy: 1.0000 - val_loss: 4.9388 - val_accuracy: 0.5862\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2689e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.4277e-05 - accuracy: 1.0000 - val_loss: 4.9461 - val_accuracy: 0.5862\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 5.6314e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.3147e-05 - accuracy: 1.0000 - val_loss: 4.9476 - val_accuracy: 0.5862\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3734e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 5.2661e-05 - accuracy: 1.0000 - val_loss: 4.9407 - val_accuracy: 0.5862\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3004e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.2329e-05 - accuracy: 1.0000 - val_loss: 4.9461 - val_accuracy: 0.5862\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3736e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 5.1074e-05 - accuracy: 1.0000 - val_loss: 4.9549 - val_accuracy: 0.5862\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9752e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.0246e-05 - accuracy: 1.0000 - val_loss: 4.9651 - val_accuracy: 0.5862\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5489e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 4.9332e-05 - accuracy: 1.0000 - val_loss: 4.9735 - val_accuracy: 0.5862\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8398e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.8328e-05 - accuracy: 1.0000 - val_loss: 4.9870 - val_accuracy: 0.5862\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4417e-05 - accuracy: 1.00 - 0s 137us/sample - loss: 4.7718e-05 - accuracy: 1.0000 - val_loss: 5.0037 - val_accuracy: 0.5862\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6981e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.7262e-05 - accuracy: 1.0000 - val_loss: 5.0152 - val_accuracy: 0.5862\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0677e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.6597e-05 - accuracy: 1.0000 - val_loss: 5.0203 - val_accuracy: 0.5862\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3651e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.5635e-05 - accuracy: 1.0000 - val_loss: 5.0266 - val_accuracy: 0.5862\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0087e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.5140e-05 - accuracy: 1.0000 - val_loss: 5.0294 - val_accuracy: 0.5862\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0344e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.4543e-05 - accuracy: 1.0000 - val_loss: 5.0376 - val_accuracy: 0.5862\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5208e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 4.3897e-05 - accuracy: 1.0000 - val_loss: 5.0404 - val_accuracy: 0.5862\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7846e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.3805e-05 - accuracy: 1.0000 - val_loss: 5.0414 - val_accuracy: 0.5862\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3535e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.2326e-05 - accuracy: 1.0000 - val_loss: 5.0548 - val_accuracy: 0.5862\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2766e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.3191e-05 - accuracy: 1.0000 - val_loss: 5.0713 - val_accuracy: 0.5862\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7138e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.1522e-05 - accuracy: 1.0000 - val_loss: 5.0722 - val_accuracy: 0.5862\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3773e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.0686e-05 - accuracy: 1.0000 - val_loss: 5.0693 - val_accuracy: 0.5862\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9565e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.0504e-05 - accuracy: 1.0000 - val_loss: 5.0697 - val_accuracy: 0.5862\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9648e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.0192e-05 - accuracy: 1.0000 - val_loss: 5.0770 - val_accuracy: 0.5862\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9518e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.9534e-05 - accuracy: 1.0000 - val_loss: 5.0844 - val_accuracy: 0.5862\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6482e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.9021e-05 - accuracy: 1.0000 - val_loss: 5.0988 - val_accuracy: 0.5862\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0848e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.8332e-05 - accuracy: 1.0000 - val_loss: 5.1083 - val_accuracy: 0.5862\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 1s - loss: 0.6955 - accuracy: 0.50 - 1s 6ms/sample - loss: 0.6679 - accuracy: 0.6207 - val_loss: 0.6383 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6929 - accuracy: 0.59 - 0s 492us/sample - loss: 0.6353 - accuracy: 0.6638 - val_loss: 0.6337 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5141 - accuracy: 0.78 - 0s 490us/sample - loss: 0.6054 - accuracy: 0.6638 - val_loss: 0.6340 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5572 - accuracy: 0.71 - 0s 481us/sample - loss: 0.5997 - accuracy: 0.6638 - val_loss: 0.6181 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5809 - accuracy: 0.68 - 0s 499us/sample - loss: 0.5827 - accuracy: 0.6638 - val_loss: 0.6038 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.84 - 0s 473us/sample - loss: 0.5530 - accuracy: 0.7414 - val_loss: 0.6058 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5045 - accuracy: 0.84 - 0s 487us/sample - loss: 0.5529 - accuracy: 0.7328 - val_loss: 0.6109 - val_accuracy: 0.5517\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.68 - 0s 499us/sample - loss: 0.5269 - accuracy: 0.7414 - val_loss: 0.5979 - val_accuracy: 0.5862\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3987 - accuracy: 0.87 - 0s 158us/sample - loss: 0.5123 - accuracy: 0.7414 - val_loss: 0.5952 - val_accuracy: 0.6207\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4360 - accuracy: 0.81 - 0s 163us/sample - loss: 0.4366 - accuracy: 0.7845 - val_loss: 0.6425 - val_accuracy: 0.6207\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4389 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4216 - accuracy: 0.8103 - val_loss: 0.7015 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3890 - accuracy: 0.87 - 0s 146us/sample - loss: 0.4120 - accuracy: 0.8190 - val_loss: 0.6930 - val_accuracy: 0.5517\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3489 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3966 - accuracy: 0.8276 - val_loss: 0.8424 - val_accuracy: 0.6897\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4447 - accuracy: 0.7759 - val_loss: 0.6982 - val_accuracy: 0.5862\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2395 - accuracy: 0.93 - 0s 155us/sample - loss: 0.3755 - accuracy: 0.8534 - val_loss: 0.5925 - val_accuracy: 0.7586\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.93 - 0s 146us/sample - loss: 0.3351 - accuracy: 0.8534 - val_loss: 0.6364 - val_accuracy: 0.7586\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4214 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3085 - accuracy: 0.8966 - val_loss: 0.7137 - val_accuracy: 0.5517\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2907 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2732 - accuracy: 0.9052 - val_loss: 0.7858 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3572 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2597 - accuracy: 0.9052 - val_loss: 0.6623 - val_accuracy: 0.7241\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2510 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2351 - accuracy: 0.9138 - val_loss: 0.8578 - val_accuracy: 0.6897\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2104 - accuracy: 0.9310 - val_loss: 0.7704 - val_accuracy: 0.7241\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1362 - accuracy: 0.96 - 0s 163us/sample - loss: 0.2205 - accuracy: 0.9052 - val_loss: 0.7246 - val_accuracy: 0.7931\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2673 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2326 - accuracy: 0.9138 - val_loss: 0.6869 - val_accuracy: 0.7241\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1802 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2103 - accuracy: 0.9138 - val_loss: 0.6925 - val_accuracy: 0.7241\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2962 - accuracy: 0.84 - 0s 138us/sample - loss: 0.1907 - accuracy: 0.9310 - val_loss: 0.8033 - val_accuracy: 0.7241\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1947 - accuracy: 0.9483 - val_loss: 1.2598 - val_accuracy: 0.5517\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2040 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1720 - accuracy: 0.9310 - val_loss: 0.7810 - val_accuracy: 0.7241\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1169 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2030 - accuracy: 0.9052 - val_loss: 0.9477 - val_accuracy: 0.6207\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1537 - accuracy: 0.9483 - val_loss: 0.7649 - val_accuracy: 0.7241\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0821 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1473 - accuracy: 0.9483 - val_loss: 1.0757 - val_accuracy: 0.6207\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0920 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1816 - accuracy: 0.9224 - val_loss: 1.2608 - val_accuracy: 0.6552\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2208 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2153 - accuracy: 0.9052 - val_loss: 1.2964 - val_accuracy: 0.5862\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1404 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1401 - accuracy: 0.9569 - val_loss: 1.3639 - val_accuracy: 0.7241\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1789 - accuracy: 0.9397 - val_loss: 1.2109 - val_accuracy: 0.6897\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1446 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1338 - accuracy: 0.9483 - val_loss: 1.2940 - val_accuracy: 0.7241\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2873 - accuracy: 0.84 - 0s 146us/sample - loss: 0.1527 - accuracy: 0.9310 - val_loss: 1.4990 - val_accuracy: 0.5517\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.96 - 0s 198us/sample - loss: 0.0950 - accuracy: 0.9569 - val_loss: 1.5837 - val_accuracy: 0.6552\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1320 - accuracy: 0.90 - 0s 172us/sample - loss: 0.0847 - accuracy: 0.9569 - val_loss: 1.5664 - val_accuracy: 0.6552\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0648 - accuracy: 0.9741 - val_loss: 1.5340 - val_accuracy: 0.6552\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.96 - 0s 189us/sample - loss: 0.0551 - accuracy: 0.9828 - val_loss: 1.6015 - val_accuracy: 0.6897\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0640 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0528 - accuracy: 0.9741 - val_loss: 1.9959 - val_accuracy: 0.6207\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0387 - accuracy: 0.9828 - val_loss: 2.3070 - val_accuracy: 0.6207\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0442 - accuracy: 0.9828 - val_loss: 2.4738 - val_accuracy: 0.6207\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0515 - accuracy: 1.0000 - val_loss: 2.6035 - val_accuracy: 0.6897\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0632 - accuracy: 0.9655 - val_loss: 3.9568 - val_accuracy: 0.5862\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 1.00 - 0s 172us/sample - loss: 0.2339 - accuracy: 0.9483 - val_loss: 3.6680 - val_accuracy: 0.6897\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0987 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1610 - accuracy: 0.9310 - val_loss: 3.2099 - val_accuracy: 0.6552\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2469 - accuracy: 0.90 - 0s 163us/sample - loss: 0.2133 - accuracy: 0.8879 - val_loss: 3.3037 - val_accuracy: 0.5862\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 1.00 - 0s 138us/sample - loss: 0.2199 - accuracy: 0.9310 - val_loss: 3.4084 - val_accuracy: 0.6207\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 1.00 - 0s 181us/sample - loss: 0.0691 - accuracy: 0.9741 - val_loss: 3.6024 - val_accuracy: 0.5862\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1084 - accuracy: 0.96 - 0s 198us/sample - loss: 0.1039 - accuracy: 0.9483 - val_loss: 3.3343 - val_accuracy: 0.5517\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.96 - 0s 189us/sample - loss: 0.0572 - accuracy: 0.9914 - val_loss: 3.0879 - val_accuracy: 0.6207\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1049 - accuracy: 0.9483 - val_loss: 3.3851 - val_accuracy: 0.6552\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 1.00 - 0s 189us/sample - loss: 0.0420 - accuracy: 0.9914 - val_loss: 3.8581 - val_accuracy: 0.5862\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0472 - accuracy: 0.9914 - val_loss: 4.1356 - val_accuracy: 0.6207\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0450 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0297 - accuracy: 1.0000 - val_loss: 4.5756 - val_accuracy: 0.6207\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0288 - accuracy: 0.9914 - val_loss: 5.0456 - val_accuracy: 0.5172\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 1.00 - 0s 206us/sample - loss: 0.0195 - accuracy: 1.0000 - val_loss: 5.6598 - val_accuracy: 0.5172\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0143 - accuracy: 1.0000 - val_loss: 6.0006 - val_accuracy: 0.5862\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0113 - accuracy: 1.0000 - val_loss: 6.0807 - val_accuracy: 0.5862\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0083 - accuracy: 1.0000 - val_loss: 6.2273 - val_accuracy: 0.5862\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 6.3876 - val_accuracy: 0.5862\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 6.5630 - val_accuracy: 0.5862\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 189us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 6.7184 - val_accuracy: 0.5862\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 206us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 6.8159 - val_accuracy: 0.5862\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 6.8889 - val_accuracy: 0.5862\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 6.9201 - val_accuracy: 0.5862\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 6.9940 - val_accuracy: 0.5862\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 7.0713 - val_accuracy: 0.5862\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 7.1469 - val_accuracy: 0.5862\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 7.2175 - val_accuracy: 0.5862\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 215us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 7.2591 - val_accuracy: 0.5862\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 7.2959 - val_accuracy: 0.5862\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 7.3396 - val_accuracy: 0.5862\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 7.3970 - val_accuracy: 0.5862\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.4601 - val_accuracy: 0.5862\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 7.5070 - val_accuracy: 0.5862\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.5536 - val_accuracy: 0.5862\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.5936 - val_accuracy: 0.5862\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 7.6372 - val_accuracy: 0.5862\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 7.6803 - val_accuracy: 0.5862\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 138us/sample - loss: 9.8496e-04 - accuracy: 1.0000 - val_loss: 7.7164 - val_accuracy: 0.5862\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 146us/sample - loss: 9.3321e-04 - accuracy: 1.0000 - val_loss: 7.7413 - val_accuracy: 0.5862\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2125e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 8.8759e-04 - accuracy: 1.0000 - val_loss: 7.7840 - val_accuracy: 0.5862\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 129us/sample - loss: 8.5080e-04 - accuracy: 1.0000 - val_loss: 7.8212 - val_accuracy: 0.5862\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4465e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 8.0257e-04 - accuracy: 1.0000 - val_loss: 7.8655 - val_accuracy: 0.5862\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 146us/sample - loss: 7.7074e-04 - accuracy: 1.0000 - val_loss: 7.9033 - val_accuracy: 0.5862\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8737e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.3374e-04 - accuracy: 1.0000 - val_loss: 7.9378 - val_accuracy: 0.5862\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 155us/sample - loss: 7.2142e-04 - accuracy: 1.0000 - val_loss: 7.9628 - val_accuracy: 0.5862\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 155us/sample - loss: 6.8701e-04 - accuracy: 1.0000 - val_loss: 8.0013 - val_accuracy: 0.5862\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4071e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 6.5238e-04 - accuracy: 1.0000 - val_loss: 8.0399 - val_accuracy: 0.5862\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0756e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 6.2774e-04 - accuracy: 1.0000 - val_loss: 8.0630 - val_accuracy: 0.5862\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1640e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.9366e-04 - accuracy: 1.0000 - val_loss: 8.0972 - val_accuracy: 0.5862\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3620e-04 - accuracy: 1.00 - 0s 361us/sample - loss: 5.7464e-04 - accuracy: 1.0000 - val_loss: 8.1355 - val_accuracy: 0.5862\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9677e-04 - accuracy: 1.00 - 0s 181us/sample - loss: 5.5719e-04 - accuracy: 1.0000 - val_loss: 8.1657 - val_accuracy: 0.5862\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4781e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 5.3484e-04 - accuracy: 1.0000 - val_loss: 8.1917 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 181us/sample - loss: 5.1916e-04 - accuracy: 1.0000 - val_loss: 8.2275 - val_accuracy: 0.5862\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3111e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 4.9446e-04 - accuracy: 1.0000 - val_loss: 8.2564 - val_accuracy: 0.5862\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1557e-04 - accuracy: 1.00 - 0s 151us/sample - loss: 4.7880e-04 - accuracy: 1.0000 - val_loss: 8.2879 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9381e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 4.5954e-04 - accuracy: 1.0000 - val_loss: 8.3167 - val_accuracy: 0.5862\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6395e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 4.4452e-04 - accuracy: 1.0000 - val_loss: 8.3432 - val_accuracy: 0.5862\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7553e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 4.3033e-04 - accuracy: 1.0000 - val_loss: 8.3766 - val_accuracy: 0.5862\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6046e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.1412e-04 - accuracy: 1.0000 - val_loss: 8.4085 - val_accuracy: 0.5862\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 1.9154e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.0306e-04 - accuracy: 1.0000 - val_loss: 8.4335 - val_accuracy: 0.5862\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8771e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.9019e-04 - accuracy: 1.0000 - val_loss: 8.4600 - val_accuracy: 0.5862\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.2292e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.7723e-04 - accuracy: 1.0000 - val_loss: 8.4870 - val_accuracy: 0.5862\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1588e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.6753e-04 - accuracy: 1.0000 - val_loss: 8.5165 - val_accuracy: 0.5862\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5700e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.5614e-04 - accuracy: 1.0000 - val_loss: 8.5375 - val_accuracy: 0.5862\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5574e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.4394e-04 - accuracy: 1.0000 - val_loss: 8.5596 - val_accuracy: 0.5862\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7638e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.3409e-04 - accuracy: 1.0000 - val_loss: 8.5899 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4591e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.2400e-04 - accuracy: 1.0000 - val_loss: 8.6244 - val_accuracy: 0.5862\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0710e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.1557e-04 - accuracy: 1.0000 - val_loss: 8.6448 - val_accuracy: 0.5862\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5723e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.0425e-04 - accuracy: 1.0000 - val_loss: 8.6708 - val_accuracy: 0.5862\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2297e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.9827e-04 - accuracy: 1.0000 - val_loss: 8.6898 - val_accuracy: 0.5862\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1541e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.8833e-04 - accuracy: 1.0000 - val_loss: 8.7158 - val_accuracy: 0.5862\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1236e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.8050e-04 - accuracy: 1.0000 - val_loss: 8.7423 - val_accuracy: 0.5862\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2297e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.7346e-04 - accuracy: 1.0000 - val_loss: 8.7688 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7209e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.6724e-04 - accuracy: 1.0000 - val_loss: 8.7925 - val_accuracy: 0.5862\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4397e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.6074e-04 - accuracy: 1.0000 - val_loss: 8.8071 - val_accuracy: 0.5862\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2585e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.5526e-04 - accuracy: 1.0000 - val_loss: 8.8323 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8941e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 2.4771e-04 - accuracy: 1.0000 - val_loss: 8.8619 - val_accuracy: 0.5862\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7198e-04 - accuracy: 1.00 - 0s 133us/sample - loss: 2.4036e-04 - accuracy: 1.0000 - val_loss: 8.8891 - val_accuracy: 0.5862\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0262e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.3487e-04 - accuracy: 1.0000 - val_loss: 8.9095 - val_accuracy: 0.5862\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8462e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.2890e-04 - accuracy: 1.0000 - val_loss: 8.9278 - val_accuracy: 0.5862\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3906e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.2477e-04 - accuracy: 1.0000 - val_loss: 8.9447 - val_accuracy: 0.5862\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0169e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 2.1829e-04 - accuracy: 1.0000 - val_loss: 8.9708 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0134e-05 - accuracy: 1.00 - 0s 133us/sample - loss: 2.1216e-04 - accuracy: 1.0000 - val_loss: 8.9914 - val_accuracy: 0.5862\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3091e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.0867e-04 - accuracy: 1.0000 - val_loss: 9.0150 - val_accuracy: 0.5862\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1811e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.0460e-04 - accuracy: 1.0000 - val_loss: 9.0272 - val_accuracy: 0.5862\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6491e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.9933e-04 - accuracy: 1.0000 - val_loss: 9.0492 - val_accuracy: 0.5862\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7606e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.9535e-04 - accuracy: 1.0000 - val_loss: 9.0665 - val_accuracy: 0.5862\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6751e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 1.9105e-04 - accuracy: 1.0000 - val_loss: 9.0940 - val_accuracy: 0.5862\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4751e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.8496e-04 - accuracy: 1.0000 - val_loss: 9.1112 - val_accuracy: 0.5862\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0609e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.8060e-04 - accuracy: 1.0000 - val_loss: 9.1311 - val_accuracy: 0.5862\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6585e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7639e-04 - accuracy: 1.0000 - val_loss: 9.1509 - val_accuracy: 0.5862\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7316e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.7314e-04 - accuracy: 1.0000 - val_loss: 9.1730 - val_accuracy: 0.5862\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2746e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.6932e-04 - accuracy: 1.0000 - val_loss: 9.1875 - val_accuracy: 0.5862\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0136e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6584e-04 - accuracy: 1.0000 - val_loss: 9.2103 - val_accuracy: 0.5862\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6171e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.6196e-04 - accuracy: 1.0000 - val_loss: 9.2342 - val_accuracy: 0.5862\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6933e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.5874e-04 - accuracy: 1.0000 - val_loss: 9.2527 - val_accuracy: 0.5862\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0957e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.5537e-04 - accuracy: 1.0000 - val_loss: 9.2685 - val_accuracy: 0.5862\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4172e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5337e-04 - accuracy: 1.0000 - val_loss: 9.2854 - val_accuracy: 0.5862\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9341e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.4946e-04 - accuracy: 1.0000 - val_loss: 9.3105 - val_accuracy: 0.5862\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4320e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.4760e-04 - accuracy: 1.0000 - val_loss: 9.3302 - val_accuracy: 0.5862\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0939e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 1.4424e-04 - accuracy: 1.0000 - val_loss: 9.3464 - val_accuracy: 0.5862\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.8900e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4061e-04 - accuracy: 1.0000 - val_loss: 9.3618 - val_accuracy: 0.5862\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7712e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.3842e-04 - accuracy: 1.0000 - val_loss: 9.3774 - val_accuracy: 0.5862\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2335e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.3632e-04 - accuracy: 1.0000 - val_loss: 9.3938 - val_accuracy: 0.5862\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7101e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.3345e-04 - accuracy: 1.0000 - val_loss: 9.4139 - val_accuracy: 0.5862\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9808e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3105e-04 - accuracy: 1.0000 - val_loss: 9.4311 - val_accuracy: 0.5862\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3302e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.2868e-04 - accuracy: 1.0000 - val_loss: 9.4453 - val_accuracy: 0.5862\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7238e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.2670e-04 - accuracy: 1.0000 - val_loss: 9.4616 - val_accuracy: 0.5862\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2792e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.2431e-04 - accuracy: 1.0000 - val_loss: 9.4777 - val_accuracy: 0.5862\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3324e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.2198e-04 - accuracy: 1.0000 - val_loss: 9.4924 - val_accuracy: 0.5862\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8131e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.2033e-04 - accuracy: 1.0000 - val_loss: 9.5036 - val_accuracy: 0.5862\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4109e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1789e-04 - accuracy: 1.0000 - val_loss: 9.5201 - val_accuracy: 0.5862\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6017e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.1587e-04 - accuracy: 1.0000 - val_loss: 9.5357 - val_accuracy: 0.5862\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2343e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1382e-04 - accuracy: 1.0000 - val_loss: 9.5531 - val_accuracy: 0.5862\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6215e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.1179e-04 - accuracy: 1.0000 - val_loss: 9.5684 - val_accuracy: 0.5862\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8527e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.1005e-04 - accuracy: 1.0000 - val_loss: 9.5806 - val_accuracy: 0.5862\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5981e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0809e-04 - accuracy: 1.0000 - val_loss: 9.5968 - val_accuracy: 0.5862\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3663e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0593e-04 - accuracy: 1.0000 - val_loss: 9.6168 - val_accuracy: 0.5862\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8543e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0438e-04 - accuracy: 1.0000 - val_loss: 9.6328 - val_accuracy: 0.5862\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9304e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0267e-04 - accuracy: 1.0000 - val_loss: 9.6474 - val_accuracy: 0.5862\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3008e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.0077e-04 - accuracy: 1.0000 - val_loss: 9.6594 - val_accuracy: 0.5862\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1011e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 9.9276e-05 - accuracy: 1.0000 - val_loss: 9.6757 - val_accuracy: 0.5862\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7840e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 9.7584e-05 - accuracy: 1.0000 - val_loss: 9.6923 - val_accuracy: 0.5862\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0582e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 9.5930e-05 - accuracy: 1.0000 - val_loss: 9.7060 - val_accuracy: 0.5862\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0150e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 9.4452e-05 - accuracy: 1.0000 - val_loss: 9.7221 - val_accuracy: 0.5862\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2634e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 9.3084e-05 - accuracy: 1.0000 - val_loss: 9.7386 - val_accuracy: 0.5862\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1697e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 9.1629e-05 - accuracy: 1.0000 - val_loss: 9.7528 - val_accuracy: 0.5862\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2532e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 9.0047e-05 - accuracy: 1.0000 - val_loss: 9.7651 - val_accuracy: 0.5862\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2655e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 8.9295e-05 - accuracy: 1.0000 - val_loss: 9.7764 - val_accuracy: 0.5862\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7135e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 8.7450e-05 - accuracy: 1.0000 - val_loss: 9.7933 - val_accuracy: 0.5862\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0641e-04 - accuracy: 1.00 - 0s 158us/sample - loss: 8.6734e-05 - accuracy: 1.0000 - val_loss: 9.8101 - val_accuracy: 0.5862\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0015e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 8.4851e-05 - accuracy: 1.0000 - val_loss: 9.8198 - val_accuracy: 0.5862\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.5877e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 8.3732e-05 - accuracy: 1.0000 - val_loss: 9.8301 - val_accuracy: 0.5862\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5000e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 8.2876e-05 - accuracy: 1.0000 - val_loss: 9.8439 - val_accuracy: 0.5862\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3874e-05 - accuracy: 1.00 - 0s 154us/sample - loss: 8.1446e-05 - accuracy: 1.0000 - val_loss: 9.8597 - val_accuracy: 0.5862\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2252e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 8.0225e-05 - accuracy: 1.0000 - val_loss: 9.8740 - val_accuracy: 0.5862\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2794e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.9173e-05 - accuracy: 1.0000 - val_loss: 9.8851 - val_accuracy: 0.5862\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5385e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.7978e-05 - accuracy: 1.0000 - val_loss: 9.9010 - val_accuracy: 0.5862\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2383e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.6564e-05 - accuracy: 1.0000 - val_loss: 9.9151 - val_accuracy: 0.5862\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2193e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.5665e-05 - accuracy: 1.0000 - val_loss: 9.9275 - val_accuracy: 0.5862\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2372e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.4309e-05 - accuracy: 1.0000 - val_loss: 9.9435 - val_accuracy: 0.5862\n",
      "Epoch 186/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 1.7251e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.3188e-05 - accuracy: 1.0000 - val_loss: 9.9576 - val_accuracy: 0.5862\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0991e-05 - accuracy: 1.00 - 0s 249us/sample - loss: 7.2435e-05 - accuracy: 1.0000 - val_loss: 9.9691 - val_accuracy: 0.5862\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8350e-05 - accuracy: 1.00 - 0s 456us/sample - loss: 7.1209e-05 - accuracy: 1.0000 - val_loss: 9.9841 - val_accuracy: 0.5862\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.8230e-05 - accuracy: 1.00 - 0s 506us/sample - loss: 7.0355e-05 - accuracy: 1.0000 - val_loss: 9.9961 - val_accuracy: 0.5862\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1100e-05 - accuracy: 1.00 - 0s 481us/sample - loss: 6.9304e-05 - accuracy: 1.0000 - val_loss: 10.0087 - val_accuracy: 0.5862\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2563e-05 - accuracy: 1.00 - 0s 490us/sample - loss: 6.8566e-05 - accuracy: 1.0000 - val_loss: 10.0145 - val_accuracy: 0.5862\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1321e-05 - accuracy: 1.00 - 0s 546us/sample - loss: 6.7589e-05 - accuracy: 1.0000 - val_loss: 10.0269 - val_accuracy: 0.5862\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5300e-05 - accuracy: 1.00 - 0s 486us/sample - loss: 6.6540e-05 - accuracy: 1.0000 - val_loss: 10.0420 - val_accuracy: 0.5862\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.8218e-05 - accuracy: 1.00 - 0s 516us/sample - loss: 6.5721e-05 - accuracy: 1.0000 - val_loss: 10.0539 - val_accuracy: 0.5862\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2018e-04 - accuracy: 1.00 - 0s 542us/sample - loss: 6.4732e-05 - accuracy: 1.0000 - val_loss: 10.0682 - val_accuracy: 0.5862\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0937e-04 - accuracy: 1.00 - 0s 481us/sample - loss: 6.3893e-05 - accuracy: 1.0000 - val_loss: 10.0830 - val_accuracy: 0.5862\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1128e-05 - accuracy: 1.00 - 0s 490us/sample - loss: 6.3021e-05 - accuracy: 1.0000 - val_loss: 10.0957 - val_accuracy: 0.5862\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1422e-04 - accuracy: 1.00 - 0s 490us/sample - loss: 6.2484e-05 - accuracy: 1.0000 - val_loss: 10.1045 - val_accuracy: 0.5862\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8505e-05 - accuracy: 1.00 - 0s 456us/sample - loss: 6.1413e-05 - accuracy: 1.0000 - val_loss: 10.1196 - val_accuracy: 0.5862\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2901e-05 - accuracy: 1.00 - 0s 499us/sample - loss: 6.0561e-05 - accuracy: 1.0000 - val_loss: 10.1326 - val_accuracy: 0.5862\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6952 - accuracy: 0.34 - 0s 3ms/sample - loss: 0.6505 - accuracy: 0.5776 - val_loss: 0.6592 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7008 - accuracy: 0.62 - 0s 172us/sample - loss: 0.6291 - accuracy: 0.6638 - val_loss: 0.6336 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6676 - accuracy: 0.59 - 0s 163us/sample - loss: 0.6299 - accuracy: 0.6638 - val_loss: 0.6194 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6665 - accuracy: 0.59 - 0s 155us/sample - loss: 0.5911 - accuracy: 0.6638 - val_loss: 0.6299 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6861 - accuracy: 0.56 - 0s 146us/sample - loss: 0.5923 - accuracy: 0.6897 - val_loss: 0.6017 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5385 - accuracy: 0.78 - 0s 155us/sample - loss: 0.5627 - accuracy: 0.7328 - val_loss: 0.5925 - val_accuracy: 0.6207\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.81 - 0s 163us/sample - loss: 0.5252 - accuracy: 0.7414 - val_loss: 0.5959 - val_accuracy: 0.5862\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5032 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4948 - accuracy: 0.7586 - val_loss: 0.6273 - val_accuracy: 0.6897\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5120 - accuracy: 0.75 - 0s 146us/sample - loss: 0.4818 - accuracy: 0.7328 - val_loss: 0.6615 - val_accuracy: 0.5862\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5467 - accuracy: 0.68 - 0s 146us/sample - loss: 0.4614 - accuracy: 0.7586 - val_loss: 0.6426 - val_accuracy: 0.7241\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3602 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4795 - accuracy: 0.7328 - val_loss: 0.6707 - val_accuracy: 0.6207\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3868 - accuracy: 0.90 - 0s 155us/sample - loss: 0.4120 - accuracy: 0.8362 - val_loss: 0.6450 - val_accuracy: 0.7241\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5481 - accuracy: 0.71 - 0s 146us/sample - loss: 0.4282 - accuracy: 0.7845 - val_loss: 0.6503 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4521 - accuracy: 0.84 - 0s 149us/sample - loss: 0.3760 - accuracy: 0.8448 - val_loss: 0.7017 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3733 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3468 - accuracy: 0.8707 - val_loss: 0.9061 - val_accuracy: 0.5517\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.93 - 0s 138us/sample - loss: 0.4024 - accuracy: 0.8448 - val_loss: 0.7991 - val_accuracy: 0.7241\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4598 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3420 - accuracy: 0.8534 - val_loss: 0.6947 - val_accuracy: 0.4828\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3435 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3200 - accuracy: 0.8793 - val_loss: 0.7011 - val_accuracy: 0.7586\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3208 - accuracy: 0.81 - 0s 163us/sample - loss: 0.3059 - accuracy: 0.8621 - val_loss: 0.9850 - val_accuracy: 0.5172\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1672 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2610 - accuracy: 0.9052 - val_loss: 0.8751 - val_accuracy: 0.7241\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2517 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2268 - accuracy: 0.9310 - val_loss: 1.0358 - val_accuracy: 0.5862\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 1.00 - 0s 172us/sample - loss: 0.2149 - accuracy: 0.9224 - val_loss: 1.0621 - val_accuracy: 0.6897\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1038 - accuracy: 0.96 - 0s 133us/sample - loss: 0.1941 - accuracy: 0.9483 - val_loss: 1.2529 - val_accuracy: 0.7241\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 1.00 - 0s 146us/sample - loss: 0.2206 - accuracy: 0.9224 - val_loss: 2.1090 - val_accuracy: 0.4828\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4365 - accuracy: 0.75 - 0s 172us/sample - loss: 0.2234 - accuracy: 0.8966 - val_loss: 1.2807 - val_accuracy: 0.7241\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1272 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1930 - accuracy: 0.9310 - val_loss: 1.9585 - val_accuracy: 0.5172\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1507 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1821 - accuracy: 0.9569 - val_loss: 1.7496 - val_accuracy: 0.6552\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1635 - accuracy: 0.9483 - val_loss: 2.0513 - val_accuracy: 0.6207\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1477 - accuracy: 0.9569 - val_loss: 1.9509 - val_accuracy: 0.6897\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1255 - accuracy: 0.9741 - val_loss: 1.8683 - val_accuracy: 0.6552\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1138 - accuracy: 0.9655 - val_loss: 1.9346 - val_accuracy: 0.6552\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0967 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1081 - accuracy: 0.9741 - val_loss: 2.2496 - val_accuracy: 0.6897\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1933 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1488 - accuracy: 0.9310 - val_loss: 3.2315 - val_accuracy: 0.5172\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1074 - accuracy: 0.96 - 0s 181us/sample - loss: 0.1195 - accuracy: 0.9569 - val_loss: 2.7504 - val_accuracy: 0.6552\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1258 - accuracy: 0.96 - 0s 224us/sample - loss: 0.1165 - accuracy: 0.9655 - val_loss: 3.1418 - val_accuracy: 0.5862\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1558 - accuracy: 0.87 - 0s 172us/sample - loss: 0.1051 - accuracy: 0.9483 - val_loss: 2.4588 - val_accuracy: 0.6897\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1277 - accuracy: 0.9569 - val_loss: 2.8588 - val_accuracy: 0.6207\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1124 - accuracy: 0.9569 - val_loss: 1.9735 - val_accuracy: 0.7241\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1528 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1477 - accuracy: 0.9310 - val_loss: 3.5249 - val_accuracy: 0.6897\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1923 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2662 - accuracy: 0.9310 - val_loss: 2.7816 - val_accuracy: 0.7241\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4122 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3181 - accuracy: 0.8534 - val_loss: 3.5542 - val_accuracy: 0.6552\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2207 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3023 - accuracy: 0.8707 - val_loss: 1.9861 - val_accuracy: 0.6552\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2975 - accuracy: 0.81 - 0s 129us/sample - loss: 0.3022 - accuracy: 0.8707 - val_loss: 1.6376 - val_accuracy: 0.6552\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2333 - accuracy: 0.81 - 0s 138us/sample - loss: 0.2412 - accuracy: 0.8534 - val_loss: 1.8441 - val_accuracy: 0.6552\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1239 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2357 - accuracy: 0.8879 - val_loss: 1.9586 - val_accuracy: 0.6552\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2040 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2199 - accuracy: 0.9224 - val_loss: 1.7172 - val_accuracy: 0.6207\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2468 - accuracy: 0.9138 - val_loss: 1.2451 - val_accuracy: 0.6552\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2503 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2158 - accuracy: 0.9224 - val_loss: 1.5082 - val_accuracy: 0.6897\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2141 - accuracy: 0.9224 - val_loss: 1.9117 - val_accuracy: 0.6207\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0730 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1701 - accuracy: 0.9138 - val_loss: 2.2523 - val_accuracy: 0.6207\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1543 - accuracy: 0.9310 - val_loss: 3.2728 - val_accuracy: 0.5862\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3228 - accuracy: 0.81 - 0s 155us/sample - loss: 0.1737 - accuracy: 0.9483 - val_loss: 2.8954 - val_accuracy: 0.5862\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1405 - accuracy: 0.9397 - val_loss: 2.9527 - val_accuracy: 0.5862\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0798 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1201 - accuracy: 0.9569 - val_loss: 2.9338 - val_accuracy: 0.5862\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1583 - accuracy: 0.9569 - val_loss: 2.9207 - val_accuracy: 0.5862\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1010 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0866 - accuracy: 0.9828 - val_loss: 3.2589 - val_accuracy: 0.5862\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1035 - accuracy: 1.00 - 0s 163us/sample - loss: 0.1233 - accuracy: 0.9483 - val_loss: 3.1349 - val_accuracy: 0.5862\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0719 - accuracy: 0.9741 - val_loss: 3.1068 - val_accuracy: 0.5862\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0709 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0940 - accuracy: 0.9655 - val_loss: 3.1404 - val_accuracy: 0.5517\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0708 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0484 - accuracy: 1.0000 - val_loss: 3.2125 - val_accuracy: 0.5862\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0520 - accuracy: 0.9828 - val_loss: 3.4444 - val_accuracy: 0.5862\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0324 - accuracy: 1.0000 - val_loss: 3.6718 - val_accuracy: 0.5862\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0273 - accuracy: 0.9914 - val_loss: 3.8753 - val_accuracy: 0.5517\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0169 - accuracy: 1.0000 - val_loss: 3.8296 - val_accuracy: 0.5517\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0145 - accuracy: 1.0000 - val_loss: 3.6891 - val_accuracy: 0.5862\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0124 - accuracy: 1.0000 - val_loss: 3.6898 - val_accuracy: 0.6207\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 3.6509 - val_accuracy: 0.5862\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.7156 - val_accuracy: 0.5517\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0108 - accuracy: 1.0000 - val_loss: 3.7980 - val_accuracy: 0.5862\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 3.8348 - val_accuracy: 0.6207\n",
      "Epoch 71/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.8123 - val_accuracy: 0.5517\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.8093 - val_accuracy: 0.5862\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.1676e-04 - accuracy: 1.00 - 0s 139us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.8256 - val_accuracy: 0.5862\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.1801e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.8666 - val_accuracy: 0.5862\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.9161 - val_accuracy: 0.5862\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8609e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.9594 - val_accuracy: 0.5862\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.9890 - val_accuracy: 0.5862\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.0201 - val_accuracy: 0.5862\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.0501 - val_accuracy: 0.5862\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 8.2888e-04 - accuracy: 1.0000 - val_loss: 4.0875 - val_accuracy: 0.5862\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0183e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.1204 - val_accuracy: 0.5862\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 154us/sample - loss: 9.5189e-04 - accuracy: 1.0000 - val_loss: 4.1421 - val_accuracy: 0.5862\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0973e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.3540e-04 - accuracy: 1.0000 - val_loss: 4.1660 - val_accuracy: 0.5862\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3739e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 7.4008e-04 - accuracy: 1.0000 - val_loss: 4.1912 - val_accuracy: 0.5862\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9743e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.8655e-04 - accuracy: 1.0000 - val_loss: 4.2240 - val_accuracy: 0.5862\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0823e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.5664e-04 - accuracy: 1.0000 - val_loss: 4.2564 - val_accuracy: 0.5862\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0819e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.8245e-04 - accuracy: 1.0000 - val_loss: 4.2841 - val_accuracy: 0.5862\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 146us/sample - loss: 5.4186e-04 - accuracy: 1.0000 - val_loss: 4.2983 - val_accuracy: 0.5862\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.6863e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.6555e-04 - accuracy: 1.0000 - val_loss: 4.3155 - val_accuracy: 0.5862\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9614e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.7888e-04 - accuracy: 1.0000 - val_loss: 4.3355 - val_accuracy: 0.5862\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8872e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.4660e-04 - accuracy: 1.0000 - val_loss: 4.3597 - val_accuracy: 0.5862\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1671e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.0480e-04 - accuracy: 1.0000 - val_loss: 4.3843 - val_accuracy: 0.5862\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4393e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.9456e-04 - accuracy: 1.0000 - val_loss: 4.4104 - val_accuracy: 0.5862\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4395e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.9016e-04 - accuracy: 1.0000 - val_loss: 4.4302 - val_accuracy: 0.5862\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5525e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.8165e-04 - accuracy: 1.0000 - val_loss: 4.4474 - val_accuracy: 0.5862\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5352e-04 - accuracy: 1.00 - 0s 164us/sample - loss: 3.5902e-04 - accuracy: 1.0000 - val_loss: 4.4572 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5646e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.5826e-04 - accuracy: 1.0000 - val_loss: 4.4706 - val_accuracy: 0.5862\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.2883e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.4142e-04 - accuracy: 1.0000 - val_loss: 4.4919 - val_accuracy: 0.5862\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0668e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.1895e-04 - accuracy: 1.0000 - val_loss: 4.5137 - val_accuracy: 0.5862\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3633e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.0452e-04 - accuracy: 1.0000 - val_loss: 4.5337 - val_accuracy: 0.5862\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7216e-04 - accuracy: 1.00 - 0s 151us/sample - loss: 3.0414e-04 - accuracy: 1.0000 - val_loss: 4.5522 - val_accuracy: 0.5862\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5461e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.9453e-04 - accuracy: 1.0000 - val_loss: 4.5669 - val_accuracy: 0.5862\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7941e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 2.7945e-04 - accuracy: 1.0000 - val_loss: 4.5824 - val_accuracy: 0.5862\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4226e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 2.6835e-04 - accuracy: 1.0000 - val_loss: 4.5962 - val_accuracy: 0.5862\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4269e-04 - accuracy: 1.00 - 0s 168us/sample - loss: 2.6362e-04 - accuracy: 1.0000 - val_loss: 4.6131 - val_accuracy: 0.5862\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9099e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.5416e-04 - accuracy: 1.0000 - val_loss: 4.6303 - val_accuracy: 0.5862\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4805e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.4255e-04 - accuracy: 1.0000 - val_loss: 4.6531 - val_accuracy: 0.5862\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1388e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.3590e-04 - accuracy: 1.0000 - val_loss: 4.6761 - val_accuracy: 0.5862\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8864e-04 - accuracy: 1.00 - 0s 189us/sample - loss: 2.3203e-04 - accuracy: 1.0000 - val_loss: 4.6955 - val_accuracy: 0.5862\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0215e-04 - accuracy: 1.00 - 0s 198us/sample - loss: 2.2862e-04 - accuracy: 1.0000 - val_loss: 4.7086 - val_accuracy: 0.5862\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0827e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 2.1488e-04 - accuracy: 1.0000 - val_loss: 4.7257 - val_accuracy: 0.5862\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4191e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.1639e-04 - accuracy: 1.0000 - val_loss: 4.7481 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3394e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.0608e-04 - accuracy: 1.0000 - val_loss: 4.7613 - val_accuracy: 0.5862\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3329e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.9587e-04 - accuracy: 1.0000 - val_loss: 4.7774 - val_accuracy: 0.5862\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2034e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.8952e-04 - accuracy: 1.0000 - val_loss: 4.7962 - val_accuracy: 0.5862\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5360e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8635e-04 - accuracy: 1.0000 - val_loss: 4.8126 - val_accuracy: 0.5862\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1649e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.8267e-04 - accuracy: 1.0000 - val_loss: 4.8320 - val_accuracy: 0.5862\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6570e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7403e-04 - accuracy: 1.0000 - val_loss: 4.8454 - val_accuracy: 0.5862\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8394e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7160e-04 - accuracy: 1.0000 - val_loss: 4.8604 - val_accuracy: 0.5862\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1056e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.6570e-04 - accuracy: 1.0000 - val_loss: 4.8783 - val_accuracy: 0.5862\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4171e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.6104e-04 - accuracy: 1.0000 - val_loss: 4.8979 - val_accuracy: 0.5862\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5889e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.5996e-04 - accuracy: 1.0000 - val_loss: 4.9180 - val_accuracy: 0.5862\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3242e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.5391e-04 - accuracy: 1.0000 - val_loss: 4.9330 - val_accuracy: 0.5862\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7904e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.4966e-04 - accuracy: 1.0000 - val_loss: 4.9485 - val_accuracy: 0.5862\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1986e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.4531e-04 - accuracy: 1.0000 - val_loss: 4.9604 - val_accuracy: 0.5862\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0889e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4274e-04 - accuracy: 1.0000 - val_loss: 4.9792 - val_accuracy: 0.5862\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2722e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3798e-04 - accuracy: 1.0000 - val_loss: 4.9972 - val_accuracy: 0.5862\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5878e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3597e-04 - accuracy: 1.0000 - val_loss: 5.0138 - val_accuracy: 0.5862\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3899e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3239e-04 - accuracy: 1.0000 - val_loss: 5.0319 - val_accuracy: 0.5862\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8670e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.2875e-04 - accuracy: 1.0000 - val_loss: 5.0529 - val_accuracy: 0.5862\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7253e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.2567e-04 - accuracy: 1.0000 - val_loss: 5.0701 - val_accuracy: 0.5862\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0583e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.2349e-04 - accuracy: 1.0000 - val_loss: 5.0857 - val_accuracy: 0.5862\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.1961e-05 - accuracy: 1.00 - 0s 181us/sample - loss: 1.1905e-04 - accuracy: 1.0000 - val_loss: 5.0959 - val_accuracy: 0.5862\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3024e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 1.1665e-04 - accuracy: 1.0000 - val_loss: 5.1131 - val_accuracy: 0.5862\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9692e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1377e-04 - accuracy: 1.0000 - val_loss: 5.1323 - val_accuracy: 0.5862\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3668e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.1124e-04 - accuracy: 1.0000 - val_loss: 5.1539 - val_accuracy: 0.5862\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6106e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0830e-04 - accuracy: 1.0000 - val_loss: 5.1754 - val_accuracy: 0.5862\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5754e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.0506e-04 - accuracy: 1.0000 - val_loss: 5.1937 - val_accuracy: 0.5862\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1706e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0259e-04 - accuracy: 1.0000 - val_loss: 5.2132 - val_accuracy: 0.5862\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8503e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0046e-04 - accuracy: 1.0000 - val_loss: 5.2319 - val_accuracy: 0.5862\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9251e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.8437e-05 - accuracy: 1.0000 - val_loss: 5.2476 - val_accuracy: 0.5862\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0151e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 9.6787e-05 - accuracy: 1.0000 - val_loss: 5.2643 - val_accuracy: 0.5862\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7512e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 9.3388e-05 - accuracy: 1.0000 - val_loss: 5.2777 - val_accuracy: 0.5862\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2374e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 9.1575e-05 - accuracy: 1.0000 - val_loss: 5.2963 - val_accuracy: 0.5862\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7610e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.9588e-05 - accuracy: 1.0000 - val_loss: 5.3142 - val_accuracy: 0.5862\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.8877e-05 - accuracy: 1.00 - 0s 133us/sample - loss: 8.8792e-05 - accuracy: 1.0000 - val_loss: 5.3271 - val_accuracy: 0.5862\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2886e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.5681e-05 - accuracy: 1.0000 - val_loss: 5.3490 - val_accuracy: 0.5862\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4700e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.3443e-05 - accuracy: 1.0000 - val_loss: 5.3683 - val_accuracy: 0.5862\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.9533e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.1425e-05 - accuracy: 1.0000 - val_loss: 5.3857 - val_accuracy: 0.5862\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.5259e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.9973e-05 - accuracy: 1.0000 - val_loss: 5.4001 - val_accuracy: 0.5862\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3985e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.8276e-05 - accuracy: 1.0000 - val_loss: 5.4189 - val_accuracy: 0.5862\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7031e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 7.6251e-05 - accuracy: 1.0000 - val_loss: 5.4355 - val_accuracy: 0.5862\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8073e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.5098e-05 - accuracy: 1.0000 - val_loss: 5.4488 - val_accuracy: 0.5862\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.5470e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.3525e-05 - accuracy: 1.0000 - val_loss: 5.4667 - val_accuracy: 0.5862\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.8603e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.1881e-05 - accuracy: 1.0000 - val_loss: 5.4866 - val_accuracy: 0.5862\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0166e-05 - accuracy: 1.00 - 0s 151us/sample - loss: 7.0543e-05 - accuracy: 1.0000 - val_loss: 5.5015 - val_accuracy: 0.5862\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.8907e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.9069e-05 - accuracy: 1.0000 - val_loss: 5.5159 - val_accuracy: 0.5862\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9208e-05 - accuracy: 1.00 - 0s 482us/sample - loss: 6.7437e-05 - accuracy: 1.0000 - val_loss: 5.5284 - val_accuracy: 0.5862\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1732e-05 - accuracy: 1.00 - 0s 507us/sample - loss: 6.6390e-05 - accuracy: 1.0000 - val_loss: 5.5443 - val_accuracy: 0.5862\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6689e-05 - accuracy: 1.00 - 0s 482us/sample - loss: 6.4738e-05 - accuracy: 1.0000 - val_loss: 5.5627 - val_accuracy: 0.5862\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6650e-05 - accuracy: 1.00 - 0s 482us/sample - loss: 6.4150e-05 - accuracy: 1.0000 - val_loss: 5.5753 - val_accuracy: 0.5862\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0753e-04 - accuracy: 1.00 - 0s 542us/sample - loss: 6.2427e-05 - accuracy: 1.0000 - val_loss: 5.5902 - val_accuracy: 0.5862\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8657e-05 - accuracy: 1.00 - 0s 507us/sample - loss: 6.0813e-05 - accuracy: 1.0000 - val_loss: 5.6063 - val_accuracy: 0.5862\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6631e-05 - accuracy: 1.00 - 0s 495us/sample - loss: 5.9867e-05 - accuracy: 1.0000 - val_loss: 5.6196 - val_accuracy: 0.5862\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5617e-05 - accuracy: 1.00 - 0s 507us/sample - loss: 5.8948e-05 - accuracy: 1.0000 - val_loss: 5.6352 - val_accuracy: 0.5862\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0655e-05 - accuracy: 1.00 - 0s 550us/sample - loss: 5.7661e-05 - accuracy: 1.0000 - val_loss: 5.6494 - val_accuracy: 0.5862\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0884e-05 - accuracy: 1.00 - 0s 473us/sample - loss: 5.6493e-05 - accuracy: 1.0000 - val_loss: 5.6681 - val_accuracy: 0.5862\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3946e-05 - accuracy: 1.00 - 0s 481us/sample - loss: 5.5553e-05 - accuracy: 1.0000 - val_loss: 5.6819 - val_accuracy: 0.5862\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4304e-04 - accuracy: 1.00 - 0s 542us/sample - loss: 5.4606e-05 - accuracy: 1.0000 - val_loss: 5.6964 - val_accuracy: 0.5862\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0375e-05 - accuracy: 1.00 - 0s 490us/sample - loss: 5.3687e-05 - accuracy: 1.0000 - val_loss: 5.7063 - val_accuracy: 0.5862\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.5564e-05 - accuracy: 1.00 - 0s 301us/sample - loss: 5.2879e-05 - accuracy: 1.0000 - val_loss: 5.7212 - val_accuracy: 0.5862\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1852e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.1714e-05 - accuracy: 1.0000 - val_loss: 5.7305 - val_accuracy: 0.5862\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7918e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.0847e-05 - accuracy: 1.0000 - val_loss: 5.7458 - val_accuracy: 0.5862\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3567e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.0273e-05 - accuracy: 1.0000 - val_loss: 5.7614 - val_accuracy: 0.5862\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6679e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.8706e-05 - accuracy: 1.0000 - val_loss: 5.7786 - val_accuracy: 0.5862\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3887e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.8024e-05 - accuracy: 1.0000 - val_loss: 5.7927 - val_accuracy: 0.5862\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6847e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.7726e-05 - accuracy: 1.0000 - val_loss: 5.8097 - val_accuracy: 0.5862\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3517e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.6455e-05 - accuracy: 1.0000 - val_loss: 5.8178 - val_accuracy: 0.5862\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1056e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.5415e-05 - accuracy: 1.0000 - val_loss: 5.8276 - val_accuracy: 0.5862\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0443e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.4705e-05 - accuracy: 1.0000 - val_loss: 5.8413 - val_accuracy: 0.5862\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1855e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 4.4190e-05 - accuracy: 1.0000 - val_loss: 5.8576 - val_accuracy: 0.5862\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3979e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.3151e-05 - accuracy: 1.0000 - val_loss: 5.8667 - val_accuracy: 0.5862\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2555e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.2458e-05 - accuracy: 1.0000 - val_loss: 5.8776 - val_accuracy: 0.5862\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6425e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.1881e-05 - accuracy: 1.0000 - val_loss: 5.8922 - val_accuracy: 0.5862\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7336e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.1417e-05 - accuracy: 1.0000 - val_loss: 5.9066 - val_accuracy: 0.5862\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6147e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.0508e-05 - accuracy: 1.0000 - val_loss: 5.9172 - val_accuracy: 0.5862\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8734e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.9981e-05 - accuracy: 1.0000 - val_loss: 5.9235 - val_accuracy: 0.5862\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5840e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.9310e-05 - accuracy: 1.0000 - val_loss: 5.9384 - val_accuracy: 0.5862\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7153e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.8743e-05 - accuracy: 1.0000 - val_loss: 5.9563 - val_accuracy: 0.5862\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0515e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.7959e-05 - accuracy: 1.0000 - val_loss: 5.9699 - val_accuracy: 0.5862\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6057e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.7317e-05 - accuracy: 1.0000 - val_loss: 5.9802 - val_accuracy: 0.5862\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2579e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.6796e-05 - accuracy: 1.0000 - val_loss: 5.9951 - val_accuracy: 0.5862\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4052e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.6306e-05 - accuracy: 1.0000 - val_loss: 6.0137 - val_accuracy: 0.5862\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2426e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.5897e-05 - accuracy: 1.0000 - val_loss: 6.0311 - val_accuracy: 0.5862\n",
      "Epoch 195/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 6.1002e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.5312e-05 - accuracy: 1.0000 - val_loss: 6.0410 - val_accuracy: 0.5862\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3043e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.4538e-05 - accuracy: 1.0000 - val_loss: 6.0495 - val_accuracy: 0.5862\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4966e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.3948e-05 - accuracy: 1.0000 - val_loss: 6.0560 - val_accuracy: 0.5862\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9985e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.3612e-05 - accuracy: 1.0000 - val_loss: 6.0650 - val_accuracy: 0.5862\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9813e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.3128e-05 - accuracy: 1.0000 - val_loss: 6.0794 - val_accuracy: 0.5862\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9604e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.2389e-05 - accuracy: 1.0000 - val_loss: 6.0981 - val_accuracy: 0.5862\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: f317fb9284e38c0636dc1f74ae3e2bf4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7758620977401733</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 48</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 120</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 72</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 154</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6918 - accuracy: 0.50 - 1s 5ms/sample - loss: 0.6687 - accuracy: 0.5948 - val_loss: 0.6282 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.8545 - accuracy: 0.40 - 0s 266us/sample - loss: 0.6605 - accuracy: 0.6638 - val_loss: 0.6362 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6302 - accuracy: 0.65 - 0s 155us/sample - loss: 0.6116 - accuracy: 0.6638 - val_loss: 0.6248 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5208 - accuracy: 0.78 - 0s 163us/sample - loss: 0.6140 - accuracy: 0.6638 - val_loss: 0.6314 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3948 - accuracy: 0.87 - 0s 163us/sample - loss: 0.5928 - accuracy: 0.6724 - val_loss: 0.6234 - val_accuracy: 0.6207\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7089 - accuracy: 0.59 - 0s 163us/sample - loss: 0.5828 - accuracy: 0.7328 - val_loss: 0.6325 - val_accuracy: 0.5862\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5637 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5673 - accuracy: 0.7155 - val_loss: 0.6106 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4593 - accuracy: 0.81 - 0s 138us/sample - loss: 0.5447 - accuracy: 0.7155 - val_loss: 0.6021 - val_accuracy: 0.5862\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5191 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5237 - accuracy: 0.7328 - val_loss: 0.5972 - val_accuracy: 0.6552\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4159 - accuracy: 0.84 - 0s 1ms/sample - loss: 0.5211 - accuracy: 0.7500 - val_loss: 0.6007 - val_accuracy: 0.6897\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.75 - 0s 293us/sample - loss: 0.4929 - accuracy: 0.7931 - val_loss: 0.6309 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5023 - accuracy: 0.78 - 0s 155us/sample - loss: 0.4776 - accuracy: 0.7931 - val_loss: 0.6252 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5271 - accuracy: 0.68 - 0s 146us/sample - loss: 0.4497 - accuracy: 0.7672 - val_loss: 0.6315 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4657 - accuracy: 0.84 - 0s 155us/sample - loss: 0.4360 - accuracy: 0.8017 - val_loss: 0.6324 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4394 - accuracy: 0.75 - 0s 163us/sample - loss: 0.4243 - accuracy: 0.8190 - val_loss: 0.6362 - val_accuracy: 0.6897\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4126 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4043 - accuracy: 0.8017 - val_loss: 0.6763 - val_accuracy: 0.6897\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5172 - accuracy: 0.81 - 0s 163us/sample - loss: 0.4082 - accuracy: 0.8534 - val_loss: 0.6715 - val_accuracy: 0.6897\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.78 - 0s 1ms/sample - loss: 0.3561 - accuracy: 0.8190 - val_loss: 0.6954 - val_accuracy: 0.7241\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1924 - accuracy: 0.96 - 0s 172us/sample - loss: 0.3274 - accuracy: 0.8707 - val_loss: 0.7507 - val_accuracy: 0.5172\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3024 - accuracy: 0.93 - 0s 163us/sample - loss: 0.3305 - accuracy: 0.8966 - val_loss: 0.7789 - val_accuracy: 0.6897\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3574 - accuracy: 0.90 - 0s 172us/sample - loss: 0.3079 - accuracy: 0.8793 - val_loss: 0.7751 - val_accuracy: 0.6897\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4459 - accuracy: 0.81 - 0s 172us/sample - loss: 0.2896 - accuracy: 0.9224 - val_loss: 0.8576 - val_accuracy: 0.7241\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2807 - accuracy: 0.9052 - val_loss: 0.9762 - val_accuracy: 0.6552\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2511 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2576 - accuracy: 0.8966 - val_loss: 0.9507 - val_accuracy: 0.6552\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1897 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2385 - accuracy: 0.9310 - val_loss: 0.9864 - val_accuracy: 0.6897\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2892 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2290 - accuracy: 0.9310 - val_loss: 1.0664 - val_accuracy: 0.6207\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2427 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2163 - accuracy: 0.9397 - val_loss: 1.1940 - val_accuracy: 0.6552\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1980 - accuracy: 0.9397 - val_loss: 1.2311 - val_accuracy: 0.6552\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2022 - accuracy: 0.96 - 0s 151us/sample - loss: 0.1962 - accuracy: 0.9397 - val_loss: 1.2884 - val_accuracy: 0.6207\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1883 - accuracy: 0.9397 - val_loss: 1.2778 - val_accuracy: 0.5862\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1969 - accuracy: 0.9224 - val_loss: 1.2300 - val_accuracy: 0.6897\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1585 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1670 - accuracy: 0.9483 - val_loss: 1.3070 - val_accuracy: 0.6207\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 1.00 - 0s 2ms/sample - loss: 0.1597 - accuracy: 0.9483 - val_loss: 1.3905 - val_accuracy: 0.7586\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2350 - accuracy: 0.87 - 0s 146us/sample - loss: 0.1433 - accuracy: 0.9397 - val_loss: 1.4464 - val_accuracy: 0.7241\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1411 - accuracy: 0.9569 - val_loss: 1.4345 - val_accuracy: 0.7241\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1176 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1496 - accuracy: 0.9310 - val_loss: 1.6411 - val_accuracy: 0.6207\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1182 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1385 - accuracy: 0.9741 - val_loss: 1.6525 - val_accuracy: 0.6552\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1050 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1167 - accuracy: 0.9569 - val_loss: 1.6189 - val_accuracy: 0.6207\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0893 - accuracy: 0.9828 - val_loss: 1.6666 - val_accuracy: 0.6897\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0930 - accuracy: 0.9655 - val_loss: 1.9075 - val_accuracy: 0.5172\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0982 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0910 - accuracy: 1.0000 - val_loss: 2.0293 - val_accuracy: 0.6207\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1657 - accuracy: 0.90 - 0s 155us/sample - loss: 0.0980 - accuracy: 0.9569 - val_loss: 1.8388 - val_accuracy: 0.6207\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0663 - accuracy: 0.9914 - val_loss: 1.9628 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0579 - accuracy: 0.9828 - val_loss: 2.0736 - val_accuracy: 0.6897\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0765 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0509 - accuracy: 0.9828 - val_loss: 2.1663 - val_accuracy: 0.6207\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 1.00 - 0s 164us/sample - loss: 0.0470 - accuracy: 1.0000 - val_loss: 2.2007 - val_accuracy: 0.6897\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0502 - accuracy: 0.9741 - val_loss: 2.3226 - val_accuracy: 0.6207\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0651 - accuracy: 0.9828 - val_loss: 2.3577 - val_accuracy: 0.6552\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0856 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0613 - accuracy: 0.9569 - val_loss: 2.4185 - val_accuracy: 0.6552\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0447 - accuracy: 1.0000 - val_loss: 2.5270 - val_accuracy: 0.6897\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0124 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0537 - accuracy: 0.9741 - val_loss: 2.7431 - val_accuracy: 0.6207\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0669 - accuracy: 0.9828 - val_loss: 2.7061 - val_accuracy: 0.6552\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0971 - accuracy: 0.9569 - val_loss: 3.0447 - val_accuracy: 0.6552\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0772 - accuracy: 0.9569 - val_loss: 3.0492 - val_accuracy: 0.6552\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0274 - accuracy: 1.0000 - val_loss: 2.8571 - val_accuracy: 0.6552\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0935 - accuracy: 0.93 - 0s 129us/sample - loss: 0.0476 - accuracy: 0.9828 - val_loss: 2.8076 - val_accuracy: 0.6552\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0294 - accuracy: 1.0000 - val_loss: 2.9233 - val_accuracy: 0.6207\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0206 - accuracy: 1.0000 - val_loss: 3.1287 - val_accuracy: 0.6552\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0169 - accuracy: 1.0000 - val_loss: 3.3247 - val_accuracy: 0.5862\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0156 - accuracy: 1.0000 - val_loss: 3.4319 - val_accuracy: 0.6207\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0092 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0109 - accuracy: 1.0000 - val_loss: 3.4869 - val_accuracy: 0.6207\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0092 - accuracy: 1.0000 - val_loss: 3.4787 - val_accuracy: 0.5862\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 3.4587 - val_accuracy: 0.5862\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0082 - accuracy: 1.0000 - val_loss: 3.4542 - val_accuracy: 0.6552\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 3.5448 - val_accuracy: 0.6207\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.5563 - val_accuracy: 0.6552\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 3.5858 - val_accuracy: 0.5862\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.5915 - val_accuracy: 0.5862\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0051 - accuracy: 1.0000 - val_loss: 3.6095 - val_accuracy: 0.6207\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.6664 - val_accuracy: 0.6207\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.00 - 0s 151us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 3.7240 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.7526 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.7752 - val_accuracy: 0.6207\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.8001 - val_accuracy: 0.6207\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 3.7944 - val_accuracy: 0.6552\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.8038 - val_accuracy: 0.6207\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.8388 - val_accuracy: 0.6207\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.8652 - val_accuracy: 0.6207\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.8840 - val_accuracy: 0.6207\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 148us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.8958 - val_accuracy: 0.6207\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.9235 - val_accuracy: 0.6207\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.9271 - val_accuracy: 0.6207\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.9264 - val_accuracy: 0.6207\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.9457 - val_accuracy: 0.6552\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.00 - 0s 140us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.9874 - val_accuracy: 0.6552\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.9929 - val_accuracy: 0.6552\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.0011 - val_accuracy: 0.6207\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.0102 - val_accuracy: 0.6207\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.0214 - val_accuracy: 0.6207\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.0422 - val_accuracy: 0.6207\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.0722 - val_accuracy: 0.6552\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.0939 - val_accuracy: 0.6552\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.1097 - val_accuracy: 0.6207\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.1123 - val_accuracy: 0.6207\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.1294 - val_accuracy: 0.6207\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.1526 - val_accuracy: 0.6552\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.1737 - val_accuracy: 0.6552\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.1829 - val_accuracy: 0.6207\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3346e-04 - accuracy: 1.00 - 0s 162us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.1937 - val_accuracy: 0.6207\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.1977 - val_accuracy: 0.6207\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4312e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.2015 - val_accuracy: 0.6207\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.2064 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.2322 - val_accuracy: 0.6207\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.2448 - val_accuracy: 0.6207\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.2533 - val_accuracy: 0.6552\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4754e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.2725 - val_accuracy: 0.6207\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7136e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.2908 - val_accuracy: 0.6207\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 125us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.3053 - val_accuracy: 0.6207\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7235e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.3057 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.6235e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.3014 - val_accuracy: 0.6207\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2339e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.3120 - val_accuracy: 0.6207\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.3424 - val_accuracy: 0.6207\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.3526 - val_accuracy: 0.6207\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.3583 - val_accuracy: 0.6207\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8218e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.3666 - val_accuracy: 0.6207\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.3806 - val_accuracy: 0.6207\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7446e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 9.6833e-04 - accuracy: 1.0000 - val_loss: 4.3891 - val_accuracy: 0.6207\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 146us/sample - loss: 9.4355e-04 - accuracy: 1.0000 - val_loss: 4.4099 - val_accuracy: 0.6207\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 146us/sample - loss: 9.3035e-04 - accuracy: 1.0000 - val_loss: 4.4208 - val_accuracy: 0.5862\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7775e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 9.1538e-04 - accuracy: 1.0000 - val_loss: 4.4242 - val_accuracy: 0.6207\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4345e-04 - accuracy: 1.00 - 0s 181us/sample - loss: 8.9121e-04 - accuracy: 1.0000 - val_loss: 4.4265 - val_accuracy: 0.5862\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2322e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.7244e-04 - accuracy: 1.0000 - val_loss: 4.4421 - val_accuracy: 0.5862\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 163us/sample - loss: 8.7624e-04 - accuracy: 1.0000 - val_loss: 4.4593 - val_accuracy: 0.5862\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.1423e-04 - accuracy: 1.00 - 0s 181us/sample - loss: 8.5234e-04 - accuracy: 1.0000 - val_loss: 4.4599 - val_accuracy: 0.6207\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0257e-04 - accuracy: 1.00 - 0s 198us/sample - loss: 8.5108e-04 - accuracy: 1.0000 - val_loss: 4.4655 - val_accuracy: 0.6207\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 198us/sample - loss: 8.3056e-04 - accuracy: 1.0000 - val_loss: 4.4859 - val_accuracy: 0.6207\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 155us/sample - loss: 7.9063e-04 - accuracy: 1.0000 - val_loss: 4.4900 - val_accuracy: 0.6207\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9847e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 7.5932e-04 - accuracy: 1.0000 - val_loss: 4.4987 - val_accuracy: 0.6207\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 1.7006e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 7.5362e-04 - accuracy: 1.0000 - val_loss: 4.5147 - val_accuracy: 0.6207\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8915e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 7.6563e-04 - accuracy: 1.0000 - val_loss: 4.5257 - val_accuracy: 0.6207\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 163us/sample - loss: 7.4717e-04 - accuracy: 1.0000 - val_loss: 4.5410 - val_accuracy: 0.5862\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 181us/sample - loss: 7.5216e-04 - accuracy: 1.0000 - val_loss: 4.5478 - val_accuracy: 0.5862\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0856e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.4774e-04 - accuracy: 1.0000 - val_loss: 4.5403 - val_accuracy: 0.6207\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3616e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.8522e-04 - accuracy: 1.0000 - val_loss: 4.5544 - val_accuracy: 0.6207\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7299e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.5581e-04 - accuracy: 1.0000 - val_loss: 4.5743 - val_accuracy: 0.6207\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7850e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 6.6410e-04 - accuracy: 1.0000 - val_loss: 4.5899 - val_accuracy: 0.5862\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0685e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.4927e-04 - accuracy: 1.0000 - val_loss: 4.5962 - val_accuracy: 0.6207\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3511e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 6.4038e-04 - accuracy: 1.0000 - val_loss: 4.6000 - val_accuracy: 0.6207\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9889e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 6.2188e-04 - accuracy: 1.0000 - val_loss: 4.6179 - val_accuracy: 0.6207\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2517e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 6.0584e-04 - accuracy: 1.0000 - val_loss: 4.6296 - val_accuracy: 0.5862\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4769e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 6.0924e-04 - accuracy: 1.0000 - val_loss: 4.6412 - val_accuracy: 0.5862\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1023e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.8805e-04 - accuracy: 1.0000 - val_loss: 4.6444 - val_accuracy: 0.5862\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5774e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.7327e-04 - accuracy: 1.0000 - val_loss: 4.6439 - val_accuracy: 0.6552\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8109e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.8176e-04 - accuracy: 1.0000 - val_loss: 4.6537 - val_accuracy: 0.6552\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0041e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.7525e-04 - accuracy: 1.0000 - val_loss: 4.6737 - val_accuracy: 0.6207\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6454e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.5582e-04 - accuracy: 1.0000 - val_loss: 4.6780 - val_accuracy: 0.6207\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4280e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.3869e-04 - accuracy: 1.0000 - val_loss: 4.6830 - val_accuracy: 0.6207\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7869e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.2771e-04 - accuracy: 1.0000 - val_loss: 4.6908 - val_accuracy: 0.5862\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8722e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.2001e-04 - accuracy: 1.0000 - val_loss: 4.7014 - val_accuracy: 0.5862\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9641e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.1091e-04 - accuracy: 1.0000 - val_loss: 4.7107 - val_accuracy: 0.5862\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5032e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.0465e-04 - accuracy: 1.0000 - val_loss: 4.7218 - val_accuracy: 0.6207\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6200e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.9686e-04 - accuracy: 1.0000 - val_loss: 4.7283 - val_accuracy: 0.6207\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2847e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.8788e-04 - accuracy: 1.0000 - val_loss: 4.7305 - val_accuracy: 0.5862\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5800e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.7627e-04 - accuracy: 1.0000 - val_loss: 4.7395 - val_accuracy: 0.5862\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1942e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.7453e-04 - accuracy: 1.0000 - val_loss: 4.7538 - val_accuracy: 0.5862\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1314e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.6881e-04 - accuracy: 1.0000 - val_loss: 4.7569 - val_accuracy: 0.5862\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5516e-04 - accuracy: 1.00 - 0s 150us/sample - loss: 4.5345e-04 - accuracy: 1.0000 - val_loss: 4.7625 - val_accuracy: 0.6207\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5791e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.4978e-04 - accuracy: 1.0000 - val_loss: 4.7674 - val_accuracy: 0.6207\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2616e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.4096e-04 - accuracy: 1.0000 - val_loss: 4.7750 - val_accuracy: 0.5862\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5439e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.3033e-04 - accuracy: 1.0000 - val_loss: 4.7834 - val_accuracy: 0.5862\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4633e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.2802e-04 - accuracy: 1.0000 - val_loss: 4.7914 - val_accuracy: 0.5862\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7285e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.1732e-04 - accuracy: 1.0000 - val_loss: 4.8007 - val_accuracy: 0.5862\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7765e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 4.1688e-04 - accuracy: 1.0000 - val_loss: 4.8054 - val_accuracy: 0.6207\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2492e-04 - accuracy: 1.00 - 0s 275us/sample - loss: 4.0886e-04 - accuracy: 1.0000 - val_loss: 4.8184 - val_accuracy: 0.6207\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6072e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.9892e-04 - accuracy: 1.0000 - val_loss: 4.8280 - val_accuracy: 0.6207\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9750e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.9635e-04 - accuracy: 1.0000 - val_loss: 4.8376 - val_accuracy: 0.6207\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7487e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.8865e-04 - accuracy: 1.0000 - val_loss: 4.8517 - val_accuracy: 0.5862\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0206e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.8697e-04 - accuracy: 1.0000 - val_loss: 4.8631 - val_accuracy: 0.5862\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3327e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.7759e-04 - accuracy: 1.0000 - val_loss: 4.8672 - val_accuracy: 0.5862\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3114e-04 - accuracy: 1.00 - 0s 164us/sample - loss: 3.7707e-04 - accuracy: 1.0000 - val_loss: 4.8737 - val_accuracy: 0.5862\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8860e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.7077e-04 - accuracy: 1.0000 - val_loss: 4.8862 - val_accuracy: 0.6207\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4398e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.6705e-04 - accuracy: 1.0000 - val_loss: 4.8975 - val_accuracy: 0.5862\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5340e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.5978e-04 - accuracy: 1.0000 - val_loss: 4.8946 - val_accuracy: 0.5862\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9577e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.5286e-04 - accuracy: 1.0000 - val_loss: 4.8946 - val_accuracy: 0.5862\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1813e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.6116e-04 - accuracy: 1.0000 - val_loss: 4.9094 - val_accuracy: 0.5862\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0323e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.4553e-04 - accuracy: 1.0000 - val_loss: 4.9198 - val_accuracy: 0.6207\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1656e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.3992e-04 - accuracy: 1.0000 - val_loss: 4.9322 - val_accuracy: 0.6207\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8385e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.4782e-04 - accuracy: 1.0000 - val_loss: 4.9351 - val_accuracy: 0.6207\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6718e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.2947e-04 - accuracy: 1.0000 - val_loss: 4.9475 - val_accuracy: 0.5862\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3041e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.3402e-04 - accuracy: 1.0000 - val_loss: 4.9550 - val_accuracy: 0.5862\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2695e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.2345e-04 - accuracy: 1.0000 - val_loss: 4.9587 - val_accuracy: 0.5862\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6491e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 3.1725e-04 - accuracy: 1.0000 - val_loss: 4.9680 - val_accuracy: 0.5862\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6110e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.1525e-04 - accuracy: 1.0000 - val_loss: 4.9777 - val_accuracy: 0.6207\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4780e-04 - accuracy: 1.00 - 0s 139us/sample - loss: 3.0515e-04 - accuracy: 1.0000 - val_loss: 4.9935 - val_accuracy: 0.6207\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6353e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.0002e-04 - accuracy: 1.0000 - val_loss: 5.0064 - val_accuracy: 0.6207\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0541e-04 - accuracy: 1.00 - 0s 147us/sample - loss: 2.9578e-04 - accuracy: 1.0000 - val_loss: 5.0192 - val_accuracy: 0.5862\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5275e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.9474e-04 - accuracy: 1.0000 - val_loss: 5.0292 - val_accuracy: 0.5862\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2294e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.8612e-04 - accuracy: 1.0000 - val_loss: 5.0479 - val_accuracy: 0.6207\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4082e-04 - accuracy: 1.00 - 0s 125us/sample - loss: 2.8107e-04 - accuracy: 1.0000 - val_loss: 5.0643 - val_accuracy: 0.6207\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9328e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.7325e-04 - accuracy: 1.0000 - val_loss: 5.0880 - val_accuracy: 0.6207\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6683e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.5913e-04 - accuracy: 1.0000 - val_loss: 5.1161 - val_accuracy: 0.5862\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8100e-04 - accuracy: 1.00 - 0s 189us/sample - loss: 2.4767e-04 - accuracy: 1.0000 - val_loss: 5.1426 - val_accuracy: 0.5862\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0111e-04 - accuracy: 1.00 - 0s 181us/sample - loss: 2.4011e-04 - accuracy: 1.0000 - val_loss: 5.1729 - val_accuracy: 0.5862\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2567e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 2.3362e-04 - accuracy: 1.0000 - val_loss: 5.1981 - val_accuracy: 0.5862\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9845e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.2496e-04 - accuracy: 1.0000 - val_loss: 5.2161 - val_accuracy: 0.5862\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5069e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.1776e-04 - accuracy: 1.0000 - val_loss: 5.2426 - val_accuracy: 0.5862\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4806e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.1041e-04 - accuracy: 1.0000 - val_loss: 5.2666 - val_accuracy: 0.5862\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8600e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 2.0364e-04 - accuracy: 1.0000 - val_loss: 5.2934 - val_accuracy: 0.5862\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2926e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.9846e-04 - accuracy: 1.0000 - val_loss: 5.3260 - val_accuracy: 0.5862\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0594e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.9464e-04 - accuracy: 1.0000 - val_loss: 5.3512 - val_accuracy: 0.5862\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 2s - loss: 0.6980 - accuracy: 0.43 - 1s 9ms/sample - loss: 0.6422 - accuracy: 0.6293 - val_loss: 0.6525 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7072 - accuracy: 0.62 - 0s 456us/sample - loss: 0.6382 - accuracy: 0.6638 - val_loss: 0.6287 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5851 - accuracy: 0.68 - 0s 180us/sample - loss: 0.6082 - accuracy: 0.6724 - val_loss: 0.6214 - val_accuracy: 0.6207\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6127 - accuracy: 0.65 - 0s 146us/sample - loss: 0.5812 - accuracy: 0.6897 - val_loss: 0.6085 - val_accuracy: 0.6897\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5057 - accuracy: 0.71 - 0s 146us/sample - loss: 0.5676 - accuracy: 0.6897 - val_loss: 0.6089 - val_accuracy: 0.6207\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.62 - 0s 138us/sample - loss: 0.5808 - accuracy: 0.7414 - val_loss: 0.5983 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6583 - accuracy: 0.59 - 0s 138us/sample - loss: 0.5253 - accuracy: 0.7069 - val_loss: 0.6103 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5030 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5136 - accuracy: 0.7414 - val_loss: 0.6047 - val_accuracy: 0.5862\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5161 - accuracy: 0.59 - 0s 138us/sample - loss: 0.5662 - accuracy: 0.6638 - val_loss: 0.5998 - val_accuracy: 0.6552\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4731 - accuracy: 0.75 - 0s 129us/sample - loss: 0.4901 - accuracy: 0.7672 - val_loss: 0.6374 - val_accuracy: 0.6552\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6784 - accuracy: 0.59 - 0s 129us/sample - loss: 0.4961 - accuracy: 0.7500 - val_loss: 0.6053 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4096 - accuracy: 0.90 - 0s 129us/sample - loss: 0.4767 - accuracy: 0.7931 - val_loss: 0.6076 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4351 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4473 - accuracy: 0.7759 - val_loss: 0.6233 - val_accuracy: 0.7586\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4373 - accuracy: 0.75 - 0s 129us/sample - loss: 0.4468 - accuracy: 0.7759 - val_loss: 0.6282 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4427 - accuracy: 0.7672 - val_loss: 0.6591 - val_accuracy: 0.7241\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3158 - accuracy: 0.84 - 0s 120us/sample - loss: 0.4218 - accuracy: 0.8103 - val_loss: 0.6842 - val_accuracy: 0.5862\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4106 - accuracy: 0.90 - 0s 120us/sample - loss: 0.3819 - accuracy: 0.8362 - val_loss: 0.7084 - val_accuracy: 0.6897\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3687 - accuracy: 0.75 - 0s 138us/sample - loss: 0.3829 - accuracy: 0.7845 - val_loss: 0.7013 - val_accuracy: 0.7241\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3604 - accuracy: 0.84 - 0s 138us/sample - loss: 0.3915 - accuracy: 0.8190 - val_loss: 0.7050 - val_accuracy: 0.6552\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2765 - accuracy: 0.90 - 0s 138us/sample - loss: 0.3577 - accuracy: 0.8362 - val_loss: 0.7627 - val_accuracy: 0.6897\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2498 - accuracy: 0.87 - 0s 129us/sample - loss: 0.2953 - accuracy: 0.8793 - val_loss: 0.7916 - val_accuracy: 0.6552\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3367 - accuracy: 0.87 - 0s 129us/sample - loss: 0.3040 - accuracy: 0.8793 - val_loss: 0.8034 - val_accuracy: 0.7241\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3270 - accuracy: 0.81 - 0s 129us/sample - loss: 0.2798 - accuracy: 0.8879 - val_loss: 0.8119 - val_accuracy: 0.7241\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2667 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2574 - accuracy: 0.9224 - val_loss: 0.8811 - val_accuracy: 0.7241\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2597 - accuracy: 0.9052 - val_loss: 0.9421 - val_accuracy: 0.6897\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.96 - 0s 129us/sample - loss: 0.2670 - accuracy: 0.8707 - val_loss: 0.8966 - val_accuracy: 0.7241\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2429 - accuracy: 0.9224 - val_loss: 1.0031 - val_accuracy: 0.7586\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2576 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2335 - accuracy: 0.9052 - val_loss: 1.0525 - val_accuracy: 0.6897\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.90 - 0s 138us/sample - loss: 0.2107 - accuracy: 0.9052 - val_loss: 1.0803 - val_accuracy: 0.7241\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1997 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2191 - accuracy: 0.9138 - val_loss: 1.2753 - val_accuracy: 0.6552\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1422 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1661 - accuracy: 0.9310 - val_loss: 1.2885 - val_accuracy: 0.7241\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0735 - accuracy: 1.00 - 0s 138us/sample - loss: 0.1803 - accuracy: 0.9310 - val_loss: 1.3085 - val_accuracy: 0.6552\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1777 - accuracy: 0.9397 - val_loss: 1.3306 - val_accuracy: 0.7241\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1728 - accuracy: 0.9310 - val_loss: 1.3683 - val_accuracy: 0.6207\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2076 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1448 - accuracy: 0.9569 - val_loss: 1.4068 - val_accuracy: 0.7241\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1379 - accuracy: 0.9655 - val_loss: 1.5695 - val_accuracy: 0.6552\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1476 - accuracy: 0.96 - 0s 120us/sample - loss: 0.1084 - accuracy: 0.9741 - val_loss: 1.6762 - val_accuracy: 0.6897\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.96 - 0s 129us/sample - loss: 0.1088 - accuracy: 0.9483 - val_loss: 1.6548 - val_accuracy: 0.6897\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0998 - accuracy: 0.9741 - val_loss: 1.6032 - val_accuracy: 0.6552\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0940 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0903 - accuracy: 0.9828 - val_loss: 1.8120 - val_accuracy: 0.6207\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0529 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0844 - accuracy: 0.9741 - val_loss: 1.9155 - val_accuracy: 0.6207\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0906 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0638 - accuracy: 0.9828 - val_loss: 2.1160 - val_accuracy: 0.5862\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0601 - accuracy: 0.9741 - val_loss: 2.2244 - val_accuracy: 0.5517\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0465 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0474 - accuracy: 1.0000 - val_loss: 2.3893 - val_accuracy: 0.6552\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0494 - accuracy: 0.9828 - val_loss: 2.3381 - val_accuracy: 0.5862\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 1.00 - 0s 143us/sample - loss: 0.0352 - accuracy: 1.0000 - val_loss: 2.5095 - val_accuracy: 0.6552\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0367 - accuracy: 0.9914 - val_loss: 2.5307 - val_accuracy: 0.6207\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0299 - accuracy: 1.0000 - val_loss: 2.7041 - val_accuracy: 0.6552\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0327 - accuracy: 0.9828 - val_loss: 2.7555 - val_accuracy: 0.5862\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0241 - accuracy: 1.0000 - val_loss: 2.8513 - val_accuracy: 0.5862\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0189 - accuracy: 1.0000 - val_loss: 2.9951 - val_accuracy: 0.6207\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0150 - accuracy: 1.0000 - val_loss: 3.0514 - val_accuracy: 0.5862\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0143 - accuracy: 1.0000 - val_loss: 3.2122 - val_accuracy: 0.6207\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0147 - accuracy: 1.0000 - val_loss: 3.2194 - val_accuracy: 0.5862\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0119 - accuracy: 1.0000 - val_loss: 3.2939 - val_accuracy: 0.6207\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0084 - accuracy: 1.0000 - val_loss: 3.2535 - val_accuracy: 0.5862\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.3217 - val_accuracy: 0.6207\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.3949 - val_accuracy: 0.6207\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.4600 - val_accuracy: 0.6207\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.5118 - val_accuracy: 0.6207\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 3.5985 - val_accuracy: 0.6207\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.00 - 0s 130us/sample - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.5568 - val_accuracy: 0.6207\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 3.5656 - val_accuracy: 0.6207\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 3.7789 - val_accuracy: 0.6207\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 3.6337 - val_accuracy: 0.6207\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0262 - accuracy: 0.9828 - val_loss: 3.7968 - val_accuracy: 0.6552\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.96 - 0s 133us/sample - loss: 0.0160 - accuracy: 0.9914 - val_loss: 3.5876 - val_accuracy: 0.5862\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0249 - accuracy: 1.0000 - val_loss: 4.2880 - val_accuracy: 0.6552\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0446 - accuracy: 0.96 - 0s 120us/sample - loss: 0.0321 - accuracy: 0.9828 - val_loss: 4.2103 - val_accuracy: 0.5172\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0830 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0340 - accuracy: 0.9914 - val_loss: 4.6086 - val_accuracy: 0.6552\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0691 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0354 - accuracy: 0.9914 - val_loss: 4.3834 - val_accuracy: 0.5862\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 1.00 - 0s 124us/sample - loss: 0.0400 - accuracy: 0.9914 - val_loss: 4.4962 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0594 - accuracy: 0.9828 - val_loss: 4.4652 - val_accuracy: 0.5517\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 1.00 - 0s 129us/sample - loss: 0.1629 - accuracy: 0.9138 - val_loss: 4.4168 - val_accuracy: 0.6552\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1544 - accuracy: 0.90 - 0s 138us/sample - loss: 0.1185 - accuracy: 0.9397 - val_loss: 4.1811 - val_accuracy: 0.4483\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4541 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2941 - accuracy: 0.8879 - val_loss: 5.2078 - val_accuracy: 0.5517\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3971 - accuracy: 0.84 - 0s 133us/sample - loss: 0.2276 - accuracy: 0.9138 - val_loss: 4.6154 - val_accuracy: 0.5172\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.81 - 0s 129us/sample - loss: 0.2765 - accuracy: 0.8534 - val_loss: 4.9279 - val_accuracy: 0.6207\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3846 - accuracy: 0.81 - 0s 137us/sample - loss: 0.1736 - accuracy: 0.9224 - val_loss: 4.7411 - val_accuracy: 0.5172\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 0.93 - 0s 129us/sample - loss: 0.1412 - accuracy: 0.9397 - val_loss: 3.8528 - val_accuracy: 0.5517\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0677 - accuracy: 0.9741 - val_loss: 3.3532 - val_accuracy: 0.6207\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0826 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0716 - accuracy: 0.9569 - val_loss: 3.2547 - val_accuracy: 0.6552\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0611 - accuracy: 0.9914 - val_loss: 3.2928 - val_accuracy: 0.6552\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0412 - accuracy: 1.0000 - val_loss: 3.3835 - val_accuracy: 0.7241\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0301 - accuracy: 1.0000 - val_loss: 3.4049 - val_accuracy: 0.6897\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0374 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0303 - accuracy: 1.0000 - val_loss: 3.4391 - val_accuracy: 0.6897\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0176 - accuracy: 1.0000 - val_loss: 3.5108 - val_accuracy: 0.6897\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0159 - accuracy: 1.0000 - val_loss: 3.5848 - val_accuracy: 0.6897\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0129 - accuracy: 1.0000 - val_loss: 3.6099 - val_accuracy: 0.6552\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0140 - accuracy: 1.0000 - val_loss: 3.6905 - val_accuracy: 0.6552\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0102 - accuracy: 1.0000 - val_loss: 3.8484 - val_accuracy: 0.6897\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0143 - accuracy: 0.9914 - val_loss: 3.7899 - val_accuracy: 0.6552\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 3.7301 - val_accuracy: 0.6552\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0110 - accuracy: 1.0000 - val_loss: 3.8092 - val_accuracy: 0.6552\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 3.9055 - val_accuracy: 0.6552\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 3.9016 - val_accuracy: 0.6552\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.9062 - val_accuracy: 0.6552\n",
      "Epoch 98/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.0044 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.9524 - val_accuracy: 0.6552\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 4.0085 - val_accuracy: 0.6897\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 3.9891 - val_accuracy: 0.6897\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.9863 - val_accuracy: 0.6552\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.0037 - val_accuracy: 0.6552\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.0234 - val_accuracy: 0.6897\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5461e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.0341 - val_accuracy: 0.6897\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.0080 - val_accuracy: 0.6552\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 4.0444 - val_accuracy: 0.6552\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.0853 - val_accuracy: 0.6897\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.1346 - val_accuracy: 0.6897\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.1091 - val_accuracy: 0.6552\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 4.1226 - val_accuracy: 0.6897\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.1346 - val_accuracy: 0.6897\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.1528 - val_accuracy: 0.6897\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.1634 - val_accuracy: 0.6897\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 4.1970 - val_accuracy: 0.6897\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 4.1910 - val_accuracy: 0.6897\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.1766 - val_accuracy: 0.6552\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 4.2135 - val_accuracy: 0.6897\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.2477 - val_accuracy: 0.6897\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.2543 - val_accuracy: 0.6897\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.2556 - val_accuracy: 0.6897\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.2610 - val_accuracy: 0.6897\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 112us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.2677 - val_accuracy: 0.6552\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.2804 - val_accuracy: 0.6552\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.3001 - val_accuracy: 0.6897\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.3096 - val_accuracy: 0.6897\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.2934 - val_accuracy: 0.6552\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9013e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.2994 - val_accuracy: 0.6552\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.3499 - val_accuracy: 0.6897\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.3689 - val_accuracy: 0.6897\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 112us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.3544 - val_accuracy: 0.6897\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.3698 - val_accuracy: 0.6897\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0106e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.3661 - val_accuracy: 0.6552\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.3791 - val_accuracy: 0.6552\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.4011 - val_accuracy: 0.6897\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 112us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.4030 - val_accuracy: 0.6897\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7557e-04 - accuracy: 1.00 - 0s 112us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.4113 - val_accuracy: 0.6552\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1680e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.4251 - val_accuracy: 0.6897\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.4135 - val_accuracy: 0.6552\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.4447 - val_accuracy: 0.6897\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7223e-04 - accuracy: 1.00 - 0s 112us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.4552 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5377e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 9.8497e-04 - accuracy: 1.0000 - val_loss: 4.4591 - val_accuracy: 0.6897\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8331e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 9.5489e-04 - accuracy: 1.0000 - val_loss: 4.4629 - val_accuracy: 0.6897\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0365e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 9.3704e-04 - accuracy: 1.0000 - val_loss: 4.4725 - val_accuracy: 0.6897\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4954e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 9.0421e-04 - accuracy: 1.0000 - val_loss: 4.4810 - val_accuracy: 0.6897\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5400e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 8.8682e-04 - accuracy: 1.0000 - val_loss: 4.4935 - val_accuracy: 0.6897\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2993e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 8.8556e-04 - accuracy: 1.0000 - val_loss: 4.4840 - val_accuracy: 0.6552\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 129us/sample - loss: 8.4682e-04 - accuracy: 1.0000 - val_loss: 4.5089 - val_accuracy: 0.6897\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0419e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 8.3427e-04 - accuracy: 1.0000 - val_loss: 4.5346 - val_accuracy: 0.6897\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9859e-04 - accuracy: 1.00 - 0s 112us/sample - loss: 7.9052e-04 - accuracy: 1.0000 - val_loss: 4.5313 - val_accuracy: 0.6897\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3650e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 7.9108e-04 - accuracy: 1.0000 - val_loss: 4.5255 - val_accuracy: 0.6897\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5180e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.4396e-04 - accuracy: 1.0000 - val_loss: 4.5438 - val_accuracy: 0.6897\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3556e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.2457e-04 - accuracy: 1.0000 - val_loss: 4.5644 - val_accuracy: 0.6897\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1676e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.2311e-04 - accuracy: 1.0000 - val_loss: 4.5730 - val_accuracy: 0.6897\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2685e-04 - accuracy: 1.00 - 0s 133us/sample - loss: 6.8912e-04 - accuracy: 1.0000 - val_loss: 4.5651 - val_accuracy: 0.6897\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4837e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.8144e-04 - accuracy: 1.0000 - val_loss: 4.5699 - val_accuracy: 0.6552\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5989e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 6.5532e-04 - accuracy: 1.0000 - val_loss: 4.5989 - val_accuracy: 0.6897\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3841e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 6.5514e-04 - accuracy: 1.0000 - val_loss: 4.6121 - val_accuracy: 0.6897\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4859e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 6.2233e-04 - accuracy: 1.0000 - val_loss: 4.6054 - val_accuracy: 0.6897\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7203e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 6.0222e-04 - accuracy: 1.0000 - val_loss: 4.6121 - val_accuracy: 0.6897\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.2508e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.8554e-04 - accuracy: 1.0000 - val_loss: 4.6302 - val_accuracy: 0.6897\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 129us/sample - loss: 5.7253e-04 - accuracy: 1.0000 - val_loss: 4.6395 - val_accuracy: 0.6897\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6645e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.5516e-04 - accuracy: 1.0000 - val_loss: 4.6539 - val_accuracy: 0.6897\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6651e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.4295e-04 - accuracy: 1.0000 - val_loss: 4.6696 - val_accuracy: 0.6897\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8364e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.3862e-04 - accuracy: 1.0000 - val_loss: 4.6761 - val_accuracy: 0.6897\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8353e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 5.1348e-04 - accuracy: 1.0000 - val_loss: 4.6969 - val_accuracy: 0.6552\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9438e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 5.2615e-04 - accuracy: 1.0000 - val_loss: 4.7201 - val_accuracy: 0.6552\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0406e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 5.0073e-04 - accuracy: 1.0000 - val_loss: 4.7138 - val_accuracy: 0.6552\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3927e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.8260e-04 - accuracy: 1.0000 - val_loss: 4.7244 - val_accuracy: 0.6207\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5579e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.7489e-04 - accuracy: 1.0000 - val_loss: 4.7482 - val_accuracy: 0.6552\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4867e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 4.6192e-04 - accuracy: 1.0000 - val_loss: 4.7846 - val_accuracy: 0.6552\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3631e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 4.6319e-04 - accuracy: 1.0000 - val_loss: 4.8096 - val_accuracy: 0.6552\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4442e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.4712e-04 - accuracy: 1.0000 - val_loss: 4.8042 - val_accuracy: 0.6552\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2089e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.2889e-04 - accuracy: 1.0000 - val_loss: 4.8136 - val_accuracy: 0.6552\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7398e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 4.1894e-04 - accuracy: 1.0000 - val_loss: 4.8361 - val_accuracy: 0.6552\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6361e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 4.1351e-04 - accuracy: 1.0000 - val_loss: 4.8617 - val_accuracy: 0.6552\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6123e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.0371e-04 - accuracy: 1.0000 - val_loss: 4.8700 - val_accuracy: 0.6552\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7930e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.9355e-04 - accuracy: 1.0000 - val_loss: 4.8894 - val_accuracy: 0.6552\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5405e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.8196e-04 - accuracy: 1.0000 - val_loss: 4.9171 - val_accuracy: 0.6552\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4417e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.7969e-04 - accuracy: 1.0000 - val_loss: 4.9371 - val_accuracy: 0.6552\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5161e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.8072e-04 - accuracy: 1.0000 - val_loss: 4.9342 - val_accuracy: 0.6552\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8151e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.6328e-04 - accuracy: 1.0000 - val_loss: 4.9508 - val_accuracy: 0.6552\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6506e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.5483e-04 - accuracy: 1.0000 - val_loss: 4.9778 - val_accuracy: 0.6552\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0833e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.6308e-04 - accuracy: 1.0000 - val_loss: 5.0037 - val_accuracy: 0.6552\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1624e-05 - accuracy: 1.00 - 0s 112us/sample - loss: 3.3576e-04 - accuracy: 1.0000 - val_loss: 5.0031 - val_accuracy: 0.6552\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6062e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.2898e-04 - accuracy: 1.0000 - val_loss: 5.0144 - val_accuracy: 0.6207\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1772e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.3251e-04 - accuracy: 1.0000 - val_loss: 5.0346 - val_accuracy: 0.6207\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7057e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.2054e-04 - accuracy: 1.0000 - val_loss: 5.0568 - val_accuracy: 0.6207\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9029e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.0674e-04 - accuracy: 1.0000 - val_loss: 5.0856 - val_accuracy: 0.6552\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7541e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 3.0439e-04 - accuracy: 1.0000 - val_loss: 5.1168 - val_accuracy: 0.6552\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7145e-04 - accuracy: 1.00 - 0s 112us/sample - loss: 3.1783e-04 - accuracy: 1.0000 - val_loss: 5.1352 - val_accuracy: 0.6552\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6099e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 2.9341e-04 - accuracy: 1.0000 - val_loss: 5.1276 - val_accuracy: 0.6207\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6514e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 2.8733e-04 - accuracy: 1.0000 - val_loss: 5.1288 - val_accuracy: 0.6207\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8334e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.8917e-04 - accuracy: 1.0000 - val_loss: 5.1503 - val_accuracy: 0.6207\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6904e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.8088e-04 - accuracy: 1.0000 - val_loss: 5.1750 - val_accuracy: 0.6207\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3446e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.7339e-04 - accuracy: 1.0000 - val_loss: 5.1972 - val_accuracy: 0.6552\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5723e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.6922e-04 - accuracy: 1.0000 - val_loss: 5.2247 - val_accuracy: 0.6552\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5140e-04 - accuracy: 1.00 - 0s 112us/sample - loss: 2.6509e-04 - accuracy: 1.0000 - val_loss: 5.2389 - val_accuracy: 0.6552\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7466e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.6155e-04 - accuracy: 1.0000 - val_loss: 5.2398 - val_accuracy: 0.6207\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.9911e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.5224e-04 - accuracy: 1.0000 - val_loss: 5.2507 - val_accuracy: 0.6207\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7107e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.4999e-04 - accuracy: 1.0000 - val_loss: 5.2750 - val_accuracy: 0.6207\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6960 - accuracy: 0.37 - 0s 3ms/sample - loss: 0.6590 - accuracy: 0.6121 - val_loss: 0.6559 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5841 - accuracy: 0.71 - 0s 138us/sample - loss: 0.6258 - accuracy: 0.6638 - val_loss: 0.6528 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6432 - accuracy: 0.68 - 0s 142us/sample - loss: 0.6443 - accuracy: 0.6552 - val_loss: 0.6338 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6108 - accuracy: 0.68 - 0s 138us/sample - loss: 0.6092 - accuracy: 0.6724 - val_loss: 0.6325 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.71 - 0s 138us/sample - loss: 0.5978 - accuracy: 0.6810 - val_loss: 0.6171 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6020 - accuracy: 0.71 - 0s 137us/sample - loss: 0.5713 - accuracy: 0.7328 - val_loss: 0.6111 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5723 - accuracy: 0.75 - 0s 138us/sample - loss: 0.5651 - accuracy: 0.7328 - val_loss: 0.6013 - val_accuracy: 0.6897\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4876 - accuracy: 0.78 - 0s 129us/sample - loss: 0.5428 - accuracy: 0.7414 - val_loss: 0.5866 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6551 - accuracy: 0.59 - 0s 138us/sample - loss: 0.5267 - accuracy: 0.7414 - val_loss: 0.5791 - val_accuracy: 0.6897\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4151 - accuracy: 0.84 - 0s 155us/sample - loss: 0.5007 - accuracy: 0.7414 - val_loss: 0.5748 - val_accuracy: 0.6897\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4348 - accuracy: 0.81 - 0s 181us/sample - loss: 0.4684 - accuracy: 0.7759 - val_loss: 0.6083 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4415 - accuracy: 0.78 - 0s 181us/sample - loss: 0.4589 - accuracy: 0.7845 - val_loss: 0.5917 - val_accuracy: 0.7241\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5153 - accuracy: 0.71 - 0s 155us/sample - loss: 0.4290 - accuracy: 0.7931 - val_loss: 0.6051 - val_accuracy: 0.7241\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4375 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4101 - accuracy: 0.8017 - val_loss: 0.6120 - val_accuracy: 0.7241\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3806 - accuracy: 0.8362 - val_loss: 0.6343 - val_accuracy: 0.6897\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3191 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3638 - accuracy: 0.8534 - val_loss: 0.6412 - val_accuracy: 0.7241\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.87 - 0s 138us/sample - loss: 0.3495 - accuracy: 0.8362 - val_loss: 0.6403 - val_accuracy: 0.6897\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2236 - accuracy: 0.96 - 0s 155us/sample - loss: 0.3417 - accuracy: 0.8707 - val_loss: 0.6428 - val_accuracy: 0.7241\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3352 - accuracy: 0.8190 - val_loss: 0.6550 - val_accuracy: 0.7241\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2904 - accuracy: 0.87 - 0s 146us/sample - loss: 0.3198 - accuracy: 0.8879 - val_loss: 0.6865 - val_accuracy: 0.7241\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3541 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3031 - accuracy: 0.8879 - val_loss: 0.6980 - val_accuracy: 0.7241\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2719 - accuracy: 0.8966 - val_loss: 0.7279 - val_accuracy: 0.6552\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2453 - accuracy: 0.9052 - val_loss: 0.7345 - val_accuracy: 0.7586\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.1260 - accuracy: 0.93 - 0s 163us/sample - loss: 0.2330 - accuracy: 0.9138 - val_loss: 0.7838 - val_accuracy: 0.6897\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1072 - accuracy: 1.00 - 0s 138us/sample - loss: 0.2272 - accuracy: 0.8879 - val_loss: 0.8570 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 1.00 - 0s 138us/sample - loss: 0.2622 - accuracy: 0.8707 - val_loss: 0.8744 - val_accuracy: 0.7241\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1984 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2260 - accuracy: 0.9138 - val_loss: 0.9185 - val_accuracy: 0.7241\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2402 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1848 - accuracy: 0.9310 - val_loss: 0.9796 - val_accuracy: 0.7241\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2030 - accuracy: 0.9052 - val_loss: 1.0849 - val_accuracy: 0.6552\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0955 - accuracy: 1.00 - 0s 172us/sample - loss: 0.2040 - accuracy: 0.9052 - val_loss: 1.2658 - val_accuracy: 0.6552\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.96 - 0s 155us/sample - loss: 0.2005 - accuracy: 0.9138 - val_loss: 1.2470 - val_accuracy: 0.6552\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1768 - accuracy: 0.9397 - val_loss: 1.1039 - val_accuracy: 0.6897\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1594 - accuracy: 0.9397 - val_loss: 1.3545 - val_accuracy: 0.5862\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1522 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1508 - accuracy: 0.9310 - val_loss: 1.3891 - val_accuracy: 0.6897\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1136 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1202 - accuracy: 0.9569 - val_loss: 1.3978 - val_accuracy: 0.5862\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1090 - accuracy: 1.00 - 0s 137us/sample - loss: 0.1120 - accuracy: 0.9828 - val_loss: 1.4056 - val_accuracy: 0.6897\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1394 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1066 - accuracy: 0.9741 - val_loss: 1.5617 - val_accuracy: 0.6207\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0883 - accuracy: 0.9655 - val_loss: 1.7604 - val_accuracy: 0.6207\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0683 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0817 - accuracy: 0.9741 - val_loss: 1.9356 - val_accuracy: 0.5862\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0968 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0794 - accuracy: 0.9741 - val_loss: 1.9334 - val_accuracy: 0.6207\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0634 - accuracy: 1.0000 - val_loss: 1.9632 - val_accuracy: 0.6552\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0551 - accuracy: 1.0000 - val_loss: 2.0553 - val_accuracy: 0.6552\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 1.00 - 0s 165us/sample - loss: 0.0478 - accuracy: 1.0000 - val_loss: 2.1625 - val_accuracy: 0.6207\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0481 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0414 - accuracy: 1.0000 - val_loss: 2.2656 - val_accuracy: 0.6552\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0351 - accuracy: 1.0000 - val_loss: 2.3048 - val_accuracy: 0.6207\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0331 - accuracy: 1.0000 - val_loss: 2.3614 - val_accuracy: 0.6207\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0304 - accuracy: 1.0000 - val_loss: 2.4902 - val_accuracy: 0.6552\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 1.00 - 0s 151us/sample - loss: 0.0317 - accuracy: 0.9914 - val_loss: 2.5794 - val_accuracy: 0.6552\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0384 - accuracy: 1.0000 - val_loss: 2.6580 - val_accuracy: 0.6897\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0521 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0304 - accuracy: 1.0000 - val_loss: 2.6529 - val_accuracy: 0.6552\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0232 - accuracy: 1.0000 - val_loss: 2.7162 - val_accuracy: 0.6552\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.8562 - val_accuracy: 0.6552\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0156 - accuracy: 1.0000 - val_loss: 2.8984 - val_accuracy: 0.6552\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0173 - accuracy: 1.0000 - val_loss: 2.9373 - val_accuracy: 0.6897\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0127 - accuracy: 1.0000 - val_loss: 2.9542 - val_accuracy: 0.6897\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0105 - accuracy: 1.0000 - val_loss: 2.9851 - val_accuracy: 0.6897\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 1.00 - 0s 147us/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 3.0288 - val_accuracy: 0.6897\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 3.0772 - val_accuracy: 0.6552\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0077 - accuracy: 1.0000 - val_loss: 3.1359 - val_accuracy: 0.6552\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.1689 - val_accuracy: 0.6897\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1685 - val_accuracy: 0.6552\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.2142 - val_accuracy: 0.6552\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.2761 - val_accuracy: 0.6552\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0061 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0055 - accuracy: 1.0000 - val_loss: 3.3209 - val_accuracy: 0.6552\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 3.3376 - val_accuracy: 0.6897\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.3751 - val_accuracy: 0.6897\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0030 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.3778 - val_accuracy: 0.6552\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.3943 - val_accuracy: 0.6552\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.4620 - val_accuracy: 0.6897\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.4679 - val_accuracy: 0.6552\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.4781 - val_accuracy: 0.6552\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.5179 - val_accuracy: 0.6552\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.5174 - val_accuracy: 0.6552\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.5520 - val_accuracy: 0.6897\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.5911 - val_accuracy: 0.6897\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 157us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.6154 - val_accuracy: 0.6552\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.6245 - val_accuracy: 0.6552\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.6619 - val_accuracy: 0.6552\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.7064 - val_accuracy: 0.6897\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 148us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.7263 - val_accuracy: 0.6897\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.7316 - val_accuracy: 0.6552\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.7537 - val_accuracy: 0.6552\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.7801 - val_accuracy: 0.6552\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 198us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.8030 - val_accuracy: 0.6552\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.8300 - val_accuracy: 0.6552\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.8409 - val_accuracy: 0.6552\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.8586 - val_accuracy: 0.6552\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.8825 - val_accuracy: 0.6552\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.9054 - val_accuracy: 0.6552\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.9101 - val_accuracy: 0.6552\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.9319 - val_accuracy: 0.6552\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.9576 - val_accuracy: 0.6552\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.9730 - val_accuracy: 0.6552\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.9913 - val_accuracy: 0.6552\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.0215 - val_accuracy: 0.6552\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.0429 - val_accuracy: 0.6552\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.0623 - val_accuracy: 0.6552\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9847e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.0757 - val_accuracy: 0.6552\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0877e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.1012 - val_accuracy: 0.6552\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0145e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.1182 - val_accuracy: 0.6552\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.1269 - val_accuracy: 0.6552\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.1514 - val_accuracy: 0.6552\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.1570 - val_accuracy: 0.6552\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.1795 - val_accuracy: 0.6552\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.1963 - val_accuracy: 0.6552\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.2137 - val_accuracy: 0.6552\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3756e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.2197 - val_accuracy: 0.6552\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0586e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.2399 - val_accuracy: 0.6552\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9235e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.2587 - val_accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 9.6455e-04 - accuracy: 1.0000 - val_loss: 4.2766 - val_accuracy: 0.6552\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 146us/sample - loss: 9.4592e-04 - accuracy: 1.0000 - val_loss: 4.2962 - val_accuracy: 0.6552\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 138us/sample - loss: 9.2586e-04 - accuracy: 1.0000 - val_loss: 4.3115 - val_accuracy: 0.6552\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0818e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 9.0638e-04 - accuracy: 1.0000 - val_loss: 4.3250 - val_accuracy: 0.6552\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0420e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 8.8693e-04 - accuracy: 1.0000 - val_loss: 4.3324 - val_accuracy: 0.6552\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.6037e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 8.6234e-04 - accuracy: 1.0000 - val_loss: 4.3533 - val_accuracy: 0.6552\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0135e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.3719e-04 - accuracy: 1.0000 - val_loss: 4.3700 - val_accuracy: 0.6552\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3716e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 8.3663e-04 - accuracy: 1.0000 - val_loss: 4.3797 - val_accuracy: 0.6552\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5179e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.8316e-04 - accuracy: 1.0000 - val_loss: 4.3836 - val_accuracy: 0.6552\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0788e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.0289e-04 - accuracy: 1.0000 - val_loss: 4.3969 - val_accuracy: 0.6552\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7253e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.8711e-04 - accuracy: 1.0000 - val_loss: 4.4170 - val_accuracy: 0.6552\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0562e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.5682e-04 - accuracy: 1.0000 - val_loss: 4.4331 - val_accuracy: 0.6552\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9822e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 7.4532e-04 - accuracy: 1.0000 - val_loss: 4.4412 - val_accuracy: 0.6552\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0437e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.2926e-04 - accuracy: 1.0000 - val_loss: 4.4586 - val_accuracy: 0.6552\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.9815e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.1515e-04 - accuracy: 1.0000 - val_loss: 4.4724 - val_accuracy: 0.6552\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4086e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.1597e-04 - accuracy: 1.0000 - val_loss: 4.4822 - val_accuracy: 0.6552\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3740e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.9200e-04 - accuracy: 1.0000 - val_loss: 4.4865 - val_accuracy: 0.6552\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0294e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 6.7635e-04 - accuracy: 1.0000 - val_loss: 4.4987 - val_accuracy: 0.6552\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4465e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.6404e-04 - accuracy: 1.0000 - val_loss: 4.5145 - val_accuracy: 0.6552\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4911e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 6.4219e-04 - accuracy: 1.0000 - val_loss: 4.5323 - val_accuracy: 0.6552\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.8903e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.3070e-04 - accuracy: 1.0000 - val_loss: 4.5461 - val_accuracy: 0.6552\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2571e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.1813e-04 - accuracy: 1.0000 - val_loss: 4.5590 - val_accuracy: 0.6552\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0954e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.0643e-04 - accuracy: 1.0000 - val_loss: 4.5678 - val_accuracy: 0.6552\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8640e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.9748e-04 - accuracy: 1.0000 - val_loss: 4.5794 - val_accuracy: 0.6552\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3250e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.9119e-04 - accuracy: 1.0000 - val_loss: 4.5904 - val_accuracy: 0.6552\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9654e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.7996e-04 - accuracy: 1.0000 - val_loss: 4.6003 - val_accuracy: 0.6552\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3631e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.8163e-04 - accuracy: 1.0000 - val_loss: 4.6238 - val_accuracy: 0.6552\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7712e-04 - accuracy: 1.00 - 0s 144us/sample - loss: 5.5565e-04 - accuracy: 1.0000 - val_loss: 4.6450 - val_accuracy: 0.6552\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8010e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.5134e-04 - accuracy: 1.0000 - val_loss: 4.6594 - val_accuracy: 0.6552\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1103e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.4310e-04 - accuracy: 1.0000 - val_loss: 4.6613 - val_accuracy: 0.6552\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5145e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.3163e-04 - accuracy: 1.0000 - val_loss: 4.6663 - val_accuracy: 0.6552\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6569e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.4064e-04 - accuracy: 1.0000 - val_loss: 4.6795 - val_accuracy: 0.6552\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5687e-04 - accuracy: 1.00 - 0s 143us/sample - loss: 5.1064e-04 - accuracy: 1.0000 - val_loss: 4.6983 - val_accuracy: 0.6552\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0044e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.0274e-04 - accuracy: 1.0000 - val_loss: 4.7099 - val_accuracy: 0.6552\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8085e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.9946e-04 - accuracy: 1.0000 - val_loss: 4.7161 - val_accuracy: 0.6552\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4466e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.8305e-04 - accuracy: 1.0000 - val_loss: 4.7229 - val_accuracy: 0.6552\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2817e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.7634e-04 - accuracy: 1.0000 - val_loss: 4.7361 - val_accuracy: 0.6552\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3836e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.6617e-04 - accuracy: 1.0000 - val_loss: 4.7494 - val_accuracy: 0.6552\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3391e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.6239e-04 - accuracy: 1.0000 - val_loss: 4.7649 - val_accuracy: 0.6552\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8028e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.5274e-04 - accuracy: 1.0000 - val_loss: 4.7756 - val_accuracy: 0.6552\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9462e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.4607e-04 - accuracy: 1.0000 - val_loss: 4.7836 - val_accuracy: 0.6552\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9884e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.4220e-04 - accuracy: 1.0000 - val_loss: 4.7945 - val_accuracy: 0.6552\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4268e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.3326e-04 - accuracy: 1.0000 - val_loss: 4.8001 - val_accuracy: 0.6552\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2544e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.3044e-04 - accuracy: 1.0000 - val_loss: 4.8101 - val_accuracy: 0.6552\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6517e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.1884e-04 - accuracy: 1.0000 - val_loss: 4.8155 - val_accuracy: 0.6552\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8292e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.1063e-04 - accuracy: 1.0000 - val_loss: 4.8216 - val_accuracy: 0.6552\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9731e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 4.1074e-04 - accuracy: 1.0000 - val_loss: 4.8326 - val_accuracy: 0.6552\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7996e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.1035e-04 - accuracy: 1.0000 - val_loss: 4.8471 - val_accuracy: 0.6552\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4569e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.0010e-04 - accuracy: 1.0000 - val_loss: 4.8559 - val_accuracy: 0.6552\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5419e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.9566e-04 - accuracy: 1.0000 - val_loss: 4.8603 - val_accuracy: 0.6552\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1212e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.8606e-04 - accuracy: 1.0000 - val_loss: 4.8701 - val_accuracy: 0.6552\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1510e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 3.8232e-04 - accuracy: 1.0000 - val_loss: 4.8810 - val_accuracy: 0.6552\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0306e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.7643e-04 - accuracy: 1.0000 - val_loss: 4.8919 - val_accuracy: 0.6552\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9190e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.7506e-04 - accuracy: 1.0000 - val_loss: 4.9002 - val_accuracy: 0.6552\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1432e-04 - accuracy: 1.00 - 0s 181us/sample - loss: 3.6508e-04 - accuracy: 1.0000 - val_loss: 4.9058 - val_accuracy: 0.6552\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3444e-04 - accuracy: 1.00 - 0s 452us/sample - loss: 3.5855e-04 - accuracy: 1.0000 - val_loss: 4.9120 - val_accuracy: 0.6552\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4779e-04 - accuracy: 1.00 - 0s 503us/sample - loss: 3.5617e-04 - accuracy: 1.0000 - val_loss: 4.9213 - val_accuracy: 0.6552\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9915e-04 - accuracy: 1.00 - 0s 499us/sample - loss: 3.5156e-04 - accuracy: 1.0000 - val_loss: 4.9334 - val_accuracy: 0.6552\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3826e-04 - accuracy: 1.00 - 0s 507us/sample - loss: 3.4599e-04 - accuracy: 1.0000 - val_loss: 4.9417 - val_accuracy: 0.6552\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1696e-04 - accuracy: 1.00 - 0s 524us/sample - loss: 3.4123e-04 - accuracy: 1.0000 - val_loss: 4.9511 - val_accuracy: 0.6552\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7890e-04 - accuracy: 1.00 - 0s 473us/sample - loss: 3.3418e-04 - accuracy: 1.0000 - val_loss: 4.9543 - val_accuracy: 0.6552\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4042e-04 - accuracy: 1.00 - 0s 473us/sample - loss: 3.3562e-04 - accuracy: 1.0000 - val_loss: 4.9604 - val_accuracy: 0.6552\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6112e-04 - accuracy: 1.00 - 0s 473us/sample - loss: 3.2797e-04 - accuracy: 1.0000 - val_loss: 4.9735 - val_accuracy: 0.6552\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3082e-04 - accuracy: 1.00 - 0s 464us/sample - loss: 3.2172e-04 - accuracy: 1.0000 - val_loss: 4.9880 - val_accuracy: 0.6552\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6216e-04 - accuracy: 1.00 - 0s 490us/sample - loss: 3.2041e-04 - accuracy: 1.0000 - val_loss: 4.9970 - val_accuracy: 0.6552\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0706e-04 - accuracy: 1.00 - 0s 464us/sample - loss: 3.1296e-04 - accuracy: 1.0000 - val_loss: 5.0044 - val_accuracy: 0.6552\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7850e-04 - accuracy: 1.00 - 0s 542us/sample - loss: 3.1159e-04 - accuracy: 1.0000 - val_loss: 5.0117 - val_accuracy: 0.6552\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5817e-04 - accuracy: 1.00 - 0s 447us/sample - loss: 3.0920e-04 - accuracy: 1.0000 - val_loss: 5.0205 - val_accuracy: 0.6552\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1057e-04 - accuracy: 1.00 - 0s 309us/sample - loss: 3.0646e-04 - accuracy: 1.0000 - val_loss: 5.0320 - val_accuracy: 0.6552\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7523e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.9924e-04 - accuracy: 1.0000 - val_loss: 5.0433 - val_accuracy: 0.6552\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4884e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 2.9482e-04 - accuracy: 1.0000 - val_loss: 5.0520 - val_accuracy: 0.6552\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0782e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.9337e-04 - accuracy: 1.0000 - val_loss: 5.0565 - val_accuracy: 0.6552\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9100e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.9304e-04 - accuracy: 1.0000 - val_loss: 5.0633 - val_accuracy: 0.6552\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3886e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.8845e-04 - accuracy: 1.0000 - val_loss: 5.0658 - val_accuracy: 0.6552\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3536e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.8613e-04 - accuracy: 1.0000 - val_loss: 5.0739 - val_accuracy: 0.6552\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3162e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.8088e-04 - accuracy: 1.0000 - val_loss: 5.0881 - val_accuracy: 0.6552\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3144e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.7282e-04 - accuracy: 1.0000 - val_loss: 5.0993 - val_accuracy: 0.6552\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8201e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.7686e-04 - accuracy: 1.0000 - val_loss: 5.1079 - val_accuracy: 0.6552\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4982e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.7882e-04 - accuracy: 1.0000 - val_loss: 5.1188 - val_accuracy: 0.6552\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9956e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.6868e-04 - accuracy: 1.0000 - val_loss: 5.1207 - val_accuracy: 0.6552\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6799e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.6140e-04 - accuracy: 1.0000 - val_loss: 5.1261 - val_accuracy: 0.6552\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2534e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.6421e-04 - accuracy: 1.0000 - val_loss: 5.1344 - val_accuracy: 0.6552\n",
      "Epoch 192/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 2.6752e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.6028e-04 - accuracy: 1.0000 - val_loss: 5.1457 - val_accuracy: 0.6552\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.9328e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.5304e-04 - accuracy: 1.0000 - val_loss: 5.1539 - val_accuracy: 0.6552\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7977e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.5424e-04 - accuracy: 1.0000 - val_loss: 5.1596 - val_accuracy: 0.6552\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0625e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.4752e-04 - accuracy: 1.0000 - val_loss: 5.1613 - val_accuracy: 0.6552\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2563e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.4641e-04 - accuracy: 1.0000 - val_loss: 5.1671 - val_accuracy: 0.6552\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3534e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.4319e-04 - accuracy: 1.0000 - val_loss: 5.1777 - val_accuracy: 0.6552\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3803e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.3772e-04 - accuracy: 1.0000 - val_loss: 5.1919 - val_accuracy: 0.6552\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1145e-04 - accuracy: 1.00 - 0s 140us/sample - loss: 2.3941e-04 - accuracy: 1.0000 - val_loss: 5.2068 - val_accuracy: 0.6552\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6530e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.3618e-04 - accuracy: 1.0000 - val_loss: 5.2127 - val_accuracy: 0.6552\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7006 - accuracy: 0.31 - 0s 3ms/sample - loss: 0.7118 - accuracy: 0.5431 - val_loss: 0.6443 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6243 - accuracy: 0.65 - 0s 155us/sample - loss: 0.6352 - accuracy: 0.6638 - val_loss: 0.6587 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6920 - accuracy: 0.50 - 0s 155us/sample - loss: 0.6361 - accuracy: 0.6724 - val_loss: 0.6419 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6583 - accuracy: 0.59 - 0s 146us/sample - loss: 0.6030 - accuracy: 0.6724 - val_loss: 0.6399 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5491 - accuracy: 0.71 - 0s 155us/sample - loss: 0.6050 - accuracy: 0.6724 - val_loss: 0.6313 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6669 - accuracy: 0.65 - 0s 155us/sample - loss: 0.5758 - accuracy: 0.7328 - val_loss: 0.6231 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5573 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5658 - accuracy: 0.7328 - val_loss: 0.6027 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6578 - accuracy: 0.62 - 0s 155us/sample - loss: 0.5452 - accuracy: 0.7414 - val_loss: 0.5928 - val_accuracy: 0.6552\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5546 - accuracy: 0.68 - 0s 146us/sample - loss: 0.5183 - accuracy: 0.7500 - val_loss: 0.5921 - val_accuracy: 0.6207\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.78 - 0s 146us/sample - loss: 0.5021 - accuracy: 0.7931 - val_loss: 0.5934 - val_accuracy: 0.6897\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5771 - accuracy: 0.65 - 0s 146us/sample - loss: 0.5018 - accuracy: 0.7414 - val_loss: 0.5860 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4454 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4761 - accuracy: 0.8276 - val_loss: 0.5888 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4240 - accuracy: 0.87 - 0s 146us/sample - loss: 0.4512 - accuracy: 0.7931 - val_loss: 0.5977 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4635 - accuracy: 0.65 - 0s 146us/sample - loss: 0.4353 - accuracy: 0.7759 - val_loss: 0.5845 - val_accuracy: 0.6552\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4211 - accuracy: 0.81 - 0s 138us/sample - loss: 0.4227 - accuracy: 0.8190 - val_loss: 0.5767 - val_accuracy: 0.6897\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2908 - accuracy: 0.93 - 0s 146us/sample - loss: 0.4405 - accuracy: 0.8017 - val_loss: 0.5824 - val_accuracy: 0.7241\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3665 - accuracy: 0.87 - 0s 138us/sample - loss: 0.4075 - accuracy: 0.8534 - val_loss: 0.5922 - val_accuracy: 0.6207\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2873 - accuracy: 0.96 - 0s 155us/sample - loss: 0.4026 - accuracy: 0.8534 - val_loss: 0.6155 - val_accuracy: 0.7241\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2446 - accuracy: 0.90 - 0s 146us/sample - loss: 0.3608 - accuracy: 0.8448 - val_loss: 0.5974 - val_accuracy: 0.6207\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3994 - accuracy: 0.84 - 0s 146us/sample - loss: 0.3598 - accuracy: 0.8707 - val_loss: 0.5955 - val_accuracy: 0.7241\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3723 - accuracy: 0.87 - 0s 172us/sample - loss: 0.3251 - accuracy: 0.8966 - val_loss: 0.6277 - val_accuracy: 0.7241\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2678 - accuracy: 0.90 - 0s 172us/sample - loss: 0.3058 - accuracy: 0.8879 - val_loss: 0.6265 - val_accuracy: 0.6552\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 1.00 - 0s 146us/sample - loss: 0.2979 - accuracy: 0.9397 - val_loss: 0.6175 - val_accuracy: 0.6897\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3063 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2832 - accuracy: 0.9224 - val_loss: 0.6097 - val_accuracy: 0.7241\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2636 - accuracy: 0.90 - 0s 129us/sample - loss: 0.2650 - accuracy: 0.9138 - val_loss: 0.6387 - val_accuracy: 0.7586\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1359 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2420 - accuracy: 0.9138 - val_loss: 0.6674 - val_accuracy: 0.6207\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.93 - 0s 2ms/sample - loss: 0.2391 - accuracy: 0.9310 - val_loss: 0.6303 - val_accuracy: 0.7931\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2333 - accuracy: 0.9224 - val_loss: 0.7312 - val_accuracy: 0.5862\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.93 - 0s 129us/sample - loss: 0.2083 - accuracy: 0.9483 - val_loss: 0.7133 - val_accuracy: 0.7241\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1828 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2042 - accuracy: 0.9224 - val_loss: 0.7603 - val_accuracy: 0.6552\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2597 - accuracy: 0.90 - 0s 189us/sample - loss: 0.1919 - accuracy: 0.9483 - val_loss: 0.7578 - val_accuracy: 0.7586\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.96 - 0s 215us/sample - loss: 0.1698 - accuracy: 0.9569 - val_loss: 0.8336 - val_accuracy: 0.6207\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2236 - accuracy: 0.93 - 0s 172us/sample - loss: 0.1460 - accuracy: 0.9569 - val_loss: 0.8469 - val_accuracy: 0.6207\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0954 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1486 - accuracy: 0.9483 - val_loss: 0.9583 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 1.00 - 0s 181us/sample - loss: 0.1309 - accuracy: 0.9655 - val_loss: 0.8711 - val_accuracy: 0.7241\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1447 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1286 - accuracy: 0.9655 - val_loss: 0.9798 - val_accuracy: 0.6207\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 1.00 - 0s 224us/sample - loss: 0.1069 - accuracy: 0.9741 - val_loss: 0.9685 - val_accuracy: 0.6552\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.96 - 0s 198us/sample - loss: 0.0867 - accuracy: 0.9828 - val_loss: 1.0052 - val_accuracy: 0.6552\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0846 - accuracy: 0.9828 - val_loss: 0.9879 - val_accuracy: 0.6552\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0360 - accuracy: 1.00 - 0s 158us/sample - loss: 0.0708 - accuracy: 0.9828 - val_loss: 1.1284 - val_accuracy: 0.6552\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 1.00 - 0s 206us/sample - loss: 0.0833 - accuracy: 0.9914 - val_loss: 0.9652 - val_accuracy: 0.7241\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0835 - accuracy: 0.9655 - val_loss: 1.1343 - val_accuracy: 0.6552\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0925 - accuracy: 0.9828 - val_loss: 1.2283 - val_accuracy: 0.6897\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.93 - 0s 159us/sample - loss: 0.1354 - accuracy: 0.9483 - val_loss: 1.3641 - val_accuracy: 0.5862\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1239 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1063 - accuracy: 0.9569 - val_loss: 1.2138 - val_accuracy: 0.6552\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0993 - accuracy: 0.9655 - val_loss: 1.4250 - val_accuracy: 0.6207\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1323 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0792 - accuracy: 0.9828 - val_loss: 1.4487 - val_accuracy: 0.6897\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0666 - accuracy: 0.9741 - val_loss: 1.5921 - val_accuracy: 0.6207\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0476 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0579 - accuracy: 0.9914 - val_loss: 1.5812 - val_accuracy: 0.6552\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0437 - accuracy: 0.9914 - val_loss: 1.6796 - val_accuracy: 0.6207\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0316 - accuracy: 1.0000 - val_loss: 1.7554 - val_accuracy: 0.6207\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0279 - accuracy: 1.0000 - val_loss: 1.8320 - val_accuracy: 0.6207\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0228 - accuracy: 1.0000 - val_loss: 1.9314 - val_accuracy: 0.6207\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.0255 - val_accuracy: 0.6207\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0203 - accuracy: 1.0000 - val_loss: 2.1155 - val_accuracy: 0.6207\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.1971 - val_accuracy: 0.6552\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.2530 - val_accuracy: 0.6207\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 2.2412 - val_accuracy: 0.6207\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.2642 - val_accuracy: 0.6207\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0098 - accuracy: 1.0000 - val_loss: 2.3017 - val_accuracy: 0.6207\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.3205 - val_accuracy: 0.6207\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.3433 - val_accuracy: 0.6207\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.3696 - val_accuracy: 0.6207\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0047 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.3849 - val_accuracy: 0.6207\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.4389 - val_accuracy: 0.6552\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.4503 - val_accuracy: 0.6207\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.4948 - val_accuracy: 0.6207\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.5581 - val_accuracy: 0.6207\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.6128 - val_accuracy: 0.6897\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.5961 - val_accuracy: 0.6207\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.6495 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0066 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.7400 - val_accuracy: 0.7241\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.7261 - val_accuracy: 0.6552\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.7538 - val_accuracy: 0.6207\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.8311 - val_accuracy: 0.7241\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.8156 - val_accuracy: 0.6552\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0058 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.8672 - val_accuracy: 0.6552\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.9520 - val_accuracy: 0.6897\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.9642 - val_accuracy: 0.6552\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.9727 - val_accuracy: 0.6552\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.0180 - val_accuracy: 0.6552\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0529 - val_accuracy: 0.6552\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0807 - val_accuracy: 0.6552\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.1129 - val_accuracy: 0.6552\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1422 - val_accuracy: 0.6552\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.1883 - val_accuracy: 0.6552\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.2050 - val_accuracy: 0.6552\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.2102 - val_accuracy: 0.6552\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.2476 - val_accuracy: 0.6552\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2968 - val_accuracy: 0.6552\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3347 - val_accuracy: 0.6552\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6790e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.3411 - val_accuracy: 0.6552\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3415 - val_accuracy: 0.6552\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3341e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.3709 - val_accuracy: 0.6552\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.4128 - val_accuracy: 0.6552\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 129us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.4493 - val_accuracy: 0.6552\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.4656 - val_accuracy: 0.6552\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8612e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.4900 - val_accuracy: 0.6552\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1743e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.5145 - val_accuracy: 0.6552\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.5439 - val_accuracy: 0.6552\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.5589 - val_accuracy: 0.6552\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7051e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.5891 - val_accuracy: 0.6552\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8134e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.6197 - val_accuracy: 0.6552\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 146us/sample - loss: 9.7836e-04 - accuracy: 1.0000 - val_loss: 3.6470 - val_accuracy: 0.6552\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 146us/sample - loss: 9.6057e-04 - accuracy: 1.0000 - val_loss: 3.6674 - val_accuracy: 0.6552\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3728e-04 - accuracy: 1.00 - 0s 144us/sample - loss: 9.1330e-04 - accuracy: 1.0000 - val_loss: 3.6937 - val_accuracy: 0.6552\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7737e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.7746e-04 - accuracy: 1.0000 - val_loss: 3.7159 - val_accuracy: 0.6552\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4265e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.7717e-04 - accuracy: 1.0000 - val_loss: 3.7364 - val_accuracy: 0.6552\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5120e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 9.1363e-04 - accuracy: 1.0000 - val_loss: 3.7863 - val_accuracy: 0.6552\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9690e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.3546e-04 - accuracy: 1.0000 - val_loss: 3.7837 - val_accuracy: 0.6552\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 155us/sample - loss: 8.5674e-04 - accuracy: 1.0000 - val_loss: 3.7934 - val_accuracy: 0.6552\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3951e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 8.0678e-04 - accuracy: 1.0000 - val_loss: 3.8424 - val_accuracy: 0.6552\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7951e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.7377e-04 - accuracy: 1.0000 - val_loss: 3.8812 - val_accuracy: 0.6552\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4582e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.2049e-04 - accuracy: 1.0000 - val_loss: 3.8833 - val_accuracy: 0.6552\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3016e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 6.8864e-04 - accuracy: 1.0000 - val_loss: 3.9019 - val_accuracy: 0.6552\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 137us/sample - loss: 6.8430e-04 - accuracy: 1.0000 - val_loss: 3.9333 - val_accuracy: 0.6552\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9603e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.4331e-04 - accuracy: 1.0000 - val_loss: 3.9767 - val_accuracy: 0.6552\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5660e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 6.5071e-04 - accuracy: 1.0000 - val_loss: 4.0015 - val_accuracy: 0.6552\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2258e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 6.1345e-04 - accuracy: 1.0000 - val_loss: 4.0066 - val_accuracy: 0.6552\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 5.8196e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.2836e-04 - accuracy: 1.0000 - val_loss: 4.0141 - val_accuracy: 0.6552\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.9193e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.8128e-04 - accuracy: 1.0000 - val_loss: 4.0550 - val_accuracy: 0.6552\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7346e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.5206e-04 - accuracy: 1.0000 - val_loss: 4.0993 - val_accuracy: 0.6552\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1789e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 5.7372e-04 - accuracy: 1.0000 - val_loss: 4.1179 - val_accuracy: 0.6552\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5670e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.4046e-04 - accuracy: 1.0000 - val_loss: 4.1154 - val_accuracy: 0.6552\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1486e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 5.3414e-04 - accuracy: 1.0000 - val_loss: 4.1274 - val_accuracy: 0.6552\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6863e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.0910e-04 - accuracy: 1.0000 - val_loss: 4.1652 - val_accuracy: 0.6552\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1395e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.9272e-04 - accuracy: 1.0000 - val_loss: 4.1939 - val_accuracy: 0.6552\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0467e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.8195e-04 - accuracy: 1.0000 - val_loss: 4.2172 - val_accuracy: 0.6552\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5473e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.8035e-04 - accuracy: 1.0000 - val_loss: 4.2197 - val_accuracy: 0.6552\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3323e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.6228e-04 - accuracy: 1.0000 - val_loss: 4.2499 - val_accuracy: 0.6552\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1719e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.4348e-04 - accuracy: 1.0000 - val_loss: 4.2709 - val_accuracy: 0.6552\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9427e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.3558e-04 - accuracy: 1.0000 - val_loss: 4.2911 - val_accuracy: 0.6552\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9725e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.2815e-04 - accuracy: 1.0000 - val_loss: 4.2958 - val_accuracy: 0.6552\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7555e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.2511e-04 - accuracy: 1.0000 - val_loss: 4.3189 - val_accuracy: 0.6552\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2577e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.0245e-04 - accuracy: 1.0000 - val_loss: 4.3629 - val_accuracy: 0.6552\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4366e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.9725e-04 - accuracy: 1.0000 - val_loss: 4.3895 - val_accuracy: 0.6552\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9487e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.8980e-04 - accuracy: 1.0000 - val_loss: 4.3913 - val_accuracy: 0.6552\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0267e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.7186e-04 - accuracy: 1.0000 - val_loss: 4.4024 - val_accuracy: 0.6552\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8705e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.7083e-04 - accuracy: 1.0000 - val_loss: 4.4153 - val_accuracy: 0.6552\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2221e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.6212e-04 - accuracy: 1.0000 - val_loss: 4.4546 - val_accuracy: 0.6552\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5776e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.5280e-04 - accuracy: 1.0000 - val_loss: 4.4705 - val_accuracy: 0.6552\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1813e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.3944e-04 - accuracy: 1.0000 - val_loss: 4.4834 - val_accuracy: 0.6552\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9070e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.3402e-04 - accuracy: 1.0000 - val_loss: 4.5067 - val_accuracy: 0.6552\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3597e-04 - accuracy: 1.00 - 0s 164us/sample - loss: 3.2375e-04 - accuracy: 1.0000 - val_loss: 4.5270 - val_accuracy: 0.6552\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1630e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.1738e-04 - accuracy: 1.0000 - val_loss: 4.5416 - val_accuracy: 0.6552\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8652e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.1459e-04 - accuracy: 1.0000 - val_loss: 4.5637 - val_accuracy: 0.6552\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0671e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.0211e-04 - accuracy: 1.0000 - val_loss: 4.5695 - val_accuracy: 0.6552\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7111e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.9637e-04 - accuracy: 1.0000 - val_loss: 4.5925 - val_accuracy: 0.6552\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2358e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 2.9052e-04 - accuracy: 1.0000 - val_loss: 4.6144 - val_accuracy: 0.6552\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5384e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.8428e-04 - accuracy: 1.0000 - val_loss: 4.6404 - val_accuracy: 0.6552\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1970e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.8081e-04 - accuracy: 1.0000 - val_loss: 4.6564 - val_accuracy: 0.6552\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0254e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.7051e-04 - accuracy: 1.0000 - val_loss: 4.6566 - val_accuracy: 0.6552\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8567e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.6998e-04 - accuracy: 1.0000 - val_loss: 4.6630 - val_accuracy: 0.6552\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0329e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.6271e-04 - accuracy: 1.0000 - val_loss: 4.6863 - val_accuracy: 0.6552\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6908e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.5250e-04 - accuracy: 1.0000 - val_loss: 4.7154 - val_accuracy: 0.6552\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7586e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.5903e-04 - accuracy: 1.0000 - val_loss: 4.7404 - val_accuracy: 0.6552\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5667e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.5128e-04 - accuracy: 1.0000 - val_loss: 4.7438 - val_accuracy: 0.6552\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2185e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.4323e-04 - accuracy: 1.0000 - val_loss: 4.7499 - val_accuracy: 0.6552\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3763e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.3835e-04 - accuracy: 1.0000 - val_loss: 4.7695 - val_accuracy: 0.6552\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2457e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.3337e-04 - accuracy: 1.0000 - val_loss: 4.7945 - val_accuracy: 0.6552\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8992e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.2807e-04 - accuracy: 1.0000 - val_loss: 4.8100 - val_accuracy: 0.6552\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0870e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 2.2467e-04 - accuracy: 1.0000 - val_loss: 4.8095 - val_accuracy: 0.6552\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0382e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.2602e-04 - accuracy: 1.0000 - val_loss: 4.8190 - val_accuracy: 0.6552\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0852e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.1885e-04 - accuracy: 1.0000 - val_loss: 4.8465 - val_accuracy: 0.6552\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9778e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.1341e-04 - accuracy: 1.0000 - val_loss: 4.8709 - val_accuracy: 0.6552\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9308e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.0836e-04 - accuracy: 1.0000 - val_loss: 4.8763 - val_accuracy: 0.6552\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8821e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.0419e-04 - accuracy: 1.0000 - val_loss: 4.8950 - val_accuracy: 0.6552\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7182e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.9942e-04 - accuracy: 1.0000 - val_loss: 4.9043 - val_accuracy: 0.6552\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1670e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.9567e-04 - accuracy: 1.0000 - val_loss: 4.9152 - val_accuracy: 0.6552\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9729e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.9190e-04 - accuracy: 1.0000 - val_loss: 4.9321 - val_accuracy: 0.6552\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3832e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.8984e-04 - accuracy: 1.0000 - val_loss: 4.9486 - val_accuracy: 0.6552\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2408e-04 - accuracy: 1.00 - 0s 141us/sample - loss: 1.8439e-04 - accuracy: 1.0000 - val_loss: 4.9600 - val_accuracy: 0.6552\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5328e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.8256e-04 - accuracy: 1.0000 - val_loss: 4.9767 - val_accuracy: 0.6552\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6250e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.7728e-04 - accuracy: 1.0000 - val_loss: 4.9857 - val_accuracy: 0.6552\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8373e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7811e-04 - accuracy: 1.0000 - val_loss: 4.9964 - val_accuracy: 0.6552\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4379e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.7267e-04 - accuracy: 1.0000 - val_loss: 5.0220 - val_accuracy: 0.6552\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1729e-04 - accuracy: 1.00 - 0s 151us/sample - loss: 1.7069e-04 - accuracy: 1.0000 - val_loss: 5.0389 - val_accuracy: 0.6552\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1497e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.6877e-04 - accuracy: 1.0000 - val_loss: 5.0451 - val_accuracy: 0.6552\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6920e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.6448e-04 - accuracy: 1.0000 - val_loss: 5.0567 - val_accuracy: 0.6552\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.9998e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.6180e-04 - accuracy: 1.0000 - val_loss: 5.0691 - val_accuracy: 0.6552\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3833e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.5981e-04 - accuracy: 1.0000 - val_loss: 5.0740 - val_accuracy: 0.6552\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6042e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5683e-04 - accuracy: 1.0000 - val_loss: 5.0911 - val_accuracy: 0.6552\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1799e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.5543e-04 - accuracy: 1.0000 - val_loss: 5.1142 - val_accuracy: 0.6552\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1517e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5305e-04 - accuracy: 1.0000 - val_loss: 5.1263 - val_accuracy: 0.6552\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1965e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5075e-04 - accuracy: 1.0000 - val_loss: 5.1236 - val_accuracy: 0.6552\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4277e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.4891e-04 - accuracy: 1.0000 - val_loss: 5.1426 - val_accuracy: 0.6552\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4440e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4573e-04 - accuracy: 1.0000 - val_loss: 5.1596 - val_accuracy: 0.6552\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2483e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4275e-04 - accuracy: 1.0000 - val_loss: 5.1798 - val_accuracy: 0.6552\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9095e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.4046e-04 - accuracy: 1.0000 - val_loss: 5.1864 - val_accuracy: 0.6552\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7049e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3992e-04 - accuracy: 1.0000 - val_loss: 5.1963 - val_accuracy: 0.6552\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7918e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3866e-04 - accuracy: 1.0000 - val_loss: 5.2158 - val_accuracy: 0.6552\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6029e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3387e-04 - accuracy: 1.0000 - val_loss: 5.2233 - val_accuracy: 0.6552\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1375e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3274e-04 - accuracy: 1.0000 - val_loss: 5.2288 - val_accuracy: 0.6552\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9657e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3248e-04 - accuracy: 1.0000 - val_loss: 5.2427 - val_accuracy: 0.6552\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9816e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.2793e-04 - accuracy: 1.0000 - val_loss: 5.2682 - val_accuracy: 0.6552\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3691e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2691e-04 - accuracy: 1.0000 - val_loss: 5.2866 - val_accuracy: 0.6207\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8039e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.2435e-04 - accuracy: 1.0000 - val_loss: 5.2920 - val_accuracy: 0.6552\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5329e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.2290e-04 - accuracy: 1.0000 - val_loss: 5.2941 - val_accuracy: 0.6552\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9937e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.2056e-04 - accuracy: 1.0000 - val_loss: 5.3060 - val_accuracy: 0.6552\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5177e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1930e-04 - accuracy: 1.0000 - val_loss: 5.3230 - val_accuracy: 0.6207\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: b9708bd61a5649dc81467b11ff68a50d</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.767241358757019</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 108</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 84</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 84</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 115</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 2s - loss: 0.7048 - accuracy: 0.43 - 1s 11ms/sample - loss: 0.6525 - accuracy: 0.6293 - val_loss: 0.6464 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5035 - accuracy: 0.81 - 0s 370us/sample - loss: 0.6356 - accuracy: 0.6638 - val_loss: 0.6480 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6323 - accuracy: 0.65 - 0s 163us/sample - loss: 0.6380 - accuracy: 0.6638 - val_loss: 0.6422 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5984 - accuracy: 0.71 - 0s 155us/sample - loss: 0.6196 - accuracy: 0.6638 - val_loss: 0.6486 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5203 - accuracy: 0.71 - 0s 138us/sample - loss: 0.5817 - accuracy: 0.6638 - val_loss: 0.6334 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5703 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5804 - accuracy: 0.7241 - val_loss: 0.6277 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5891 - accuracy: 0.68 - 0s 155us/sample - loss: 0.5405 - accuracy: 0.7328 - val_loss: 0.6400 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5529 - accuracy: 0.71 - 0s 137us/sample - loss: 0.5353 - accuracy: 0.6983 - val_loss: 0.6583 - val_accuracy: 0.5862\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5864 - accuracy: 0.68 - 0s 146us/sample - loss: 0.4852 - accuracy: 0.7500 - val_loss: 0.6723 - val_accuracy: 0.5862\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4686 - accuracy: 0.7759 - val_loss: 0.7383 - val_accuracy: 0.6207\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3536 - accuracy: 0.81 - 0s 146us/sample - loss: 0.4174 - accuracy: 0.7845 - val_loss: 0.7852 - val_accuracy: 0.4828\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.75 - 0s 138us/sample - loss: 0.4188 - accuracy: 0.8017 - val_loss: 0.8853 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3655 - accuracy: 0.84 - 0s 138us/sample - loss: 0.4992 - accuracy: 0.7845 - val_loss: 0.8285 - val_accuracy: 0.5172\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3944 - accuracy: 0.78 - 0s 1ms/sample - loss: 0.4551 - accuracy: 0.8017 - val_loss: 0.7329 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4021 - accuracy: 0.87 - 0s 163us/sample - loss: 0.3892 - accuracy: 0.8448 - val_loss: 0.7636 - val_accuracy: 0.6897\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4465 - accuracy: 0.78 - 0s 164us/sample - loss: 0.3650 - accuracy: 0.8362 - val_loss: 0.8011 - val_accuracy: 0.6552\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3385 - accuracy: 0.84 - 0s 163us/sample - loss: 0.3472 - accuracy: 0.8707 - val_loss: 0.9744 - val_accuracy: 0.6552\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2277 - accuracy: 0.90 - 0s 163us/sample - loss: 0.3220 - accuracy: 0.8621 - val_loss: 1.3386 - val_accuracy: 0.4828\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3231 - accuracy: 0.87 - 0s 181us/sample - loss: 0.3101 - accuracy: 0.8534 - val_loss: 1.1525 - val_accuracy: 0.6897\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.90 - 0s 164us/sample - loss: 0.2632 - accuracy: 0.8966 - val_loss: 1.3678 - val_accuracy: 0.5517\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3181 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2937 - accuracy: 0.8621 - val_loss: 1.5034 - val_accuracy: 0.6897\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3502 - accuracy: 0.81 - 0s 155us/sample - loss: 0.2590 - accuracy: 0.8966 - val_loss: 1.6786 - val_accuracy: 0.5862\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2681 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2146 - accuracy: 0.9310 - val_loss: 1.7054 - val_accuracy: 0.6897\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1626 - accuracy: 0.93 - 0s 163us/sample - loss: 0.1759 - accuracy: 0.9224 - val_loss: 2.0844 - val_accuracy: 0.5862\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2030 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1692 - accuracy: 0.9397 - val_loss: 2.2636 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4832 - accuracy: 0.78 - 0s 172us/sample - loss: 0.2426 - accuracy: 0.8793 - val_loss: 2.3295 - val_accuracy: 0.6207\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1105 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1977 - accuracy: 0.9224 - val_loss: 2.5358 - val_accuracy: 0.5862\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1588 - accuracy: 0.90 - 0s 164us/sample - loss: 0.1528 - accuracy: 0.9310 - val_loss: 2.5475 - val_accuracy: 0.6207\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1490 - accuracy: 0.9397 - val_loss: 2.7792 - val_accuracy: 0.5172\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1568 - accuracy: 0.93 - 0s 138us/sample - loss: 0.1339 - accuracy: 0.9483 - val_loss: 2.5497 - val_accuracy: 0.6207\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 0.93 - 0s 144us/sample - loss: 0.0954 - accuracy: 0.9569 - val_loss: 2.7194 - val_accuracy: 0.6552\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0935 - accuracy: 0.9828 - val_loss: 3.0043 - val_accuracy: 0.6897\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0638 - accuracy: 0.9741 - val_loss: 3.6636 - val_accuracy: 0.6207\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0821 - accuracy: 0.9483 - val_loss: 4.2185 - val_accuracy: 0.5517\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0387 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0788 - accuracy: 0.9828 - val_loss: 3.9586 - val_accuracy: 0.6552\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.96 - 0s 149us/sample - loss: 0.2076 - accuracy: 0.9310 - val_loss: 4.6634 - val_accuracy: 0.5172\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3267 - accuracy: 0.84 - 0s 146us/sample - loss: 0.1761 - accuracy: 0.9224 - val_loss: 4.1436 - val_accuracy: 0.5862\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1066 - accuracy: 0.9397 - val_loss: 3.9061 - val_accuracy: 0.5172\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2169 - accuracy: 0.93 - 0s 331us/sample - loss: 0.0938 - accuracy: 0.9828 - val_loss: 3.2495 - val_accuracy: 0.6552\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 0.90 - 0s 155us/sample - loss: 0.0912 - accuracy: 0.9483 - val_loss: 4.1455 - val_accuracy: 0.5172\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2553 - accuracy: 0.87 - 0s 155us/sample - loss: 0.1092 - accuracy: 0.9483 - val_loss: 4.7183 - val_accuracy: 0.6552\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0461 - accuracy: 0.96 - 0s 181us/sample - loss: 0.1979 - accuracy: 0.9483 - val_loss: 3.9936 - val_accuracy: 0.6897\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0490 - accuracy: 1.00 - 0s 181us/sample - loss: 0.0888 - accuracy: 0.9569 - val_loss: 3.3854 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0744 - accuracy: 0.9741 - val_loss: 3.2288 - val_accuracy: 0.5517\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0323 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0466 - accuracy: 0.9914 - val_loss: 3.3648 - val_accuracy: 0.5517\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0561 - accuracy: 0.9741 - val_loss: 3.3291 - val_accuracy: 0.5517\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0581 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0385 - accuracy: 0.9914 - val_loss: 3.1611 - val_accuracy: 0.5862\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 1.00 - 0s 142us/sample - loss: 0.0151 - accuracy: 1.0000 - val_loss: 3.3405 - val_accuracy: 0.5862\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0138 - accuracy: 1.0000 - val_loss: 3.5659 - val_accuracy: 0.5862\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0097 - accuracy: 1.0000 - val_loss: 3.7724 - val_accuracy: 0.5862\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.8999 - val_accuracy: 0.5862\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0096 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0053 - accuracy: 1.0000 - val_loss: 3.9806 - val_accuracy: 0.5862\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.0501 - val_accuracy: 0.5862\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.1435 - val_accuracy: 0.5862\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 4.2087 - val_accuracy: 0.5862\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.2603 - val_accuracy: 0.5862\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.3035 - val_accuracy: 0.5862\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.3470 - val_accuracy: 0.5862\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0022 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.3774 - val_accuracy: 0.5862\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.4114 - val_accuracy: 0.5862\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.4341 - val_accuracy: 0.5862\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 172us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.4473 - val_accuracy: 0.5862\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7605e-04 - accuracy: 1.00 - 0s 189us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.4692 - val_accuracy: 0.5862\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 181us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.4784 - val_accuracy: 0.5862\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 180us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.4898 - val_accuracy: 0.5862\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.5065 - val_accuracy: 0.5862\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 181us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.5165 - val_accuracy: 0.5862\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5818e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 9.1831e-04 - accuracy: 1.0000 - val_loss: 4.5380 - val_accuracy: 0.5862\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8998e-04 - accuracy: 1.00 - 0s 189us/sample - loss: 8.8236e-04 - accuracy: 1.0000 - val_loss: 4.5588 - val_accuracy: 0.5862\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2500e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 8.2169e-04 - accuracy: 1.0000 - val_loss: 4.5768 - val_accuracy: 0.5862\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5829e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 8.0605e-04 - accuracy: 1.0000 - val_loss: 4.5976 - val_accuracy: 0.5862\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4053e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.5667e-04 - accuracy: 1.0000 - val_loss: 4.6191 - val_accuracy: 0.5862\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.00 - 0s 146us/sample - loss: 7.4024e-04 - accuracy: 1.0000 - val_loss: 4.6340 - val_accuracy: 0.5862\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8771e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.9005e-04 - accuracy: 1.0000 - val_loss: 4.6452 - val_accuracy: 0.5862\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3924e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.5904e-04 - accuracy: 1.0000 - val_loss: 4.6596 - val_accuracy: 0.5862\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4742e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 6.3784e-04 - accuracy: 1.0000 - val_loss: 4.6786 - val_accuracy: 0.5862\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9452e-04 - accuracy: 1.00 - 0s 181us/sample - loss: 6.1718e-04 - accuracy: 1.0000 - val_loss: 4.6890 - val_accuracy: 0.5862\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9266e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.8820e-04 - accuracy: 1.0000 - val_loss: 4.7009 - val_accuracy: 0.5862\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3610e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.6482e-04 - accuracy: 1.0000 - val_loss: 4.7112 - val_accuracy: 0.5862\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8079e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.4555e-04 - accuracy: 1.0000 - val_loss: 4.7202 - val_accuracy: 0.5862\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4079e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.2011e-04 - accuracy: 1.0000 - val_loss: 4.7315 - val_accuracy: 0.5862\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9865e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.0711e-04 - accuracy: 1.0000 - val_loss: 4.7436 - val_accuracy: 0.5862\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4313e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.9525e-04 - accuracy: 1.0000 - val_loss: 4.7607 - val_accuracy: 0.5862\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4588e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.7965e-04 - accuracy: 1.0000 - val_loss: 4.7734 - val_accuracy: 0.5862\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7097e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 4.6457e-04 - accuracy: 1.0000 - val_loss: 4.7840 - val_accuracy: 0.5862\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3458e-04 - accuracy: 1.00 - 0s 181us/sample - loss: 4.4525e-04 - accuracy: 1.0000 - val_loss: 4.7936 - val_accuracy: 0.5862\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0668e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 4.4107e-04 - accuracy: 1.0000 - val_loss: 4.8007 - val_accuracy: 0.5862\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3070e-04 - accuracy: 1.00 - 0s 181us/sample - loss: 4.1651e-04 - accuracy: 1.0000 - val_loss: 4.8090 - val_accuracy: 0.5862\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4825e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.0696e-04 - accuracy: 1.0000 - val_loss: 4.8178 - val_accuracy: 0.5862\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7141e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.9880e-04 - accuracy: 1.0000 - val_loss: 4.8255 - val_accuracy: 0.5862\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6627e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.8620e-04 - accuracy: 1.0000 - val_loss: 4.8352 - val_accuracy: 0.5862\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4616e-04 - accuracy: 1.00 - 0s 147us/sample - loss: 3.7520e-04 - accuracy: 1.0000 - val_loss: 4.8465 - val_accuracy: 0.5862\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1860e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 3.6605e-04 - accuracy: 1.0000 - val_loss: 4.8564 - val_accuracy: 0.5862\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9306e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.5919e-04 - accuracy: 1.0000 - val_loss: 4.8650 - val_accuracy: 0.5862\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9646e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.5234e-04 - accuracy: 1.0000 - val_loss: 4.8744 - val_accuracy: 0.5862\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1088e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.4523e-04 - accuracy: 1.0000 - val_loss: 4.8845 - val_accuracy: 0.5862\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8781e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.3451e-04 - accuracy: 1.0000 - val_loss: 4.8927 - val_accuracy: 0.6207\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8264e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.2584e-04 - accuracy: 1.0000 - val_loss: 4.9011 - val_accuracy: 0.6207\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2771e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.1266e-04 - accuracy: 1.0000 - val_loss: 4.9076 - val_accuracy: 0.6207\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7347e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.0729e-04 - accuracy: 1.0000 - val_loss: 4.9159 - val_accuracy: 0.6207\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2412e-04 - accuracy: 1.00 - 0s 143us/sample - loss: 2.9675e-04 - accuracy: 1.0000 - val_loss: 4.9243 - val_accuracy: 0.6207\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8298e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.8995e-04 - accuracy: 1.0000 - val_loss: 4.9316 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7501e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.8378e-04 - accuracy: 1.0000 - val_loss: 4.9414 - val_accuracy: 0.6207\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2702e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.7757e-04 - accuracy: 1.0000 - val_loss: 4.9522 - val_accuracy: 0.6207\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4049e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.7206e-04 - accuracy: 1.0000 - val_loss: 4.9638 - val_accuracy: 0.6207\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1220e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 2.6464e-04 - accuracy: 1.0000 - val_loss: 4.9724 - val_accuracy: 0.6207\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5821e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.6023e-04 - accuracy: 1.0000 - val_loss: 4.9780 - val_accuracy: 0.6207\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4633e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 2.5593e-04 - accuracy: 1.0000 - val_loss: 4.9843 - val_accuracy: 0.6207\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4795e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.4815e-04 - accuracy: 1.0000 - val_loss: 4.9894 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.8379e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.4274e-04 - accuracy: 1.0000 - val_loss: 4.9955 - val_accuracy: 0.6207\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3028e-04 - accuracy: 1.00 - 0s 159us/sample - loss: 2.4252e-04 - accuracy: 1.0000 - val_loss: 5.0036 - val_accuracy: 0.6207\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7832e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.3458e-04 - accuracy: 1.0000 - val_loss: 5.0109 - val_accuracy: 0.6207\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3121e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.3749e-04 - accuracy: 1.0000 - val_loss: 5.0196 - val_accuracy: 0.6207\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4012e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.2788e-04 - accuracy: 1.0000 - val_loss: 5.0297 - val_accuracy: 0.6207\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2553e-04 - accuracy: 1.00 - 0s 217us/sample - loss: 2.2285e-04 - accuracy: 1.0000 - val_loss: 5.0371 - val_accuracy: 0.6207\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6939e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.1717e-04 - accuracy: 1.0000 - val_loss: 5.0434 - val_accuracy: 0.6207\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6816e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 2.1153e-04 - accuracy: 1.0000 - val_loss: 5.0492 - val_accuracy: 0.6207\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4027e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.0802e-04 - accuracy: 1.0000 - val_loss: 5.0546 - val_accuracy: 0.6207\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5121e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.0596e-04 - accuracy: 1.0000 - val_loss: 5.0634 - val_accuracy: 0.6207\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3481e-04 - accuracy: 1.00 - 0s 164us/sample - loss: 2.0262e-04 - accuracy: 1.0000 - val_loss: 5.0730 - val_accuracy: 0.6207\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1558e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.9985e-04 - accuracy: 1.0000 - val_loss: 5.0796 - val_accuracy: 0.6207\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9224e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.9200e-04 - accuracy: 1.0000 - val_loss: 5.0864 - val_accuracy: 0.6207\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7049e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.8875e-04 - accuracy: 1.0000 - val_loss: 5.0947 - val_accuracy: 0.6207\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6221e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.8507e-04 - accuracy: 1.0000 - val_loss: 5.0988 - val_accuracy: 0.6207\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2891e-05 - accuracy: 1.00 - 0s 137us/sample - loss: 1.8205e-04 - accuracy: 1.0000 - val_loss: 5.1047 - val_accuracy: 0.6207\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5630e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7739e-04 - accuracy: 1.0000 - val_loss: 5.1133 - val_accuracy: 0.6207\n",
      "Epoch 127/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 9.2679e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.7548e-04 - accuracy: 1.0000 - val_loss: 5.1213 - val_accuracy: 0.6207\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0972e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.7394e-04 - accuracy: 1.0000 - val_loss: 5.1279 - val_accuracy: 0.6207\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5381e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.6939e-04 - accuracy: 1.0000 - val_loss: 5.1317 - val_accuracy: 0.6207\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1378e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.6610e-04 - accuracy: 1.0000 - val_loss: 5.1387 - val_accuracy: 0.6207\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8321e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.6403e-04 - accuracy: 1.0000 - val_loss: 5.1457 - val_accuracy: 0.6207\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.2459e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.6058e-04 - accuracy: 1.0000 - val_loss: 5.1523 - val_accuracy: 0.6207\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1908e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.5831e-04 - accuracy: 1.0000 - val_loss: 5.1563 - val_accuracy: 0.6207\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6674e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5537e-04 - accuracy: 1.0000 - val_loss: 5.1573 - val_accuracy: 0.6207\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.8233e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5279e-04 - accuracy: 1.0000 - val_loss: 5.1619 - val_accuracy: 0.6207\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9803e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4999e-04 - accuracy: 1.0000 - val_loss: 5.1686 - val_accuracy: 0.6207\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8689e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4750e-04 - accuracy: 1.0000 - val_loss: 5.1759 - val_accuracy: 0.6207\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1669e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4659e-04 - accuracy: 1.0000 - val_loss: 5.1820 - val_accuracy: 0.6207\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5590e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4404e-04 - accuracy: 1.0000 - val_loss: 5.1870 - val_accuracy: 0.6207\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0426e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4182e-04 - accuracy: 1.0000 - val_loss: 5.1937 - val_accuracy: 0.6207\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2978e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4001e-04 - accuracy: 1.0000 - val_loss: 5.2027 - val_accuracy: 0.6207\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8819e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.3713e-04 - accuracy: 1.0000 - val_loss: 5.2087 - val_accuracy: 0.6207\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2163e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3406e-04 - accuracy: 1.0000 - val_loss: 5.2135 - val_accuracy: 0.6207\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1528e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.3264e-04 - accuracy: 1.0000 - val_loss: 5.2187 - val_accuracy: 0.6207\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0034e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.3000e-04 - accuracy: 1.0000 - val_loss: 5.2244 - val_accuracy: 0.6207\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3717e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2858e-04 - accuracy: 1.0000 - val_loss: 5.2284 - val_accuracy: 0.6207\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1599e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2631e-04 - accuracy: 1.0000 - val_loss: 5.2357 - val_accuracy: 0.6207\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2221e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2447e-04 - accuracy: 1.0000 - val_loss: 5.2413 - val_accuracy: 0.6207\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.5141e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2299e-04 - accuracy: 1.0000 - val_loss: 5.2480 - val_accuracy: 0.6207\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0669e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2171e-04 - accuracy: 1.0000 - val_loss: 5.2535 - val_accuracy: 0.6207\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5758e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1953e-04 - accuracy: 1.0000 - val_loss: 5.2576 - val_accuracy: 0.6207\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3989e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1710e-04 - accuracy: 1.0000 - val_loss: 5.2634 - val_accuracy: 0.6207\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.5975e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1582e-04 - accuracy: 1.0000 - val_loss: 5.2674 - val_accuracy: 0.6207\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.4320e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1458e-04 - accuracy: 1.0000 - val_loss: 5.2706 - val_accuracy: 0.6207\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2926e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1351e-04 - accuracy: 1.0000 - val_loss: 5.2758 - val_accuracy: 0.6207\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1982e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1178e-04 - accuracy: 1.0000 - val_loss: 5.2819 - val_accuracy: 0.6207\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1338e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.0999e-04 - accuracy: 1.0000 - val_loss: 5.2906 - val_accuracy: 0.6207\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0953e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0861e-04 - accuracy: 1.0000 - val_loss: 5.2988 - val_accuracy: 0.6207\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9259e-05 - accuracy: 1.00 - 0s 473us/sample - loss: 1.0680e-04 - accuracy: 1.0000 - val_loss: 5.3032 - val_accuracy: 0.6207\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1121e-04 - accuracy: 1.00 - 0s 490us/sample - loss: 1.0542e-04 - accuracy: 1.0000 - val_loss: 5.3071 - val_accuracy: 0.6207\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4574e-05 - accuracy: 1.00 - 0s 473us/sample - loss: 1.0333e-04 - accuracy: 1.0000 - val_loss: 5.3115 - val_accuracy: 0.6207\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5061e-05 - accuracy: 1.00 - 0s 481us/sample - loss: 1.0216e-04 - accuracy: 1.0000 - val_loss: 5.3150 - val_accuracy: 0.6207\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8445e-05 - accuracy: 1.00 - 0s 499us/sample - loss: 1.0048e-04 - accuracy: 1.0000 - val_loss: 5.3189 - val_accuracy: 0.6207\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2588e-04 - accuracy: 1.00 - 0s 464us/sample - loss: 9.9416e-05 - accuracy: 1.0000 - val_loss: 5.3260 - val_accuracy: 0.6207\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7956e-05 - accuracy: 1.00 - 0s 490us/sample - loss: 9.7820e-05 - accuracy: 1.0000 - val_loss: 5.3336 - val_accuracy: 0.6207\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9555e-05 - accuracy: 1.00 - 0s 473us/sample - loss: 9.6597e-05 - accuracy: 1.0000 - val_loss: 5.3377 - val_accuracy: 0.6207\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3610e-05 - accuracy: 1.00 - 0s 516us/sample - loss: 9.5461e-05 - accuracy: 1.0000 - val_loss: 5.3422 - val_accuracy: 0.6207\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6348e-04 - accuracy: 1.00 - 0s 477us/sample - loss: 9.4409e-05 - accuracy: 1.0000 - val_loss: 5.3463 - val_accuracy: 0.6207\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3704e-04 - accuracy: 1.00 - 0s 447us/sample - loss: 9.3164e-05 - accuracy: 1.0000 - val_loss: 5.3505 - val_accuracy: 0.6207\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0872e-04 - accuracy: 1.00 - 0s 507us/sample - loss: 9.1884e-05 - accuracy: 1.0000 - val_loss: 5.3569 - val_accuracy: 0.6207\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0646e-04 - accuracy: 1.00 - 0s 490us/sample - loss: 9.1520e-05 - accuracy: 1.0000 - val_loss: 5.3618 - val_accuracy: 0.6207\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0540e-04 - accuracy: 1.00 - 0s 395us/sample - loss: 8.9607e-05 - accuracy: 1.0000 - val_loss: 5.3663 - val_accuracy: 0.6207\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0021e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 8.8528e-05 - accuracy: 1.0000 - val_loss: 5.3702 - val_accuracy: 0.6207\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.6896e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.8071e-05 - accuracy: 1.0000 - val_loss: 5.3738 - val_accuracy: 0.6207\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7389e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.7733e-05 - accuracy: 1.0000 - val_loss: 5.3772 - val_accuracy: 0.6207\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6728e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 8.5968e-05 - accuracy: 1.0000 - val_loss: 5.3838 - val_accuracy: 0.6207\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5150e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.4794e-05 - accuracy: 1.0000 - val_loss: 5.3924 - val_accuracy: 0.6207\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9687e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.3211e-05 - accuracy: 1.0000 - val_loss: 5.3988 - val_accuracy: 0.6207\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9214e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 8.3534e-05 - accuracy: 1.0000 - val_loss: 5.4042 - val_accuracy: 0.6207\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8746e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.2200e-05 - accuracy: 1.0000 - val_loss: 5.4085 - val_accuracy: 0.6207\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2153e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 8.1327e-05 - accuracy: 1.0000 - val_loss: 5.4091 - val_accuracy: 0.6207\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4162e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.9572e-05 - accuracy: 1.0000 - val_loss: 5.4117 - val_accuracy: 0.6207\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0413e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 7.9091e-05 - accuracy: 1.0000 - val_loss: 5.4172 - val_accuracy: 0.6207\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3192e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.8672e-05 - accuracy: 1.0000 - val_loss: 5.4227 - val_accuracy: 0.6207\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1838e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.6817e-05 - accuracy: 1.0000 - val_loss: 5.4287 - val_accuracy: 0.6207\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8736e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.6822e-05 - accuracy: 1.0000 - val_loss: 5.4342 - val_accuracy: 0.6207\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4128e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.5346e-05 - accuracy: 1.0000 - val_loss: 5.4372 - val_accuracy: 0.6207\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9650e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.4302e-05 - accuracy: 1.0000 - val_loss: 5.4405 - val_accuracy: 0.6207\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0379e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.3672e-05 - accuracy: 1.0000 - val_loss: 5.4451 - val_accuracy: 0.6207\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1802e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.2970e-05 - accuracy: 1.0000 - val_loss: 5.4502 - val_accuracy: 0.6207\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2611e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.2170e-05 - accuracy: 1.0000 - val_loss: 5.4555 - val_accuracy: 0.6207\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4901e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.1238e-05 - accuracy: 1.0000 - val_loss: 5.4593 - val_accuracy: 0.6207\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4045e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.0193e-05 - accuracy: 1.0000 - val_loss: 5.4634 - val_accuracy: 0.6207\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7581e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.9400e-05 - accuracy: 1.0000 - val_loss: 5.4668 - val_accuracy: 0.6207\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1836e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.8659e-05 - accuracy: 1.0000 - val_loss: 5.4713 - val_accuracy: 0.6207\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1678e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.8103e-05 - accuracy: 1.0000 - val_loss: 5.4759 - val_accuracy: 0.6207\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4296e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 6.7323e-05 - accuracy: 1.0000 - val_loss: 5.4795 - val_accuracy: 0.6552\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0686e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 6.6648e-05 - accuracy: 1.0000 - val_loss: 5.4845 - val_accuracy: 0.6552\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1623e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 6.5944e-05 - accuracy: 1.0000 - val_loss: 5.4893 - val_accuracy: 0.6552\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1302e-04 - accuracy: 1.00 - 0s 133us/sample - loss: 6.5642e-05 - accuracy: 1.0000 - val_loss: 5.4939 - val_accuracy: 0.6552\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7033 - accuracy: 0.31 - 0s 3ms/sample - loss: 0.6690 - accuracy: 0.5603 - val_loss: 0.6518 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7864 - accuracy: 0.50 - 0s 172us/sample - loss: 0.6513 - accuracy: 0.6638 - val_loss: 0.6391 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6459 - accuracy: 0.62 - 0s 163us/sample - loss: 0.6176 - accuracy: 0.6638 - val_loss: 0.6254 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6113 - accuracy: 0.65 - 0s 172us/sample - loss: 0.6037 - accuracy: 0.6638 - val_loss: 0.6097 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6035 - accuracy: 0.62 - 0s 155us/sample - loss: 0.5813 - accuracy: 0.6983 - val_loss: 0.5877 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6148 - accuracy: 0.71 - 0s 155us/sample - loss: 0.5615 - accuracy: 0.7414 - val_loss: 0.5913 - val_accuracy: 0.6207\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4840 - accuracy: 0.81 - 0s 2ms/sample - loss: 0.5540 - accuracy: 0.7241 - val_loss: 0.5781 - val_accuracy: 0.7241\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5248 - accuracy: 0.78 - 0s 155us/sample - loss: 0.5315 - accuracy: 0.7586 - val_loss: 0.5796 - val_accuracy: 0.7241\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 0.4669 - accuracy: 0.78 - 0s 163us/sample - loss: 0.4796 - accuracy: 0.7759 - val_loss: 0.6052 - val_accuracy: 0.7241\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5840 - accuracy: 0.71 - 0s 172us/sample - loss: 0.4865 - accuracy: 0.7759 - val_loss: 0.6390 - val_accuracy: 0.7241\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4572 - accuracy: 0.78 - 0s 164us/sample - loss: 0.4597 - accuracy: 0.7845 - val_loss: 0.6105 - val_accuracy: 0.6552\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.87 - 0s 163us/sample - loss: 0.4533 - accuracy: 0.8103 - val_loss: 0.6024 - val_accuracy: 0.6897\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3828 - accuracy: 0.84 - 0s 172us/sample - loss: 0.4436 - accuracy: 0.7931 - val_loss: 0.6153 - val_accuracy: 0.6897\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4867 - accuracy: 0.71 - 0s 155us/sample - loss: 0.4349 - accuracy: 0.8103 - val_loss: 0.6189 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5289 - accuracy: 0.71 - 0s 146us/sample - loss: 0.3611 - accuracy: 0.8534 - val_loss: 0.7061 - val_accuracy: 0.6552\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.78 - 0s 138us/sample - loss: 0.3502 - accuracy: 0.8707 - val_loss: 0.7440 - val_accuracy: 0.5862\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1874 - accuracy: 0.96 - 0s 146us/sample - loss: 0.3156 - accuracy: 0.8879 - val_loss: 0.8541 - val_accuracy: 0.6897\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3198 - accuracy: 0.84 - 0s 129us/sample - loss: 0.2948 - accuracy: 0.8879 - val_loss: 0.8210 - val_accuracy: 0.5862\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.96 - 0s 146us/sample - loss: 0.3030 - accuracy: 0.9052 - val_loss: 0.8511 - val_accuracy: 0.5862\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2983 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2952 - accuracy: 0.8707 - val_loss: 0.7150 - val_accuracy: 0.7241\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3047 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2719 - accuracy: 0.9052 - val_loss: 0.7846 - val_accuracy: 0.5517\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3428 - accuracy: 0.87 - 0s 163us/sample - loss: 0.2379 - accuracy: 0.9224 - val_loss: 0.8391 - val_accuracy: 0.7241\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2055 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2272 - accuracy: 0.9224 - val_loss: 1.0969 - val_accuracy: 0.6207\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.96 - 0s 163us/sample - loss: 0.2222 - accuracy: 0.9052 - val_loss: 1.1696 - val_accuracy: 0.6552\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 1.00 - 0s 172us/sample - loss: 0.2174 - accuracy: 0.9052 - val_loss: 1.1784 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1201 - accuracy: 1.00 - 0s 155us/sample - loss: 0.2156 - accuracy: 0.9138 - val_loss: 1.2305 - val_accuracy: 0.6207\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.96 - 0s 163us/sample - loss: 0.1961 - accuracy: 0.9397 - val_loss: 1.1680 - val_accuracy: 0.7241\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1653 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1600 - accuracy: 0.9569 - val_loss: 1.2291 - val_accuracy: 0.6552\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0443 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1248 - accuracy: 0.9397 - val_loss: 1.2334 - val_accuracy: 0.5862\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0866 - accuracy: 0.96 - 0s 2ms/sample - loss: 0.1300 - accuracy: 0.9397 - val_loss: 1.6090 - val_accuracy: 0.7586\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1568 - accuracy: 0.87 - 0s 292us/sample - loss: 0.2315 - accuracy: 0.8793 - val_loss: 2.2112 - val_accuracy: 0.6207\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2293 - accuracy: 0.93 - 0s 181us/sample - loss: 0.2732 - accuracy: 0.8966 - val_loss: 2.0380 - val_accuracy: 0.6897\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4124 - accuracy: 0.81 - 0s 164us/sample - loss: 0.2848 - accuracy: 0.8707 - val_loss: 2.3017 - val_accuracy: 0.5517\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2000 - accuracy: 0.9224 - val_loss: 1.7780 - val_accuracy: 0.6207\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1653 - accuracy: 0.9310 - val_loss: 1.5716 - val_accuracy: 0.6552\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 1.00 - 0s 172us/sample - loss: 0.1678 - accuracy: 0.9397 - val_loss: 1.6846 - val_accuracy: 0.6207\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1326 - accuracy: 0.9483 - val_loss: 1.9465 - val_accuracy: 0.6207\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1014 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1181 - accuracy: 0.9655 - val_loss: 1.8370 - val_accuracy: 0.6552\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1192 - accuracy: 0.9569 - val_loss: 2.0749 - val_accuracy: 0.5862\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 1.00 - 0s 158us/sample - loss: 0.0746 - accuracy: 0.9828 - val_loss: 2.2218 - val_accuracy: 0.5862\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0829 - accuracy: 0.9741 - val_loss: 2.6284 - val_accuracy: 0.6552\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1229 - accuracy: 0.90 - 0s 155us/sample - loss: 0.0877 - accuracy: 0.9569 - val_loss: 2.5273 - val_accuracy: 0.5517\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0526 - accuracy: 0.9741 - val_loss: 2.6535 - val_accuracy: 0.6552\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 1.00 - 0s 269us/sample - loss: 0.0488 - accuracy: 0.9914 - val_loss: 2.4987 - val_accuracy: 0.6207\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0645 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0599 - accuracy: 0.9655 - val_loss: 2.5554 - val_accuracy: 0.6897\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0557 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0421 - accuracy: 0.9828 - val_loss: 2.8508 - val_accuracy: 0.6207\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0435 - accuracy: 0.9828 - val_loss: 2.6254 - val_accuracy: 0.6207\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0659 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0339 - accuracy: 0.9914 - val_loss: 2.8214 - val_accuracy: 0.6552\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.00 - 0s 215us/sample - loss: 0.0793 - accuracy: 0.9741 - val_loss: 2.8856 - val_accuracy: 0.6552\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0732 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0935 - accuracy: 0.9569 - val_loss: 2.6600 - val_accuracy: 0.6552\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1876 - accuracy: 0.9224 - val_loss: 2.3277 - val_accuracy: 0.6552\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.96 - 0s 146us/sample - loss: 0.4089 - accuracy: 0.8534 - val_loss: 2.0125 - val_accuracy: 0.7241\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1568 - accuracy: 0.93 - 0s 146us/sample - loss: 0.4241 - accuracy: 0.8448 - val_loss: 2.0994 - val_accuracy: 0.6552\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2822 - accuracy: 0.8621 - val_loss: 2.0273 - val_accuracy: 0.6207\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4182 - accuracy: 0.84 - 0s 155us/sample - loss: 0.2894 - accuracy: 0.8793 - val_loss: 1.8620 - val_accuracy: 0.6897\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2614 - accuracy: 0.84 - 0s 138us/sample - loss: 0.2407 - accuracy: 0.9052 - val_loss: 2.0924 - val_accuracy: 0.6552\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1811 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1789 - accuracy: 0.9310 - val_loss: 2.2863 - val_accuracy: 0.5517\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2312 - accuracy: 0.84 - 0s 138us/sample - loss: 0.1517 - accuracy: 0.9310 - val_loss: 2.0399 - val_accuracy: 0.6897\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.93 - 0s 155us/sample - loss: 0.0909 - accuracy: 0.9741 - val_loss: 2.2191 - val_accuracy: 0.5862\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0877 - accuracy: 0.9828 - val_loss: 2.1656 - val_accuracy: 0.7241\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.93 - 0s 146us/sample - loss: 0.0847 - accuracy: 0.9741 - val_loss: 2.3034 - val_accuracy: 0.6552\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0433 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0500 - accuracy: 0.9828 - val_loss: 2.4784 - val_accuracy: 0.6897\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 1.00 - 0s 120us/sample - loss: 0.0316 - accuracy: 0.9914 - val_loss: 2.6407 - val_accuracy: 0.6552\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0103 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0280 - accuracy: 0.9914 - val_loss: 2.7907 - val_accuracy: 0.6897\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0210 - accuracy: 0.9914 - val_loss: 2.8895 - val_accuracy: 0.6552\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0244 - accuracy: 0.9914 - val_loss: 2.9939 - val_accuracy: 0.6552\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0095 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0120 - accuracy: 1.0000 - val_loss: 3.1981 - val_accuracy: 0.7241\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0197 - accuracy: 0.9914 - val_loss: 3.2844 - val_accuracy: 0.6552\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0173 - accuracy: 1.0000 - val_loss: 3.4229 - val_accuracy: 0.6552\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0089 - accuracy: 1.0000 - val_loss: 3.6575 - val_accuracy: 0.6897\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0102 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0101 - accuracy: 1.0000 - val_loss: 3.7754 - val_accuracy: 0.6897\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.9017 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0048 - accuracy: 1.0000 - val_loss: 4.0760 - val_accuracy: 0.6897\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0037 - accuracy: 1.0000 - val_loss: 4.1891 - val_accuracy: 0.6897\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.2572 - val_accuracy: 0.6897\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.3372 - val_accuracy: 0.6552\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0043 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.4345 - val_accuracy: 0.6552\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.5397 - val_accuracy: 0.6552\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4502e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.6214 - val_accuracy: 0.6897\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6966e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.6715 - val_accuracy: 0.6552\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 146us/sample - loss: 9.8592e-04 - accuracy: 1.0000 - val_loss: 4.7259 - val_accuracy: 0.6552\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 146us/sample - loss: 9.4519e-04 - accuracy: 1.0000 - val_loss: 4.7643 - val_accuracy: 0.6552\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3112e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.0403e-04 - accuracy: 1.0000 - val_loss: 4.8244 - val_accuracy: 0.6552\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.2418e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 8.1227e-04 - accuracy: 1.0000 - val_loss: 4.9066 - val_accuracy: 0.6897\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9436e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 7.1610e-04 - accuracy: 1.0000 - val_loss: 4.9660 - val_accuracy: 0.6897\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 155us/sample - loss: 6.7258e-04 - accuracy: 1.0000 - val_loss: 5.0242 - val_accuracy: 0.6897\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5157e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 6.4892e-04 - accuracy: 1.0000 - val_loss: 5.0726 - val_accuracy: 0.6552\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.9103e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.1144e-04 - accuracy: 1.0000 - val_loss: 5.0889 - val_accuracy: 0.6552\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 137us/sample - loss: 5.3893e-04 - accuracy: 1.0000 - val_loss: 5.1326 - val_accuracy: 0.6552\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7190e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.1226e-04 - accuracy: 1.0000 - val_loss: 5.1877 - val_accuracy: 0.6552\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4687e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.6495e-04 - accuracy: 1.0000 - val_loss: 5.2425 - val_accuracy: 0.6897\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4750e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.3398e-04 - accuracy: 1.0000 - val_loss: 5.2863 - val_accuracy: 0.6897\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6919e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.1780e-04 - accuracy: 1.0000 - val_loss: 5.3375 - val_accuracy: 0.6897\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6660e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.8787e-04 - accuracy: 1.0000 - val_loss: 5.3760 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7910e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.5454e-04 - accuracy: 1.0000 - val_loss: 5.4089 - val_accuracy: 0.6897\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0667e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.5038e-04 - accuracy: 1.0000 - val_loss: 5.4418 - val_accuracy: 0.6897\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0008e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.3432e-04 - accuracy: 1.0000 - val_loss: 5.4845 - val_accuracy: 0.6897\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4610e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 3.0571e-04 - accuracy: 1.0000 - val_loss: 5.5237 - val_accuracy: 0.6897\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6366e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.8936e-04 - accuracy: 1.0000 - val_loss: 5.5624 - val_accuracy: 0.6897\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3314e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.7824e-04 - accuracy: 1.0000 - val_loss: 5.5946 - val_accuracy: 0.6552\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3085e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.6651e-04 - accuracy: 1.0000 - val_loss: 5.6219 - val_accuracy: 0.6552\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9115e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.5890e-04 - accuracy: 1.0000 - val_loss: 5.6447 - val_accuracy: 0.6552\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1536e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.4254e-04 - accuracy: 1.0000 - val_loss: 5.6827 - val_accuracy: 0.6552\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0363e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 2.3008e-04 - accuracy: 1.0000 - val_loss: 5.7101 - val_accuracy: 0.6552\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.6241e-05 - accuracy: 1.00 - 0s 180us/sample - loss: 2.1870e-04 - accuracy: 1.0000 - val_loss: 5.7385 - val_accuracy: 0.6552\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5921e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 2.1070e-04 - accuracy: 1.0000 - val_loss: 5.7671 - val_accuracy: 0.6552\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3068e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.0115e-04 - accuracy: 1.0000 - val_loss: 5.7932 - val_accuracy: 0.6552\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7161e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.9732e-04 - accuracy: 1.0000 - val_loss: 5.8191 - val_accuracy: 0.6552\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2304e-04 - accuracy: 1.00 - 0s 159us/sample - loss: 1.8743e-04 - accuracy: 1.0000 - val_loss: 5.8449 - val_accuracy: 0.6552\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5619e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.8171e-04 - accuracy: 1.0000 - val_loss: 5.8768 - val_accuracy: 0.6552\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2642e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.7520e-04 - accuracy: 1.0000 - val_loss: 5.9010 - val_accuracy: 0.6552\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2392e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.6793e-04 - accuracy: 1.0000 - val_loss: 5.9244 - val_accuracy: 0.6552\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9844e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 1.6216e-04 - accuracy: 1.0000 - val_loss: 5.9487 - val_accuracy: 0.6552\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2839e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.5542e-04 - accuracy: 1.0000 - val_loss: 5.9714 - val_accuracy: 0.6552\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7540e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.4930e-04 - accuracy: 1.0000 - val_loss: 5.9916 - val_accuracy: 0.6552\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9679e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4684e-04 - accuracy: 1.0000 - val_loss: 6.0129 - val_accuracy: 0.6552\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4823e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.4072e-04 - accuracy: 1.0000 - val_loss: 6.0402 - val_accuracy: 0.6552\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9451e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 1.3604e-04 - accuracy: 1.0000 - val_loss: 6.0652 - val_accuracy: 0.6552\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5831e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 1.3213e-04 - accuracy: 1.0000 - val_loss: 6.0897 - val_accuracy: 0.6552\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9927e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 1.2856e-04 - accuracy: 1.0000 - val_loss: 6.1117 - val_accuracy: 0.6552\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0238e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.2553e-04 - accuracy: 1.0000 - val_loss: 6.1255 - val_accuracy: 0.6552\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1212e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.2002e-04 - accuracy: 1.0000 - val_loss: 6.1458 - val_accuracy: 0.6552\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4734e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1735e-04 - accuracy: 1.0000 - val_loss: 6.1685 - val_accuracy: 0.6552\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3426e-04 - accuracy: 1.00 - 0s 120us/sample - loss: 1.1363e-04 - accuracy: 1.0000 - val_loss: 6.1891 - val_accuracy: 0.6552\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0687e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.1014e-04 - accuracy: 1.0000 - val_loss: 6.2100 - val_accuracy: 0.6552\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4254e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0620e-04 - accuracy: 1.0000 - val_loss: 6.2320 - val_accuracy: 0.6552\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6193e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.0365e-04 - accuracy: 1.0000 - val_loss: 6.2519 - val_accuracy: 0.6552\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.5260e-05 - accuracy: 1.00 - 0s 112us/sample - loss: 1.0148e-04 - accuracy: 1.0000 - val_loss: 6.2726 - val_accuracy: 0.6552\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3806e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 9.8328e-05 - accuracy: 1.0000 - val_loss: 6.2927 - val_accuracy: 0.6552\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1028e-04 - accuracy: 1.00 - 0s 103us/sample - loss: 9.5656e-05 - accuracy: 1.0000 - val_loss: 6.3110 - val_accuracy: 0.6552\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6559e-04 - accuracy: 1.00 - 0s 112us/sample - loss: 9.3556e-05 - accuracy: 1.0000 - val_loss: 6.3262 - val_accuracy: 0.6552\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4754e-04 - accuracy: 1.00 - 0s 112us/sample - loss: 9.1492e-05 - accuracy: 1.0000 - val_loss: 6.3426 - val_accuracy: 0.6552\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2806e-04 - accuracy: 1.00 - 0s 111us/sample - loss: 8.9152e-05 - accuracy: 1.0000 - val_loss: 6.3619 - val_accuracy: 0.6552\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4145e-05 - accuracy: 1.00 - 0s 120us/sample - loss: 8.6098e-05 - accuracy: 1.0000 - val_loss: 6.3825 - val_accuracy: 0.6552\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0489e-05 - accuracy: 1.00 - 0s 121us/sample - loss: 8.4660e-05 - accuracy: 1.0000 - val_loss: 6.4039 - val_accuracy: 0.6552\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1360e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 8.2497e-05 - accuracy: 1.0000 - val_loss: 6.4220 - val_accuracy: 0.6552\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1361e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.0683e-05 - accuracy: 1.0000 - val_loss: 6.4375 - val_accuracy: 0.6552\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0329e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.8796e-05 - accuracy: 1.0000 - val_loss: 6.4547 - val_accuracy: 0.6552\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.7364e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.7159e-05 - accuracy: 1.0000 - val_loss: 6.4690 - val_accuracy: 0.6552\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9143e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.4968e-05 - accuracy: 1.0000 - val_loss: 6.4860 - val_accuracy: 0.6552\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3319e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 7.3835e-05 - accuracy: 1.0000 - val_loss: 6.5036 - val_accuracy: 0.6552\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2885e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 7.1813e-05 - accuracy: 1.0000 - val_loss: 6.5198 - val_accuracy: 0.6552\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.8885e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 7.0409e-05 - accuracy: 1.0000 - val_loss: 6.5346 - val_accuracy: 0.6552\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1970e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 6.8835e-05 - accuracy: 1.0000 - val_loss: 6.5514 - val_accuracy: 0.6552\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5068e-05 - accuracy: 1.00 - 0s 137us/sample - loss: 6.7407e-05 - accuracy: 1.0000 - val_loss: 6.5672 - val_accuracy: 0.6552\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4565e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 6.6105e-05 - accuracy: 1.0000 - val_loss: 6.5810 - val_accuracy: 0.6552\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5176e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 6.4604e-05 - accuracy: 1.0000 - val_loss: 6.5960 - val_accuracy: 0.6552\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9614e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.3402e-05 - accuracy: 1.0000 - val_loss: 6.6097 - val_accuracy: 0.6552\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3256e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.2325e-05 - accuracy: 1.0000 - val_loss: 6.6244 - val_accuracy: 0.6552\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0148e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.0975e-05 - accuracy: 1.0000 - val_loss: 6.6414 - val_accuracy: 0.6552\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.0633e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.0490e-05 - accuracy: 1.0000 - val_loss: 6.6596 - val_accuracy: 0.6552\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5172e-05 - accuracy: 1.00 - 0s 181us/sample - loss: 5.8631e-05 - accuracy: 1.0000 - val_loss: 6.6726 - val_accuracy: 0.6552\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.5505e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.7579e-05 - accuracy: 1.0000 - val_loss: 6.6869 - val_accuracy: 0.6552\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7584e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.6712e-05 - accuracy: 1.0000 - val_loss: 6.7014 - val_accuracy: 0.6552\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6757e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.5637e-05 - accuracy: 1.0000 - val_loss: 6.7160 - val_accuracy: 0.6552\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3057e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 5.4521e-05 - accuracy: 1.0000 - val_loss: 6.7286 - val_accuracy: 0.6552\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9538e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.3814e-05 - accuracy: 1.0000 - val_loss: 6.7407 - val_accuracy: 0.6552\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9344e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 5.2919e-05 - accuracy: 1.0000 - val_loss: 6.7539 - val_accuracy: 0.6552\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8456e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.2071e-05 - accuracy: 1.0000 - val_loss: 6.7711 - val_accuracy: 0.6552\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.6890e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 5.0850e-05 - accuracy: 1.0000 - val_loss: 6.7834 - val_accuracy: 0.6552\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0946e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.0019e-05 - accuracy: 1.0000 - val_loss: 6.7965 - val_accuracy: 0.6552\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2991e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 4.9149e-05 - accuracy: 1.0000 - val_loss: 6.8087 - val_accuracy: 0.6552\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.1847e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.8215e-05 - accuracy: 1.0000 - val_loss: 6.8233 - val_accuracy: 0.6552\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9494e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.7465e-05 - accuracy: 1.0000 - val_loss: 6.8361 - val_accuracy: 0.6552\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6425e-05 - accuracy: 1.00 - 0s 189us/sample - loss: 4.6726e-05 - accuracy: 1.0000 - val_loss: 6.8505 - val_accuracy: 0.6552\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4560e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 4.6059e-05 - accuracy: 1.0000 - val_loss: 6.8628 - val_accuracy: 0.6552\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7748e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.5201e-05 - accuracy: 1.0000 - val_loss: 6.8745 - val_accuracy: 0.6552\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2606e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.4504e-05 - accuracy: 1.0000 - val_loss: 6.8872 - val_accuracy: 0.6552\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.8966e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 4.3801e-05 - accuracy: 1.0000 - val_loss: 6.8991 - val_accuracy: 0.6552\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7457e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.3033e-05 - accuracy: 1.0000 - val_loss: 6.9122 - val_accuracy: 0.6552\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1423e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.2355e-05 - accuracy: 1.0000 - val_loss: 6.9240 - val_accuracy: 0.6552\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.3666e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.1728e-05 - accuracy: 1.0000 - val_loss: 6.9391 - val_accuracy: 0.6552\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0446e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.1040e-05 - accuracy: 1.0000 - val_loss: 6.9526 - val_accuracy: 0.6552\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9804e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.0534e-05 - accuracy: 1.0000 - val_loss: 6.9651 - val_accuracy: 0.6552\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9094e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.9903e-05 - accuracy: 1.0000 - val_loss: 6.9763 - val_accuracy: 0.6552\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7398e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 3.9272e-05 - accuracy: 1.0000 - val_loss: 6.9871 - val_accuracy: 0.6552\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 3.3894e-05 - accuracy: 1.00 - 0s 172us/sample - loss: 3.8666e-05 - accuracy: 1.0000 - val_loss: 6.9974 - val_accuracy: 0.6552\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4186e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.8263e-05 - accuracy: 1.0000 - val_loss: 7.0099 - val_accuracy: 0.6552\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9977e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.7743e-05 - accuracy: 1.0000 - val_loss: 7.0203 - val_accuracy: 0.6552\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4966e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.7045e-05 - accuracy: 1.0000 - val_loss: 7.0322 - val_accuracy: 0.6552\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8861e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.6588e-05 - accuracy: 1.0000 - val_loss: 7.0433 - val_accuracy: 0.6552\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9290e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.6097e-05 - accuracy: 1.0000 - val_loss: 7.0547 - val_accuracy: 0.6552\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2123e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.5605e-05 - accuracy: 1.0000 - val_loss: 7.0642 - val_accuracy: 0.6552\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4225e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.5162e-05 - accuracy: 1.0000 - val_loss: 7.0746 - val_accuracy: 0.6552\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3172e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.4668e-05 - accuracy: 1.0000 - val_loss: 7.0862 - val_accuracy: 0.6552\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2954e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.4266e-05 - accuracy: 1.0000 - val_loss: 7.0974 - val_accuracy: 0.6552\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4123e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.3788e-05 - accuracy: 1.0000 - val_loss: 7.1093 - val_accuracy: 0.6552\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1506e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.3383e-05 - accuracy: 1.0000 - val_loss: 7.1196 - val_accuracy: 0.6552\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9602e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.2905e-05 - accuracy: 1.0000 - val_loss: 7.1307 - val_accuracy: 0.6552\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6456e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.2459e-05 - accuracy: 1.0000 - val_loss: 7.1408 - val_accuracy: 0.6552\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6043e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.2149e-05 - accuracy: 1.0000 - val_loss: 7.1497 - val_accuracy: 0.6552\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5111e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.1796e-05 - accuracy: 1.0000 - val_loss: 7.1611 - val_accuracy: 0.6552\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3847e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.1426e-05 - accuracy: 1.0000 - val_loss: 7.1723 - val_accuracy: 0.6552\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6805e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.1025e-05 - accuracy: 1.0000 - val_loss: 7.1807 - val_accuracy: 0.6552\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3133e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 3.0543e-05 - accuracy: 1.0000 - val_loss: 7.1917 - val_accuracy: 0.6552\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4502e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.0209e-05 - accuracy: 1.0000 - val_loss: 7.2036 - val_accuracy: 0.6552\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4665e-05 - accuracy: 1.00 - 0s 137us/sample - loss: 2.9811e-05 - accuracy: 1.0000 - val_loss: 7.2138 - val_accuracy: 0.6552\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9382e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 2.9370e-05 - accuracy: 1.0000 - val_loss: 7.2239 - val_accuracy: 0.6552\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4023e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.9106e-05 - accuracy: 1.0000 - val_loss: 7.2334 - val_accuracy: 0.6552\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9338e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 2.8847e-05 - accuracy: 1.0000 - val_loss: 7.2426 - val_accuracy: 0.6552\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 1s - loss: 0.6980 - accuracy: 0.31 - 1s 6ms/sample - loss: 0.6535 - accuracy: 0.5776 - val_loss: 0.6481 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6394 - accuracy: 0.65 - 0s 163us/sample - loss: 0.6279 - accuracy: 0.6638 - val_loss: 0.6383 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6011 - accuracy: 0.65 - 0s 146us/sample - loss: 0.6146 - accuracy: 0.6810 - val_loss: 0.6332 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6052 - accuracy: 0.65 - 0s 181us/sample - loss: 0.5940 - accuracy: 0.6810 - val_loss: 0.6124 - val_accuracy: 0.6207\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.71 - 0s 172us/sample - loss: 0.5761 - accuracy: 0.7155 - val_loss: 0.6215 - val_accuracy: 0.6552\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5226 - accuracy: 0.71 - 0s 163us/sample - loss: 0.5834 - accuracy: 0.7069 - val_loss: 0.6351 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4520 - accuracy: 0.75 - 0s 172us/sample - loss: 0.5225 - accuracy: 0.6810 - val_loss: 0.6401 - val_accuracy: 0.5862\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.81 - 0s 163us/sample - loss: 0.5147 - accuracy: 0.7414 - val_loss: 0.6262 - val_accuracy: 0.6207\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4065 - accuracy: 0.84 - 0s 163us/sample - loss: 0.4693 - accuracy: 0.7759 - val_loss: 0.6651 - val_accuracy: 0.5862\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3955 - accuracy: 0.81 - 0s 163us/sample - loss: 0.4740 - accuracy: 0.7931 - val_loss: 0.6431 - val_accuracy: 0.6552\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3464 - accuracy: 0.84 - 0s 163us/sample - loss: 0.4233 - accuracy: 0.8103 - val_loss: 0.6616 - val_accuracy: 0.5862\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4924 - accuracy: 0.78 - 0s 138us/sample - loss: 0.4162 - accuracy: 0.8017 - val_loss: 0.6310 - val_accuracy: 0.6897\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4001 - accuracy: 0.81 - 0s 146us/sample - loss: 0.3788 - accuracy: 0.8534 - val_loss: 0.7175 - val_accuracy: 0.6552\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.93 - 0s 155us/sample - loss: 0.3584 - accuracy: 0.8621 - val_loss: 0.7503 - val_accuracy: 0.6897\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.90 - 0s 163us/sample - loss: 0.3652 - accuracy: 0.8017 - val_loss: 0.7164 - val_accuracy: 0.6897\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2516 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3257 - accuracy: 0.8707 - val_loss: 0.8163 - val_accuracy: 0.5517\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2426 - accuracy: 0.87 - 0s 155us/sample - loss: 0.2866 - accuracy: 0.9138 - val_loss: 0.9607 - val_accuracy: 0.5862\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2431 - accuracy: 0.90 - 0s 155us/sample - loss: 0.2488 - accuracy: 0.9138 - val_loss: 1.0163 - val_accuracy: 0.6897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2868 - accuracy: 0.93 - 0s 146us/sample - loss: 0.2372 - accuracy: 0.8966 - val_loss: 1.2185 - val_accuracy: 0.6207\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2158 - accuracy: 0.9224 - val_loss: 1.3621 - val_accuracy: 0.5862\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1731 - accuracy: 0.96 - 0s 301us/sample - loss: 0.2075 - accuracy: 0.9397 - val_loss: 1.1128 - val_accuracy: 0.6897\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2872 - accuracy: 0.84 - 0s 146us/sample - loss: 0.2378 - accuracy: 0.8966 - val_loss: 1.6000 - val_accuracy: 0.5517\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2850 - accuracy: 0.78 - 0s 146us/sample - loss: 0.2069 - accuracy: 0.8879 - val_loss: 1.7033 - val_accuracy: 0.6552\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3319 - accuracy: 0.87 - 0s 146us/sample - loss: 0.2106 - accuracy: 0.9138 - val_loss: 1.7006 - val_accuracy: 0.6207\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1406 - accuracy: 0.9569 - val_loss: 1.7769 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1352 - accuracy: 0.9397 - val_loss: 2.4263 - val_accuracy: 0.5517\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1514 - accuracy: 0.9224 - val_loss: 2.0593 - val_accuracy: 0.6552\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0969 - accuracy: 0.9741 - val_loss: 2.1108 - val_accuracy: 0.6552\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2056 - accuracy: 0.90 - 0s 146us/sample - loss: 0.1264 - accuracy: 0.9397 - val_loss: 2.7745 - val_accuracy: 0.5862\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1380 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1410 - accuracy: 0.9224 - val_loss: 2.3393 - val_accuracy: 0.6552\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1638 - accuracy: 0.9310 - val_loss: 3.5570 - val_accuracy: 0.6207\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1510 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2521 - accuracy: 0.8621 - val_loss: 3.0829 - val_accuracy: 0.6207\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2274 - accuracy: 0.9052 - val_loss: 3.6796 - val_accuracy: 0.5517\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3029 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2251 - accuracy: 0.9052 - val_loss: 1.7259 - val_accuracy: 0.5862\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.87 - 0s 138us/sample - loss: 0.2916 - accuracy: 0.8707 - val_loss: 0.9831 - val_accuracy: 0.5862\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.96 - 0s 146us/sample - loss: 0.2216 - accuracy: 0.8966 - val_loss: 1.8645 - val_accuracy: 0.6552\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2837 - accuracy: 0.84 - 0s 155us/sample - loss: 0.2248 - accuracy: 0.9224 - val_loss: 2.2127 - val_accuracy: 0.5517\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1415 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1809 - accuracy: 0.9138 - val_loss: 2.1027 - val_accuracy: 0.5517\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.96 - 0s 155us/sample - loss: 0.1174 - accuracy: 0.9569 - val_loss: 2.0585 - val_accuracy: 0.5517\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.93 - 0s 168us/sample - loss: 0.0898 - accuracy: 0.9569 - val_loss: 2.1971 - val_accuracy: 0.5862\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0494 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0654 - accuracy: 0.9741 - val_loss: 2.4779 - val_accuracy: 0.6552\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0483 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0492 - accuracy: 0.9914 - val_loss: 2.8164 - val_accuracy: 0.6207\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.93 - 0s 138us/sample - loss: 0.0637 - accuracy: 0.9655 - val_loss: 2.9077 - val_accuracy: 0.6207\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0591 - accuracy: 0.9741 - val_loss: 2.9493 - val_accuracy: 0.5862\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0405 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0401 - accuracy: 0.9914 - val_loss: 3.0424 - val_accuracy: 0.6207\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0266 - accuracy: 1.0000 - val_loss: 3.4655 - val_accuracy: 0.6207\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0297 - accuracy: 0.9914 - val_loss: 3.5150 - val_accuracy: 0.6207\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0243 - accuracy: 0.9914 - val_loss: 3.8863 - val_accuracy: 0.6207\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0083 - accuracy: 1.00 - 0s 144us/sample - loss: 0.0279 - accuracy: 0.9828 - val_loss: 3.6982 - val_accuracy: 0.6897\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0172 - accuracy: 1.0000 - val_loss: 3.8340 - val_accuracy: 0.6552\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0064 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0079 - accuracy: 1.0000 - val_loss: 4.1430 - val_accuracy: 0.6207\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0101 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.0790 - val_accuracy: 0.6552\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 4.2950 - val_accuracy: 0.6207\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.3731 - val_accuracy: 0.6207\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.3244 - val_accuracy: 0.6897\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0029 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.4102 - val_accuracy: 0.6552\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.5654 - val_accuracy: 0.6207\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.6868 - val_accuracy: 0.6207\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.6883 - val_accuracy: 0.6207\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 198us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.7050 - val_accuracy: 0.6207\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0010 - accuracy: 1.0000 - val_loss: 4.7353 - val_accuracy: 0.6207\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.4354e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 8.8601e-04 - accuracy: 1.0000 - val_loss: 4.8119 - val_accuracy: 0.6207\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5065e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.9662e-04 - accuracy: 1.0000 - val_loss: 4.8916 - val_accuracy: 0.6207\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 146us/sample - loss: 8.0991e-04 - accuracy: 1.0000 - val_loss: 4.8954 - val_accuracy: 0.6207\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.00 - 0s 146us/sample - loss: 7.7003e-04 - accuracy: 1.0000 - val_loss: 4.9068 - val_accuracy: 0.6207\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7725e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 7.0866e-04 - accuracy: 1.0000 - val_loss: 4.9615 - val_accuracy: 0.6207\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3910e-04 - accuracy: 1.00 - 0s 149us/sample - loss: 6.4674e-04 - accuracy: 1.0000 - val_loss: 5.0107 - val_accuracy: 0.6207\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4349e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 6.1199e-04 - accuracy: 1.0000 - val_loss: 5.0628 - val_accuracy: 0.6207\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.00 - 0s 138us/sample - loss: 5.8948e-04 - accuracy: 1.0000 - val_loss: 5.0841 - val_accuracy: 0.6207\n",
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9555e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.5117e-04 - accuracy: 1.0000 - val_loss: 5.1019 - val_accuracy: 0.6207\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8564e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 5.2076e-04 - accuracy: 1.0000 - val_loss: 5.1064 - val_accuracy: 0.6207\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6180e-04 - accuracy: 1.00 - 0s 140us/sample - loss: 5.1510e-04 - accuracy: 1.0000 - val_loss: 5.1174 - val_accuracy: 0.6207\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3238e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.8720e-04 - accuracy: 1.0000 - val_loss: 5.1584 - val_accuracy: 0.6207\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0298e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.6149e-04 - accuracy: 1.0000 - val_loss: 5.1923 - val_accuracy: 0.6207\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4601e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 4.4484e-04 - accuracy: 1.0000 - val_loss: 5.2173 - val_accuracy: 0.6207\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7197e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 4.2954e-04 - accuracy: 1.0000 - val_loss: 5.2376 - val_accuracy: 0.6207\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6384e-04 - accuracy: 1.00 - 0s 142us/sample - loss: 4.1177e-04 - accuracy: 1.0000 - val_loss: 5.2503 - val_accuracy: 0.6207\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6711e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.0272e-04 - accuracy: 1.0000 - val_loss: 5.2710 - val_accuracy: 0.6207\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0175e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.8103e-04 - accuracy: 1.0000 - val_loss: 5.2861 - val_accuracy: 0.6207\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0630e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.7113e-04 - accuracy: 1.0000 - val_loss: 5.3125 - val_accuracy: 0.6207\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8879e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 3.5856e-04 - accuracy: 1.0000 - val_loss: 5.3327 - val_accuracy: 0.6207\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.1242e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.4393e-04 - accuracy: 1.0000 - val_loss: 5.3669 - val_accuracy: 0.6207\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3986e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.3306e-04 - accuracy: 1.0000 - val_loss: 5.3942 - val_accuracy: 0.6207\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5111e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 3.2920e-04 - accuracy: 1.0000 - val_loss: 5.4032 - val_accuracy: 0.6207\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7617e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.1057e-04 - accuracy: 1.0000 - val_loss: 5.4216 - val_accuracy: 0.6207\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1868e-04 - accuracy: 1.00 - 0s 151us/sample - loss: 3.0347e-04 - accuracy: 1.0000 - val_loss: 5.4428 - val_accuracy: 0.6207\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8935e-04 - accuracy: 1.00 - 0s 137us/sample - loss: 2.9322e-04 - accuracy: 1.0000 - val_loss: 5.4611 - val_accuracy: 0.6207\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8444e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.8543e-04 - accuracy: 1.0000 - val_loss: 5.4752 - val_accuracy: 0.6207\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3825e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.7449e-04 - accuracy: 1.0000 - val_loss: 5.4870 - val_accuracy: 0.6207\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9387e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.7017e-04 - accuracy: 1.0000 - val_loss: 5.4944 - val_accuracy: 0.6207\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6693e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.6178e-04 - accuracy: 1.0000 - val_loss: 5.5157 - val_accuracy: 0.6207\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0713e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.5731e-04 - accuracy: 1.0000 - val_loss: 5.5548 - val_accuracy: 0.6207\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3703e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.4621e-04 - accuracy: 1.0000 - val_loss: 5.5680 - val_accuracy: 0.6207\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6435e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.3764e-04 - accuracy: 1.0000 - val_loss: 5.5854 - val_accuracy: 0.6207\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7058e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.3172e-04 - accuracy: 1.0000 - val_loss: 5.5906 - val_accuracy: 0.6207\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6797e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.2390e-04 - accuracy: 1.0000 - val_loss: 5.6050 - val_accuracy: 0.6207\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7095e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.1978e-04 - accuracy: 1.0000 - val_loss: 5.6116 - val_accuracy: 0.6207\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2402e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.1160e-04 - accuracy: 1.0000 - val_loss: 5.6267 - val_accuracy: 0.6207\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1448e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 2.0673e-04 - accuracy: 1.0000 - val_loss: 5.6458 - val_accuracy: 0.6207\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2411e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.0072e-04 - accuracy: 1.0000 - val_loss: 5.6644 - val_accuracy: 0.6207\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2916e-04 - accuracy: 1.00 - 0s 181us/sample - loss: 1.9588e-04 - accuracy: 1.0000 - val_loss: 5.6894 - val_accuracy: 0.6207\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4915e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.9165e-04 - accuracy: 1.0000 - val_loss: 5.7061 - val_accuracy: 0.6207\n",
      "Epoch 103/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 1.6090e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.8691e-04 - accuracy: 1.0000 - val_loss: 5.7221 - val_accuracy: 0.6207\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0923e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.8181e-04 - accuracy: 1.0000 - val_loss: 5.7286 - val_accuracy: 0.6207\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9832e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7792e-04 - accuracy: 1.0000 - val_loss: 5.7340 - val_accuracy: 0.6207\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.1234e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.7299e-04 - accuracy: 1.0000 - val_loss: 5.7460 - val_accuracy: 0.6207\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4770e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.6868e-04 - accuracy: 1.0000 - val_loss: 5.7666 - val_accuracy: 0.6207\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8580e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.6503e-04 - accuracy: 1.0000 - val_loss: 5.7815 - val_accuracy: 0.6207\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0462e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.6345e-04 - accuracy: 1.0000 - val_loss: 5.8035 - val_accuracy: 0.6207\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9565e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5813e-04 - accuracy: 1.0000 - val_loss: 5.8131 - val_accuracy: 0.6207\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5477e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.5486e-04 - accuracy: 1.0000 - val_loss: 5.8188 - val_accuracy: 0.6207\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3848e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.5122e-04 - accuracy: 1.0000 - val_loss: 5.8235 - val_accuracy: 0.6207\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0347e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4885e-04 - accuracy: 1.0000 - val_loss: 5.8426 - val_accuracy: 0.6207\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9899e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.4376e-04 - accuracy: 1.0000 - val_loss: 5.8538 - val_accuracy: 0.6207\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5623e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4113e-04 - accuracy: 1.0000 - val_loss: 5.8647 - val_accuracy: 0.6207\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2708e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3889e-04 - accuracy: 1.0000 - val_loss: 5.8799 - val_accuracy: 0.6207\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6860e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3543e-04 - accuracy: 1.0000 - val_loss: 5.8910 - val_accuracy: 0.6207\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9795e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.3262e-04 - accuracy: 1.0000 - val_loss: 5.9043 - val_accuracy: 0.6207\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1343e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2977e-04 - accuracy: 1.0000 - val_loss: 5.9139 - val_accuracy: 0.6207\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3408e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3101e-04 - accuracy: 1.0000 - val_loss: 5.9136 - val_accuracy: 0.6207\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3047e-04 - accuracy: 1.00 - 0s 172us/sample - loss: 1.2593e-04 - accuracy: 1.0000 - val_loss: 5.9317 - val_accuracy: 0.6207\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4308e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.2228e-04 - accuracy: 1.0000 - val_loss: 5.9498 - val_accuracy: 0.6207\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.9762e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.2256e-04 - accuracy: 1.0000 - val_loss: 5.9685 - val_accuracy: 0.6207\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6704e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1694e-04 - accuracy: 1.0000 - val_loss: 5.9718 - val_accuracy: 0.6207\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2412e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1484e-04 - accuracy: 1.0000 - val_loss: 5.9759 - val_accuracy: 0.6207\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1310e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.1268e-04 - accuracy: 1.0000 - val_loss: 5.9874 - val_accuracy: 0.6207\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0581e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1102e-04 - accuracy: 1.0000 - val_loss: 5.9977 - val_accuracy: 0.6207\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4926e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0914e-04 - accuracy: 1.0000 - val_loss: 6.0117 - val_accuracy: 0.6207\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7622e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0642e-04 - accuracy: 1.0000 - val_loss: 6.0233 - val_accuracy: 0.6207\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.6440e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0490e-04 - accuracy: 1.0000 - val_loss: 6.0396 - val_accuracy: 0.6207\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4734e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.0314e-04 - accuracy: 1.0000 - val_loss: 6.0529 - val_accuracy: 0.6207\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1157e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0054e-04 - accuracy: 1.0000 - val_loss: 6.0597 - val_accuracy: 0.6207\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6418e-05 - accuracy: 1.00 - 0s 160us/sample - loss: 9.8505e-05 - accuracy: 1.0000 - val_loss: 6.0610 - val_accuracy: 0.6207\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2911e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.9225e-05 - accuracy: 1.0000 - val_loss: 6.0645 - val_accuracy: 0.6207\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4542e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 9.6083e-05 - accuracy: 1.0000 - val_loss: 6.0847 - val_accuracy: 0.6207\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0144e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.3281e-05 - accuracy: 1.0000 - val_loss: 6.1028 - val_accuracy: 0.6207\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0201e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 9.2291e-05 - accuracy: 1.0000 - val_loss: 6.1190 - val_accuracy: 0.6207\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.9549e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 9.0719e-05 - accuracy: 1.0000 - val_loss: 6.1270 - val_accuracy: 0.6207\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5947e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.8900e-05 - accuracy: 1.0000 - val_loss: 6.1370 - val_accuracy: 0.6207\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6580e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.7438e-05 - accuracy: 1.0000 - val_loss: 6.1455 - val_accuracy: 0.6207\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5875e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.5970e-05 - accuracy: 1.0000 - val_loss: 6.1568 - val_accuracy: 0.6207\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2713e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.4676e-05 - accuracy: 1.0000 - val_loss: 6.1663 - val_accuracy: 0.6207\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5123e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.3891e-05 - accuracy: 1.0000 - val_loss: 6.1661 - val_accuracy: 0.6207\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3644e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.2147e-05 - accuracy: 1.0000 - val_loss: 6.1720 - val_accuracy: 0.6207\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9247e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.0992e-05 - accuracy: 1.0000 - val_loss: 6.1840 - val_accuracy: 0.6207\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8769e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 7.9302e-05 - accuracy: 1.0000 - val_loss: 6.1972 - val_accuracy: 0.6207\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1536e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.7864e-05 - accuracy: 1.0000 - val_loss: 6.2097 - val_accuracy: 0.6207\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.5383e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.6626e-05 - accuracy: 1.0000 - val_loss: 6.2189 - val_accuracy: 0.6207\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6477e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.5263e-05 - accuracy: 1.0000 - val_loss: 6.2300 - val_accuracy: 0.6207\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1755e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 7.4194e-05 - accuracy: 1.0000 - val_loss: 6.2406 - val_accuracy: 0.6207\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7483e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.3087e-05 - accuracy: 1.0000 - val_loss: 6.2493 - val_accuracy: 0.6207\n",
      "Epoch 152/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9314e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.1973e-05 - accuracy: 1.0000 - val_loss: 6.2584 - val_accuracy: 0.6207\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.3524e-05 - accuracy: 1.00 - 0s 140us/sample - loss: 7.1077e-05 - accuracy: 1.0000 - val_loss: 6.2670 - val_accuracy: 0.6207\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4162e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 7.0002e-05 - accuracy: 1.0000 - val_loss: 6.2735 - val_accuracy: 0.6207\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1194e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 6.8654e-05 - accuracy: 1.0000 - val_loss: 6.2801 - val_accuracy: 0.6207\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0966e-05 - accuracy: 1.00 - 0s 137us/sample - loss: 6.7785e-05 - accuracy: 1.0000 - val_loss: 6.2860 - val_accuracy: 0.6207\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3012e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.6834e-05 - accuracy: 1.0000 - val_loss: 6.2957 - val_accuracy: 0.6207\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7501e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.5884e-05 - accuracy: 1.0000 - val_loss: 6.3022 - val_accuracy: 0.6207\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1796e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 6.4768e-05 - accuracy: 1.0000 - val_loss: 6.3105 - val_accuracy: 0.6207\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.0754e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.4041e-05 - accuracy: 1.0000 - val_loss: 6.3246 - val_accuracy: 0.6207\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1940e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 6.2932e-05 - accuracy: 1.0000 - val_loss: 6.3344 - val_accuracy: 0.6207\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5342e-05 - accuracy: 1.00 - 0s 133us/sample - loss: 6.2335e-05 - accuracy: 1.0000 - val_loss: 6.3394 - val_accuracy: 0.6207\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0996e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.1040e-05 - accuracy: 1.0000 - val_loss: 6.3491 - val_accuracy: 0.6207\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.8686e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 6.0201e-05 - accuracy: 1.0000 - val_loss: 6.3593 - val_accuracy: 0.6207\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2262e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.9302e-05 - accuracy: 1.0000 - val_loss: 6.3681 - val_accuracy: 0.6207\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.8188e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.8497e-05 - accuracy: 1.0000 - val_loss: 6.3769 - val_accuracy: 0.6207\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.8693e-05 - accuracy: 1.00 - 0s 141us/sample - loss: 5.7420e-05 - accuracy: 1.0000 - val_loss: 6.3856 - val_accuracy: 0.6207\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6377e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.7271e-05 - accuracy: 1.0000 - val_loss: 6.3916 - val_accuracy: 0.6207\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.5249e-05 - accuracy: 1.00 - 0s 181us/sample - loss: 5.6132e-05 - accuracy: 1.0000 - val_loss: 6.4034 - val_accuracy: 0.6207\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8212e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.5435e-05 - accuracy: 1.0000 - val_loss: 6.4108 - val_accuracy: 0.6207\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7602e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.4424e-05 - accuracy: 1.0000 - val_loss: 6.4160 - val_accuracy: 0.6207\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6806e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 5.3870e-05 - accuracy: 1.0000 - val_loss: 6.4191 - val_accuracy: 0.6207\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6696e-05 - accuracy: 1.00 - 0s 181us/sample - loss: 5.3099e-05 - accuracy: 1.0000 - val_loss: 6.4291 - val_accuracy: 0.6207\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7535e-05 - accuracy: 1.00 - 0s 301us/sample - loss: 5.2346e-05 - accuracy: 1.0000 - val_loss: 6.4369 - val_accuracy: 0.6207\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.7981e-05 - accuracy: 1.00 - 0s 542us/sample - loss: 5.1580e-05 - accuracy: 1.0000 - val_loss: 6.4460 - val_accuracy: 0.6207\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4579e-05 - accuracy: 1.00 - 0s 490us/sample - loss: 5.1328e-05 - accuracy: 1.0000 - val_loss: 6.4595 - val_accuracy: 0.6207\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9704e-05 - accuracy: 1.00 - 0s 533us/sample - loss: 5.0342e-05 - accuracy: 1.0000 - val_loss: 6.4676 - val_accuracy: 0.6207\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6721e-05 - accuracy: 1.00 - 0s 490us/sample - loss: 4.9449e-05 - accuracy: 1.0000 - val_loss: 6.4709 - val_accuracy: 0.6207\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5151e-05 - accuracy: 1.00 - 0s 516us/sample - loss: 4.9168e-05 - accuracy: 1.0000 - val_loss: 6.4717 - val_accuracy: 0.6207\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3478e-05 - accuracy: 1.00 - 0s 481us/sample - loss: 4.8418e-05 - accuracy: 1.0000 - val_loss: 6.4791 - val_accuracy: 0.6207\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8569e-05 - accuracy: 1.00 - 0s 481us/sample - loss: 4.7795e-05 - accuracy: 1.0000 - val_loss: 6.4853 - val_accuracy: 0.6207\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0935e-05 - accuracy: 1.00 - 0s 507us/sample - loss: 4.7137e-05 - accuracy: 1.0000 - val_loss: 6.4969 - val_accuracy: 0.6207\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6795e-05 - accuracy: 1.00 - 0s 481us/sample - loss: 4.6433e-05 - accuracy: 1.0000 - val_loss: 6.5070 - val_accuracy: 0.6207\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1809e-05 - accuracy: 1.00 - 0s 481us/sample - loss: 4.5974e-05 - accuracy: 1.0000 - val_loss: 6.5194 - val_accuracy: 0.6207\n",
      "Epoch 185/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 5.5937e-05 - accuracy: 1.00 - 0s 464us/sample - loss: 4.5377e-05 - accuracy: 1.0000 - val_loss: 6.5263 - val_accuracy: 0.6207\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.8125e-05 - accuracy: 1.00 - 0s 473us/sample - loss: 4.4795e-05 - accuracy: 1.0000 - val_loss: 6.5338 - val_accuracy: 0.6207\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4140e-05 - accuracy: 1.00 - 0s 524us/sample - loss: 4.4333e-05 - accuracy: 1.0000 - val_loss: 6.5409 - val_accuracy: 0.6207\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7805e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 4.3699e-05 - accuracy: 1.0000 - val_loss: 6.5474 - val_accuracy: 0.6207\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1866e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.2977e-05 - accuracy: 1.0000 - val_loss: 6.5517 - val_accuracy: 0.6207\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6119e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.2650e-05 - accuracy: 1.0000 - val_loss: 6.5537 - val_accuracy: 0.6207\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9607e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.2116e-05 - accuracy: 1.0000 - val_loss: 6.5581 - val_accuracy: 0.6207\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1245e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.1779e-05 - accuracy: 1.0000 - val_loss: 6.5695 - val_accuracy: 0.6207\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9602e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.1067e-05 - accuracy: 1.0000 - val_loss: 6.5752 - val_accuracy: 0.6207\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9835e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.0535e-05 - accuracy: 1.0000 - val_loss: 6.5830 - val_accuracy: 0.6207\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6584e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.0015e-05 - accuracy: 1.0000 - val_loss: 6.5905 - val_accuracy: 0.6207\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3692e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.9566e-05 - accuracy: 1.0000 - val_loss: 6.5988 - val_accuracy: 0.6207\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7365e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.9210e-05 - accuracy: 1.0000 - val_loss: 6.6071 - val_accuracy: 0.6207\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3889e-05 - accuracy: 1.00 - 0s 142us/sample - loss: 3.8643e-05 - accuracy: 1.0000 - val_loss: 6.6124 - val_accuracy: 0.6207\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2105e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.8159e-05 - accuracy: 1.0000 - val_loss: 6.6209 - val_accuracy: 0.6207\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4857e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 3.7759e-05 - accuracy: 1.0000 - val_loss: 6.6267 - val_accuracy: 0.6207\n",
      "Train on 116 samples, validate on 29 samples\n",
      "Epoch 1/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.7083 - accuracy: 0.34 - 0s 3ms/sample - loss: 0.6663 - accuracy: 0.5776 - val_loss: 0.6452 - val_accuracy: 0.6552\n",
      "Epoch 2/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5413 - accuracy: 0.75 - 0s 172us/sample - loss: 0.6371 - accuracy: 0.6638 - val_loss: 0.6379 - val_accuracy: 0.6552\n",
      "Epoch 3/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6143 - accuracy: 0.68 - 0s 163us/sample - loss: 0.6311 - accuracy: 0.6897 - val_loss: 0.6385 - val_accuracy: 0.6552\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.6306 - accuracy: 0.65 - 0s 163us/sample - loss: 0.5942 - accuracy: 0.6897 - val_loss: 0.6370 - val_accuracy: 0.6552\n",
      "Epoch 5/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5314 - accuracy: 0.75 - 0s 164us/sample - loss: 0.6060 - accuracy: 0.6897 - val_loss: 0.6101 - val_accuracy: 0.6207\n",
      "Epoch 6/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5264 - accuracy: 0.75 - 0s 155us/sample - loss: 0.5746 - accuracy: 0.6897 - val_loss: 0.5991 - val_accuracy: 0.6552\n",
      "Epoch 7/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.75 - 0s 163us/sample - loss: 0.5270 - accuracy: 0.7586 - val_loss: 0.6172 - val_accuracy: 0.6552\n",
      "Epoch 8/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.5915 - accuracy: 0.75 - 0s 163us/sample - loss: 0.5399 - accuracy: 0.7328 - val_loss: 0.6060 - val_accuracy: 0.5517\n",
      "Epoch 9/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4712 - accuracy: 0.78 - 0s 163us/sample - loss: 0.4950 - accuracy: 0.7500 - val_loss: 0.5995 - val_accuracy: 0.6207\n",
      "Epoch 10/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.81 - 0s 155us/sample - loss: 0.4818 - accuracy: 0.7500 - val_loss: 0.6146 - val_accuracy: 0.6897\n",
      "Epoch 11/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4518 - accuracy: 0.81 - 0s 163us/sample - loss: 0.4440 - accuracy: 0.8017 - val_loss: 0.6405 - val_accuracy: 0.5862\n",
      "Epoch 12/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3989 - accuracy: 0.84 - 0s 146us/sample - loss: 0.4002 - accuracy: 0.8276 - val_loss: 0.6671 - val_accuracy: 0.6552\n",
      "Epoch 13/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.84 - 0s 155us/sample - loss: 0.3704 - accuracy: 0.8621 - val_loss: 0.7497 - val_accuracy: 0.6207\n",
      "Epoch 14/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2684 - accuracy: 0.90 - 0s 155us/sample - loss: 0.3628 - accuracy: 0.8448 - val_loss: 0.7946 - val_accuracy: 0.5862\n",
      "Epoch 15/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3278 - accuracy: 0.87 - 0s 155us/sample - loss: 0.3505 - accuracy: 0.8534 - val_loss: 0.7856 - val_accuracy: 0.6897\n",
      "Epoch 16/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3813 - accuracy: 0.75 - 0s 146us/sample - loss: 0.3314 - accuracy: 0.8276 - val_loss: 0.8125 - val_accuracy: 0.6552\n",
      "Epoch 17/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1398 - accuracy: 1.00 - 0s 146us/sample - loss: 0.3154 - accuracy: 0.8793 - val_loss: 0.8672 - val_accuracy: 0.6207\n",
      "Epoch 18/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2767 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2704 - accuracy: 0.9224 - val_loss: 0.8801 - val_accuracy: 0.6552\n",
      "Epoch 19/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.90 - 0s 154us/sample - loss: 0.2384 - accuracy: 0.9310 - val_loss: 0.9817 - val_accuracy: 0.6207\n",
      "Epoch 20/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.93 - 0s 155us/sample - loss: 0.2182 - accuracy: 0.9310 - val_loss: 0.9628 - val_accuracy: 0.7241\n",
      "Epoch 21/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3614 - accuracy: 0.87 - 0s 138us/sample - loss: 0.1932 - accuracy: 0.9310 - val_loss: 0.9478 - val_accuracy: 0.7241\n",
      "Epoch 22/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1956 - accuracy: 0.9310 - val_loss: 1.1291 - val_accuracy: 0.5862\n",
      "Epoch 23/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.96 - 0s 138us/sample - loss: 0.2014 - accuracy: 0.9483 - val_loss: 1.2320 - val_accuracy: 0.6552\n",
      "Epoch 24/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.4069 - accuracy: 0.84 - 0s 146us/sample - loss: 0.1935 - accuracy: 0.9397 - val_loss: 1.2493 - val_accuracy: 0.5862\n",
      "Epoch 25/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1986 - accuracy: 0.90 - 0s 155us/sample - loss: 0.1636 - accuracy: 0.9397 - val_loss: 1.1740 - val_accuracy: 0.6552\n",
      "Epoch 26/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1464 - accuracy: 0.93 - 0s 146us/sample - loss: 0.1963 - accuracy: 0.9052 - val_loss: 1.1731 - val_accuracy: 0.6897\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.96 - 0s 146us/sample - loss: 0.1635 - accuracy: 0.9310 - val_loss: 1.1774 - val_accuracy: 0.6897\n",
      "Epoch 28/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1398 - accuracy: 0.96 - 0s 172us/sample - loss: 0.1307 - accuracy: 0.9655 - val_loss: 1.1567 - val_accuracy: 0.6207\n",
      "Epoch 29/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.96 - 0s 163us/sample - loss: 0.0938 - accuracy: 0.9655 - val_loss: 1.2754 - val_accuracy: 0.6552\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0871 - accuracy: 0.96 - 0s 155us/sample - loss: 0.0795 - accuracy: 0.9828 - val_loss: 1.3620 - val_accuracy: 0.6897\n",
      "Epoch 31/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0379 - accuracy: 1.00 - 0s 155us/sample - loss: 0.1200 - accuracy: 0.9569 - val_loss: 2.4280 - val_accuracy: 0.5172\n",
      "Epoch 32/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1901 - accuracy: 0.96 - 0s 146us/sample - loss: 0.4556 - accuracy: 0.8707 - val_loss: 1.4115 - val_accuracy: 0.6897\n",
      "Epoch 33/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3238 - accuracy: 0.90 - 0s 146us/sample - loss: 0.2207 - accuracy: 0.9138 - val_loss: 1.1766 - val_accuracy: 0.6207\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.3112 - accuracy: 0.81 - 0s 138us/sample - loss: 0.2315 - accuracy: 0.8879 - val_loss: 0.8433 - val_accuracy: 0.6897\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1161 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1909 - accuracy: 0.9138 - val_loss: 1.3384 - val_accuracy: 0.6552\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1776 - accuracy: 0.93 - 0s 155us/sample - loss: 0.1184 - accuracy: 0.9741 - val_loss: 1.6582 - val_accuracy: 0.6897\n",
      "Epoch 37/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 1.00 - 0s 146us/sample - loss: 0.1219 - accuracy: 0.9483 - val_loss: 1.9908 - val_accuracy: 0.6552\n",
      "Epoch 38/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.96 - 0s 138us/sample - loss: 0.1273 - accuracy: 0.9483 - val_loss: 1.7355 - val_accuracy: 0.6552\n",
      "Epoch 39/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.96 - 0s 138us/sample - loss: 0.0880 - accuracy: 0.9741 - val_loss: 1.5623 - val_accuracy: 0.6897\n",
      "Epoch 40/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0904 - accuracy: 0.9655 - val_loss: 1.8340 - val_accuracy: 0.5517\n",
      "Epoch 41/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0672 - accuracy: 0.9828 - val_loss: 1.8328 - val_accuracy: 0.5862\n",
      "Epoch 42/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0563 - accuracy: 0.9741 - val_loss: 1.9529 - val_accuracy: 0.5862\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.96 - 0s 146us/sample - loss: 0.0414 - accuracy: 0.9741 - val_loss: 2.0155 - val_accuracy: 0.5517\n",
      "Epoch 44/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0729 - accuracy: 0.96 - 0s 129us/sample - loss: 0.0411 - accuracy: 0.9914 - val_loss: 2.0232 - val_accuracy: 0.5172\n",
      "Epoch 45/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0311 - accuracy: 0.9914 - val_loss: 2.2570 - val_accuracy: 0.5862\n",
      "Epoch 46/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0199 - accuracy: 1.0000 - val_loss: 2.2386 - val_accuracy: 0.5172\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.5172 - val_accuracy: 0.5862\n",
      "Epoch 48/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0106 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.6340 - val_accuracy: 0.5517\n",
      "Epoch 49/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0071 - accuracy: 1.00 - 0s 137us/sample - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.8100 - val_accuracy: 0.5517\n",
      "Epoch 50/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.9843 - val_accuracy: 0.5517\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 1.00 - 0s 151us/sample - loss: 0.0052 - accuracy: 1.0000 - val_loss: 3.0928 - val_accuracy: 0.5517\n",
      "Epoch 52/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0028 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.2244 - val_accuracy: 0.5172\n",
      "Epoch 53/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.3567 - val_accuracy: 0.5172\n",
      "Epoch 54/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 1.00 - 0s 138us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.4631 - val_accuracy: 0.5172\n",
      "Epoch 55/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.2183e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.4924 - val_accuracy: 0.5172\n",
      "Epoch 56/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 1.00 - 0s 150us/sample - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.5664 - val_accuracy: 0.5172\n",
      "Epoch 57/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6309e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.6820 - val_accuracy: 0.5172\n",
      "Epoch 58/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.8092 - val_accuracy: 0.5172\n",
      "Epoch 59/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.00 - 0s 155us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.8658 - val_accuracy: 0.5172\n",
      "Epoch 60/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 1.00 - 0s 146us/sample - loss: 9.3034e-04 - accuracy: 1.0000 - val_loss: 3.9007 - val_accuracy: 0.5172\n",
      "Epoch 61/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.3649e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 8.2470e-04 - accuracy: 1.0000 - val_loss: 3.9757 - val_accuracy: 0.5172\n",
      "Epoch 62/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5857e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 7.0473e-04 - accuracy: 1.0000 - val_loss: 4.0806 - val_accuracy: 0.5172\n",
      "Epoch 63/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6065e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 6.2033e-04 - accuracy: 1.0000 - val_loss: 4.1681 - val_accuracy: 0.5172\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2775e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 5.3517e-04 - accuracy: 1.0000 - val_loss: 4.2031 - val_accuracy: 0.5172\n",
      "Epoch 65/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9604e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 4.7055e-04 - accuracy: 1.0000 - val_loss: 4.2582 - val_accuracy: 0.5172\n",
      "Epoch 66/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5571e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 4.2565e-04 - accuracy: 1.0000 - val_loss: 4.3212 - val_accuracy: 0.5172\n",
      "Epoch 67/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9038e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 3.8709e-04 - accuracy: 1.0000 - val_loss: 4.3775 - val_accuracy: 0.5172\n",
      "Epoch 68/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9162e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.5676e-04 - accuracy: 1.0000 - val_loss: 4.4194 - val_accuracy: 0.5172\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.6230e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 3.2704e-04 - accuracy: 1.0000 - val_loss: 4.4725 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9364e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.9922e-04 - accuracy: 1.0000 - val_loss: 4.5134 - val_accuracy: 0.5517\n",
      "Epoch 71/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3470e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.7872e-04 - accuracy: 1.0000 - val_loss: 4.5582 - val_accuracy: 0.5517\n",
      "Epoch 72/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1553e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.6051e-04 - accuracy: 1.0000 - val_loss: 4.5983 - val_accuracy: 0.5517\n",
      "Epoch 73/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.3373e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.4517e-04 - accuracy: 1.0000 - val_loss: 4.6417 - val_accuracy: 0.5517\n",
      "Epoch 74/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9192e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 2.2852e-04 - accuracy: 1.0000 - val_loss: 4.6817 - val_accuracy: 0.5517\n",
      "Epoch 75/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1920e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 2.1592e-04 - accuracy: 1.0000 - val_loss: 4.7198 - val_accuracy: 0.5517\n",
      "Epoch 76/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7025e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 2.0495e-04 - accuracy: 1.0000 - val_loss: 4.7465 - val_accuracy: 0.5517\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5710e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.9376e-04 - accuracy: 1.0000 - val_loss: 4.7765 - val_accuracy: 0.5517\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1860e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.8409e-04 - accuracy: 1.0000 - val_loss: 4.8041 - val_accuracy: 0.5517\n",
      "Epoch 79/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3490e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.7469e-04 - accuracy: 1.0000 - val_loss: 4.8336 - val_accuracy: 0.5517\n",
      "Epoch 80/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3667e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.6556e-04 - accuracy: 1.0000 - val_loss: 4.8681 - val_accuracy: 0.5517\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0459e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.5875e-04 - accuracy: 1.0000 - val_loss: 4.8985 - val_accuracy: 0.5517\n",
      "Epoch 82/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6966e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 1.5310e-04 - accuracy: 1.0000 - val_loss: 4.9226 - val_accuracy: 0.5517\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5962e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.4522e-04 - accuracy: 1.0000 - val_loss: 4.9493 - val_accuracy: 0.5517\n",
      "Epoch 84/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3859e-04 - accuracy: 1.00 - 0s 163us/sample - loss: 1.3877e-04 - accuracy: 1.0000 - val_loss: 4.9839 - val_accuracy: 0.5517\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7757e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.3345e-04 - accuracy: 1.0000 - val_loss: 5.0126 - val_accuracy: 0.5517\n",
      "Epoch 86/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6262e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2893e-04 - accuracy: 1.0000 - val_loss: 5.0364 - val_accuracy: 0.5517\n",
      "Epoch 87/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0351e-04 - accuracy: 1.00 - 0s 155us/sample - loss: 1.2329e-04 - accuracy: 1.0000 - val_loss: 5.0579 - val_accuracy: 0.5517\n",
      "Epoch 88/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4827e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 1.1856e-04 - accuracy: 1.0000 - val_loss: 5.0824 - val_accuracy: 0.5517\n",
      "Epoch 89/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.3509e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.1304e-04 - accuracy: 1.0000 - val_loss: 5.1020 - val_accuracy: 0.5517\n",
      "Epoch 90/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6469e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0981e-04 - accuracy: 1.0000 - val_loss: 5.1225 - val_accuracy: 0.5517\n",
      "Epoch 91/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.2072e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0546e-04 - accuracy: 1.0000 - val_loss: 5.1465 - val_accuracy: 0.5517\n",
      "Epoch 92/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3861e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.0105e-04 - accuracy: 1.0000 - val_loss: 5.1759 - val_accuracy: 0.5517\n",
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.7662e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 9.8764e-05 - accuracy: 1.0000 - val_loss: 5.2045 - val_accuracy: 0.5517\n",
      "Epoch 94/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1708e-04 - accuracy: 1.00 - 0s 129us/sample - loss: 9.4389e-05 - accuracy: 1.0000 - val_loss: 5.2232 - val_accuracy: 0.5517\n",
      "Epoch 95/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5716e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 9.1053e-05 - accuracy: 1.0000 - val_loss: 5.2398 - val_accuracy: 0.5517\n",
      "Epoch 96/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5440e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 8.8136e-05 - accuracy: 1.0000 - val_loss: 5.2582 - val_accuracy: 0.5517\n",
      "Epoch 97/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.8628e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 8.5405e-05 - accuracy: 1.0000 - val_loss: 5.2746 - val_accuracy: 0.5517\n",
      "Epoch 98/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5936e-04 - accuracy: 1.00 - 0s 146us/sample - loss: 8.3014e-05 - accuracy: 1.0000 - val_loss: 5.2973 - val_accuracy: 0.5517\n",
      "Epoch 99/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4694e-04 - accuracy: 1.00 - 0s 138us/sample - loss: 8.1061e-05 - accuracy: 1.0000 - val_loss: 5.3237 - val_accuracy: 0.5517\n",
      "Epoch 100/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6870e-05 - accuracy: 1.00 - 0s 133us/sample - loss: 7.8164e-05 - accuracy: 1.0000 - val_loss: 5.3450 - val_accuracy: 0.5517\n",
      "Epoch 101/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9966e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 7.5380e-05 - accuracy: 1.0000 - val_loss: 5.3557 - val_accuracy: 0.5517\n",
      "Epoch 102/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.2199e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 7.2802e-05 - accuracy: 1.0000 - val_loss: 5.3684 - val_accuracy: 0.5517\n",
      "Epoch 103/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.1444e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 7.1829e-05 - accuracy: 1.0000 - val_loss: 5.3818 - val_accuracy: 0.5517\n",
      "Epoch 104/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7681e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.9610e-05 - accuracy: 1.0000 - val_loss: 5.3987 - val_accuracy: 0.5517\n",
      "Epoch 105/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1601e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 6.7765e-05 - accuracy: 1.0000 - val_loss: 5.4191 - val_accuracy: 0.5517\n",
      "Epoch 106/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.0391e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.5397e-05 - accuracy: 1.0000 - val_loss: 5.4392 - val_accuracy: 0.5517\n",
      "Epoch 107/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2505e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 6.4073e-05 - accuracy: 1.0000 - val_loss: 5.4625 - val_accuracy: 0.5517\n",
      "Epoch 108/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.0437e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 6.1838e-05 - accuracy: 1.0000 - val_loss: 5.4793 - val_accuracy: 0.5517\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.2396e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 6.0127e-05 - accuracy: 1.0000 - val_loss: 5.4959 - val_accuracy: 0.5517\n",
      "Epoch 110/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5756e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.8546e-05 - accuracy: 1.0000 - val_loss: 5.5139 - val_accuracy: 0.5517\n",
      "Epoch 111/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.3557e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.7055e-05 - accuracy: 1.0000 - val_loss: 5.5275 - val_accuracy: 0.5517\n",
      "Epoch 112/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7143e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.5735e-05 - accuracy: 1.0000 - val_loss: 5.5476 - val_accuracy: 0.5517\n",
      "Epoch 113/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.4248e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 5.4137e-05 - accuracy: 1.0000 - val_loss: 5.5653 - val_accuracy: 0.5517\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.2173e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 5.2575e-05 - accuracy: 1.0000 - val_loss: 5.5838 - val_accuracy: 0.5517\n",
      "Epoch 115/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2439e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 5.1625e-05 - accuracy: 1.0000 - val_loss: 5.6039 - val_accuracy: 0.5517\n",
      "Epoch 116/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6749e-05 - accuracy: 1.00 - 0s 137us/sample - loss: 5.0393e-05 - accuracy: 1.0000 - val_loss: 5.6183 - val_accuracy: 0.5517\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2243e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.9162e-05 - accuracy: 1.0000 - val_loss: 5.6296 - val_accuracy: 0.5517\n",
      "Epoch 118/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 9.7070e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 4.8116e-05 - accuracy: 1.0000 - val_loss: 5.6425 - val_accuracy: 0.5517\n",
      "Epoch 119/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9197e-05 - accuracy: 1.00 - 0s 128us/sample - loss: 4.6818e-05 - accuracy: 1.0000 - val_loss: 5.6558 - val_accuracy: 0.5517\n",
      "Epoch 120/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.0459e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 4.5681e-05 - accuracy: 1.0000 - val_loss: 5.6670 - val_accuracy: 0.5517\n",
      "Epoch 121/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9001e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.4932e-05 - accuracy: 1.0000 - val_loss: 5.6812 - val_accuracy: 0.5517\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2753e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.3983e-05 - accuracy: 1.0000 - val_loss: 5.6991 - val_accuracy: 0.5517\n",
      "Epoch 123/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.7736e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 4.2951e-05 - accuracy: 1.0000 - val_loss: 5.7121 - val_accuracy: 0.5517\n",
      "Epoch 124/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.6104e-05 - accuracy: 1.00 - 0s 133us/sample - loss: 4.2040e-05 - accuracy: 1.0000 - val_loss: 5.7239 - val_accuracy: 0.5517\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.5133e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 4.1227e-05 - accuracy: 1.0000 - val_loss: 5.7331 - val_accuracy: 0.5517\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.7879e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 4.0350e-05 - accuracy: 1.0000 - val_loss: 5.7450 - val_accuracy: 0.5517\n",
      "Epoch 127/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.4936e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.9707e-05 - accuracy: 1.0000 - val_loss: 5.7554 - val_accuracy: 0.5517\n",
      "Epoch 128/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.9751e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.8975e-05 - accuracy: 1.0000 - val_loss: 5.7705 - val_accuracy: 0.5517\n",
      "Epoch 129/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4028e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.8025e-05 - accuracy: 1.0000 - val_loss: 5.7819 - val_accuracy: 0.5517\n",
      "Epoch 130/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0012e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.7337e-05 - accuracy: 1.0000 - val_loss: 5.7955 - val_accuracy: 0.5517\n",
      "Epoch 131/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4900e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.6683e-05 - accuracy: 1.0000 - val_loss: 5.8113 - val_accuracy: 0.5517\n",
      "Epoch 132/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.8045e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.5964e-05 - accuracy: 1.0000 - val_loss: 5.8235 - val_accuracy: 0.5517\n",
      "Epoch 133/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.2867e-05 - accuracy: 1.00 - 0s 215us/sample - loss: 3.5166e-05 - accuracy: 1.0000 - val_loss: 5.8362 - val_accuracy: 0.5517\n",
      "Epoch 134/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0083e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 3.4476e-05 - accuracy: 1.0000 - val_loss: 5.8490 - val_accuracy: 0.5517\n",
      "Epoch 135/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4916e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.3971e-05 - accuracy: 1.0000 - val_loss: 5.8623 - val_accuracy: 0.5517\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.3559e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.3422e-05 - accuracy: 1.0000 - val_loss: 5.8720 - val_accuracy: 0.5517\n",
      "Epoch 137/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4797e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.2778e-05 - accuracy: 1.0000 - val_loss: 5.8806 - val_accuracy: 0.5517\n",
      "Epoch 138/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2338e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 3.2134e-05 - accuracy: 1.0000 - val_loss: 5.8915 - val_accuracy: 0.5517\n",
      "Epoch 139/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3272e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.1521e-05 - accuracy: 1.0000 - val_loss: 5.9014 - val_accuracy: 0.5517\n",
      "Epoch 140/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9303e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 3.1044e-05 - accuracy: 1.0000 - val_loss: 5.9110 - val_accuracy: 0.5517\n",
      "Epoch 141/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.5014e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 3.0460e-05 - accuracy: 1.0000 - val_loss: 5.9223 - val_accuracy: 0.5517\n",
      "Epoch 142/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7497e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 2.9914e-05 - accuracy: 1.0000 - val_loss: 5.9318 - val_accuracy: 0.5517\n",
      "Epoch 143/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.9408e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.9554e-05 - accuracy: 1.0000 - val_loss: 5.9476 - val_accuracy: 0.5517\n",
      "Epoch 144/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5750e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.8923e-05 - accuracy: 1.0000 - val_loss: 5.9605 - val_accuracy: 0.5517\n",
      "Epoch 145/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2317e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 2.8467e-05 - accuracy: 1.0000 - val_loss: 5.9722 - val_accuracy: 0.5517\n",
      "Epoch 146/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.6034e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 2.8011e-05 - accuracy: 1.0000 - val_loss: 5.9824 - val_accuracy: 0.5517\n",
      "Epoch 147/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9326e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 2.7513e-05 - accuracy: 1.0000 - val_loss: 5.9925 - val_accuracy: 0.5517\n",
      "Epoch 148/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7903e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.6991e-05 - accuracy: 1.0000 - val_loss: 6.0028 - val_accuracy: 0.5517\n",
      "Epoch 149/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1382e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 2.6656e-05 - accuracy: 1.0000 - val_loss: 6.0136 - val_accuracy: 0.5517\n",
      "Epoch 150/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4735e-05 - accuracy: 1.00 - 0s 198us/sample - loss: 2.6142e-05 - accuracy: 1.0000 - val_loss: 6.0240 - val_accuracy: 0.5517\n",
      "Epoch 151/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9217e-05 - accuracy: 1.00 - 0s 456us/sample - loss: 2.5706e-05 - accuracy: 1.0000 - val_loss: 6.0358 - val_accuracy: 0.5517\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - ETA: 0s - loss: 2.7520e-05 - accuracy: 1.00 - 0s 499us/sample - loss: 2.5350e-05 - accuracy: 1.0000 - val_loss: 6.0472 - val_accuracy: 0.5517\n",
      "Epoch 153/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0475e-05 - accuracy: 1.00 - 0s 473us/sample - loss: 2.4911e-05 - accuracy: 1.0000 - val_loss: 6.0569 - val_accuracy: 0.5517\n",
      "Epoch 154/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4110e-05 - accuracy: 1.00 - 0s 499us/sample - loss: 2.4507e-05 - accuracy: 1.0000 - val_loss: 6.0663 - val_accuracy: 0.5517\n",
      "Epoch 155/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9651e-05 - accuracy: 1.00 - 0s 464us/sample - loss: 2.4171e-05 - accuracy: 1.0000 - val_loss: 6.0752 - val_accuracy: 0.5517\n",
      "Epoch 156/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.2869e-05 - accuracy: 1.00 - 0s 490us/sample - loss: 2.3902e-05 - accuracy: 1.0000 - val_loss: 6.0855 - val_accuracy: 0.5517\n",
      "Epoch 157/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5667e-05 - accuracy: 1.00 - 0s 481us/sample - loss: 2.3443e-05 - accuracy: 1.0000 - val_loss: 6.0971 - val_accuracy: 0.5517\n",
      "Epoch 158/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3793e-05 - accuracy: 1.00 - 0s 481us/sample - loss: 2.3072e-05 - accuracy: 1.0000 - val_loss: 6.1082 - val_accuracy: 0.5517\n",
      "Epoch 159/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.1332e-05 - accuracy: 1.00 - 0s 522us/sample - loss: 2.2721e-05 - accuracy: 1.0000 - val_loss: 6.1183 - val_accuracy: 0.5517\n",
      "Epoch 160/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4465e-05 - accuracy: 1.00 - 0s 507us/sample - loss: 2.2383e-05 - accuracy: 1.0000 - val_loss: 6.1270 - val_accuracy: 0.5517\n",
      "Epoch 161/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0039e-05 - accuracy: 1.00 - 0s 490us/sample - loss: 2.2083e-05 - accuracy: 1.0000 - val_loss: 6.1336 - val_accuracy: 0.5517\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.5117e-06 - accuracy: 1.00 - 0s 507us/sample - loss: 2.1746e-05 - accuracy: 1.0000 - val_loss: 6.1409 - val_accuracy: 0.5517\n",
      "Epoch 163/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2422e-05 - accuracy: 1.00 - 0s 524us/sample - loss: 2.1459e-05 - accuracy: 1.0000 - val_loss: 6.1513 - val_accuracy: 0.5517\n",
      "Epoch 164/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6510e-05 - accuracy: 1.00 - 0s 258us/sample - loss: 2.1137e-05 - accuracy: 1.0000 - val_loss: 6.1610 - val_accuracy: 0.5517\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.1410e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.0885e-05 - accuracy: 1.0000 - val_loss: 6.1718 - val_accuracy: 0.5517\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.2945e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 2.0509e-05 - accuracy: 1.0000 - val_loss: 6.1845 - val_accuracy: 0.5517\n",
      "Epoch 167/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1664e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 2.0241e-05 - accuracy: 1.0000 - val_loss: 6.1961 - val_accuracy: 0.5517\n",
      "Epoch 168/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.7146e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 1.9906e-05 - accuracy: 1.0000 - val_loss: 6.2049 - val_accuracy: 0.5517\n",
      "Epoch 169/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4702e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.9702e-05 - accuracy: 1.0000 - val_loss: 6.2129 - val_accuracy: 0.5517\n",
      "Epoch 170/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3241e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.9385e-05 - accuracy: 1.0000 - val_loss: 6.2222 - val_accuracy: 0.5517\n",
      "Epoch 171/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.3006e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.9083e-05 - accuracy: 1.0000 - val_loss: 6.2318 - val_accuracy: 0.5517\n",
      "Epoch 172/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5097e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.8864e-05 - accuracy: 1.0000 - val_loss: 6.2412 - val_accuracy: 0.5517\n",
      "Epoch 173/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.5858e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.8588e-05 - accuracy: 1.0000 - val_loss: 6.2476 - val_accuracy: 0.5517\n",
      "Epoch 174/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.1879e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.8287e-05 - accuracy: 1.0000 - val_loss: 6.2551 - val_accuracy: 0.5517\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 6.9871e-06 - accuracy: 1.00 - 0s 155us/sample - loss: 1.8050e-05 - accuracy: 1.0000 - val_loss: 6.2624 - val_accuracy: 0.5517\n",
      "Epoch 176/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.4013e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7833e-05 - accuracy: 1.0000 - val_loss: 6.2712 - val_accuracy: 0.5517\n",
      "Epoch 177/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0030e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7564e-05 - accuracy: 1.0000 - val_loss: 6.2798 - val_accuracy: 0.5517\n",
      "Epoch 178/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.0617e-06 - accuracy: 1.00 - 0s 155us/sample - loss: 1.7322e-05 - accuracy: 1.0000 - val_loss: 6.2882 - val_accuracy: 0.5517\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.6985e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.7145e-05 - accuracy: 1.0000 - val_loss: 6.2972 - val_accuracy: 0.5517\n",
      "Epoch 180/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3181e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.6889e-05 - accuracy: 1.0000 - val_loss: 6.3061 - val_accuracy: 0.5517\n",
      "Epoch 181/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.0982e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.6651e-05 - accuracy: 1.0000 - val_loss: 6.3139 - val_accuracy: 0.5517\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9389e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.6469e-05 - accuracy: 1.0000 - val_loss: 6.3221 - val_accuracy: 0.5517\n",
      "Epoch 183/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8547e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.6245e-05 - accuracy: 1.0000 - val_loss: 6.3317 - val_accuracy: 0.5517\n",
      "Epoch 184/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7933e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.6032e-05 - accuracy: 1.0000 - val_loss: 6.3398 - val_accuracy: 0.5517\n",
      "Epoch 185/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.8126e-05 - accuracy: 1.00 - 0s 163us/sample - loss: 1.5808e-05 - accuracy: 1.0000 - val_loss: 6.3493 - val_accuracy: 0.5517\n",
      "Epoch 186/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7896e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.5614e-05 - accuracy: 1.0000 - val_loss: 6.3579 - val_accuracy: 0.5517\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4154e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.5433e-05 - accuracy: 1.0000 - val_loss: 6.3644 - val_accuracy: 0.5517\n",
      "Epoch 188/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9173e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.5246e-05 - accuracy: 1.0000 - val_loss: 6.3713 - val_accuracy: 0.5517\n",
      "Epoch 189/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.1963e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 1.5008e-05 - accuracy: 1.0000 - val_loss: 6.3802 - val_accuracy: 0.5517\n",
      "Epoch 190/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.6705e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4828e-05 - accuracy: 1.0000 - val_loss: 6.3890 - val_accuracy: 0.5517\n",
      "Epoch 191/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.4973e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4617e-05 - accuracy: 1.0000 - val_loss: 6.3988 - val_accuracy: 0.5517\n",
      "Epoch 192/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.9756e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.4414e-05 - accuracy: 1.0000 - val_loss: 6.4082 - val_accuracy: 0.5517\n",
      "Epoch 193/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4046e-05 - accuracy: 1.00 - 0s 155us/sample - loss: 1.4172e-05 - accuracy: 1.0000 - val_loss: 6.4181 - val_accuracy: 0.5517\n",
      "Epoch 194/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.9333e-06 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3942e-05 - accuracy: 1.0000 - val_loss: 6.4295 - val_accuracy: 0.5517\n",
      "Epoch 195/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.5009e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3732e-05 - accuracy: 1.0000 - val_loss: 6.4401 - val_accuracy: 0.5517\n",
      "Epoch 196/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.0317e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.3527e-05 - accuracy: 1.0000 - val_loss: 6.4492 - val_accuracy: 0.5517\n",
      "Epoch 197/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 4.0470e-06 - accuracy: 1.00 - 0s 138us/sample - loss: 1.3295e-05 - accuracy: 1.0000 - val_loss: 6.4571 - val_accuracy: 0.5517\n",
      "Epoch 198/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.9423e-05 - accuracy: 1.00 - 0s 138us/sample - loss: 1.3138e-05 - accuracy: 1.0000 - val_loss: 6.4674 - val_accuracy: 0.5517\n",
      "Epoch 199/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4361e-05 - accuracy: 1.00 - 0s 129us/sample - loss: 1.2934e-05 - accuracy: 1.0000 - val_loss: 6.4759 - val_accuracy: 0.5517\n",
      "Epoch 200/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4423e-05 - accuracy: 1.00 - 0s 146us/sample - loss: 1.2702e-05 - accuracy: 1.0000 - val_loss: 6.4882 - val_accuracy: 0.5517\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 98ce83addb53b84070acff99f09f6335</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7155171632766724</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 108</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 108</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 60</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 76</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LOG_DIR=f\"last_year\\{int(time.time())}\"\n",
    "\n",
    "tuner_last= RandomSearch(\n",
    "    build_model_last,\n",
    "    objective=kt.Objective(\"val_accuracy\",direction='max'),\n",
    "    max_trials=4,\n",
    "    executions_per_trial=4,\n",
    "    directory=LOG_DIR\n",
    ")\n",
    "\n",
    "earlyStopping =EarlyStopping(monitor='loss', patience=50, verbose=0, mode='min')\n",
    "#mcp_save = ModelCheckpoint('mp.hdf5', save_best_only=True, monitor='loss', mode='min')\n",
    "#reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=7, verbose=1,min_delta=0.01, mode='min')\n",
    "\n",
    "tuner_last.search(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_test,y_test),\n",
    "    epochs=200,\n",
    "    callbacks=[earlyStopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_units': 154, 'n_layers': 2, 'dense_0_units': 48, 'dense_1_units': 120, 'dense_2_units': 72}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Results summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Results in last_year\\1584346833\\untitled_project</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Showing 10 best trials</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Objective(name='val_accuracy', direction='max')</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: f317fb9284e38c0636dc1f74ae3e2bf4</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7758620977401733</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 48</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 120</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 72</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 154</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: b9708bd61a5649dc81467b11ff68a50d</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.767241358757019</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 108</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 84</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 84</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 115</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 1</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 54dc66a7b8cd993fa7e4f96d7b399349</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.732758641242981</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 60</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 24</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 24</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 115</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 3</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: 98ce83addb53b84070acff99f09f6335</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.7155171632766724</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_0_units: 108</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-dense_1_units: 108</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-dense_2_units: 60</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-input_units: 76</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-n_layers: 2</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(tuner_last.get_best_hyperparameters()[0].values)\n",
    "\n",
    "print(tuner_last.results_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.7236842105263157  Accuracy: 0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "best_model_last=tuner_last.get_best_models()[0]\n",
    "\n",
    "y_pred=best_model_last.predict(X_test)\n",
    "y_pred[y_pred<0.5]=0\n",
    "y_pred[y_pred>0.5]=1\n",
    "auc_nn_last=metrics.roc_auc_score(y_test,y_pred)\n",
    "acc_nn_last=metrics.accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(\"AUC:\",auc_nn_last,\" Accuracy:\",acc_nn_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deep Neural Network_AUC</th>\n",
       "      <th>Deep Neural Network_ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1 years before</th>\n",
       "      <td>0.673684</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 years before</th>\n",
       "      <td>0.797368</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last year</th>\n",
       "      <td>0.723684</td>\n",
       "      <td>0.793103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Deep Neural Network_AUC  Deep Neural Network_ACC\n",
       "1 years before                 0.673684                 0.758621\n",
       "2 years before                 0.797368                 0.827586\n",
       "last year                      0.723684                 0.793103"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={'Deep Neural Network_AUC':[auc_nn,auc_nn2,auc_nn_last],\n",
    "     'Deep Neural Network_ACC':[acc_nn,acc_nn2,acc_nn_last]}\n",
    "\n",
    "results=pd.DataFrame(data,index=['1 years before','2 years before','last year'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
